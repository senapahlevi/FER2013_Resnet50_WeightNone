{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER2013_Resnet50_weightnone_seed1_fixTrainTestVal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-Qn1jsBTIBl0b7myLQxqa8WjCcfbamqM",
      "authorship_tag": "ABX9TyOwpgFRBsGefNDA6u6EtjaK"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b86nukQOxN7l"
      },
      "source": [
        "Resnet-50 From Scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p8gxtGy0TWP",
        "outputId": "f9fbfbdb-7032-4dc5-e0cf-ed7ce4be00b1"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "inputFolder = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth' \n",
        "for root, directories, filenames in os.walk(inputFolder): \n",
        "    for filename in filenames: print(os.path.join(root,filename))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Best_Model_resnet50Scracth1again.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe4.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth1again.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50ScracthSGD1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50AUGScracthadam3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD1try2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD4.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50oriSGD1st.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50SGD5stori.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editSGD5st.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editAdamst120epochBS128.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editAdamst120epochBS128_1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editAdamst120epochBS128+aug:vf_2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50oriAdamst120epochBS128_aug1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50oriAdamst120epochBS128_noaug1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_noAug_adam1_shuffalse1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_seed_Aug_adam1_shuffalse1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50oriScracth_sena2.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsiscWIMBDX2",
        "outputId": "bdfa4c17-2cbf-4d01-d676-06ec0dc897b0"
      },
      "source": [
        "%cd /content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "wLMSe510xNCJ",
        "outputId": "3da9f6f5-cb75-4f61-d978-1e7de9a074fc"
      },
      "source": [
        "#Create a directory to save our generated models.dasdas\n",
        "\n",
        "#os.mkdir(\"./modelscracth\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-cf55f19f3613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#os.mkdir(\"./modelscracth\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ls' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_kluusLxM1B",
        "outputId": "4a03057c-90ac-4cea-ef54-aebfa4c2372a"
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:400: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfUSF_tAxNMP"
      },
      "source": [
        "#Define the identity block helper function.\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "   \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VdYtzhn1F0I"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path \n",
        "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b',padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd-O8ZMx1GAW"
      },
      "source": [
        "def ResNet50(input_shape = (48,48,1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    #X = ZeroPadding2D((1, 1))(X_input)\n",
        "    X = X_input\n",
        "    # Stage 1\n",
        "\n",
        "    X = Conv2D(8, (3, 3), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # removed maxpool\n",
        "    #X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='c')\n",
        "\n",
        "\n",
        "    # Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [64,64,256], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL . \n",
        "    X = AveragePooling2D((2,2), name='avg_pool')(X)\n",
        "    \n",
        "    # output layerds\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(512, activation = 'relu', name='fc1024' , kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GKsSwtp-GuL"
      },
      "source": [
        "\"\"\"def ResNet50ori(input_shape = (48, 48, 1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns: dsdsf\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50ori')\n",
        "\n",
        "    return model\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oWTDXlyBHM2"
      },
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        " \n",
        "dataset_path = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv'\n",
        "image_size=(48,48)\n",
        "#batch_size = 64\n",
        "\n",
        "def load_fer2013():\n",
        "    data = pd.read_csv(dataset_path)\n",
        "    data = (data[data['pixels'].notnull()])\n",
        "    pixels = data['pixels'].tolist()\n",
        "    width, height = 48, 48\n",
        "    faces = []\n",
        "    for pixel_sequence in pixels:\n",
        "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "        face = np.asarray(face).reshape(width, height)\n",
        "        face = cv2.resize(face.astype('uint8'),image_size)\n",
        "        faces.append(face.astype('float32'))\n",
        "    faces = np.asarray(faces)\n",
        "    faces = np.expand_dims(faces, -1)\n",
        "    emotions = (data['emotion'])#.values\n",
        "    return faces, emotions\n",
        " \n",
        "def preprocess_input(x, v2=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if v2:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x\n",
        " \n",
        "faces, emotions = load_fer2013()\n",
        "faces = preprocess_input(faces)\n",
        "#xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
        "#Data Augumentation\n",
        "\"\"\"data_generator = ImageDataGenerator(\n",
        "                        rotation_range=10,\n",
        "                        shear_range = 10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True,\n",
        "                        )\"\"\"\n",
        "#\n",
        "data_generator = ImageDataGenerator( )\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWLhavr-rSF5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "895f7f85-9930-46ca-c552-cbb571846a4e"
      },
      "source": [
        "\"\"\"\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.1,)\n",
        "x_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1,)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nxtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.1,)\\nx_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1,)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "RGhnYFXgaqL9",
        "outputId": "0e60da2f-3a44-4d06-910b-2e0f2fa4191a"
      },
      "source": [
        "\"\"\"print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (y_train.shape)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'print (\"validasi\",x_val.shape)\\nprint (y_val.shape)\\nprint (\"test\",xtest.shape)\\nprint (ytest.shape)\\nprint (\"train\",xtrain.shape)\\nprint (y_train.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rDS3hqhDSteM",
        "outputId": "00ea5408-c5f1-4247-f420-1468a72696a4"
      },
      "source": [
        "train_ratio = 0.80\n",
        "validation_ratio = 0.10\n",
        "test_ratio = 0.10\n",
        "\n",
        "# train is now 75% of the entire data set\n",
        "# the _junk suffix means that we drop that variable completely # the _junk suffix means that we drop that variable completely\n",
        "#x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=1 - train_ratio,random_state=42)\n",
        "\n",
        "# test is now 10% of the initial data set\n",
        "# validation is now 15% of the initial data set\n",
        "#x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "x_val, xtest, y_val, ytest = train_test_split(xtest, ytest, test_size=test_ratio/(test_ratio + validation_ratio), random_state=42) \n",
        "\n",
        "print(xtrain, x_val, xtest)\n",
        "\n",
        "\"\"\"X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2\"\"\""
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[-0.96862745]\n",
            "   [-0.96862745]\n",
            "   [-0.96862745]\n",
            "   ...\n",
            "   [-0.77254903]\n",
            "   [-0.7490196 ]\n",
            "   [-0.75686276]]\n",
            "\n",
            "  [[-0.92156863]\n",
            "   [-0.92941177]\n",
            "   [-0.9529412 ]\n",
            "   ...\n",
            "   [-0.02745098]\n",
            "   [ 0.05882359]\n",
            "   [ 0.05882359]]\n",
            "\n",
            "  [[-0.92941177]\n",
            "   [-0.92941177]\n",
            "   [-0.94509804]\n",
            "   ...\n",
            "   [-0.06666666]\n",
            "   [ 0.00392163]\n",
            "   [ 0.02745104]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.08235294]\n",
            "   [-0.06666666]\n",
            "   [-0.00392157]\n",
            "   ...\n",
            "   [-0.94509804]\n",
            "   [-0.96862745]\n",
            "   [-0.96862745]]\n",
            "\n",
            "  [[-0.88235295]\n",
            "   [-0.90588236]\n",
            "   [-0.8352941 ]\n",
            "   ...\n",
            "   [-0.9764706 ]\n",
            "   [-0.9843137 ]\n",
            "   [-0.9764706 ]]\n",
            "\n",
            "  [[-0.99215686]\n",
            "   [-0.99215686]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.9764706 ]\n",
            "   [-0.9764706 ]\n",
            "   [-0.9764706 ]]]\n",
            "\n",
            "\n",
            " [[[-0.7647059 ]\n",
            "   [-0.7490196 ]\n",
            "   [-0.6784314 ]\n",
            "   ...\n",
            "   [ 0.427451  ]\n",
            "   [ 0.27058828]\n",
            "   [ 0.22352946]]\n",
            "\n",
            "  [[-0.8117647 ]\n",
            "   [-0.70980394]\n",
            "   [-0.75686276]\n",
            "   ...\n",
            "   [ 0.41960788]\n",
            "   [ 0.254902  ]\n",
            "   [ 0.18431377]]\n",
            "\n",
            "  [[-0.77254903]\n",
            "   [-0.75686276]\n",
            "   [-0.8352941 ]\n",
            "   ...\n",
            "   [ 0.4666667 ]\n",
            "   [ 0.254902  ]\n",
            "   [ 0.1686275 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.34901965]\n",
            "   [ 0.36470592]\n",
            "   [-0.05098039]\n",
            "   ...\n",
            "   [-0.01176471]\n",
            "   [-0.12941176]\n",
            "   [-0.0745098 ]]\n",
            "\n",
            "  [[ 0.33333337]\n",
            "   [ 0.33333337]\n",
            "   [-0.21568626]\n",
            "   ...\n",
            "   [-0.06666666]\n",
            "   [-0.06666666]\n",
            "   [-0.10588235]]\n",
            "\n",
            "  [[ 0.36470592]\n",
            "   [ 0.27843142]\n",
            "   [-0.26274508]\n",
            "   ...\n",
            "   [-0.15294117]\n",
            "   [-0.09019607]\n",
            "   [-0.0745098 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.96862745]\n",
            "   [ 0.92156863]\n",
            "   [ 0.62352943]\n",
            "   ...\n",
            "   [-0.38823527]\n",
            "   [-0.32549018]\n",
            "   [-0.26274508]]\n",
            "\n",
            "  [[ 0.9529412 ]\n",
            "   [ 0.6627451 ]\n",
            "   [ 0.10588241]\n",
            "   ...\n",
            "   [-0.40392154]\n",
            "   [-0.34117645]\n",
            "   [-0.2862745 ]]\n",
            "\n",
            "  [[ 0.78039217]\n",
            "   [ 0.24705887]\n",
            "   [-0.19215685]\n",
            "   ...\n",
            "   [-0.5294118 ]\n",
            "   [-0.41176468]\n",
            "   [-0.34117645]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.28627455]\n",
            "   [ 0.2941177 ]\n",
            "   [ 0.3176471 ]\n",
            "   ...\n",
            "   [-0.35686272]\n",
            "   [-0.73333335]\n",
            "   [-0.96862745]]\n",
            "\n",
            "  [[ 0.34901965]\n",
            "   [ 0.27058828]\n",
            "   [ 0.28627455]\n",
            "   ...\n",
            "   [-0.41960782]\n",
            "   [-0.8980392 ]\n",
            "   [-0.94509804]]\n",
            "\n",
            "  [[ 0.3411765 ]\n",
            "   [ 0.26274514]\n",
            "   [ 0.26274514]\n",
            "   ...\n",
            "   [-0.5137255 ]\n",
            "   [-0.9843137 ]\n",
            "   [-0.9137255 ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.23921567]\n",
            "   [-0.27058822]\n",
            "   [-0.52156866]\n",
            "   ...\n",
            "   [ 0.16078436]\n",
            "   [ 0.03529418]\n",
            "   [ 0.01176476]]\n",
            "\n",
            "  [[-0.16862744]\n",
            "   [-0.30196077]\n",
            "   [-0.4823529 ]\n",
            "   ...\n",
            "   [ 0.254902  ]\n",
            "   [ 0.05098045]\n",
            "   [ 0.03529418]]\n",
            "\n",
            "  [[-0.38039213]\n",
            "   [-0.3098039 ]\n",
            "   [-0.4588235 ]\n",
            "   ...\n",
            "   [ 0.30980396]\n",
            "   [ 0.14509809]\n",
            "   [ 0.02745104]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.81960785]\n",
            "   [-0.9607843 ]\n",
            "   [-0.9607843 ]\n",
            "   ...\n",
            "   [-0.47450978]\n",
            "   [-0.15294117]\n",
            "   [ 0.45882356]]\n",
            "\n",
            "  [[-0.7882353 ]\n",
            "   [-0.92156863]\n",
            "   [-0.96862745]\n",
            "   ...\n",
            "   [-0.4352941 ]\n",
            "   [-0.19999999]\n",
            "   [ 0.4431373 ]]\n",
            "\n",
            "  [[-0.8901961 ]\n",
            "   [-0.88235295]\n",
            "   [-0.96862745]\n",
            "   ...\n",
            "   [-0.35686272]\n",
            "   [-0.16862744]\n",
            "   [ 0.27058828]]]\n",
            "\n",
            "\n",
            " [[[ 0.99215686]\n",
            "   [ 0.7882353 ]\n",
            "   [ 0.69411767]\n",
            "   ...\n",
            "   [ 0.37254906]\n",
            "   [ 0.27843142]\n",
            "   [ 0.24705887]]\n",
            "\n",
            "  [[ 0.92156863]\n",
            "   [ 0.6862745 ]\n",
            "   [ 0.6784314 ]\n",
            "   ...\n",
            "   [ 0.33333337]\n",
            "   [ 0.30196083]\n",
            "   [ 0.20000005]]\n",
            "\n",
            "  [[ 0.8117647 ]\n",
            "   [ 0.6313726 ]\n",
            "   [ 0.6392157 ]\n",
            "   ...\n",
            "   [ 0.27843142]\n",
            "   [ 0.35686278]\n",
            "   [ 0.16078436]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.77254903]\n",
            "   [ 0.64705884]\n",
            "   [ 0.7019608 ]\n",
            "   ...\n",
            "   [ 0.15294123]\n",
            "   [ 0.5137255 ]\n",
            "   [ 0.6       ]]\n",
            "\n",
            "  [[ 0.6784314 ]\n",
            "   [ 0.6784314 ]\n",
            "   [ 0.654902  ]\n",
            "   ...\n",
            "   [ 0.39607847]\n",
            "   [ 0.52156866]\n",
            "   [ 0.6156863 ]]\n",
            "\n",
            "  [[ 0.7254902 ]\n",
            "   [ 0.64705884]\n",
            "   [ 0.70980394]\n",
            "   ...\n",
            "   [ 0.4901961 ]\n",
            "   [ 0.70980394]\n",
            "   [ 0.75686276]]]\n",
            "\n",
            "\n",
            " [[[-0.06666666]\n",
            "   [-0.20784312]\n",
            "   [-0.85882354]\n",
            "   ...\n",
            "   [-0.99215686]\n",
            "   [-0.99215686]\n",
            "   [-0.9843137 ]]\n",
            "\n",
            "  [[-0.03529412]\n",
            "   [-0.5764706 ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.9843137 ]\n",
            "   [-0.9607843 ]\n",
            "   [-0.9843137 ]]\n",
            "\n",
            "  [[-0.26274508]\n",
            "   [-0.88235295]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-1.        ]\n",
            "   [-0.9607843 ]\n",
            "   [-0.99215686]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]]\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]]\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]]]] [[[[ 0.427451  ]\n",
            "   [ 0.36470592]\n",
            "   [ 0.28627455]\n",
            "   ...\n",
            "   [ 0.43529415]\n",
            "   [ 0.22352946]\n",
            "   [ 0.00392163]]\n",
            "\n",
            "  [[ 0.3803922 ]\n",
            "   [ 0.30980396]\n",
            "   [ 0.07450986]\n",
            "   ...\n",
            "   [ 0.34901965]\n",
            "   [ 0.2941177 ]\n",
            "   [ 0.11372554]]\n",
            "\n",
            "  [[ 0.41176474]\n",
            "   [ 0.12156868]\n",
            "   [-0.09803921]\n",
            "   ...\n",
            "   [ 0.19215691]\n",
            "   [ 0.26274514]\n",
            "   [ 0.17647064]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.5921569 ]\n",
            "   [ 0.64705884]\n",
            "   [ 0.62352943]\n",
            "   ...\n",
            "   [ 0.73333335]\n",
            "   [ 0.73333335]\n",
            "   [ 0.7176471 ]]\n",
            "\n",
            "  [[ 0.5686275 ]\n",
            "   [ 0.6392157 ]\n",
            "   [ 0.6313726 ]\n",
            "   ...\n",
            "   [ 0.7254902 ]\n",
            "   [ 0.7176471 ]\n",
            "   [ 0.6784314 ]]\n",
            "\n",
            "  [[ 0.5372549 ]\n",
            "   [ 0.60784316]\n",
            "   [ 0.6392157 ]\n",
            "   ...\n",
            "   [ 0.69411767]\n",
            "   [ 0.6784314 ]\n",
            "   [ 0.6392157 ]]]\n",
            "\n",
            "\n",
            " [[[-0.34117645]\n",
            "   [-0.34117645]\n",
            "   [-0.34117645]\n",
            "   ...\n",
            "   [-0.30196077]\n",
            "   [-0.29411763]\n",
            "   [-0.30196077]]\n",
            "\n",
            "  [[-0.3333333 ]\n",
            "   [-0.32549018]\n",
            "   [-0.3333333 ]\n",
            "   ...\n",
            "   [-0.30196077]\n",
            "   [-0.30196077]\n",
            "   [-0.30196077]]\n",
            "\n",
            "  [[-0.3333333 ]\n",
            "   [-0.32549018]\n",
            "   [-0.3333333 ]\n",
            "   ...\n",
            "   [-0.29411763]\n",
            "   [-0.3098039 ]\n",
            "   [-0.29411763]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.1372549 ]\n",
            "   [-0.1372549 ]\n",
            "   [-0.12156862]\n",
            "   ...\n",
            "   [ 0.45098042]\n",
            "   [ 0.33333337]\n",
            "   [-0.08235294]]\n",
            "\n",
            "  [[-0.1372549 ]\n",
            "   [-0.1372549 ]\n",
            "   [-0.11372548]\n",
            "   ...\n",
            "   [ 0.43529415]\n",
            "   [ 0.4431373 ]\n",
            "   [ 0.0196079 ]]\n",
            "\n",
            "  [[-0.12941176]\n",
            "   [-0.12941176]\n",
            "   [-0.12156862]\n",
            "   ...\n",
            "   [ 0.254902  ]\n",
            "   [ 0.49803925]\n",
            "   [ 0.24705887]]]\n",
            "\n",
            "\n",
            " [[[ 0.99215686]\n",
            "   [ 0.8509804 ]\n",
            "   [ 0.5058824 ]\n",
            "   ...\n",
            "   [ 0.9764706 ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 0.99215686]\n",
            "   [ 0.5137255 ]\n",
            "   [ 0.05882359]\n",
            "   ...\n",
            "   [ 0.9764706 ]\n",
            "   [ 1.        ]\n",
            "   [ 0.99215686]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 0.5764706 ]\n",
            "   [ 0.09019613]\n",
            "   ...\n",
            "   [ 0.9529412 ]\n",
            "   [ 1.        ]\n",
            "   [ 0.99215686]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.73333335]\n",
            "   [-0.7490196 ]\n",
            "   [-0.75686276]\n",
            "   ...\n",
            "   [-0.7490196 ]\n",
            "   [-0.73333335]\n",
            "   [-0.73333335]]\n",
            "\n",
            "  [[-0.7647059 ]\n",
            "   [-0.7647059 ]\n",
            "   [-0.78039217]\n",
            "   ...\n",
            "   [-0.79607844]\n",
            "   [-0.8039216 ]\n",
            "   [-0.7647059 ]]\n",
            "\n",
            "  [[-0.6862745 ]\n",
            "   [-0.7411765 ]\n",
            "   [-0.78039217]\n",
            "   ...\n",
            "   [-0.8352941 ]\n",
            "   [-0.78039217]\n",
            "   [-0.654902  ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.3490196 ]\n",
            "   [-0.16862744]\n",
            "   [ 0.52156866]\n",
            "   ...\n",
            "   [ 0.36470592]\n",
            "   [ 0.41960788]\n",
            "   [ 0.19215691]]\n",
            "\n",
            "  [[-0.36470586]\n",
            "   [-0.06666666]\n",
            "   [ 0.6156863 ]\n",
            "   ...\n",
            "   [ 0.32549024]\n",
            "   [ 0.49803925]\n",
            "   [ 0.27843142]]\n",
            "\n",
            "  [[-0.3960784 ]\n",
            "   [ 0.18431377]\n",
            "   [ 0.6627451 ]\n",
            "   ...\n",
            "   [ 0.27058828]\n",
            "   [ 0.4039216 ]\n",
            "   [ 0.48235297]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.38823533]\n",
            "   [ 0.23921573]\n",
            "   [ 0.27843142]\n",
            "   ...\n",
            "   [ 0.02745104]\n",
            "   [ 0.0196079 ]\n",
            "   [-0.24705881]]\n",
            "\n",
            "  [[ 0.41960788]\n",
            "   [ 0.33333337]\n",
            "   [ 0.30196083]\n",
            "   ...\n",
            "   [ 0.09803927]\n",
            "   [-0.19215685]\n",
            "   [-0.23137254]]\n",
            "\n",
            "  [[ 0.41176474]\n",
            "   [ 0.33333337]\n",
            "   [ 0.2941177 ]\n",
            "   ...\n",
            "   [-0.09019607]\n",
            "   [-0.34117645]\n",
            "   [-0.14509803]]]\n",
            "\n",
            "\n",
            " [[[ 0.15294123]\n",
            "   [ 0.07450986]\n",
            "   [ 0.00392163]\n",
            "   ...\n",
            "   [-0.18431371]\n",
            "   [-0.05098039]\n",
            "   [ 0.0196079 ]]\n",
            "\n",
            "  [[ 0.12156868]\n",
            "   [ 0.04313731]\n",
            "   [ 0.03529418]\n",
            "   ...\n",
            "   [-0.27058822]\n",
            "   [-0.09803921]\n",
            "   [-0.01176471]]\n",
            "\n",
            "  [[ 0.09019613]\n",
            "   [ 0.04313731]\n",
            "   [ 0.05882359]\n",
            "   ...\n",
            "   [-0.372549  ]\n",
            "   [-0.15294117]\n",
            "   [-0.0745098 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.13725495]\n",
            "   [ 0.05882359]\n",
            "   [-0.00392157]\n",
            "   ...\n",
            "   [-0.64705884]\n",
            "   [-0.3098039 ]\n",
            "   [ 0.04313731]]\n",
            "\n",
            "  [[ 0.01176476]\n",
            "   [-0.01176471]\n",
            "   [-0.01176471]\n",
            "   ...\n",
            "   [-0.6       ]\n",
            "   [-0.3098039 ]\n",
            "   [ 0.23921573]]\n",
            "\n",
            "  [[-0.11372548]\n",
            "   [-0.01960784]\n",
            "   [-0.01176471]\n",
            "   ...\n",
            "   [-0.4352941 ]\n",
            "   [-0.2862745 ]\n",
            "   [ 0.18431377]]]\n",
            "\n",
            "\n",
            " [[[-0.827451  ]\n",
            "   [-0.8509804 ]\n",
            "   [-0.85882354]\n",
            "   ...\n",
            "   [-0.69411767]\n",
            "   [-0.69411767]\n",
            "   [-0.7254902 ]]\n",
            "\n",
            "  [[-0.73333335]\n",
            "   [-0.6627451 ]\n",
            "   [-0.8039216 ]\n",
            "   ...\n",
            "   [-0.67058825]\n",
            "   [-0.67058825]\n",
            "   [-0.7176471 ]]\n",
            "\n",
            "  [[-0.7647059 ]\n",
            "   [-0.6392157 ]\n",
            "   [-0.7176471 ]\n",
            "   ...\n",
            "   [-0.6392157 ]\n",
            "   [-0.7019608 ]\n",
            "   [-0.7019608 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.56078434]\n",
            "   [-0.60784316]\n",
            "   [-0.6392157 ]\n",
            "   ...\n",
            "   [-0.5372549 ]\n",
            "   [-0.40392154]\n",
            "   [-0.3098039 ]]\n",
            "\n",
            "  [[-0.35686272]\n",
            "   [-0.44313723]\n",
            "   [-0.49019605]\n",
            "   ...\n",
            "   [-0.372549  ]\n",
            "   [-0.3098039 ]\n",
            "   [-0.23137254]]\n",
            "\n",
            "  [[-0.4352941 ]\n",
            "   [-0.38039213]\n",
            "   [-0.3333333 ]\n",
            "   ...\n",
            "   [-0.12941176]\n",
            "   [-0.09019607]\n",
            "   [-0.03529412]]]] [[[[-0.5058824 ]\n",
            "   [-0.372549  ]\n",
            "   [-0.17647058]\n",
            "   ...\n",
            "   [-0.42745095]\n",
            "   [-0.5921569 ]\n",
            "   [-0.4980392 ]]\n",
            "\n",
            "  [[-0.5686275 ]\n",
            "   [-0.38823527]\n",
            "   [-0.15294117]\n",
            "   ...\n",
            "   [-0.41176468]\n",
            "   [-0.5764706 ]\n",
            "   [-0.52156866]]\n",
            "\n",
            "  [[-0.60784316]\n",
            "   [-0.41176468]\n",
            "   [-0.19215685]\n",
            "   ...\n",
            "   [-0.42745095]\n",
            "   [-0.5686275 ]\n",
            "   [-0.5137255 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.99215686]\n",
            "   [-0.99215686]\n",
            "   [-0.99215686]\n",
            "   ...\n",
            "   [-0.96862745]\n",
            "   [-1.        ]\n",
            "   [-1.        ]]\n",
            "\n",
            "  [[-0.99215686]\n",
            "   [-0.99215686]\n",
            "   [-0.99215686]\n",
            "   ...\n",
            "   [-0.9843137 ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]]\n",
            "\n",
            "  [[-0.99215686]\n",
            "   [-0.99215686]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.9843137 ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]]]\n",
            "\n",
            "\n",
            " [[[ 0.3176471 ]\n",
            "   [ 0.24705887]\n",
            "   [ 0.27843142]\n",
            "   ...\n",
            "   [-0.84313726]\n",
            "   [-0.85882354]\n",
            "   [-0.8666667 ]]\n",
            "\n",
            "  [[ 0.41176474]\n",
            "   [ 0.27058828]\n",
            "   [ 0.2941177 ]\n",
            "   ...\n",
            "   [-0.8117647 ]\n",
            "   [-0.8509804 ]\n",
            "   [-0.8666667 ]]\n",
            "\n",
            "  [[ 0.5294118 ]\n",
            "   [ 0.254902  ]\n",
            "   [ 0.2941177 ]\n",
            "   ...\n",
            "   [-0.7019608 ]\n",
            "   [-0.81960785]\n",
            "   [-0.8509804 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.88235295]\n",
            "   [ 0.48235297]\n",
            "   [ 0.34901965]\n",
            "   ...\n",
            "   [-0.654902  ]\n",
            "   [-0.6392157 ]\n",
            "   [-0.6392157 ]]\n",
            "\n",
            "  [[ 0.6627451 ]\n",
            "   [ 0.3411765 ]\n",
            "   [ 0.39607847]\n",
            "   ...\n",
            "   [-0.5921569 ]\n",
            "   [-0.6       ]\n",
            "   [-0.7647059 ]]\n",
            "\n",
            "  [[ 0.41176474]\n",
            "   [ 0.41176474]\n",
            "   [ 0.41176474]\n",
            "   ...\n",
            "   [-0.5686275 ]\n",
            "   [-0.75686276]\n",
            "   [-0.7411765 ]]]\n",
            "\n",
            "\n",
            " [[[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.01960784]\n",
            "   [-0.23137254]\n",
            "   [-0.19215685]]\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [ 0.03529418]\n",
            "   [-0.03529412]\n",
            "   [ 0.12941182]]\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [ 0.2941177 ]\n",
            "   [ 0.37254906]\n",
            "   [ 0.38823533]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [ 0.92156863]\n",
            "   [ 0.92156863]\n",
            "   [ 0.92941177]]\n",
            "\n",
            "  [[-0.9843137 ]\n",
            "   [-1.        ]\n",
            "   [-0.99215686]\n",
            "   ...\n",
            "   [ 0.92156863]\n",
            "   [ 0.92941177]\n",
            "   [ 0.9137255 ]]\n",
            "\n",
            "  [[-0.6627451 ]\n",
            "   [-1.        ]\n",
            "   [-0.99215686]\n",
            "   ...\n",
            "   [ 0.92156863]\n",
            "   [ 0.92941177]\n",
            "   [ 0.8901961 ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 0.20784318]\n",
            "   [ 0.16078436]\n",
            "   [-0.0745098 ]\n",
            "   ...\n",
            "   [ 0.36470592]\n",
            "   [ 0.28627455]\n",
            "   [ 0.3803922 ]]\n",
            "\n",
            "  [[ 0.082353  ]\n",
            "   [ 0.04313731]\n",
            "   [-0.09803921]\n",
            "   ...\n",
            "   [ 0.36470592]\n",
            "   [ 0.254902  ]\n",
            "   [ 0.34901965]]\n",
            "\n",
            "  [[-0.01960784]\n",
            "   [-0.09019607]\n",
            "   [-0.1372549 ]\n",
            "   ...\n",
            "   [ 0.30196083]\n",
            "   [ 0.254902  ]\n",
            "   [ 0.32549024]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.4823529 ]\n",
            "   [-0.5686275 ]\n",
            "   [-0.49019605]]\n",
            "\n",
            "  [[-0.99215686]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.6156863 ]\n",
            "   [-0.4980392 ]\n",
            "   [-0.45098037]]\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.77254903]\n",
            "   [-0.54509807]\n",
            "   [-0.41176468]]]\n",
            "\n",
            "\n",
            " [[[-0.73333335]\n",
            "   [-0.73333335]\n",
            "   [-0.73333335]\n",
            "   ...\n",
            "   [ 0.45882356]\n",
            "   [ 0.39607847]\n",
            "   [ 0.3176471 ]]\n",
            "\n",
            "  [[-0.7411765 ]\n",
            "   [-0.7411765 ]\n",
            "   [-0.7411765 ]\n",
            "   ...\n",
            "   [ 0.43529415]\n",
            "   [ 0.3411765 ]\n",
            "   [ 0.28627455]]\n",
            "\n",
            "  [[-0.7411765 ]\n",
            "   [-0.7490196 ]\n",
            "   [-0.7490196 ]\n",
            "   ...\n",
            "   [ 0.37254906]\n",
            "   [ 0.3176471 ]\n",
            "   [ 0.254902  ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.96862745]\n",
            "   [-0.9607843 ]\n",
            "   [-0.96862745]\n",
            "   ...\n",
            "   [-0.46666664]\n",
            "   [-0.5137255 ]\n",
            "   [-0.54509807]]\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.44313723]\n",
            "   [-0.4823529 ]\n",
            "   [-0.47450978]]\n",
            "\n",
            "  [[-0.4588235 ]\n",
            "   [-0.58431375]\n",
            "   [-0.73333335]\n",
            "   ...\n",
            "   [-0.45098037]\n",
            "   [-0.44313723]\n",
            "   [-0.40392154]]]\n",
            "\n",
            "\n",
            " [[[-0.7254902 ]\n",
            "   [-0.8039216 ]\n",
            "   [-0.62352943]\n",
            "   ...\n",
            "   [-0.00392157]\n",
            "   [-0.00392157]\n",
            "   [-0.01176471]]\n",
            "\n",
            "  [[-0.79607844]\n",
            "   [-0.8039216 ]\n",
            "   [-0.6       ]\n",
            "   ...\n",
            "   [ 0.00392163]\n",
            "   [ 0.00392163]\n",
            "   [-0.00392157]]\n",
            "\n",
            "  [[-0.81960785]\n",
            "   [-0.8039216 ]\n",
            "   [-0.56078434]\n",
            "   ...\n",
            "   [-0.00392157]\n",
            "   [-0.01176471]\n",
            "   [ 0.00392163]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.7882353 ]\n",
            "   [-0.7882353 ]\n",
            "   [-0.7490196 ]\n",
            "   ...\n",
            "   [-0.01176471]\n",
            "   [-0.01176471]\n",
            "   [-0.02745098]]\n",
            "\n",
            "  [[-0.77254903]\n",
            "   [-0.75686276]\n",
            "   [-0.7490196 ]\n",
            "   ...\n",
            "   [-0.01176471]\n",
            "   [-0.02745098]\n",
            "   [-0.02745098]]\n",
            "\n",
            "  [[-0.7490196 ]\n",
            "   [-0.73333335]\n",
            "   [-0.7490196 ]\n",
            "   ...\n",
            "   [-0.02745098]\n",
            "   [-0.02745098]\n",
            "   [-0.03529412]]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\\n\\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKvEv321Stt5",
        "outputId": "a6ac9f8b-19c6-4398-cd89-534ec26cf5fa"
      },
      "source": [
        "print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validasi (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "test (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "train (28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH9Q-TegBR26"
      },
      "source": [
        "#hyperparameter and callback\n",
        "batch_size = 64\n",
        "num_epochs = 60\n",
        "input_shape = (48, 48, 1)\n",
        "num_classes = 7\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGsscQRJBR-h"
      },
      "source": [
        "#Compile the model.\n",
        "\n",
        "\n",
        "from keras.optimizers import Adam, SGD\n",
        "model = ResNet50(input_shape = (48, 48, 1), classes = 7)\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer= optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rodttDWeT2yP"
      },
      "source": [
        "#kita mau save model callbackshuhuhuhuhhg\n",
        "\"\"\"import os\n",
        "try:\n",
        "  os.mkdir('scratchcheckpoint')\n",
        "except:\n",
        "  pass\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV29sTjET28U"
      },
      "source": [
        "\"\"\"file_name = 'Best_Model_resnet50Scracth_sena1.h5'\n",
        "\n",
        "checkpoint_path = os.path.join('checkpoint',file_name)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_S6wUaPT3Jx"
      },
      "source": [
        "\"\"\"call_back = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
        "                                               monitor='val_accuracy',\n",
        "                                               verbose=1,\n",
        "                                               save_freq='epoch',\n",
        "                                               save_best_only=True,\n",
        "                                               save_weights_only=False,\n",
        "                                               mode='max')\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy53DHMGB-Mr",
        "outputId": "f1d3d919-8718-4fda-9f49-ea1bcae82fd6"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 46, 46, 128)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 46, 46, 128)  0           activation_3[0][0]               \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 46, 46, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 46, 46, 128)  0           activation_6[0][0]               \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 46, 46, 128)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 23, 23, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 23, 23, 256)  0           activation_12[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 23, 23, 256)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 23, 23, 256)  0           activation_15[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 23, 23, 256)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 23, 23, 256)  0           activation_18[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 23, 23, 256)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 12, 12, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 12, 12, 512)  0           activation_24[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 12, 12, 512)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 12, 12, 512)  0           activation_27[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 12, 12, 512)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 12, 12, 512)  0           activation_30[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 12, 12, 512)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 12, 12, 512)  0           activation_33[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 12, 12, 512)  0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 12, 12, 512)  0           activation_36[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 12, 12, 512)  0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 6, 6, 1024)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 6, 6, 1024)   0           activation_42[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 6, 6, 1024)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 6, 6, 1024)   0           activation_45[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 6, 6, 1024)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgxCecVwCGEr"
      },
      "source": [
        "\"\"\"history = model.fit(data_generator.flow(xtrain, ytrain,),\n",
        "                        steps_per_epoch=len(xtrain) / batch_size,\n",
        "                        epochs=num_epochs, verbose=1,callbacks=call_back,\n",
        "                        validation_data= (xtest,ytest))\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2muXWns0sJSH",
        "outputId": "1d4d453b-88ad-43c5-885c-edca90ad70ed"
      },
      "source": [
        "history = model.fit(\n",
        "    data_generator.flow(xtrain, ytrain,),\n",
        "    steps_per_epoch=len(xtrain) / batch_size,\n",
        "    epochs=num_epochs,\n",
        "    shuffle=False, \n",
        "    verbose=1,\n",
        "    validation_data= (x_val,y_val))\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "448/448 [==============================] - 66s 116ms/step - loss: 3.2939 - accuracy: 0.2359 - val_loss: 1.8345 - val_accuracy: 0.2753\n",
            "Epoch 2/60\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 1.6137 - accuracy: 0.3629 - val_loss: 1.5882 - val_accuracy: 0.3923\n",
            "Epoch 3/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.4471 - accuracy: 0.4322 - val_loss: 1.5659 - val_accuracy: 0.4065\n",
            "Epoch 4/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.3373 - accuracy: 0.4696 - val_loss: 1.5666 - val_accuracy: 0.4191\n",
            "Epoch 5/60\n",
            "448/448 [==============================] - 50s 113ms/step - loss: 1.2852 - accuracy: 0.5027 - val_loss: 1.3547 - val_accuracy: 0.4904\n",
            "Epoch 6/60\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 1.2178 - accuracy: 0.5297 - val_loss: 1.3153 - val_accuracy: 0.5024\n",
            "Epoch 7/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.1591 - accuracy: 0.5576 - val_loss: 1.2392 - val_accuracy: 0.5380\n",
            "Epoch 8/60\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 1.0859 - accuracy: 0.5936 - val_loss: 1.2191 - val_accuracy: 0.5497\n",
            "Epoch 9/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.0405 - accuracy: 0.6054 - val_loss: 1.2123 - val_accuracy: 0.5364\n",
            "Epoch 10/60\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 0.9876 - accuracy: 0.6306 - val_loss: 1.3259 - val_accuracy: 0.5263\n",
            "Epoch 11/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.9512 - accuracy: 0.6426 - val_loss: 1.1501 - val_accuracy: 0.5681\n",
            "Epoch 12/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.8935 - accuracy: 0.6682 - val_loss: 1.2591 - val_accuracy: 0.5378\n",
            "Epoch 13/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.8428 - accuracy: 0.6928 - val_loss: 1.2308 - val_accuracy: 0.5525\n",
            "Epoch 14/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.7775 - accuracy: 0.7174 - val_loss: 1.2713 - val_accuracy: 0.5553\n",
            "Epoch 15/60\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 0.7525 - accuracy: 0.7299 - val_loss: 1.2943 - val_accuracy: 0.5581\n",
            "Epoch 16/60\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 0.6439 - accuracy: 0.7685 - val_loss: 1.2313 - val_accuracy: 0.5773\n",
            "Epoch 17/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.6086 - accuracy: 0.7843 - val_loss: 1.3289 - val_accuracy: 0.5389\n",
            "Epoch 18/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.5388 - accuracy: 0.8089 - val_loss: 1.3626 - val_accuracy: 0.5626\n",
            "Epoch 19/60\n",
            "448/448 [==============================] - 50s 113ms/step - loss: 0.5049 - accuracy: 0.8247 - val_loss: 1.5307 - val_accuracy: 0.5639\n",
            "Epoch 20/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.4264 - accuracy: 0.8528 - val_loss: 1.5679 - val_accuracy: 0.5639\n",
            "Epoch 21/60\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 0.4058 - accuracy: 0.8624 - val_loss: 1.5446 - val_accuracy: 0.5506\n",
            "Epoch 22/60\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 0.3542 - accuracy: 0.8771 - val_loss: 1.6892 - val_accuracy: 0.5548\n",
            "Epoch 23/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.2943 - accuracy: 0.8994 - val_loss: 1.6669 - val_accuracy: 0.5573\n",
            "Epoch 24/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.2789 - accuracy: 0.9054 - val_loss: 1.7076 - val_accuracy: 0.5603\n",
            "Epoch 25/60\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 0.2402 - accuracy: 0.9166 - val_loss: 1.8023 - val_accuracy: 0.5637\n",
            "Epoch 26/60\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 0.2331 - accuracy: 0.9240 - val_loss: 1.9626 - val_accuracy: 0.5559\n",
            "Epoch 27/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.2175 - accuracy: 0.9277 - val_loss: 1.7993 - val_accuracy: 0.5812\n",
            "Epoch 28/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.1872 - accuracy: 0.9383 - val_loss: 1.9578 - val_accuracy: 0.5559\n",
            "Epoch 29/60\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 0.1701 - accuracy: 0.9447 - val_loss: 1.9311 - val_accuracy: 0.5642\n",
            "Epoch 30/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.1686 - accuracy: 0.9437 - val_loss: 2.0731 - val_accuracy: 0.5651\n",
            "Epoch 31/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.1415 - accuracy: 0.9539 - val_loss: 2.1273 - val_accuracy: 0.5776\n",
            "Epoch 32/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.1569 - accuracy: 0.9481 - val_loss: 2.0119 - val_accuracy: 0.5715\n",
            "Epoch 33/60\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 0.1310 - accuracy: 0.9571 - val_loss: 2.0066 - val_accuracy: 0.5706\n",
            "Epoch 34/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.1340 - accuracy: 0.9583 - val_loss: 2.1649 - val_accuracy: 0.5628\n",
            "Epoch 35/60\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 0.1288 - accuracy: 0.9552 - val_loss: 2.2782 - val_accuracy: 0.5464\n",
            "Epoch 36/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.1210 - accuracy: 0.9628 - val_loss: 2.1355 - val_accuracy: 0.5754\n",
            "Epoch 37/60\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 0.1183 - accuracy: 0.9631 - val_loss: 2.2980 - val_accuracy: 0.5567\n",
            "Epoch 38/60\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 0.1362 - accuracy: 0.9571 - val_loss: 2.1243 - val_accuracy: 0.5846\n",
            "Epoch 39/60\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 0.1123 - accuracy: 0.9635 - val_loss: 2.2020 - val_accuracy: 0.5609\n",
            "Epoch 40/60\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 0.0913 - accuracy: 0.9715 - val_loss: 2.1883 - val_accuracy: 0.5868\n",
            "Epoch 41/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.0908 - accuracy: 0.9718 - val_loss: 2.4587 - val_accuracy: 0.5603\n",
            "Epoch 42/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.1056 - accuracy: 0.9659 - val_loss: 2.3507 - val_accuracy: 0.5734\n",
            "Epoch 43/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.0954 - accuracy: 0.9708 - val_loss: 2.2858 - val_accuracy: 0.5731\n",
            "Epoch 44/60\n",
            "448/448 [==============================] - 50s 113ms/step - loss: 0.1045 - accuracy: 0.9683 - val_loss: 2.3795 - val_accuracy: 0.5687\n",
            "Epoch 45/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.0767 - accuracy: 0.9764 - val_loss: 2.4897 - val_accuracy: 0.5776\n",
            "Epoch 46/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.1084 - accuracy: 0.9649 - val_loss: 2.3396 - val_accuracy: 0.5698\n",
            "Epoch 47/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.1010 - accuracy: 0.9688 - val_loss: 2.3065 - val_accuracy: 0.5698\n",
            "Epoch 48/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.0811 - accuracy: 0.9738 - val_loss: 2.3738 - val_accuracy: 0.5704\n",
            "Epoch 49/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.0801 - accuracy: 0.9742 - val_loss: 2.6062 - val_accuracy: 0.5645\n",
            "Epoch 50/60\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 0.0848 - accuracy: 0.9725 - val_loss: 2.4583 - val_accuracy: 0.5678\n",
            "Epoch 51/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.0869 - accuracy: 0.9709 - val_loss: 2.4631 - val_accuracy: 0.5834\n",
            "Epoch 52/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.0788 - accuracy: 0.9764 - val_loss: 2.3458 - val_accuracy: 0.5762\n",
            "Epoch 53/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.0778 - accuracy: 0.9737 - val_loss: 2.4457 - val_accuracy: 0.5834\n",
            "Epoch 54/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.0783 - accuracy: 0.9767 - val_loss: 2.3945 - val_accuracy: 0.5748\n",
            "Epoch 55/60\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 0.0793 - accuracy: 0.9745 - val_loss: 2.4818 - val_accuracy: 0.5846\n",
            "Epoch 56/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.0661 - accuracy: 0.9790 - val_loss: 2.4744 - val_accuracy: 0.5754\n",
            "Epoch 57/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.0701 - accuracy: 0.9769 - val_loss: 2.3974 - val_accuracy: 0.5712\n",
            "Epoch 58/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.0653 - accuracy: 0.9805 - val_loss: 2.4646 - val_accuracy: 0.5754\n",
            "Epoch 59/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.0697 - accuracy: 0.9766 - val_loss: 2.5807 - val_accuracy: 0.5731\n",
            "Epoch 60/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.0663 - accuracy: 0.9784 - val_loss: 2.5634 - val_accuracy: 0.5737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaXUP-8fDWRN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "outputId": "c638d9df-614b-4f11-8ccd-615280cb9819"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "model.save('/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_seed_adam_shuffalse_noAug1.h5')\n",
        "\n",
        "#gffhgffkjkjdskjjkjkjkjhjhnnnhjhhuyghhgdas\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "num_epochs = range(len(accuracy))\n",
        "plt.plot(num_epochs, accuracy, 'r', label='Training acc')\n",
        "plt.plot(num_epochs, val_accuracy, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(num_epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(num_epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5gUVdbA4d9hyEGQpCAooERF0ogKBjCsgC6IooIJRDHHXdfFhCyGFfNn3DWSVMzIEtaVpGJkFESiIgwyCDjkDBPO98epgZ5hQgPd09PT532eeqYr9qnunjp1b926JaqKc865xFUm1gE455yLLU8EzjmX4DwROOdcgvNE4JxzCc4TgXPOJThPBM45l+A8Ebh9iMhkEekf6WVjSURSReSsKGxXReSY4PW/ROT+cJY9gPe5TET+d6BxOlcY8fsISgcR2RoyWhnYBWQF49ep6pvFH1XJISKpwDWqOiXC21WgqaouidSyItIIWAaUU9XMSMTpXGHKxjoAFxmqWjXndWEHPREp6wcXV1L477Fk8KqhUk5EuohImoj8XURWA2+IyKEiMkFE0kVkQ/C6Qcg6M0TkmuD1ABGZKSJPBMsuE5HuB7hsYxH5XES2iMgUEXlBRMYUEHc4MT4oIl8G2/ufiNQOmX+FiCwXkXUicm8hn8+JIrJaRJJCpvUWkbnB644i8rWIbBSRVSLyvIiUL2BbI0TkoZDxvwXr/C4iA/Mse66IzBaRzSKyQkSGhsz+PPi7UUS2isjJOZ9tyPqdRGSWiGwK/nYK97PZz8+5poi8EezDBhEZFzKvl4jMCfbhVxHpFkzPVQ0nIkNzvmcRaRRUkV0tIr8B04Lp7wXfw6bgN3JsyPqVROTJ4PvcFPzGKonIRBG5Jc/+zBWR3vntqyuYJ4LEcDhQEzgKuBb73t8Ixo8EdgDPF7L+icBioDbwGPCaiMgBLPsW8B1QCxgKXFHIe4YT46XAVUBdoDxwJ4CItAJeCrZfP3i/BuRDVb8FtgFn5NnuW8HrLOCOYH9OBs4EbiwkboIYugXxnA00BfJen9gGXAnUAM4FbhCR84N5pwV/a6hqVVX9Os+2awITgWeDfXsKmCgitfLswz6fTT6K+pxHY1WNxwbbejqIoSMwCvhbsA+nAakFfR75OB1oCZwTjE/GPqe6wA9AaFXmE0AHoBP2O74LyAZGApfnLCQibYAjsM/G7Q9V9aGUDdg/5FnB6y7AbqBiIcu3BTaEjM/AqpYABgBLQuZVBhQ4fH+WxQ4ymUDlkPljgDFh7lN+Md4XMn4j8N/g9RBgbMi8KsFncFYB234IeD14XQ07SB9VwLK3Ax+FjCtwTPB6BPBQ8Pp14NGQ5ZqFLpvPdp8Bng5eNwqWLRsyfwAwM3h9BfBdnvW/BgYU9dnsz+cM1MMOuIfms9y/c+It7PcXjA/N+Z5D9q1JITHUCJapjiWqHUCbfJarCGzArruAJYwXi/v/rTQMXiJIDOmqujNnREQqi8i/g6L2ZqwqokZo9Ugeq3NeqOr24GXV/Vy2PrA+ZBrAioICDjPG1SGvt4fEVD9026q6DVhX0HthZ/8XiEgF4ALgB1VdHsTRLKguWR3E8QhWOihKrhiA5Xn270QRmR5UyWwCrg9zuznbXp5n2nLsbDhHQZ9NLkV8zg2x72xDPqs2BH4NM9787PlsRCRJRB4Nqpc2s7dkUTsYKub3XsFv+h3gchEpA/TDSjBuP3kiSAx5m4b9FWgOnKiqh7C3KqKg6p5IWAXUFJHKIdMaFrL8wcS4KnTbwXvWKmhhVV2AHUi7k7taCKyKaRF21nkIcM+BxICViEK9BYwHGqpqdeBfIdstqinf71hVTqgjgZVhxJVXYZ/zCuw7q5HPeiuAowvY5jasNJjj8HyWCd3HS4FeWPVZdazUkBPDWmBnIe81ErgMq7Lbrnmq0Vx4PBEkpmpYcXtjUN/8QLTfMDjDTgGGikh5ETkZ+HOUYnwfOE9ETgku7A6j6N/6W8Bt2IHwvTxxbAa2ikgL4IYwY3gXGCAirYJElDf+atjZ9s6gvv3SkHnpWJVMkwK2PQloJiKXikhZEbkEaAVMCDO2vHHk+zmr6iqs7v7F4KJyORHJSRSvAVeJyJkiUkZEjgg+H4A5QN9g+WSgTxgx7MJKbZWxUldODNlYNdtTIlI/KD2cHJTeCA782cCTeGnggHkiSEzPAJWws61vgP8W0/tehl1wXYfVy7+DHQDyc8Axqup84Cbs4L4Kq0dOK2K1t7ELmNNUdW3I9Duxg/QW4JUg5nBimBzswzRgSfA31I3AMBHZgl3TeDdk3e3Aw8CXYq2VTsqz7XXAedjZ/Drs4ul5eeIOV1Gf8xVABlYq+gO7RoKqfoddjH4a2AR8xt5Syv3YGfwG4B/kLmHlZxRWIlsJLAjiCHUn8BMwC1gPDCf3sWsU0Bq75uQOgN9Q5mJGRN4BFqlq1EskrvQSkSuBa1X1lFjHEq+8ROCKjYicICJHB1UJ3bB64XFFredcQYJqtxuBl2MdSzzzROCK0+FY08atWBv4G1R1dkwjcnFLRM7BrqesoejqJ1cIrxpyzrkE5yUC55xLcHHX6Vzt2rW1UaNGsQ7DOefiyvfff79WVevkNy/uEkGjRo1ISUmJdRjOORdXRCTv3eh7RK1qSEReF5E/RGReAfNFRJ4VkSVBj4HtoxWLc865gkXzGsEIoFsh87tjvQ02xXrEfCmKsTjnnCtA1BKBqn6O3QVYkF7AKDXfYB1d1YtWPM455/IXy2sER5C7d8a0YNqqvAuKyLVYqYEjj8zbdxdkZGSQlpbGzp0795nnSoaKFSvSoEEDypUrF+tQnHN5xMXFYlV9meDOweTk5H1ufEhLS6NatWo0atSIgp+X4mJFVVm3bh1paWk0btw41uE45/KI5X0EK8ndTW8DDqwbXXbu3EmtWrU8CZRQIkKtWrW8xOZcCRXLRDAeuDJoPXQSsCno9vaAeBIo2fz7ca7kilrVkIi8jT0msbaIpGH9nJcDUNV/YX2q98C66N2OdWnrnHOJIS0NvvoKli6FFi2gTRto1AhicNIUtUSgqv2KmK9Yn/Fxb926dZx55pkArF69mqSkJOrUsRv4vvvuO8qXL1/guikpKYwaNYpnn3220Pfo1KkTX331VeSCds7tv82boWpVKFNAZcrq1TBqFLzxBqxaBY0b7x2aNAFVO/h/+SX89tu+61erBscfD61bW1Jo0AAaNrShfn2oUCEquxV3nc4lJydr3juLFy5cSMuWLWMUUW5Dhw6latWq3HnnnXumZWZmUrZsXFyXj6qS9D25OLZ1K6xdCxs3wqZNe4fy5aFOHRtq17ahqFZqa9fChAnw7bdQuTJUrw41atjfSpUgNRUWL947rF1r8044ATp2tKFDB/jhB3jtNZg4EbKy4JRT7ICemgrLltmQc42sfn3o3Hnv0LQpLFoEc+fCjz/a33nzYEM+j4p+6SW4/voD+thE5HtVTc5vnh+domTAgAFUrFiR2bNn07lzZ/r27cttt93Gzp07qVSpEm+88QbNmzdnxowZPPHEE0yYMIGhQ4fy22+/sXTpUn777Tduv/12br31VgCqVq3K1q1bmTFjBkOHDqV27drMmzePDh06MGbMGESESZMm8Ze//IUqVarQuXNnli5dyoQJuZ9emJqayhVXXMG2bdsAeP755+nUqRMAw4cPZ8yYMZQpU4bu3bvz6KOPsmTJEq6//nrS09NJSkrivffe4+ijC3p8rEsYWVlWhVHQmXHocn/8YQe6xYvt76JFkJEBt9wCPXsWvI3du2HKFJg/H37+ee+wenX4cdarB23bWrVLmzb2ulw5GD8ePv4YvvgCsrPt4J6ZCcH/RS6HHw7NmkHv3nZWn5oK330Hw4fb/uU47DD4619h4EBo3jz3NlQt7sxMO8vPW/1z4ok2hNq61aqP0tJgxQr7e8IJ4e/7fih9ieD222HOnMhus21beOaZ/V4tLS2Nr776iqSkJDZv3swXX3xB2bJlmTJlCvfccw8ffPDBPussWrSI6dOns2XLFpo3b84NN9ywT9v72bNnM3/+fOrXr0/nzp358ssvSU5O5rrrruPzzz+ncePG9OuXf81c3bp1+fTTT6lYsSK//PIL/fr1IyUlhcmTJ/Pxxx/z7bffUrlyZdavt3sBL7vsMgYPHkzv3r3ZuXMn2dnZ+/05uBLujz/sjPibb+yMNDPTDlQ5A8CWLXYGnjNs2WLTy5WDihWtyqJiRTvg7dplZ787d9q2QlWubPXhGzbYgfX442HIEHudkxAWLYJXX4WRI+0MHOwsv1kz6N7dzqAPOyz32Xv16pY40tNtWLvW/v76qx0PPv1031hat4Z774VevaB9e9vXjAyr/tm0CbZvtyqZ6tXz/9y2b7dtp6RYNU737gWXQEQsKe2PqlXts2rRouhlD1LpSwQlyEUXXURSUhIAmzZton///vzyyy+ICBkZGfmuc+6551KhQgUqVKhA3bp1WbNmDQ0aNMi1TMeOHfdMa9u2LampqVStWpUmTZrsaaffr18/Xn5534c2ZWRkcPPNNzNnzhySkpL4+eefAZgyZQpXXXUVlStXBqBmzZps2bKFlStX0rt3b8BuCnMlyPbtdjZbter+racKkyfDm2/awX/pUptetiy0arX3gJ4zgNVdH320HXhzDr4idrAPPfCL5E4MFSpAzZp7D2hHHGEH/MxMePtteOgh6NMHjj0WrrjCqmlmzrRYevWys+tOnew9D8auXbBwoR24t261g3Z+Jdty5aBWLRuKUrmyxRaUqONZ6UsEB3DmHi1VqlTZ8/r++++na9eufPTRR6SmptKlS5d816kQcjEoKSmJzLxnMWEuU5Cnn36aww47jB9//JHs7Gw/uMej33+HJ5+Ef/3LksGhh8KRR9rZ65FH2sG8Sxf7G1oFsXs3jB0Ljz9uddB168Jpp8GNN8JJJ9lZcaVKxbMPZcvagf/SS+Hdd+HBB2HwYDvbHz4c+ve3s/5IqVDBSvZt20Zum6VI6UsEJdSmTZs44ogjABgxYkTEt9+8eXOWLl1KamoqjRo14p133ikwjgYNGlCmTBlGjhxJVlDHefbZZzNs2DAuu+yyPVVDNWvWpEGDBowbN47zzz+fXbt2kZWVtafU4IrZ0qXw2GPWIiUrC/r2heOOs9YnK1bYMHOmVd2AVad06QJdu1rCeOYZq2du3dpatvTtW/TF1GhLSoJ+/eDii63uvUmTmDSfTHSeCIrJXXfdRf/+/XnooYc499xzI779SpUq8eKLL9KtWzeqVKnCCQVcVLrxxhu58MILGTVq1J5lAbp168acOXNITk6mfPny9OjRg0ceeYTRo0dz3XXXMWTIEMqVK8d7771HkyZNIh5/Qlu1ypoU5gxz51q1yqGH7h2SkqyeOykJrroK7rrLDpp5qVoLlRkzYPp0G957z+Z17QqvvALnnFPyDrZJSflX1bhi4c1HS5GtW7dStWpVVJWbbrqJpk2bcscdd8Q6rD0S7nvauhVmz4bvv7dh2TKrG8/K2jts2GBn8mDVF8nJ1hwxKwvWr7f5GzbYxdlu3axVSv364cegahdMd++2qiKXsLz5aIJ45ZVXGDlyJLt376Zdu3Zcd911sQ4psezeDdOmwbhx8Pnn1vol50SrXj1rUlilip39liljf4891poEduoE7dpZW/hIEoFjjonsNl2p44mgFLnjjjtKVAmg1FO1s/Zp0+Cjj+xmos2b7WDfpQtccomd3XfosP9NB50rRp4InCtKerqd4c+caRc0V62yYfVqKwWA3cXap4+1hz/rLKvjdy5OeCJwLq+MDGvPPnUqfPaZNbUEa1p59NF2dt+smf09/HBrdtm5szWJdC4O+S/XuRw7dljTzMceg+XLrYrnlFOsrXuXLlbFE+k6fOdKAE8Ezm3ZYjdnPfkkrFkDJ58Mzz1nrXRi3c7euWIQywfTlBpdu3blk08+yTXtmWee4YYbbihwnS5dupDTDLZHjx5szLkJKMTQoUN54oknCn3vcePGsWDBgj3jQ4YMYcqUKfsTfmLavBnef9/a5B91lLXLP/54a3f/5Zfw5z97EnAJw0sEEdCvXz/Gjh3LOeecs2fa2LFjeeyxx8Jaf9KkSQf83uPGjeO8886jVdBGfNiwYQe8rVIvLQ3eecda93zxhbXpr1EDevSA226zLoWdS0BeIoiAPn36MHHiRHYHLUhSU1P5/fffOfXUU7nhhhtITk7m2GOP5YEHHsh3/UaNGrE26GXx4YcfplmzZpxyyiksXrx4zzKvvPIKJ5xwAm3atOHCCy9k+/btfPXVV4wfP56//e1vtG3bll9//ZUBAwbw/vvvAzB16lTatWtH69atGThwILt27drzfg888ADt27endevWLFq0aJ+YUlNTOfXUU2nfvj3t27fP9VCc4cOH07p1a9q0acPgwYMBWLJkCWeddRZt2rShffv2/PrrrxH4ZCNA1S76Xnih9RB5553WCuivf7WWQOnp1vmaJwGXwEpdiSAWvVDXrFmTjh07MnnyZHr16sXYsWO5+OKLEREefvhhatasSVZWFmeeeSZz587l+OOPz3c733//PWPHjmXOnDlkZmbSvn17OnToAMAFF1zAoEGDALjvvvt47bXXuOWWW+jZsyfnnXceffr0ybWtnTt3MmDAAKZOnUqzZs248soreemll7j99tsBqF27Nj/88AMvvvgiTzzxBK+++mqu9eO+u+rNm+3C70svWT/4tWpZEhg0yLsycC6PqJYIRKSbiCwWkSUiMjif+UeJyFQRmSsiM0SkQX7biQc51UNg1UI5zwN49913ad++Pe3atWP+/Pm56vPz+uKLL+jduzeVK1fmkEMOoWfPnnvmzZs3j1NPPZXWrVvz5ptvMn/+/ELjWbx4MY0bN6ZZs2YA9O/fn88//3zP/AsuuACADh06kJqaus/6GRkZDBo0iNatW3PRRRftiTvc7qpj2jHd5MnWncLtt1vVz6hRVi306KOeBJzLRzQfXp8EvACcDaQBs0RkvKqGHgmfAEap6kgROQP4J3DFwbxvrHqh7tWrF3fccQc//PAD27dvp0OHDixbtownnniCWbNmceihhzJgwAB25jyubj8NGDCAcePG0aZNG0aMGMGMGTMOKt6crqwL6sY6Lrur3rgR/vIXKwkce6x1tnbyybGOyrkSL5olgo7AElVdqqq7gbFArzzLtAKmBa+n5zM/blStWpWuXbsycODAPaWBzZs3U6VKFapXr86aNWuYPHlyods47bTTGDduHDt27GDLli385z//2TNvy5Yt1KtXj4yMDN58880906tVq8aWnKdFhWjevDmpqaksWbIEgNGjR3P66aeHvT+bNm2iXr16lClThtGjR+fqrvqNN95g+/btAKxfv55q1art6a4aYNeuXXvmF5vJk61L5lGj4J57rJM3TwLOhSWaieAIYEXIeFowLdSPwAXB695ANRHZ59FAInKtiKSISEp6enpUgo2Efv368eOPP+5JBG3atKFdu3a0aNGCSy+9lM6dOxe6fvv27bnkkkto06YN3bt3z9WV9IMPPsiJJ55I586daRHy6Lq+ffvy+OOP065du1wXaCtWrMgbb7zBRRddROvWrSlTpgzX78dDr2+88UZGjhxJmzZtWLRoUa7uqnv27ElycjJt27bd07x19OjRPPvssxx//PF06tSJ1fvzXNkDpWpP2Orb11r+1Khh4w8/bD15OufCErVuqEWkD9BNVa8Jxq8ATlTVm0OWqQ88DzQGPgcuBI5T1X0b1Qe8G+r4FbHvaccOe9LWCy/YmX+1anDrrXD//Z4AnCtArLqhXgk0DBlvEEzbQ1V/JygRiEhV4MLCkoBLcFlZ9kjD556zXj9btYIXX4TLL7dk4Jw7INFMBLOApiLSGEsAfYFLQxcQkdrAelXNBu4GXo9iPC6eZWXZXcCjR8P559sNYKefXvKetOVcHIraNQJVzQRuBj4BFgLvqup8ERkmIjntIrsAi0XkZ+Aw4OGDeL+DjNhF00F9P5mZcOWVlgSGDbO+/7t08STgXIRE9YYyVZ0ETMozbUjI6/eB9w/2fSpWrMi6deuoVasW4geHEkdVWbdu3YE1Qc3IsKqfd9+FRx6Bu++OfIDOJbhScWdxgwYNSEtLoyS3KEp0FStWpEGD/bxfcPdu6NcPPvwQHn/c7gx2zkVcqUgE5cqVo3HjxrEOw0XS9u32HICPP4ann7a7hJ1zUVEqEoErZX79FS64AH76yVoI3Xxz0es45w6YJwJXskyYYNcEypSx7qK7d491RM6Vet4NtSsZsrPhgQfsgTCNG0NKiicB54qJlwhc7G3caNcDJk+G/v2t6+hKlWIdlXMJwxOBi63Vq+3ZwPPnWwK47jq/P8C5YuaJwMXOr7/Cn/5kD4yfONFeO+eKnScCFxtz5lhJIDPTHiV54omxjsi5hOUXi13x+/xz6yeoXDl7iLwnAediyhOBK15Tp8I550D9+vDVV+DdhzsXc1415IpPaipcfDEccwzMmGEPlHfOxZyXCFzx2LHD7hbOyrLeQz0JOFdieInARZ8q3HgjzJ5tdw4fc0ysI3LOhfASgYu+f/8bRoywO4fPPTfW0Tjn8vBE4KLr66/tecI9esCQIUUv75wrdp4IXPSsWQN9+kDDhjBmjHUk55wrcfwagYuO5cutGmjDBisVHHporCNyzhXAT9Fc5H33nd0klpZmF4fbtIl1RM65QkQ1EYhINxFZLCJLRGRwPvOPFJHpIjJbROaKSI9oxuOKwQcf2IPlK1WyksAZZ8Q6IudcEaKWCEQkCXgB6A60AvqJSKs8i90HvKuq7YC+wIvRisdFmao9V/iii6wE8O23ftewc3EimiWCjsASVV2qqruBsUCvPMsocEjwujrwexTjcdF0551w112WCKZNg7p1Yx2Rcy5M0UwERwArQsbTgmmhhgKXi0gaMAm4Jb8Nici1IpIiIinp6enRiNUdjNGj4amn7NnCb7/tD5VxLs7E+mJxP2CEqjYAegCjRWSfmFT1ZVVNVtXkOnXqFHuQrhA//WQPk+nSBZ5+2puIOheHovlfuxJoGDLeIJgW6mrgXQBV/RqoCNSOYkwukjZtggsvhBo1rCRQ1lsjOxePopkIZgFNRaSxiJTHLgaPz7PMb8CZACLSEksEXvcTD1Rh4EBYuhTeeQcOPzzWETnnDlDUEoGqZgI3A58AC7HWQfNFZJiI9AwW+yswSER+BN4GBqiqRismF0FPPw0ffgjDh8Opp8Y6GufcQZB4O+4mJydrSkpKrMNIbF98AV27Qq9e8P77/rB55+KAiHyvqsn5zfMre27/LFtmD5dp3Bhef92TgHOlgF/dc+FLT7fHTO7aZY+crF491hE55yLAE4ELz9at1oncihWWBFrlvUncORevPBG4omVkWHfS339vj5ns1CnWETnnIsgTgStcdjZcfTV88gm88gr07Fn0Os65uOIXi13h7r7bupAYNgyuuSbW0TjnosATgSvYpEnw2GNw/fVw332xjsY5FyWeCFz+tm6FG26wrqSfecabiTpXivk1Ape/++6D336DmTOhQoVYR+OciyIvEbh9ffcdPPuslQg6d451NM65KPNE4HLLyIBBg6BePfjnP2MdjXOuGHjVkMvtySdh7ly7X8DvHHYuIXiJwO21ZAn84x/Quzecf36so3HOFRNPBM6o2pPGypeH55+PdTTOuWLkVUPO7h6+9VZ76PxLL0H9+rGOyDlXjDwRJLqMDBgwAN56C+6800oFzrmE4okgke3YARddBBMnwiOPwODBfuOYcwnIE0Gi2rTJOpD74gurDrr++lhH5JyLkaheLBaRbiKyWESWiMjgfOY/LSJzguFnEdkYzXhcYN06OOMM+OorqxLyJOBcQotaiUBEkoAXgLOBNGCWiIxX1QU5y6jqHSHL3wK0i1Y8LqBq3UrPmwcffww9esQ6IudcjEWzRNARWKKqS1V1NzAW6FXI8v2At6MYjwMYOdISwD//6UnAOQdENxEcAawIGU8Lpu1DRI4CGgPTCph/rYikiEhKenp6xANNGMuXw223wWmnwe23xzoa51wJUVJuKOsLvK+qWfnNVNWXVTVZVZPr1KlTzKGVEtnZcNVV9nfECChTUr5651yshXU0EJEPReRcEdmfo8dKoGHIeINgWn764tVC0fXcczB9uj1boHHjWEfjnCtBwj2wvwhcCvwiIo+KSPMw1pkFNBWRxiJSHjvYj8+7kIi0AA4Fvg4zFre/Fi2yewTOPRcGDox1NM65EiasRKCqU1T1MqA9kApMEZGvROQqESlXwDqZwM3AJ8BC4F1VnS8iw0Qk9AnofYGxqqoHsyOuABkZcMUVUKUKvPqq3zDmnNtH2M1HRaQWcDlwBTAbeBM4BegPdMlvHVWdBEzKM21InvGh+xOw2w+q1m1ESgq89x4cfnisI3LOlUBhJQIR+QhoDowG/qyqq4JZ74hISrSCcwchO9taCD3/vP3t0yfWETnnSqhwSwTPqur0/GaoanIE43GRkJ1tdwu/8gr89a/w+OOxjsg5V4KFe7G4lYjUyBkRkUNF5MYoxeQORlaWXRB+5RW45x5LAn5dwDlXiHATwSBV3dMPkKpuAAZFJyR3wDIz7cLwyJEwbBg8/LAnAedckcKtGkoSEclp2RP0I1Q+emG5/aYK11wDb78Njz4Kf/97rCNyzsWJcBPBf7ELw/8Oxq8LprmSYvRoKwncf78nAefcfgk3EfwdO/jfEIx/CrwalYjc/luyBG66CU49FR54INbROOfiTFiJQFWzgZeCwZUku3fDpZdC2bIwZgwkJcU6IudcnAn3PoKmwD+BVkDFnOmq2iRKcblwPfAAzJoF778PRx4Z62icc3Eo3FZDb2ClgUygKzAKGBOtoFyYpk2D4cNh0CC48MJYR+Oci1PhJoJKqjoVEFVdHnQLcW70wnJFWrvWmoo2bw5PPx3raJxzcSzci8W7gi6ofxGRm7HupKtGLyxXqI0b7brA2rUwYYJ1KOeccwco3BLBbUBl4FagA9b5XP9oBeUK8dVX0LatVQu9+CK088c8O+cOTpGJILh57BJV3aqqaap6lapeqKrfFEN8LkdWlt0pfKO68WsAAB2YSURBVNpp9nSxmTPtIfTOOXeQiqwaUtUsETmlOIJxBVi50q4HTJ8OffvCv/4F1avHOirnXCkR7jWC2SIyHngP2JYzUVU/jEpUbq8FC6BLF9i2Dd54A/r39/6DnHMRFW4iqAisA84ImaaAJ4JoWroUzjrLbhJLSYGWLWMdkXOuFAr3zuKroh2Iy2PlSjjzTNi1Cz77zJOAcy5qwr2z+A2sBJCLqvqT0KMhPd1KAuvWwdSpcNxxsY7IOVeKhdt8dAIwMRimAocAW4taSUS6ichiEVkiIoMLWOZiEVkgIvNF5K1wAy+1Nm6EP/0JUlPtHoETToh1RM65Ui7cqqEPQsdF5G1gZmHrBM1OXwDOBtKAWSIyXlUXhCzTFLgb6KyqG0Sk7n7GX7ps3gznngvz58P48dZU1DnnoizcEkFeTYGiDtodgSWqulRVdwNjgV55lhkEvBA88QxV/eMA44l/K1daN9LffQdvvQXdusU6Iudcggj3GsEWcl8jWI09o6AwRwArQsbTgBPzLNMs2P6XQBIwVFX3eeCNiFwLXAtwZGnsYfOnn6BHD9i0CSZOtKoh55wrJuFWDVWL4vs3BboADYDPRaR16PORg/d/GXgZIDk5eZ+L1nFt2jTo3dv6C/r8c+s+wjnnilFYVUMi0ltEqoeM1xCR84tYbSXQMGS8QTAtVBowXlUzVHUZ8DOWGBLDmDFWBdSwIXzzjScBF1OZmXZekpUV60hccQv3GsEDqropZyQ4Yy/qmYizgKYi0lhEygN9gfF5lhmHlQYQkdpYVdHSMGOKb+PGWbcRp5xi/QaVxiovVyJ88AHceqsd6Atz991268pDDxVPXLGwbBmMHWuN8wqzfDm89pr9Lcz8+TBwoD0mfM2ayMVZ7FS1yAGYm8+0n8JYrwd2lv8rcG8wbRjQM3gtwFPAAuAnoG9R2+zQoYPGvR07VBs1Um3dWnXnzlhHk9C++kr1T39SXbYs1pFEx5IlqpUrq4LqXXcVvNwnn9gytWurJiXZ51La/O9/qjVq2H5WrKh62WWq06apZmXZ/B07VN9+W/Wss1RFbLmkJFtuzpzc2/rlF5suolqlimqZMrbN225TTUsr/n0LB5CiBR2rC5qhuQ/orwcH7KOD4SlgRDjrRnooFYng0Ufto58yJdaRFGrNGtVLL1VNSYl1JNGxdq1qgwb2VZx4ouru3Qe/zXXrVAcNsoPJc8+prlx58NssyKpVqtu3Fzw/K0v11FNVq1dX7dvX9vPdd/ddbs0a1cMOUz32WNvmUUepNmmiunlz5GNevlz1llssrhdfjM575JWdbd9FUpKde/33v6o33mifC9i+Xnml6qGH2vhRR6kOHar63Xeqf/mLatWqNv2cc1THjbPvNylJtVIlS65r16r+/LPqVVfZ9PLlVW+4QXX+/L1JpiDp6arffqu6YoVqZmZ0P4dIJIIqwKNAClbl8whQJZx1Iz3EfSJYvVq1WjXVP/851pEUau1a+6cB1c6d7Z+pNMnOVj3vPPunvf9+28+//e3gtvnxx6qHH65atqxqs2a2TVDt1En1ySdV5861A+G6dVYQPJjPNC3Nzm5bt1b944/8l3n6aXv/ESNUd+1SPekkO3udN2/vMllZqt27q1aoYPGpqn7xhZ3hDhiQ/3bXrVO96Sb7CffurdqnjyWayy9Xvftu1UmTVDduzL3OokV2oCxb1obmzS22atVsW/PnH/hnUZjdu1Wvv97eq2fP3Iln+3bVMWNUu3a1UlPfvqqffrrvwXv9etVHHrFkCarlyqnefLPq77/v+35Ll6pee60tA5ZcundXHTbMtv3DD6ovvWSJp2nTvb8RsM+lUSPV006zWC6+2GI+5xzV00+3k5UPPzzwz+KgE0FJGuI+EQwaZN/44sUHtZm0NNVNmyIUUx7r16u2a2dF3SuusF/JtGnRea9Yeeop269nn7Xx666z8UmT9n9b69bZQRBUjz9edfZsm75ggeqDD6q2bZv7Hz70H79+fTurXLo0/PfLzrYDRMWKdlZ63HF2Vh9q0SKbf955exPOypV2MGvaVHXDBpuWkyxeeCH3+jnJMW8J4pNPVOvVs9jbtrVE1LKlbbNxY5sOVmXStq0dMC+6yMYrVbLSwPLlFtPXX9vvq3z5vaWyHj1yD927q55xhiXTDh2s1NK0qSWfMWPst1qQtDRbF1QHDy767LwoO3ZYsk9NLXrZFStUX31V9eqrVVu12ve7r1tXtVcvqxwYN071X/9Sveceq2469VTVY45RbdFCtU0b+1xOP92qMP/znwOPv7BEIDa/cCLyKXCRBs06ReRQYKyqnnMQlycOSHJysqakpBT320bGjz9C+/Z25e4gnjO8Ywc0aQJNm8KMGfacmkjZtAnOPttC/fhjOP10e6+WLa1FSbhU7Ubpbdv2nVetmg3RlPOzzq/H7lmzoHNnu4n7ww9tmR074MQTYdUq2/f69fddLy3N7vvbts2GrVutW6hHH7W/99wD994L5cvvu+6SJdaB7NatuddfuBD+8x/IzrZbSW66Cc45p/Dv9N134ZJL4PHH7ed03nn2HU2bBnXrWqufU06BxYvtYma9envXnTkTuna1xmpDh8LJJ9v7fvRR7s8qI8O28fPPMHcu1K5tF0Sfe85+C2++mf/D8bZtg2+/hS++sOHrr6FcOduv226z+PJKT4fXX7ffW0bGvvMrVICKFW2oUGHvc5lWr4ayZa2X9l697Dc1d67dljN3rl28LV8eXn3V2mXE0saNdq/o+vXQsSM0blz8vcmLyPeqmpzvzIIyROgAzA5nWnEMcVsiyM6205OaNQs/jQnDyy/vPbN4/fUIxadWbO7UyYq1oWceTz5p7zVzZsHr/t//qZ5yip0d1q2798wwv6FiRauzjVR10+bNdnb58st2BnraaVYkr1fPzmxXrNi77MaNduZ65JF2Jh9q4UKrIujSZW99bXa2lYbOO6/g/WndWvX77w88/hUrLM6cqoejj1b98sv8l127VrVOHdXkZNWMDJs2bZqdbbdqZTWPw4fbdt58M/9tPPecza9SxUok6en5L/fLL7bMSSfZ9wp2MbSw6xJ57d5t1VKRlpWl+s03dqbfokXu31aHDlYN9dRT0atyikdE4BrB98CRIeONgB/CWTfSQ9wmgo8/1lx1EQcoK8t++O3aWd19rVoF/yOHY+NG1Vmz7KDRubNd7MpbD7l1q7UmOeec/Lfx9tu2a23aqF54odWR3n236hNPWJH33//OPfToYcv36GEHrnBkZ1ud7BdfqL7yiuodd1g8DRvmPihXrap68slW1dOjh1VJJCWpXnCBXZu/+GIbL+hAO2KEbefee1VHjdpbrVOnjuqQIaoTJ6rOmGEX0BcuVP3tt4Ovcsixa5fq2LFWLVChgur77++7zBVXWJL98cfc06dPtyTWrJlVtVxwQcGJNjvb6qjLlCm6yu+112z/69e3Vjcl1c8/W3VYtC+4xrNIJIJuwG/AaGAMsBw4J5x1Iz3EZSLYtcsqNlu0OOimKRMm2Lc2Zoxd3CtbVnXgwMLX2bnTzow++sjOFq++2uohc85AQ8+mxo7Nfxv//Kct8+23uaf/+KMdgDp3Dv/MLztb9fnn7f3q1rWDa+i81FRLLnfcYWfirVrZGW9orJUqWTK87DLVhx+2fVu6dN+D8q+/Wh18rVp713300cLju/LKvcu2amV1vTt2hLdvkZCebslMxM5qc0yebDHdd1/+682YYd9F7dr7XjPIKyvLklhRsrPtukDe0pOLPwedCGwb1AXuA84F+gCnhbtuJIe4TAT33msfdcgRL9x/xLy6drUmjzn55K67bNOff77vstu320G/TJncB9HDDrNqnKuvtsTw0UeWKAo72G3ebNUtoY2d1q+3pnf16uXfgqIo8+btbZl0+eV2FluvXu6D/fHHq55/vjXje+EFu5ib3wG/KDt2qI4cqfrQQ0Wvu2WL6t//bs0MY9Vaavt2K13lVMds3GjVWS1aFH7rycKFNjiXVyRKBNdgN3xtAKYDO4Bp4awb6SHuEkFOs4wBA/YcVebNswMxWHvjbdvC29QPP9g6jz22d9rWrdbu+dhjc5+RL1um2r793vcYM8aqgPI269sfw4bZ9mbP3tvssFy5gqtZwrFjh+rtt1uyatLEzvCff97q3CPRrj+eZWVZqQgsQYoc3GftElskEsFP2HOL5wTjLYAPw1k30kNcJYJXXrGP+MILVTMydPt2ayJWtqxdM77sMpvdsuXeJoeFuewyqwPPafqX4z//0VxVHv/7n22/enXV8eMjtzsbNqgecog13ctpXvjii5HZdqIf9AvzzDOWBG67LdaRuHgWiUQwK/g7B6gQvJ4fzrqRHuImEbz1lv33duumumuXfvKJnfGCav/+e28C+vRTO9srX95a5xRUbbFihSWQ22/Pf37v3nvvdCxTxtqW//xz5Hfrvvt0T9XNVVeVvhvNSqoVKyJ3Udolpkgkgo+AGsBQ4HPgY2BSOOtGeoiLRPDxx9Y05fTTVbdt0+eft0+6WbP8W2mkp9vNJaB69tnWbC+vnAN8QX3i/Pbb3lvh+/a1KqNoWLvW7gZNTi7eC6jOuYNTWCII64ayPDclnA5UB/6r9uSxYlXibyibNg26d7cupadMYWNWNZo0sRt/Jk60G2Lyo2o3vtxxB+zaBYMGwZAhcPjhsGWL9VR9zjnwzjsFv/XkyXaTzYAB0b1ZZflyu8GoSpXovYdzLrIKu6FsvxNBrJXoRLB+PbRqBbVq2W2VNWty//3Wre8PP+R/J2Zeq1bBgw/CK6/YXZF33GHJY8gQu2OzY8fo74ZzrvTxRFBc+ve35w3PmgVt27JmDRx9tHVlUNiZfH6WLIH77tu7XufOdlu9c84diMISQQR7qUlwEyfCqFH2dI/gSWOPPAI7d9oZ/v465hh7gMb331s/KU88EeF4nXMu4CWCSNi0CY49Fg491I7c5cuzfDk0awZXXmnVPM45F0uFlQjCeni9K8Lf/maV+x99tKfryX/8wy7YDhkS49icc64IXjV0sKZMsVP+O++EE04ArGvhkSPhxhuttY9zzpVkUU0EItJNRBaLyBIRGZzP/AEiki4ic4LhmmjGE3Fbt8I111gd0NCheyYPGQKVK9vlAuecK+miVjUkIknAC8DZQBowS0TGq+qCPIu+o6o3RyuOqLrnHvjtN2sqWqkSYJcI3n8fHngA6tSJcXzOOReGaJYIOgJLVHVpcOPZWKBXFN+veC1aBC+8ADfcYG07sSdNnX++3Ubwl7/EOD7nnAtTNBPBEcCKkPG0YFpeF4rIXBF5X0TyrVEXkWtFJEVEUtLT06MR6/67+267tXboUFavhosvhp49oUYN+O9/4ZBDYh2gc86FJ9YXi/8DNFLV44FPgZH5LaSqL6tqsqom1ykJ9S1ffQXjxqF/u4tXP65Dy5YwfrzdQfz995Cc/1NBnXOuRIpmIlgJhJ7hNwim7aGq61R1VzD6KtAhivFEhqo9xfvwwxn4898ZNAiOP94eeF7Qg8udc64ki2YimAU0FZHGIlIe6AuMD11AROqFjPYEFkYxnsiYMAFmzmTb3Q/x5jvlGDgQpk+H5s1jHZhzzh2YqLUaUtVMEbkZ+ARIAl5X1fkiMgzrDnU8cKuI9AQygfXAgGjFExGZmTB4MDRrxsyj+5ORAZdcAmViXcHmnHMHIap3FqvqJGBSnmlDQl7fDcRPa/tRo2DBAvjgA6bMKEv58nDKKbEOyjnnDo6fy4Zrxw67U+ykk6B3b6ZOhZNPthvHnHMunnkiCNezz8LKlTB8OGvXCXPmwFlnxToo55w7eJ4IwpGeDv/8J5x3Hpx2GtOnW+OhM8+MdWDOOXfwPBGE4557YNs2eOwxAKZOhWrV9vQx55xzcc0TQVFSUuC11+C226BlS8ASQZcuUNY78XbOlQKeCAqTnQ233AJ16+55sMDy5fYYSa8Wcs6VFn5OW5jRo+Gbb2DEiD2dB02darM8ETjnSgsvERRk0ybrSuKkk+yhwYGpU+Gww+zJlM45Vxp4iaAgDz4If/xhXUoEtw6rWiI480x7DKVzzpUGXiLIz8KF8H//B1dfnasr0fnzYc0arxZyzpUungjyUrUWQlWqwCOP5JqVc33AbyRzzpUmXjWU17ffwqefwtNP7/OsySlT4Jhj4MgjYxSbc85FgZcI8nrrLahQAQYOzDU5MxM++8yrhZxzpY8nglCZmfDOO/DnP+/zrMlZs2DLFq8Wcs6VPp4IQk2bZi2FLr10n1lTplhLoa5dYxCXc85FkSeCUG++CdWrQ/fu+8yaOhXatoVatWIQl3PORZEnghw7dsCHH0KfPlCx4p7JW7daLxOffZZvfnDOubjnrYZyTJhgR/2QaqHPPoOrroLUVGtReu+9sQvPOeeixUsEOd56C+rVg9NPZ9s2KwV06WI3Fc+YAc88408jc86VTlFNBCLSTUQWi8gSERlcyHIXioiKSHJBy0TVhg0waRL07UvK7CTatIHnn4dbb4Uff4TTTotJVM45VyyiVjUkIknAC8DZQBowS0TGq+qCPMtVA24Dvo1WLEX64AN0925eLHsbf+lsncrNmAGnnx6ziJxzrthEs0TQEViiqktVdTcwFuiVz3IPAsOBnVGMpVCbR42jb9WJ3Pz4UZx9Nsye7UnAOZc4opkIjgBWhIynBdP2EJH2QENVnVjYhkTkWhFJEZGU9PT0iAb546drSP7iKT7Y1o3hw2H8eG8i6pxLLDG7WCwiZYCngL8WtayqvqyqyaqaXCdP/z8HY+FCOKlHLbZRheljVnLXXXt6nHbOuYQRzcPeSqBhyHiDYFqOasBxwAwRSQVOAsYX5wXjadNgZ2ZZPjvuZk69tGHRKzjnXCkUzfsIZgFNRaQxlgD6Ansa6avqJqB2zriIzADuVNWUKMaUy8KvN1KNMhw90C8IOOcSV9RKBKqaCdwMfAIsBN5V1fkiMkxEekbrfffHwh+205KFyLk9Yh2Kc87FTFTvLFbVScCkPNOGFLBsl2jGkp+FK6ryJ1kMTfbtZM455xJFwl4a3bQJVm09hJa106Gs97ThnEtcCZsIFi60v62axOz2BeecKxESNxHMywKgZZvyMY7EOediK2ETwYJvNlOBnTTuGLn7EpxzLh4lbOX4wrm7acYKklo2i3UozjkXUwlbIli4tAItWQjNm8c6FOeci6mETAQ7dsCydYfQstJy71jIOZfwEjIR/PwzKGVo2XBrrENxzrmYS8hEkNN0tGXL2MbhnHMlQWImgjm7KEMWzZIPiXUozjkXcwnZamhhyjYas56Kxx0T61Cccy7mErNEsFi8xZBzzgUSLhFkZsLPq6rRUhbD0UfHOhznnIu5hEsEy5bB7qyytKyzFsp79xLOOZdwiWBPi6FjMmIbiHPOlRCJlwgWZAPQsl3FGEfinHMlQ8K1GlqYsp16bKZ66yNjHYpzzpUIiVcimJflLYaccy5EVBOBiHQTkcUiskREBucz/3oR+UlE5ojITBFpFc14VGFhaiVPBM45FyJqiUBEkoAXgO5AK6BfPgf6t1S1taq2BR4DnopWPAC//w5bdpWnZYVlcPjh0Xwr55yLG9EsEXQElqjqUlXdDYwFeoUuoKqbQ0arABrFePY+nvKobSASzbdyzrm4Ec2LxUcAK0LG04AT8y4kIjcBfwHKA2fktyERuRa4FuDIIw/8Iu+epqPHJR3wNpxzrrSJ+cViVX1BVY8G/g7cV8AyL6tqsqom16lz4I+WXDg3gxps4LA2Xi3knHM5opkIVgINQ8YbBNMKMhY4P4rxsHDOTlqyEGnhF4qdcy5HNBPBLKCpiDQWkfJAX2B86AIi0jRk9FzglyjGw4JfynmLIeecyyNq1whUNVNEbgY+AZKA11V1vogMA1JUdTxws4icBWQAG4D+0Ypn/Xr4Y1NFSwRN+0XrbZxzLu5E9c5iVZ0ETMozbUjI69ui+f6h9lworrMOKlcurrd1zrkSL+YXi4vLnkTQLCu2gTjnXAmTMH0NVa6knFRmFke1qRHrUJxzrkRJmBLBpV1X8XX2iSS1bBbrUJxzrkRJmETA4sX211sMOedcLp4InHMuwSVOIqhXD84/Hxo0iHUkzjlXoiTMxWJ69bLBOedcLolTInDOOZcvTwTOOZfgPBE451yC80TgnHMJzhOBc84lOE8EzjmX4DwROOdcgvNE4JxzCU5UNdYx7BcRSQeWH+DqtYG1EQwn1krT/pSmfQHfn5KsNO0LhL8/R6lqvg99j7tEcDBEJEVVk2MdR6SUpv0pTfsCvj8lWWnaF4jM/njVkHPOJThPBM45l+ASLRG8HOsAIqw07U9p2hfw/SnJStO+QAT2J6GuETjnnNtXopUInHPO5eGJwDnnElzCJAIR6SYii0VkiYgMjnU8+0tEXheRP0RkXsi0miLyqYj8Evw9NJYxhktEGorIdBFZICLzReS2YHq87k9FEflORH4M9ucfwfTGIvJt8Jt7R0TKxzrWcIlIkojMFpEJwXg870uqiPwkInNEJCWYFq+/tRoi8r6ILBKRhSJyciT2JSESgYgkAS8A3YFWQD8RaRXbqPbbCKBbnmmDgamq2hSYGozHg0zgr6raCjgJuCn4PuJ1f3YBZ6hqG6At0E1ETgKGA0+r6jHABuDqGMa4v24DFoaMx/O+AHRV1bYh7e3j9bf2f8B/VbUF0Ab7jg5+X1S11A/AycAnIeN3A3fHOq4D2I9GwLyQ8cVAveB1PWBxrGM8wP36GDi7NOwPUBn4ATgRu9uzbDA912+wJA9Ag+CAcgYwAZB43Zcg3lSgdp5pcfdbA6oDywga+URyXxKiRAAcAawIGU8LpsW7w1R1VfB6NXBYLIM5ECLSCGgHfEsc709QlTIH+AP4FPgV2KiqmcEi8fSbewa4C8gOxmsRv/sCoMD/ROR7Ebk2mBaPv7XGQDrwRlBt96qIVCEC+5IoiaDUUzsdiKu2wCJSFfgAuF1VN4fOi7f9UdUsVW2LnU13BFrEOKQDIiLnAX+o6vexjiWCTlHV9ljV8E0iclrozDj6rZUF2gMvqWo7YBt5qoEOdF8SJRGsBBqGjDcIpsW7NSJSDyD4+0eM4wmbiJTDksCbqvphMDlu9yeHqm4EpmPVJzVEpGwwK15+c52BniKSCozFqof+j/jcFwBUdWXw9w/gIyxRx+NvLQ1IU9Vvg/H3scRw0PuSKIlgFtA0aPlQHugLjI9xTJEwHugfvO6P1bWXeCIiwGvAQlV9KmRWvO5PHRGpEbyuhF3vWIglhD7BYnGxP6p6t6o2UNVG2P/JNFW9jDjcFwARqSIi1XJeA38C5hGHvzVVXQ2sEJHmwaQzgQVEYl9ifQGkGC+09AB+xupu7411PAcQ/9vAKiADOzO4Gqu7nQr8AkwBasY6zjD35RSs+DoXmBMMPeJ4f44HZgf7Mw8YEkxvAnwHLAHeAyrEOtb93K8uwIR43pcg7h+DYX7O/34c/9baAinBb20ccGgk9sW7mHDOuQSXKFVDzjnnCuCJwDnnEpwnAuecS3CeCJxzLsF5InDOuQTnicC5YiQiXXJ69HSupPBE4JxzCc4TgXP5EJHLg2cMzBGRfwedym0VkaeDZw5MFZE6wbJtReQbEZkrIh/l9AcvIseIyJTgOQU/iMjRwearhvQp/2Zwp7VzMeOJwLk8RKQlcAnQWa0juSzgMqAKkKKqxwKfAQ8Eq4wC/q6qxwM/hUx/E3hB7TkFnbA7w8F6W70dezZGE6x/H+dipmzRiziXcM4EOgCzgpP1SlhHXtnAO8EyY4APRaQ6UENVPwumjwTeC/q3OUJVPwJQ1Z0Awfa+U9W0YHwO9pyJmdHfLefy54nAuX0JMFJV7841UeT+PMsdaP8su0JeZ+H/hy7GvGrIuX1NBfqISF3Y83zbo7D/l5weOC8FZqrqJmCDiJwaTL8C+ExVtwBpInJ+sI0KIlK5WPfCuTD5mYhzeajqAhG5D3uqVRmsx9ebsAeBdAzm/YFdRwDr+vdfwYF+KXBVMP0K4N8iMizYxkXFuBvOhc17H3UuTCKyVVWrxjoO5yLNq4accy7BeYnAOecSnJcInHMuwXkicM65BOeJwDnnEpwnAuecS3CeCJxzLsH9P/HLYeLqdYI/AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_LxatO5J-pp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c435e3d7-b840-47f8-c1da-5c4e4021633f"
      },
      "source": [
        "testloss = model.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "trainloss = model.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(trainloss[0]))\n",
        "print(\"Train Acc: \" + str(trainloss[1]))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 3s 27ms/step - loss: 2.4358 - accuracy: 0.5787\n",
            "Test Loss 2.4358339309692383\n",
            "Test Acc: 0.5787127614021301\n",
            "898/898 [==============================] - 25s 27ms/step - loss: 0.1051 - accuracy: 0.9644\n",
            "Train Loss 0.10514110326766968\n",
            "Train Acc: 0.9644362330436707\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swoRERVdKQ1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02145230-a3ba-4871-f338-5bb76236d697"
      },
      "source": [
        "testlosz = model.evaluate(x_val, y_val) \n",
        "print(\"val Loss \" + str(testlosz[0]))\n",
        "print(\"val Acc: \" + str(testlosz[1]))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 3s 27ms/step - loss: 2.5634 - accuracy: 0.5737\n",
            "val Loss 2.5633533000946045\n",
            "val Acc: 0.5736973881721497\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5iaZIU6pPzk",
        "outputId": "04954f7c-6978-433a-a077-870c1250a311"
      },
      "source": [
        "from keras.models import load_model\n",
        "model_load = load_model('/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_seed_adam_shuffalse_noAug1.h5')\n",
        "\n",
        "model_load.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 46, 46, 128)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 46, 46, 128)  0           activation_3[0][0]               \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 46, 46, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 46, 46, 128)  0           activation_6[0][0]               \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 46, 46, 128)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 23, 23, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 23, 23, 256)  0           activation_12[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 23, 23, 256)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 23, 23, 256)  0           activation_15[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 23, 23, 256)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 23, 23, 256)  0           activation_18[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 23, 23, 256)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 12, 12, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 12, 12, 512)  0           activation_24[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 12, 12, 512)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 12, 12, 512)  0           activation_27[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 12, 12, 512)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 12, 12, 512)  0           activation_30[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 12, 12, 512)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 12, 12, 512)  0           activation_33[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 12, 12, 512)  0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 12, 12, 512)  0           activation_36[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 12, 12, 512)  0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 6, 6, 1024)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 6, 6, 1024)   0           activation_42[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 6, 6, 1024)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 6, 6, 1024)   0           activation_45[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 6, 6, 1024)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypc8clklx2p8",
        "outputId": "95f671da-390a-4a9f-9a2f-47e47cd4a737"
      },
      "source": [
        "#loss,acc = model_load.evaluate(xtrain,ytrain)\n",
        "\"\"\"print(\"loss:\",loss)\n",
        "print(\"acc:\",acc)kjjkj\"\"\"\n",
        "\n",
        "\n",
        "testdatamodel = model_load.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testdatamodel[0]))\n",
        "print(\"Test Acc: \" + str(testdatamodel[1]))\n",
        "\n",
        "traindata = model_load.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(traindata[0]))\n",
        "print(\"Train Acc: \" + str(traindata[1]))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 7s 27ms/step - loss: 2.4358 - accuracy: 0.5787\n",
            "Test Loss 2.4358339309692383\n",
            "Test Acc: 0.5787127614021301\n",
            "898/898 [==============================] - 24s 27ms/step - loss: 0.1051 - accuracy: 0.9644\n",
            "Train Loss 0.10514110326766968\n",
            "Train Acc: 0.9644362330436707\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7mSww_U2O_q",
        "outputId": "68e2d2f1-2c1a-4b18-cd43-8eafc0b6110b"
      },
      "source": [
        "valdata = model_load.evaluate(x_val, y_val) \n",
        "print(\"Val Loss \" + str(valdata[0]))\n",
        "print(\"Val Acc: \" + str(valdata[1]))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 3s 27ms/step - loss: 2.5634 - accuracy: 0.5737\n",
            "Val Loss 2.5633533000946045\n",
            "Val Acc: 0.5736973881721497\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdU7uU3PYCnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e995b823-5159-49de-ff4d-0f41b6df83c1"
      },
      "source": [
        "print (x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3589, 48, 48, 1)\n",
            "(3589,)\n",
            "(3589, 48, 48, 1)\n",
            "(3589,)\n",
            "(28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_Tf1qg8TKnx",
        "outputId": "842d3ab7-fd1f-494a-feaa-3786afbe6823"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "#y_pred = model_load.predict(xtest)\n",
        "\n",
        "test_prob = model_load.predict(xtest)\n",
        "test_pred = np.argmax(test_prob, axis=1)\n",
        "test_accuracy = np.mean(test_pred == ytest)\n",
        "\n",
        "print(test_accuracy)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5787127333519086\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpwJv9V54_1M"
      },
      "source": [
        "\n",
        "emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "KMe4WL0T5BcJ",
        "outputId": "fb4e63f8-3b21-4935-d276-831299e847e7"
      },
      "source": [
        "conf_mat = confusion_matrix(ytest, test_pred)\n",
        "\n",
        "pd.DataFrame(conf_mat, columns=emotions.values(), index=emotions.values())\n",
        "\n",
        "#ghg\n",
        "\n",
        "fig, ax = plot_confusion_matrix(conf_mat=conf_mat,show_normed=True,show_absolute=False,figsize=(8, 8))\n",
        "fig.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW3FZjp-5DgF",
        "outputId": "6793c1d0-acc1-4f98-dcad-fc7aab298760"
      },
      "source": [
        "print(classification_report(ytest, test_pred, target_names=emotions.values()))\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry       0.54      0.35      0.43       480\n",
            "     Disgust       0.66      0.35      0.46        60\n",
            "        Fear       0.42      0.42      0.42       515\n",
            "       Happy       0.81      0.76      0.78       883\n",
            "         Sad       0.46      0.44      0.45       597\n",
            "    Surprise       0.62      0.84      0.72       397\n",
            "     Neutral       0.51      0.61      0.56       657\n",
            "\n",
            "    accuracy                           0.58      3589\n",
            "   macro avg       0.57      0.54      0.54      3589\n",
            "weighted avg       0.58      0.58      0.57      3589\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}