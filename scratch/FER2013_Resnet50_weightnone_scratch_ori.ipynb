{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER2013_Resnet50_weightnone_scratch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "18Zj-Yp1YlH0QWcuD4e7ugx8zCCcRS0jg",
      "authorship_tag": "ABX9TyNnFOBMn4755F37Q/K3m7Sj"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eWeoD7MRFlN",
        "outputId": "0ffe6dcc-3cd2-478a-c059-98e1992053f7"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "inputFolder = '/content/drive/MyDrive/Fer2013_backup/' \n",
        "for root, directories, filenames in os.walk(inputFolder): \n",
        "    for filename in filenames: print(os.path.join(root,filename))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Fer2013_backup/backUpfer2013.csv\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/best_model_resnet50_modelB2_170false.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/best_model_resnet50_modelD2_170false.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50Scracth_tipe7.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50Scracth_tipe8.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH8iEUJiRQS7",
        "outputId": "f1402ea2-e765-4ef8-8b84-539d5fa992f1"
      },
      "source": [
        "%cd /content/drive/MyDrive/Fer2013_backup/\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Fer2013_backup\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqZOFwxxRQaa",
        "outputId": "2d175eae-2de1-4375-e64b-f5a3789bdbc4"
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:400: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUX-dSAgRQh4"
      },
      "source": [
        "#Define the identity block helper function.\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "   \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbdQH3mkRQra"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path \n",
        "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b',padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33XH76oKRQvh"
      },
      "source": [
        "\"\"\"def ResNet50(input_shape = (48,48,1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    #X = ZeroPadding2D((1, 1))(X_input)\n",
        "    X = X_input\n",
        "    # Stage 1\n",
        "\n",
        "    X = Conv2D(8, (3, 3), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # removed maxpool\n",
        "    #X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='c')\n",
        "\n",
        "\n",
        "    # Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [64,64,256], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL . \n",
        "    X = AveragePooling2D((2,2), name='avg_pool')(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(512, activation = 'relu', name='fc1024' , kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWuYK_f2zGJF"
      },
      "source": [
        "def ResNet50ori(input_shape = (48, 48, 1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50ori')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QQOxN2cRQy3"
      },
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        " \n",
        "dataset_path = '/content/drive/MyDrive/Fer2013_backup/backUpfer2013.csv'\n",
        "image_size=(48,48)\n",
        "\n",
        "def load_fer2013():\n",
        "    data = pd.read_csv(dataset_path)\n",
        "    data = (data[data['pixels'].notnull()])\n",
        "    pixels = data['pixels'].tolist()\n",
        "    width, height = 48, 48\n",
        "    faces = []\n",
        "    for pixel_sequence in pixels:\n",
        "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "        face = np.asarray(face).reshape(width, height)\n",
        "        face = cv2.resize(face.astype('uint8'),image_size)\n",
        "        faces.append(face.astype('float32'))\n",
        "    faces = np.asarray(faces)\n",
        "    faces = np.expand_dims(faces, -1)\n",
        "    emotions = (data['emotion'])#.values\n",
        "    return faces, emotions\n",
        " \n",
        "def preprocess_input(x, v2=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if v2:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x\n",
        " \n",
        "faces, emotions = load_fer2013()\n",
        "faces = preprocess_input(faces)\n",
        "#xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
        "#Data Augumentation\n",
        "data_generator = ImageDataGenerator(\n",
        "                        rotation_range=10,\n",
        "                        shear_range = 10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        vertical_flip=True,\n",
        "                        horizontal_flip=True)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkXj6h650EVO"
      },
      "source": [
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.1, train_size=0.9)\n",
        "x_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1, train_size=0.9)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ofOj3-fRREN"
      },
      "source": [
        "#hyperparameter and callback\n",
        "batch_size = 64\n",
        "num_epochs = 60\n",
        "input_shape = (48, 48, 1)\n",
        "num_classes = 7\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXikieAnRbYs"
      },
      "source": [
        "#Compile the model.\n",
        "\n",
        "\n",
        "from keras.optimizers import Adam, SGD\n",
        "model = ResNet50ori(input_shape = (48, 48, 1), classes = 7)\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer= optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5JTFulCRbiX"
      },
      "source": [
        "#kita mau save model callbacks\n",
        "import os\n",
        "try:\n",
        "  os.mkdir('/content/drive/MyDrive/Fer2013_backup/scratchcheckpoint')\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkceBySwRgFO"
      },
      "source": [
        "file_name = 'Best_Model_resnet50oriScracth_aug_tipe2.h5'\n",
        "\n",
        "checkpoint_path = os.path.join('checkpoint',file_name)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an3sDjjGRgO1"
      },
      "source": [
        "call_back = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
        "                                               monitor='val_accuracy',\n",
        "                                               verbose=1,\n",
        "                                               save_freq='epoch',\n",
        "                                               save_best_only=True,\n",
        "                                               save_weights_only=False,\n",
        "                                               mode='max')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nefC0ZE8RgX5",
        "outputId": "d2acd80c-f51f-4a02-87b4-335be2932c42"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50ori\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPadding2D (None, 54, 54, 1)    0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 24, 24, 64)   3200        zero_padding2d_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 24, 24, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 24, 24, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 11, 11, 64)   0           activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 11, 11, 64)   4160        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 11, 11, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 11, 11, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 11, 11, 256)  16640       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 11, 11, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 11, 11, 256)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 11, 11, 256)  0           add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 11, 11, 64)   16448       activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 11, 11, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 11, 11, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_33 (Add)                    (None, 11, 11, 256)  0           activation_101[0][0]             \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 11, 11, 256)  0           add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 11, 11, 64)   16448       activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 11, 11, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 11, 11, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, 11, 11, 256)  0           activation_104[0][0]             \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 11, 11, 256)  0           add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 6, 6, 128)    32896       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 6, 6, 128)    0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 6, 6, 128)    0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 6, 6, 512)    131584      activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 6, 6, 512)    2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_35 (Add)                    (None, 6, 6, 512)    0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 6, 6, 512)    0           add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 6, 6, 128)    0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 6, 6, 128)    0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_36 (Add)                    (None, 6, 6, 512)    0           activation_110[0][0]             \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 6, 6, 512)    0           add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 6, 6, 128)    0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 6, 6, 128)    0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_37 (Add)                    (None, 6, 6, 512)    0           activation_113[0][0]             \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 6, 6, 512)    0           add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 6, 6, 128)    0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 6, 6, 128)    0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_38 (Add)                    (None, 6, 6, 512)    0           activation_116[0][0]             \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 6, 6, 512)    0           add_38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 3, 3, 256)    131328      activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 3, 3, 256)    0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 3, 3, 256)    0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 3, 3, 1024)   525312      activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 3, 3, 1024)   4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_39 (Add)                    (None, 3, 3, 1024)   0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 3, 3, 1024)   0           add_39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 3, 3, 256)    0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 3, 3, 256)    0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_40 (Add)                    (None, 3, 3, 1024)   0           activation_122[0][0]             \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 3, 3, 1024)   0           add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 3, 3, 256)    0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 3, 3, 256)    0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_41 (Add)                    (None, 3, 3, 1024)   0           activation_125[0][0]             \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 3, 3, 1024)   0           add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 3, 3, 256)    0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 3, 3, 256)    0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_42 (Add)                    (None, 3, 3, 1024)   0           activation_128[0][0]             \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 3, 3, 1024)   0           add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 3, 3, 256)    0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 3, 3, 256)    0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_43 (Add)                    (None, 3, 3, 1024)   0           activation_131[0][0]             \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 3, 3, 1024)   0           add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 3, 3, 256)    0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 3, 3, 256)    0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_44 (Add)                    (None, 3, 3, 1024)   0           activation_134[0][0]             \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 3, 3, 1024)   0           add_44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 2, 2, 512)    524800      activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 2, 2, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 2, 2, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 2, 2, 2048)   2099200     activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 2, 2, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_45 (Add)                    (None, 2, 2, 2048)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 2, 2, 2048)   0           add_45[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 2, 2, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 2, 2, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_46 (Add)                    (None, 2, 2, 2048)   0           activation_140[0][0]             \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 2, 2, 2048)   0           add_46[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 2, 2, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 2, 2, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_47 (Add)                    (None, 2, 2, 2048)   0           activation_143[0][0]             \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 2, 2, 2048)   0           add_47[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 2048)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            14343       flatten_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 23,595,783\n",
            "Trainable params: 23,542,663\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVvpTr7-RkdR",
        "outputId": "11449831-e29f-40d1-ecb4-ad15c6c44e62"
      },
      "source": [
        "\"\"\"history = model.fit(data_generator.flow(xtrain, ytrain,),\n",
        "                        steps_per_epoch=len(xtrain) / batch_size,\n",
        "                        epochs=num_epochs, verbose=1,callbacks=call_back,\n",
        "                        validation_data= (xtest,ytest))\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "448/448 [==============================] - 65s 122ms/step - loss: 2.2037 - accuracy: 0.2000 - val_loss: 1.8522 - val_accuracy: 0.2421\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.24213, saving model to checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 1.9323 - accuracy: 0.2191 - val_loss: 2.1617 - val_accuracy: 0.2207\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.24213\n",
            "Epoch 3/50\n",
            "448/448 [==============================] - 51s 115ms/step - loss: 1.8758 - accuracy: 0.2435 - val_loss: 2.0316 - val_accuracy: 0.2268\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.24213\n",
            "Epoch 4/50\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 1.8396 - accuracy: 0.2415 - val_loss: 1.9659 - val_accuracy: 0.2403\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.24213\n",
            "Epoch 5/50\n",
            "448/448 [==============================] - 51s 115ms/step - loss: 1.8367 - accuracy: 0.2446 - val_loss: 1.9846 - val_accuracy: 0.2366\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.24213\n",
            "Epoch 6/50\n",
            "448/448 [==============================] - 56s 124ms/step - loss: 1.8225 - accuracy: 0.2417 - val_loss: 1.9875 - val_accuracy: 0.2434\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.24213 to 0.24338, saving model to checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "Epoch 7/50\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 1.7984 - accuracy: 0.2575 - val_loss: 1.9273 - val_accuracy: 0.2601\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.24338 to 0.26010, saving model to checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "Epoch 8/50\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 1.7929 - accuracy: 0.2571 - val_loss: 1.8984 - val_accuracy: 0.2502\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.26010\n",
            "Epoch 9/50\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 1.7853 - accuracy: 0.2614 - val_loss: 1.8847 - val_accuracy: 0.2512\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.26010\n",
            "Epoch 10/50\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 1.7824 - accuracy: 0.2696 - val_loss: 1.8467 - val_accuracy: 0.2637\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.26010 to 0.26372, saving model to checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "Epoch 11/50\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 1.7648 - accuracy: 0.2770 - val_loss: 1.8403 - val_accuracy: 0.2740\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.26372 to 0.27403, saving model to checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "Epoch 12/50\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 1.7604 - accuracy: 0.2836 - val_loss: 1.7919 - val_accuracy: 0.2813\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.27403 to 0.28128, saving model to checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "Epoch 13/50\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 1.7526 - accuracy: 0.2837 - val_loss: 1.7943 - val_accuracy: 0.2867\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.28128 to 0.28671, saving model to checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "Epoch 14/50\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 1.7442 - accuracy: 0.2862 - val_loss: 1.7921 - val_accuracy: 0.2867\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.28671\n",
            "Epoch 15/50\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 1.7349 - accuracy: 0.3044 - val_loss: 1.7786 - val_accuracy: 0.3015\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.28671 to 0.30148, saving model to checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "Epoch 16/50\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 1.7286 - accuracy: 0.3013 - val_loss: 1.7973 - val_accuracy: 0.2907\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.30148\n",
            "Epoch 17/50\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.7191 - accuracy: 0.3055 - val_loss: 1.7580 - val_accuracy: 0.3012\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.30148\n",
            "Epoch 18/50\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.7042 - accuracy: 0.3203 - val_loss: 1.7343 - val_accuracy: 0.3169\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.30148 to 0.31694, saving model to checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "Epoch 19/50\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 1.7059 - accuracy: 0.3144 - val_loss: 1.7291 - val_accuracy: 0.3133\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.31694\n",
            "Epoch 20/50\n",
            "448/448 [==============================] - 55s 124ms/step - loss: 1.6789 - accuracy: 0.3315 - val_loss: 1.7038 - val_accuracy: 0.3292\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.31694 to 0.32920, saving model to checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "Epoch 21/50\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 1.6888 - accuracy: 0.3214 - val_loss: 1.7362 - val_accuracy: 0.3242\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.32920\n",
            "Epoch 22/50\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.6799 - accuracy: 0.3274 - val_loss: 1.7108 - val_accuracy: 0.3383\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.32920 to 0.33826, saving model to checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "Epoch 23/50\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 1.6719 - accuracy: 0.3399 - val_loss: 1.6873 - val_accuracy: 0.3357\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.33826\n",
            "Epoch 24/50\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 1.6615 - accuracy: 0.3390 - val_loss: 1.7021 - val_accuracy: 0.3366\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.33826\n",
            "Epoch 25/50\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.6339 - accuracy: 0.3560 - val_loss: 1.7363 - val_accuracy: 0.3155\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.33826\n",
            "Epoch 26/50\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.6421 - accuracy: 0.3476 - val_loss: 1.6750 - val_accuracy: 0.3423\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.33826 to 0.34230, saving model to checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "Epoch 27/50\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.6272 - accuracy: 0.3605 - val_loss: 1.6422 - val_accuracy: 0.3640\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.34230 to 0.36403, saving model to checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "Epoch 28/50\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.6160 - accuracy: 0.3723 - val_loss: 1.6246 - val_accuracy: 0.3663\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.36403 to 0.36626, saving model to checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "Epoch 29/50\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.6172 - accuracy: 0.3617 - val_loss: 1.6089 - val_accuracy: 0.3741\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.36626 to 0.37406, saving model to checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "Epoch 30/50\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 1.5968 - accuracy: 0.3776 - val_loss: 1.5940 - val_accuracy: 0.3770\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.37406 to 0.37699, saving model to checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "Epoch 31/50\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.5946 - accuracy: 0.3780 - val_loss: 1.6182 - val_accuracy: 0.3658\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.37699\n",
            "Epoch 32/50\n",
            "448/448 [==============================] - 55s 121ms/step - loss: 1.5748 - accuracy: 0.3859 - val_loss: 1.6358 - val_accuracy: 0.3608\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.37699\n",
            "Epoch 33/50\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.5793 - accuracy: 0.3804 - val_loss: 1.5892 - val_accuracy: 0.3848\n",
            "\n",
            "Epoch 00033: val_accuracy improved from 0.37699 to 0.38479, saving model to checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "Epoch 34/50\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.5550 - accuracy: 0.3955 - val_loss: 1.5574 - val_accuracy: 0.4016\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.38479 to 0.40164, saving model to checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "Epoch 35/50\n",
            "448/448 [==============================] - 55s 122ms/step - loss: 1.5469 - accuracy: 0.3924 - val_loss: 1.5700 - val_accuracy: 0.4004\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.40164\n",
            "Epoch 36/50\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.5256 - accuracy: 0.4115 - val_loss: 1.5577 - val_accuracy: 0.3904\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.40164\n",
            "Epoch 37/50\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 1.5384 - accuracy: 0.3979 - val_loss: 1.5474 - val_accuracy: 0.3980\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.40164\n",
            "Epoch 38/50\n",
            "448/448 [==============================] - 56s 124ms/step - loss: 1.5164 - accuracy: 0.4085 - val_loss: 1.5193 - val_accuracy: 0.4133\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.40164 to 0.41335, saving model to checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "Epoch 39/50\n",
            "448/448 [==============================] - 56s 124ms/step - loss: 1.5152 - accuracy: 0.4137 - val_loss: 1.5291 - val_accuracy: 0.4071\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.41335\n",
            "Epoch 40/50\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 1.5017 - accuracy: 0.4225 - val_loss: 1.5037 - val_accuracy: 0.4153\n",
            "\n",
            "Epoch 00040: val_accuracy improved from 0.41335 to 0.41530, saving model to checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "Epoch 41/50\n",
            "448/448 [==============================] - 56s 124ms/step - loss: 1.4817 - accuracy: 0.4263 - val_loss: 1.5207 - val_accuracy: 0.4089\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.41530\n",
            "Epoch 42/50\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.4934 - accuracy: 0.4222 - val_loss: 1.4833 - val_accuracy: 0.4260\n",
            "\n",
            "Epoch 00042: val_accuracy improved from 0.41530 to 0.42602, saving model to checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "Epoch 43/50\n",
            "448/448 [==============================] - 55s 122ms/step - loss: 1.4705 - accuracy: 0.4330 - val_loss: 1.5298 - val_accuracy: 0.4072\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.42602\n",
            "Epoch 44/50\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.4537 - accuracy: 0.4402 - val_loss: 1.4667 - val_accuracy: 0.4330\n",
            "\n",
            "Epoch 00044: val_accuracy improved from 0.42602 to 0.43299, saving model to checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "Epoch 45/50\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.4580 - accuracy: 0.4343 - val_loss: 1.4737 - val_accuracy: 0.4288\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.43299\n",
            "Epoch 46/50\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.4493 - accuracy: 0.4342 - val_loss: 1.5012 - val_accuracy: 0.4259\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.43299\n",
            "Epoch 47/50\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.4309 - accuracy: 0.4492 - val_loss: 1.4657 - val_accuracy: 0.4344\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.43299 to 0.43438, saving model to checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "Epoch 48/50\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.4289 - accuracy: 0.4413 - val_loss: 1.4330 - val_accuracy: 0.4409\n",
            "\n",
            "Epoch 00048: val_accuracy improved from 0.43438 to 0.44093, saving model to checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "Epoch 49/50\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 1.4104 - accuracy: 0.4547 - val_loss: 1.4492 - val_accuracy: 0.4413\n",
            "\n",
            "Epoch 00049: val_accuracy improved from 0.44093 to 0.44135, saving model to checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "Epoch 50/50\n",
            "448/448 [==============================] - 56s 124ms/step - loss: 1.4136 - accuracy: 0.4613 - val_loss: 1.5121 - val_accuracy: 0.4220\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.44135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_tXyjuSz_IP",
        "outputId": "d7cbb0a8-68da-4a81-d025-b86ef9b2b6b0"
      },
      "source": [
        "history = model.fit(\n",
        "    data_generator.flow(xtrain, ytrain,),\n",
        "    steps_per_epoch=len(xtrain) / batch_size,\n",
        "    epochs=num_epochs, \n",
        "    verbose=1,\n",
        "    callbacks=call_back,\n",
        "    validation_data= (x_val,y_val))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "504/504 [==============================] - 41s 61ms/step - loss: 2.1509 - accuracy: 0.2148 - val_loss: 1.8066 - val_accuracy: 0.2449\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.24489, saving model to checkpoint/Best_Model_resnet50oriScracth_aug_tipe2.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/60\n",
            "504/504 [==============================] - 27s 53ms/step - loss: 1.9520 - accuracy: 0.2377 - val_loss: 3.2820 - val_accuracy: 0.2703\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.24489 to 0.27028, saving model to checkpoint/Best_Model_resnet50oriScracth_aug_tipe2.h5\n",
            "Epoch 3/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.8832 - accuracy: 0.2556 - val_loss: 2.0415 - val_accuracy: 0.2771\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.27028 to 0.27709, saving model to checkpoint/Best_Model_resnet50oriScracth_aug_tipe2.h5\n",
            "Epoch 4/60\n",
            "504/504 [==============================] - 28s 55ms/step - loss: 1.8360 - accuracy: 0.2692 - val_loss: 2.4873 - val_accuracy: 0.2882\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.27709 to 0.28824, saving model to checkpoint/Best_Model_resnet50oriScracth_aug_tipe2.h5\n",
            "Epoch 5/60\n",
            "504/504 [==============================] - 28s 55ms/step - loss: 1.8139 - accuracy: 0.2713 - val_loss: 2.0281 - val_accuracy: 0.2854\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.28824\n",
            "Epoch 6/60\n",
            "504/504 [==============================] - 28s 55ms/step - loss: 1.7794 - accuracy: 0.2873 - val_loss: 2.3869 - val_accuracy: 0.3220\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.28824 to 0.32198, saving model to checkpoint/Best_Model_resnet50oriScracth_aug_tipe2.h5\n",
            "Epoch 7/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.7669 - accuracy: 0.3104 - val_loss: 1.9057 - val_accuracy: 0.3368\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.32198 to 0.33684, saving model to checkpoint/Best_Model_resnet50oriScracth_aug_tipe2.h5\n",
            "Epoch 8/60\n",
            "504/504 [==============================] - 28s 55ms/step - loss: 1.7229 - accuracy: 0.3219 - val_loss: 1.6692 - val_accuracy: 0.3523\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.33684 to 0.35232, saving model to checkpoint/Best_Model_resnet50oriScracth_aug_tipe2.h5\n",
            "Epoch 9/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.6918 - accuracy: 0.3396 - val_loss: 1.8029 - val_accuracy: 0.3492\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.35232\n",
            "Epoch 10/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.6754 - accuracy: 0.3590 - val_loss: 1.9067 - val_accuracy: 0.3898\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.35232 to 0.38978, saving model to checkpoint/Best_Model_resnet50oriScracth_aug_tipe2.h5\n",
            "Epoch 11/60\n",
            "504/504 [==============================] - 29s 58ms/step - loss: 1.6399 - accuracy: 0.3717 - val_loss: 1.9000 - val_accuracy: 0.4090\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.38978 to 0.40898, saving model to checkpoint/Best_Model_resnet50oriScracth_aug_tipe2.h5\n",
            "Epoch 12/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.6229 - accuracy: 0.3777 - val_loss: 1.7497 - val_accuracy: 0.4328\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.40898 to 0.43282, saving model to checkpoint/Best_Model_resnet50oriScracth_aug_tipe2.h5\n",
            "Epoch 13/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.5999 - accuracy: 0.3955 - val_loss: 1.7314 - val_accuracy: 0.4090\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.43282\n",
            "Epoch 14/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.5786 - accuracy: 0.3924 - val_loss: 1.9386 - val_accuracy: 0.4121\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.43282\n",
            "Epoch 15/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.5638 - accuracy: 0.4001 - val_loss: 2.1112 - val_accuracy: 0.4053\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.43282\n",
            "Epoch 16/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.5544 - accuracy: 0.4028 - val_loss: 3.5443 - val_accuracy: 0.4093\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.43282\n",
            "Epoch 17/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.5340 - accuracy: 0.4129 - val_loss: 2.1541 - val_accuracy: 0.4214\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.43282\n",
            "Epoch 18/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.5090 - accuracy: 0.4237 - val_loss: 1.4781 - val_accuracy: 0.4498\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.43282 to 0.44985, saving model to checkpoint/Best_Model_resnet50oriScracth_aug_tipe2.h5\n",
            "Epoch 19/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.4934 - accuracy: 0.4249 - val_loss: 2.4555 - val_accuracy: 0.4449\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.44985\n",
            "Epoch 20/60\n",
            "504/504 [==============================] - 30s 59ms/step - loss: 1.5180 - accuracy: 0.4203 - val_loss: 2.9188 - val_accuracy: 0.4176\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.44985\n",
            "Epoch 21/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.4715 - accuracy: 0.4395 - val_loss: 1.5109 - val_accuracy: 0.4483\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.44985\n",
            "Epoch 22/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.4612 - accuracy: 0.4433 - val_loss: 1.3648 - val_accuracy: 0.4734\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.44985 to 0.47337, saving model to checkpoint/Best_Model_resnet50oriScracth_aug_tipe2.h5\n",
            "Epoch 23/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.4414 - accuracy: 0.4514 - val_loss: 1.3605 - val_accuracy: 0.4802\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.47337 to 0.48019, saving model to checkpoint/Best_Model_resnet50oriScracth_aug_tipe2.h5\n",
            "Epoch 24/60\n",
            "504/504 [==============================] - 29s 57ms/step - loss: 1.4226 - accuracy: 0.4592 - val_loss: 1.5358 - val_accuracy: 0.4542\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.48019\n",
            "Epoch 25/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.3881 - accuracy: 0.4638 - val_loss: 1.6355 - val_accuracy: 0.4334\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.48019\n",
            "Epoch 26/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.4089 - accuracy: 0.4586 - val_loss: 1.3118 - val_accuracy: 0.4941\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.48019 to 0.49412, saving model to checkpoint/Best_Model_resnet50oriScracth_aug_tipe2.h5\n",
            "Epoch 27/60\n",
            "504/504 [==============================] - 30s 59ms/step - loss: 1.3675 - accuracy: 0.4685 - val_loss: 1.3053 - val_accuracy: 0.4969\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.49412 to 0.49690, saving model to checkpoint/Best_Model_resnet50oriScracth_aug_tipe2.h5\n",
            "Epoch 28/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.3487 - accuracy: 0.4861 - val_loss: 1.3014 - val_accuracy: 0.5059\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.49690 to 0.50588, saving model to checkpoint/Best_Model_resnet50oriScracth_aug_tipe2.h5\n",
            "Epoch 29/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.3590 - accuracy: 0.4827 - val_loss: 1.2650 - val_accuracy: 0.5161\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.50588 to 0.51610, saving model to checkpoint/Best_Model_resnet50oriScracth_aug_tipe2.h5\n",
            "Epoch 30/60\n",
            "504/504 [==============================] - 29s 57ms/step - loss: 1.3311 - accuracy: 0.4914 - val_loss: 1.3014 - val_accuracy: 0.5022\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.51610\n",
            "Epoch 31/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.2988 - accuracy: 0.5064 - val_loss: 1.3175 - val_accuracy: 0.4941\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.51610\n",
            "Epoch 32/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.3142 - accuracy: 0.4959 - val_loss: 1.3543 - val_accuracy: 0.4901\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.51610\n",
            "Epoch 33/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.3110 - accuracy: 0.4930 - val_loss: 1.3880 - val_accuracy: 0.4721\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.51610\n",
            "Epoch 34/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.3288 - accuracy: 0.4913 - val_loss: 1.2480 - val_accuracy: 0.5257\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.51610 to 0.52570, saving model to checkpoint/Best_Model_resnet50oriScracth_aug_tipe2.h5\n",
            "Epoch 35/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.3453 - accuracy: 0.4963 - val_loss: 1.4961 - val_accuracy: 0.4954\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.52570\n",
            "Epoch 36/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.2865 - accuracy: 0.5094 - val_loss: 1.2081 - val_accuracy: 0.5424\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.52570 to 0.54241, saving model to checkpoint/Best_Model_resnet50oriScracth_aug_tipe2.h5\n",
            "Epoch 37/60\n",
            "504/504 [==============================] - 30s 59ms/step - loss: 1.2628 - accuracy: 0.5231 - val_loss: 1.2157 - val_accuracy: 0.5365\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.54241\n",
            "Epoch 38/60\n",
            "504/504 [==============================] - 30s 59ms/step - loss: 1.2577 - accuracy: 0.5184 - val_loss: 1.1683 - val_accuracy: 0.5557\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.54241 to 0.55573, saving model to checkpoint/Best_Model_resnet50oriScracth_aug_tipe2.h5\n",
            "Epoch 39/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.2401 - accuracy: 0.5278 - val_loss: 1.2058 - val_accuracy: 0.5443\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.55573\n",
            "Epoch 40/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.2656 - accuracy: 0.5189 - val_loss: 1.2160 - val_accuracy: 0.5350\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.55573\n",
            "Epoch 41/60\n",
            "504/504 [==============================] - 29s 58ms/step - loss: 1.2486 - accuracy: 0.5225 - val_loss: 1.3439 - val_accuracy: 0.5183\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.55573\n",
            "Epoch 42/60\n",
            "504/504 [==============================] - 29s 57ms/step - loss: 1.2646 - accuracy: 0.5186 - val_loss: 1.1904 - val_accuracy: 0.5604\n",
            "\n",
            "Epoch 00042: val_accuracy improved from 0.55573 to 0.56037, saving model to checkpoint/Best_Model_resnet50oriScracth_aug_tipe2.h5\n",
            "Epoch 43/60\n",
            "504/504 [==============================] - 29s 57ms/step - loss: 1.2447 - accuracy: 0.5277 - val_loss: 1.2225 - val_accuracy: 0.5254\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.56037\n",
            "Epoch 44/60\n",
            "504/504 [==============================] - 30s 59ms/step - loss: 1.2349 - accuracy: 0.5312 - val_loss: 1.1927 - val_accuracy: 0.5471\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.56037\n",
            "Epoch 45/60\n",
            "504/504 [==============================] - 29s 58ms/step - loss: 1.2188 - accuracy: 0.5368 - val_loss: 1.2712 - val_accuracy: 0.5130\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.56037\n",
            "Epoch 46/60\n",
            "504/504 [==============================] - 29s 58ms/step - loss: 1.2474 - accuracy: 0.5236 - val_loss: 1.1696 - val_accuracy: 0.5585\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.56037\n",
            "Epoch 47/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.2076 - accuracy: 0.5442 - val_loss: 1.2362 - val_accuracy: 0.5443\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.56037\n",
            "Epoch 48/60\n",
            "504/504 [==============================] - 29s 56ms/step - loss: 1.2004 - accuracy: 0.5452 - val_loss: 1.1941 - val_accuracy: 0.5492\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.56037\n",
            "Epoch 49/60\n",
            "504/504 [==============================] - 29s 57ms/step - loss: 1.2157 - accuracy: 0.5355 - val_loss: 1.4080 - val_accuracy: 0.5347\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.56037\n",
            "Epoch 50/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.1895 - accuracy: 0.5450 - val_loss: 1.1486 - val_accuracy: 0.5690\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.56037 to 0.56904, saving model to checkpoint/Best_Model_resnet50oriScracth_aug_tipe2.h5\n",
            "Epoch 51/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.1664 - accuracy: 0.5586 - val_loss: 1.1590 - val_accuracy: 0.5737\n",
            "\n",
            "Epoch 00051: val_accuracy improved from 0.56904 to 0.57368, saving model to checkpoint/Best_Model_resnet50oriScracth_aug_tipe2.h5\n",
            "Epoch 52/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.1882 - accuracy: 0.5428 - val_loss: 1.1764 - val_accuracy: 0.5523\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.57368\n",
            "Epoch 53/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.1968 - accuracy: 0.5417 - val_loss: 1.1499 - val_accuracy: 0.5709\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.57368\n",
            "Epoch 54/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.1742 - accuracy: 0.5520 - val_loss: 1.1902 - val_accuracy: 0.5542\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.57368\n",
            "Epoch 55/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.1658 - accuracy: 0.5517 - val_loss: 1.1651 - val_accuracy: 0.5619\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.57368\n",
            "Epoch 56/60\n",
            "504/504 [==============================] - 30s 59ms/step - loss: 1.1611 - accuracy: 0.5590 - val_loss: 1.4224 - val_accuracy: 0.4681\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.57368\n",
            "Epoch 57/60\n",
            "504/504 [==============================] - 29s 57ms/step - loss: 1.1830 - accuracy: 0.5505 - val_loss: 1.1183 - val_accuracy: 0.5759\n",
            "\n",
            "Epoch 00057: val_accuracy improved from 0.57368 to 0.57585, saving model to checkpoint/Best_Model_resnet50oriScracth_aug_tipe2.h5\n",
            "Epoch 58/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.1632 - accuracy: 0.5588 - val_loss: 2.2610 - val_accuracy: 0.5146\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.57585\n",
            "Epoch 59/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.1347 - accuracy: 0.5655 - val_loss: 1.1293 - val_accuracy: 0.5687\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.57585\n",
            "Epoch 60/60\n",
            "504/504 [==============================] - 28s 56ms/step - loss: 1.1438 - accuracy: 0.5681 - val_loss: 1.0768 - val_accuracy: 0.6009\n",
            "\n",
            "Epoch 00060: val_accuracy improved from 0.57585 to 0.60093, saving model to checkpoint/Best_Model_resnet50oriScracth_aug_tipe2.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "cZvluWhSRkq4",
        "outputId": "57a9da09-fa27-40f1-8b3c-22364077e693"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "#gffhgffkjkjdshufdf\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "num_epochs = range(len(accuracy))\n",
        "plt.plot(num_epochs, accuracy, 'r', label='Training acc')\n",
        "plt.plot(num_epochs, val_accuracy, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(num_epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(num_epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Pzozx-30LSe",
        "outputId": "4172bf2f-4440-4f92-e8ff-ba339658fadc"
      },
      "source": [
        "testloss = model.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "trainloss = model.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(trainloss[0]))\n",
        "print(\"Train Acc: \" + str(trainloss[1]))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 2s 15ms/step - loss: 1.1191 - accuracy: 0.5829\n",
            "Test Loss 1.119066834449768\n",
            "Test Acc: 0.5828921794891357\n",
            "1010/1010 [==============================] - 14s 14ms/step - loss: 1.0515 - accuracy: 0.6019\n",
            "Train Loss 1.051533818244934\n",
            "Train Acc: 0.601925790309906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDwmru9p0gyj",
        "outputId": "5d1a9d5e-3620-47aa-e80d-78cfcb04e77d"
      },
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "y_pred1 = model.predict(xtest)\n",
        "y_pred = np.argmax(y_pred1, axis=1)\n",
        "\n",
        "# Print f1, precision, and recall scores\n",
        "print(precision_score(ytest, y_pred , average=\"macro\"))\n",
        "print(recall_score(ytest, y_pred , average=\"macro\"))\n",
        "print(f1_score(ytest, y_pred , average=\"macro\"))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5536273457378722\n",
            "0.5150967712494607\n",
            "0.5202618362454335\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}