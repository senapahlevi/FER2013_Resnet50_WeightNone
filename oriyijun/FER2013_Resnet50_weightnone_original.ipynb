{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FER2013_Resnet50_weightnone_nodropout.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-Qn1jsBTIBl0b7myLQxqa8WjCcfbamqM",
      "authorship_tag": "ABX9TyMhQRpBKUMlanaMnto1sh/2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/senapahlevi/FER2013_Resnet50_WeightNone/blob/master/oriyijun/FER2013_Resnet50_weightnone_original.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b86nukQOxN7l"
      },
      "source": [
        "Resnet-50 From Scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p8gxtGy0TWP",
        "outputId": "d71d0a17-2049-4d42-c44e-e7a0c025cd61"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "inputFolder = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth' \n",
        "for root, directories, filenames in os.walk(inputFolder): \n",
        "    for filename in filenames: print(os.path.join(root,filename))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe4.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsiscWIMBDX2",
        "outputId": "86d8b0f3-a584-4fb4-85d1-a36677092ba3"
      },
      "source": [
        "%cd /content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "wLMSe510xNCJ",
        "outputId": "3da9f6f5-cb75-4f61-d978-1e7de9a074fc"
      },
      "source": [
        "#Create a directory to save our generated models.\n",
        "\n",
        "#os.mkdir(\"./modelscracth\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-cf55f19f3613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#os.mkdir(\"./modelscracth\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ls' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_kluusLxM1B",
        "outputId": "78ad7b63-9c92-42f0-dbc5-4bf69e7e3a15"
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:400: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfUSF_tAxNMP"
      },
      "source": [
        "#Define the identity block helper function.\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "   \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VdYtzhn1F0I"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path \n",
        "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b',padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd-O8ZMx1GAW"
      },
      "source": [
        "def ResNet50(input_shape = (48,48,1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    #X = ZeroPadding2D((1, 1))(X_input)\n",
        "    X = X_input\n",
        "    # Stage 1\n",
        "\n",
        "    X = Conv2D(8, (3, 3), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # removed maxpool\n",
        "    #X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='c')\n",
        "\n",
        "\n",
        "    # Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [64,64,256], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL . \n",
        "    X = AveragePooling2D((2,2), name='avg_pool')(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(512, activation = 'relu', name='fc1024' , kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oWTDXlyBHM2"
      },
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        " \n",
        "dataset_path = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv'\n",
        "image_size=(48,48)\n",
        "#batch_size = 64\n",
        "\n",
        "def load_fer2013():\n",
        "    data = pd.read_csv(dataset_path)\n",
        "    data = (data[data['pixels'].notnull()])\n",
        "    pixels = data['pixels'].tolist()\n",
        "    width, height = 48, 48\n",
        "    faces = []\n",
        "    for pixel_sequence in pixels:\n",
        "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "        face = np.asarray(face).reshape(width, height)\n",
        "        face = cv2.resize(face.astype('uint8'),image_size)\n",
        "        faces.append(face.astype('float32'))\n",
        "    faces = np.asarray(faces)\n",
        "    faces = np.expand_dims(faces, -1)\n",
        "    emotions = (data['emotion'])#.values\n",
        "    return faces, emotions\n",
        " \n",
        "def preprocess_input(x, v2=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if v2:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x\n",
        " \n",
        "faces, emotions = load_fer2013()\n",
        "faces = preprocess_input(faces)\n",
        "#xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
        "#Data Augumentation\n",
        "\"\"\"data_generator = ImageDataGenerator(\n",
        "                        rotation_range=10,\n",
        "                        shear_range = 10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True)\"\"\"\n",
        "data_generator = ImageDataGenerator( rescale=1./255)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWLhavr-rSF5"
      },
      "source": [
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.1, train_size=0.9)\n",
        "x_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1, train_size=0.9)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH9Q-TegBR26"
      },
      "source": [
        "#hyperparameter and callback\n",
        "batch_size = 64\n",
        "num_epochs = 30\n",
        "input_shape = (48, 48, 1)\n",
        "num_classes = 7\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGsscQRJBR-h"
      },
      "source": [
        "#Compile the model.\n",
        "\n",
        "\n",
        "from keras.optimizers import Adam, SGD\n",
        "model = ResNet50(input_shape = (48, 48, 1), classes = 7)\n",
        "optimizer = Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-7)\n",
        "model.compile(optimizer= optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rodttDWeT2yP"
      },
      "source": [
        "#kita mau save model callbacks\n",
        "import os\n",
        "try:\n",
        "  os.mkdir('scratchcheckpoint')\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV29sTjET28U"
      },
      "source": [
        "file_name = 'Best_Model_resnet50Scracth_oriyijungan1.h5'\n",
        "\n",
        "checkpoint_path = os.path.join('checkpoint',file_name)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_S6wUaPT3Jx"
      },
      "source": [
        "call_back = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
        "                                               monitor='val_accuracy',\n",
        "                                               verbose=1,\n",
        "                                               save_freq='epoch',\n",
        "                                               save_best_only=True,\n",
        "                                               save_weights_only=False,\n",
        "                                               mode='max')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy53DHMGB-Mr",
        "outputId": "54df7dcb-682e-461f-a5e1-06d40742e267"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 46, 46, 128)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 46, 46, 128)  0           activation_3[0][0]               \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 46, 46, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 46, 46, 128)  0           activation_6[0][0]               \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 46, 46, 128)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 23, 23, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 23, 23, 256)  0           activation_12[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 23, 23, 256)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 23, 23, 256)  0           activation_15[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 23, 23, 256)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 23, 23, 256)  0           activation_18[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 23, 23, 256)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 12, 12, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 12, 12, 512)  0           activation_24[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 12, 12, 512)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 12, 12, 512)  0           activation_27[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 12, 12, 512)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 12, 12, 512)  0           activation_30[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 12, 12, 512)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 12, 12, 512)  0           activation_33[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 12, 12, 512)  0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 12, 12, 512)  0           activation_36[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 12, 12, 512)  0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 6, 6, 1024)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 6, 6, 1024)   0           activation_42[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 6, 6, 1024)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 6, 6, 1024)   0           activation_45[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 6, 6, 1024)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgxCecVwCGEr",
        "outputId": "8988e6bf-b434-4650-c46f-22f92303943d"
      },
      "source": [
        "\"\"\"history = model.fit(data_generator.flow(xtrain, ytrain,),\n",
        "                        steps_per_epoch=len(xtrain) / batch_size,\n",
        "                        epochs=num_epochs, verbose=1,callbacks=call_back,\n",
        "                        validation_data= (xtest,ytest))\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "448/448 [==============================] - 65s 122ms/step - loss: 2.2711 - accuracy: 0.2151 - val_loss: 1.8425 - val_accuracy: 0.2538\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.25383, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 1.8064 - accuracy: 0.2511 - val_loss: 1.8161 - val_accuracy: 0.2594\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.25383 to 0.25940, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 3/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.7689 - accuracy: 0.2632 - val_loss: 1.7616 - val_accuracy: 0.2795\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.25940 to 0.27947, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 4/50\n",
            "448/448 [==============================] - 57s 126ms/step - loss: 1.7297 - accuracy: 0.3022 - val_loss: 1.7276 - val_accuracy: 0.2990\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.27947 to 0.29897, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 5/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.6804 - accuracy: 0.3269 - val_loss: 1.6247 - val_accuracy: 0.3504\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.29897 to 0.35038, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 6/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.6096 - accuracy: 0.3661 - val_loss: 1.5590 - val_accuracy: 0.3823\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.35038 to 0.38228, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 7/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.5340 - accuracy: 0.4051 - val_loss: 1.5257 - val_accuracy: 0.4087\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.38228 to 0.40875, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 8/50\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 1.5127 - accuracy: 0.4046 - val_loss: 1.5014 - val_accuracy: 0.4139\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.40875 to 0.41390, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 9/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.4779 - accuracy: 0.4241 - val_loss: 1.4280 - val_accuracy: 0.4503\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.41390 to 0.45026, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 10/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.4282 - accuracy: 0.4475 - val_loss: 1.4991 - val_accuracy: 0.4154\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.45026\n",
            "Epoch 11/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.4105 - accuracy: 0.4555 - val_loss: 1.3838 - val_accuracy: 0.4620\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.45026 to 0.46197, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 12/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.3500 - accuracy: 0.4850 - val_loss: 1.3392 - val_accuracy: 0.4799\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.46197 to 0.47994, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 13/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 1.3333 - accuracy: 0.4895 - val_loss: 1.3158 - val_accuracy: 0.4946\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.47994 to 0.49457, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 14/50\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 1.2905 - accuracy: 0.5087 - val_loss: 1.3923 - val_accuracy: 0.4912\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.49457\n",
            "Epoch 15/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.2800 - accuracy: 0.5112 - val_loss: 1.2229 - val_accuracy: 0.5344\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.49457 to 0.53441, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 16/50\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 1.2456 - accuracy: 0.5286 - val_loss: 1.2321 - val_accuracy: 0.5258\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.53441\n",
            "Epoch 17/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.2397 - accuracy: 0.5268 - val_loss: 1.2038 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.53441 to 0.53845, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 18/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.2112 - accuracy: 0.5434 - val_loss: 1.2470 - val_accuracy: 0.5208\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.53845\n",
            "Epoch 19/50\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 1.1876 - accuracy: 0.5505 - val_loss: 1.2147 - val_accuracy: 0.5336\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.53845\n",
            "Epoch 20/50\n",
            "448/448 [==============================] - 51s 115ms/step - loss: 1.1875 - accuracy: 0.5495 - val_loss: 1.1693 - val_accuracy: 0.5511\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.53845 to 0.55113, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 21/50\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 1.1622 - accuracy: 0.5580 - val_loss: 1.2089 - val_accuracy: 0.5344\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.55113\n",
            "Epoch 22/50\n",
            "448/448 [==============================] - 56s 126ms/step - loss: 1.1420 - accuracy: 0.5658 - val_loss: 1.1683 - val_accuracy: 0.5574\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.55113 to 0.55740, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 23/50\n",
            "448/448 [==============================] - 51s 115ms/step - loss: 1.1426 - accuracy: 0.5670 - val_loss: 1.1895 - val_accuracy: 0.5475\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.55740\n",
            "Epoch 24/50\n",
            "448/448 [==============================] - 57s 126ms/step - loss: 1.1447 - accuracy: 0.5654 - val_loss: 1.1481 - val_accuracy: 0.5698\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.55740 to 0.56980, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 25/50\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 1.0988 - accuracy: 0.5806 - val_loss: 1.0838 - val_accuracy: 0.5938\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.56980 to 0.59376, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 26/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.0941 - accuracy: 0.5851 - val_loss: 1.2003 - val_accuracy: 0.5529\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.59376\n",
            "Epoch 27/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 1.0957 - accuracy: 0.5909 - val_loss: 1.1363 - val_accuracy: 0.5758\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.59376\n",
            "Epoch 28/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.0562 - accuracy: 0.6027 - val_loss: 1.1244 - val_accuracy: 0.5738\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.59376\n",
            "Epoch 29/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 1.0445 - accuracy: 0.6041 - val_loss: 1.0976 - val_accuracy: 0.5861\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.59376\n",
            "Epoch 30/50\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 1.0413 - accuracy: 0.5992 - val_loss: 1.1102 - val_accuracy: 0.5867\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.59376\n",
            "Epoch 31/50\n",
            "448/448 [==============================] - 56s 126ms/step - loss: 1.0303 - accuracy: 0.6060 - val_loss: 1.0553 - val_accuracy: 0.6056\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.59376 to 0.60560, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 32/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 1.0454 - accuracy: 0.6025 - val_loss: 1.0681 - val_accuracy: 0.5988\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.60560\n",
            "Epoch 33/50\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 1.0070 - accuracy: 0.6213 - val_loss: 1.0881 - val_accuracy: 0.5949\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.60560\n",
            "Epoch 34/50\n",
            "448/448 [==============================] - 57s 127ms/step - loss: 1.0123 - accuracy: 0.6159 - val_loss: 1.1018 - val_accuracy: 0.5897\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.60560\n",
            "Epoch 35/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 0.9944 - accuracy: 0.6208 - val_loss: 1.0713 - val_accuracy: 0.5999\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.60560\n",
            "Epoch 36/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 1.0049 - accuracy: 0.6201 - val_loss: 1.0473 - val_accuracy: 0.6127\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.60560 to 0.61271, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 37/50\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 0.9791 - accuracy: 0.6334 - val_loss: 1.0589 - val_accuracy: 0.6043\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.61271\n",
            "Epoch 38/50\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 0.9641 - accuracy: 0.6281 - val_loss: 1.0680 - val_accuracy: 0.5972\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.61271\n",
            "Epoch 39/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 0.9775 - accuracy: 0.6277 - val_loss: 1.2166 - val_accuracy: 0.5575\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.61271\n",
            "Epoch 40/50\n",
            "448/448 [==============================] - 56s 124ms/step - loss: 0.9695 - accuracy: 0.6381 - val_loss: 1.0728 - val_accuracy: 0.5947\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.61271\n",
            "Epoch 41/50\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 0.9418 - accuracy: 0.6410 - val_loss: 1.0668 - val_accuracy: 0.5978\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.61271\n",
            "Epoch 42/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 0.9483 - accuracy: 0.6383 - val_loss: 1.0436 - val_accuracy: 0.6160\n",
            "\n",
            "Epoch 00042: val_accuracy improved from 0.61271 to 0.61605, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 43/50\n",
            "448/448 [==============================] - 56s 126ms/step - loss: 0.9589 - accuracy: 0.6440 - val_loss: 1.0460 - val_accuracy: 0.6101\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.61605\n",
            "Epoch 44/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 0.9422 - accuracy: 0.6480 - val_loss: 1.0838 - val_accuracy: 0.5991\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.61605\n",
            "Epoch 45/50\n",
            "448/448 [==============================] - 51s 115ms/step - loss: 0.9410 - accuracy: 0.6449 - val_loss: 1.0646 - val_accuracy: 0.5995\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.61605\n",
            "Epoch 46/50\n",
            "448/448 [==============================] - 56s 124ms/step - loss: 0.9130 - accuracy: 0.6571 - val_loss: 1.0363 - val_accuracy: 0.6148\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.61605\n",
            "Epoch 47/50\n",
            "448/448 [==============================] - 51s 115ms/step - loss: 0.9051 - accuracy: 0.6632 - val_loss: 1.0098 - val_accuracy: 0.6296\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.61605 to 0.62956, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 48/50\n",
            "448/448 [==============================] - 56s 126ms/step - loss: 0.9064 - accuracy: 0.6556 - val_loss: 1.0776 - val_accuracy: 0.6002\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.62956\n",
            "Epoch 49/50\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 0.9066 - accuracy: 0.6624 - val_loss: 1.0612 - val_accuracy: 0.6158\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.62956\n",
            "Epoch 50/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 0.9066 - accuracy: 0.6581 - val_loss: 1.0227 - val_accuracy: 0.6211\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.62956\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2muXWns0sJSH",
        "outputId": "df7b733e-222d-42e2-eaca-1f891784c9c2"
      },
      "source": [
        "history = model.fit(\n",
        "    data_generator.flow(xtrain, ytrain,),\n",
        "    steps_per_epoch=len(xtrain) / batch_size,\n",
        "    epochs=num_epochs, \n",
        "    verbose=1,\n",
        "    callbacks=call_back,\n",
        "    validation_data= (x_val,y_val))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "504/504 [==============================] - 136s 157ms/step - loss: 21.6262 - accuracy: 0.2310 - val_loss: 1.8340 - val_accuracy: 0.2387\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.23870, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan1.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/30\n",
            "504/504 [==============================] - 75s 148ms/step - loss: 1.7653 - accuracy: 0.2732 - val_loss: 1.8291 - val_accuracy: 0.2387\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.23870\n",
            "Epoch 3/30\n",
            "504/504 [==============================] - 75s 148ms/step - loss: 1.7202 - accuracy: 0.3000 - val_loss: 1.8385 - val_accuracy: 0.2387\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.23870\n",
            "Epoch 4/30\n",
            "504/504 [==============================] - 75s 148ms/step - loss: 1.6813 - accuracy: 0.3217 - val_loss: 1.8472 - val_accuracy: 0.2387\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.23870\n",
            "Epoch 5/30\n",
            "504/504 [==============================] - 75s 148ms/step - loss: 1.6465 - accuracy: 0.3429 - val_loss: 1.8269 - val_accuracy: 0.2387\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.23870\n",
            "Epoch 6/30\n",
            "504/504 [==============================] - 75s 148ms/step - loss: 1.6598 - accuracy: 0.3349 - val_loss: 1.8240 - val_accuracy: 0.2387\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.23870\n",
            "Epoch 7/30\n",
            "504/504 [==============================] - 75s 148ms/step - loss: 1.5800 - accuracy: 0.3716 - val_loss: 1.8214 - val_accuracy: 0.2387\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.23870\n",
            "Epoch 8/30\n",
            "504/504 [==============================] - 75s 148ms/step - loss: 1.8005 - accuracy: 0.2599 - val_loss: 2.7937 - val_accuracy: 0.2384\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.23870\n",
            "Epoch 9/30\n",
            "504/504 [==============================] - 75s 148ms/step - loss: 1.7760 - accuracy: 0.2642 - val_loss: 1.8241 - val_accuracy: 0.2387\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.23870\n",
            "Epoch 10/30\n",
            "504/504 [==============================] - 74s 148ms/step - loss: 1.7587 - accuracy: 0.2846 - val_loss: 1.8230 - val_accuracy: 0.2387\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.23870\n",
            "Epoch 11/30\n",
            "504/504 [==============================] - 74s 147ms/step - loss: 1.7616 - accuracy: 0.2883 - val_loss: 1.8259 - val_accuracy: 0.2384\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.23870\n",
            "Epoch 12/30\n",
            "504/504 [==============================] - 74s 147ms/step - loss: 1.6643 - accuracy: 0.3346 - val_loss: 1.8224 - val_accuracy: 0.2387\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.23870\n",
            "Epoch 13/30\n",
            "504/504 [==============================] - 74s 147ms/step - loss: 1.5785 - accuracy: 0.3761 - val_loss: 1.8307 - val_accuracy: 0.2387\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.23870\n",
            "Epoch 14/30\n",
            "504/504 [==============================] - 74s 147ms/step - loss: 1.5526 - accuracy: 0.3885 - val_loss: 1.8263 - val_accuracy: 0.2387\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.23870\n",
            "Epoch 15/30\n",
            "504/504 [==============================] - 74s 147ms/step - loss: 1.6051 - accuracy: 0.3687 - val_loss: 1.8260 - val_accuracy: 0.2387\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.23870\n",
            "Epoch 16/30\n",
            "504/504 [==============================] - 74s 147ms/step - loss: 1.5945 - accuracy: 0.3713 - val_loss: 1.8325 - val_accuracy: 0.2387\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.23870\n",
            "Epoch 17/30\n",
            "504/504 [==============================] - 74s 147ms/step - loss: 1.5987 - accuracy: 0.3696 - val_loss: 1.8334 - val_accuracy: 0.2387\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.23870\n",
            "Epoch 18/30\n",
            "504/504 [==============================] - 74s 147ms/step - loss: 1.5440 - accuracy: 0.3973 - val_loss: 1.8293 - val_accuracy: 0.2387\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.23870\n",
            "Epoch 19/30\n",
            "504/504 [==============================] - 75s 148ms/step - loss: 1.6362 - accuracy: 0.3454 - val_loss: 1.8290 - val_accuracy: 0.2387\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.23870\n",
            "Epoch 20/30\n",
            "504/504 [==============================] - 74s 147ms/step - loss: 1.5207 - accuracy: 0.4019 - val_loss: 1.8285 - val_accuracy: 0.2387\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.23870\n",
            "Epoch 21/30\n",
            "504/504 [==============================] - 74s 147ms/step - loss: 1.6066 - accuracy: 0.3679 - val_loss: 1.8278 - val_accuracy: 0.2387\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.23870\n",
            "Epoch 22/30\n",
            "504/504 [==============================] - 74s 147ms/step - loss: 1.4899 - accuracy: 0.4210 - val_loss: 1.8323 - val_accuracy: 0.2387\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.23870\n",
            "Epoch 23/30\n",
            "504/504 [==============================] - 74s 147ms/step - loss: 1.5242 - accuracy: 0.4016 - val_loss: 1.8274 - val_accuracy: 0.2387\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.23870\n",
            "Epoch 24/30\n",
            "504/504 [==============================] - 74s 147ms/step - loss: 1.4769 - accuracy: 0.4206 - val_loss: 1.8304 - val_accuracy: 0.2387\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.23870\n",
            "Epoch 25/30\n",
            "504/504 [==============================] - 74s 147ms/step - loss: 1.4231 - accuracy: 0.4429 - val_loss: 1.8330 - val_accuracy: 0.2387\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.23870\n",
            "Epoch 26/30\n",
            "504/504 [==============================] - 74s 147ms/step - loss: 1.4124 - accuracy: 0.4491 - val_loss: 1.8337 - val_accuracy: 0.2387\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.23870\n",
            "Epoch 27/30\n",
            "504/504 [==============================] - 74s 147ms/step - loss: 1.4944 - accuracy: 0.4115 - val_loss: 1.8255 - val_accuracy: 0.2387\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.23870\n",
            "Epoch 28/30\n",
            "504/504 [==============================] - 74s 147ms/step - loss: 1.6198 - accuracy: 0.3588 - val_loss: 23.9663 - val_accuracy: 0.2387\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.23870\n",
            "Epoch 29/30\n",
            "504/504 [==============================] - 74s 147ms/step - loss: 1.5440 - accuracy: 0.4000 - val_loss: 1.8284 - val_accuracy: 0.2387\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.23870\n",
            "Epoch 30/30\n",
            "504/504 [==============================] - 76s 151ms/step - loss: 1.4473 - accuracy: 0.4333 - val_loss: 1.8203 - val_accuracy: 0.2387\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.23870\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "GaXUP-8fDWRN",
        "outputId": "fc081666-8456-4788-dc3a-7e956d58fd20"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "#gffhgffkjkjdskjj\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "num_epochs = range(len(accuracy))\n",
        "plt.plot(num_epochs, accuracy, 'r', label='Training acc')\n",
        "plt.plot(num_epochs, val_accuracy, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(num_epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(num_epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEWCAYAAACT7WsrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3iUZfbw8e8BpCNdkaIEBCKKtIgFUeworCjCCqKCXexlLbtrQVh/a9eXXRVYEWwIYgFWKRqEAKJIQCwUBQE1LAICUqSGnPeP+xmYhEwySeaZej7XlSszzzzlnplkztzt3KKqGGOMMYUpF+sCGGOMiV8WJIwxxoRkQcIYY0xIFiSMMcaEZEHCGGNMSBYkjDHGhGRBwoRNRKaKyIBI7xtLIrJGRM714bwqIsd6t4eLyMPh7FuK6/QXkY9LW05jiiM2TyK5iciOoLtVgT3Afu/+Tar6VvRLFT9EZA1wvapmRvi8CrRQ1ZWR2ldEmgKrgcNUNTcS5TSmOBViXQDjL1WtHrhd1AeiiFSwDx4TL+zvMX5Yc1OKEpGuIpIjIg+IyK/AaBGpLSIfishGEdni3W4cdMwsEbneuz1QROaKyDPevqtF5MJS7psmIrNFZLuIZIrIiyLyZohyh1PGoSLymXe+j0WkXtDjV4nITyKySUT+XsTrc7KI/Coi5YO2XSoi33i3O4nI5yLyu4isE5F/i0jFEOcaIyL/CLp/n3fM/0Tk2gL7dheRr0Rkm4j8IiKDgx6e7f3+XUR2iMipgdc26PjTRGSBiGz1fp8W7mtTwte5joiM9p7DFhGZGPRYTxFZ7D2HH0Wkm7c9X9OeiAwOvM8i0tRrdrtORH4GPvW2T/Deh63e38jxQcdXEZFnvfdzq/c3VkVEPhKR2ws8n29E5NLCnqspmgWJ1NYAqAMcA9yI+3sY7d0/GtgF/LuI408GvgfqAU8Bo0RESrHvWOBLoC4wGLiqiGuGU8YrgGuAI4CKwF8ARKQ18LJ3/obe9RpTCFWdD/wBnF3gvGO92/uBu73ncypwDnBLEeXGK0M3rzznAS2Agv0hfwBXA7WA7sAgEbnEe+wM73ctVa2uqp8XOHcd4CNgmPfcngM+EpG6BZ7DIa9NIYp7nd/ANV8e753rea8MnYDXgfu853AGsCbU61GIM4HjgAu8+1Nxr9MRwCIguHn0GaAjcBru7/h+IA94DbgysJOItAUa4V4bU1Kqaj8p8oP7Zz3Xu90V2AtULmL/dsCWoPuzcM1VAAOBlUGPVQUUaFCSfXEfQLlA1aDH3wTeDPM5FVbGh4Lu3wJM824/AowLeqya9xqcG+Lc/wBe9W7XwH2AHxNi37uAD4LuK3Csd3sM8A/v9qvAE0H7tQzet5DzvgA8791u6u1bIejxgcBc7/ZVwJcFjv8cGFjca1OS1xk4CvdhXLuQ/UYEylvU3593f3DgfQ56bs2KKEMtb5+auCC2C2hbyH6VgS24fh5wweSlaP+/JcuP1SRS20ZV3R24IyJVRWSEV33fhmveqBXc5FLAr4EbqrrTu1m9hPs2BDYHbQP4JVSBwyzjr0G3dwaVqWHwuVX1D2BTqGvhag29RKQS0AtYpKo/eeVo6TXB/OqV4/9wtYri5CsD8FOB53eyiMz0mnm2AjeHed7AuX8qsO0n3LfogFCvTT7FvM5NcO/ZlkIObQL8GGZ5C3PgtRGR8iLyhNdktY2DNZJ63k/lwq7l/U2PB64UkXJAP1zNx5SCBYnUVnBo271AK+BkVT2cg80boZqQImEdUEdEqgZta1LE/mUp47rgc3vXrBtqZ1VdivuQvZD8TU3gmq2W476tHg78rTRlwNWkgo0FJgNNVLUmMDzovMUNRfwfrnko2NHA2jDKVVBRr/MvuPesViHH/QI0D3HOP3C1yIAGhewT/ByvAHrimuRq4mobgTL8Buwu4lqvAf1xzYA7tUDTnAmfBQkTrAauCv+71779qN8X9L6ZZwODRaSiiJwK/MmnMr4L9BCR071O5iEU/z8wFrgT9yE5oUA5tgE7RCQdGBRmGd4BBopIay9IFSx/Ddy39N1e+/4VQY9txDXzNAtx7ilASxG5QkQqiMjlQGvgwzDLVrAchb7OqroO11fwktfBfZiIBILIKOAaETlHRMqJSCPv9QFYDPT19s8AeodRhj242l5VXG0tUIY8XNPdcyLS0Kt1nOrV+vCCQh7wLFaLKBMLEibYC0AV3Le0L4BpUbpuf1zn7yZcP8B43IdDYUpdRlVdAtyK++Bfh2u3zinmsLdxnamfqupvQdv/gvsA3w78xytzOGWY6j2HT4GV3u9gtwBDRGQ7rg/lnaBjdwKPA5+JG1V1SoFzbwJ64GoBm3AduT0KlDtcxb3OVwH7cLWpDbg+GVT1S1zH+PPAViCLg7Wbh3Hf/LcAj5G/ZlaY13E1ubXAUq8cwf4CfAssADYDT5L/M+11oA2uj8uUkk2mM3FHRMYDy1XV95qMSV4icjVwo6qeHuuyJDKrSZiYE5GTRKS51zzRDdcOPbG444wJxWvKuwUYGeuyJDoLEiYeNMANz9yBG+M/SFW/immJTMISkQtw/TfrKb5JyxTDmpuMMcaEZDUJY4wxISVNgr969epp06ZNY10MY4xJKAsXLvxNVeuHejxpgkTTpk3Jzs6OdTGMMSahiEjBWfr5WHOTMcaYkHwNEiLSTUS+F5GVIvJgEftd5qUJzvDuNxWRXV664cUiMtzPchpjjCmcb81NXiKwF3EpkXOABSIy2cuHE7xfDVzag/kFTvGjqrbzq3zGGGOK52efRCdceuhVACIyDjdJammB/YbiptPfF+kC7Nu3j5ycHHbv3l38ziYmKleuTOPGjTnssMNiXRRjTCH8DBKNyJ8SOQe38MwBItIBl+3yIxEpGCTSROQrXBK1h1R1TsELiMiNuMVyOProgsk0IScnhxo1atC0aVNCr4VjYkVV2bRpEzk5OaSlpcW6OMaYQsSs49rL8/4cLhlZQeuAo1W1PXAPMFZEDi+4k6qOVNUMVc2oX//QEVy7d++mbt26FiDilIhQt25dq+kZE8f8DBJryZ83vzH589rXAE4AZonIGuAUYLKIZKjqHi+jJaq6ELewSMvSFMICRHyz98eY+OZnkFgAtBC3yH1FoC9uMRUAVHWrqtZT1aaq2hSXBvhiVc0WkfqBlcZEpBlujdtVPpbVGGMOysuD//4X5s6NdUlizrcgoaq5wG3AdGAZ8I6qLhGRISJycTGHnwF8IyKLcQvF3Kyqm/0qq182bdpEu3btaNeuHQ0aNKBRo0YH7u/du7fIY7Ozs7njjjuKvcZpp50WqeIaY1Rh8mTo2BEuvhiuuy7WJYq5pEnwl5GRoQVnXC9btozjjjsuRiXKb/DgwVSvXp2//OUvB7bl5uZSoULSTHovtXh6n0yKUoVp0+CRRyA7G5o3h2OOgaws2LkTKlaMdQl9IyILVTUj1OM24zrKBg4cyM0338zJJ5/M/fffz5dffsmpp55K+/btOe200/j+++8BmDVrFj169ABcgLn22mvp2rUrzZo1Y9iwYQfOV7169QP7d+3ald69e5Oenk7//v0JfAGYMmUK6enpdOzYkTvuuOPAeYOtWbOGLl260KFDBzp06MC8efMOPPbkk0/Spk0b2rZty4MPujmRK1eu5Nxzz6Vt27Z06NCBH388ZD16Y+KfKmRmQufOcNFF8NtvMGoULFsG11wD+/dDiv9tp87X2LvugsWLI3vOdu3ghRdKfFhOTg7z5s2jfPnybNu2jTlz5lChQgUyMzP529/+xnvvvXfIMcuXL2fmzJls376dVq1aMWjQoEPmFnz11VcsWbKEhg0b0rlzZz777DMyMjK46aabmD17NmlpafTr16/QMh1xxBF88sknVK5cmRUrVtCvXz+ys7OZOnUqkyZNYv78+VStWpXNm12rX//+/XnwwQe59NJL2b17N3l5eSV+HYyJqVmzXM1hzhxo0gRGjICBAw/WGtK9pbmXL4cUrummTpCII3369KF8+fIAbN26lQEDBrBixQpEhH379hV6TPfu3alUqRKVKlXiiCOOYP369TRu3DjfPp06dTqwrV27dqxZs4bq1avTrFmzA/MQ+vXrx8iRhy7WtW/fPm677TYWL15M+fLl+eGHHwDIzMzkmmuuoWrVqgDUqVOH7du3s3btWi699FLATYgzJmF89pkLDp9+CkcdBf/+N1x/PVSqlH+/lt6ASq92H7ceewy2b4ennwYfRgumTpAoxTd+v1SrVu3A7YcffpizzjqLDz74gDVr1tC1a9dCj6kU9Adcvnx5cnNzS7VPKM8//zxHHnkkX3/9NXl5efbBb5LTU0/BAw/AEUfA88/DTTdBlSqF73v44dCwoatJxKutW+HZZ6FHD18CBFifRMxt3bqVRo0aATBmzJiIn79Vq1asWrWKNWvWADB+/PiQ5TjqqKMoV64cb7zxBvv37wfgvPPOY/To0ezcuROAzZs3U6NGDRo3bszEiW4Z6j179hx43Ji4pAr33ecCRL9+sGqVa4IOFSAC0tPjO0iMGOFqEfdFPKvRARYkYuz+++/nr3/9K+3bty/RN/9wValShZdeeolu3brRsWNHatSoQc2aNQ/Z75ZbbuG1116jbdu2LF++/EBtp1u3blx88cVkZGTQrl07nnnmGQDeeOMNhg0bxoknnshpp53Gr7/+GvGyGxMRubluKOszz8Ctt8Kbb0JQbb5IgSARj6NA9+xxLSTnngvt2/t3HVVNip+OHTtqQUuXLj1kWyravn27qqrm5eXpoEGD9LnnnotxifKz98n4Ztcu1Z49VUH10UdV8/JKdvywYe7Ydet8KV6ZjBrlyvbxx2U6DZCtRXy2Wk0iBfznP/+hXbt2HH/88WzdupWbbrop1kUyxn/btsGFF8KkSTBsGAweXPJ2+1at3O9467zOy3Md1e3auZqEj1Kn4zqF3X333dx9992xLoYx0bNhgwsQ33zjmpf69y/deYKHwZ55ZuTKV1YffujKNHasbx3WARYkjDHJ5aef4Pzz4ZdfXC3iootKf67GjaFq1fjrvH76aTcjvE8f3y9lQcIYkzyWLnUB4o8/4JNP3EzqsihXzjU5xVOQmDfPJR4cNgyikNbH+iSMMclh/nzo0sWl0sjKKnuACGjVKr76JJ5+GurUgWuvjcrlLEgYYxLfrFlwzjlQq5abUX3iiZE7d3o6rFkDu3ZF7pyltXy5a0K79dbwh/GWkQUJH5111llMnz4937YXXniBQYMGhTyma9euBLLZXnTRRfz++++H7DN48OAD8xVCmThxIkuXHlxO/JFHHiEzM7MkxTcmMajCLbdAo0auGaZZs8iePz3dXWPFisietzSefdalD7nttqhd0oKEj/r168e4cePybRs3blzIJHsFTZkyhVq1apXq2gWDxJAhQzjX56FyxsTE55+7rK0PPuhyMUVa8AinWFq3Dl5/3WWnPeKIqF3WgoSPevfuzUcffXRggaE1a9bwv//9jy5dujBo0CAyMjI4/vjjefTRRws9vmnTpvz2228APP7447Rs2ZLTTz/9QDpxcHMgTjrpJNq2bctll13Gzp07mTdvHpMnT+a+++6jXbt2/PjjjwwcOJB3330XgBkzZtC+fXvatGnDtddey549ew5c79FHH6VDhw60adOG5YX8U1hKcRN3XnkFatTwb6RPixZumGmsg8SwYW72+D33RPWyKTO6KRaZwuvUqUOnTp2YOnUqPXv2ZNy4cfz5z39GRHj88cepU6cO+/fv55xzzuGbb77hxBDtqAsXLmTcuHEsXryY3NxcOnToQMeOHQHo1asXN9xwAwAPPfQQo0aN4vbbb+fiiy+mR48e9O7dO9+5du/ezcCBA5kxYwYtW7bk6quv5uWXX+auu+4CoF69eixatIiXXnqJZ555hldeeSXf8ZZS3MSVbdtg/Hi48krw1laJuKpV4eijY9t5vX07vPwyXHYZHHtsVC9tNQmfBTc5BTc1vfPOO3To0IH27duzZMmSfE1DBc2ZM4dLL72UqlWrcvjhh3PxxQdXf/3uu+/o0qULbdq04a233mLJkiVFluf7778nLS2Nll4a5AEDBjB79uwDj/fq1QuAjh07HkgKGGzfvn3ccMMNtGnThj59+hwod7gpxQOPGxMRb7/tVo67/np/rxPrRH//+Y/L+OpjIr9QUqYmEatM4T179uTuu+9m0aJF7Ny5k44dO7J69WqeeeYZFixYQO3atRk4cCC7d+8u1fkHDhzIxIkTadu2LWPGjGHWrFllKm8g3XioVOOWUtxEhGpkZgq/8oobyZQRcvXNyEhPd4sT5eW5uRPRtHevS2vetSucdFJ0r43VJHxXvXp1zjrrLK699toDtYht27ZRrVo1atasyfr165k6dWqR5zjjjDOYOHEiu3btYvv27fz3v/898Nj27ds56qij2LdvH2+99daB7TVq1GD79u2HnKtVq1asWbOGlStXAi6b65klSDdgKcVNmd1xh/vAK2tm1cWL3XrU11/ve2oK0tNdjWXtWn+vU5hx4yAnB+6/P/rXxoJEVPTr14+vv/76QJBo27Yt7du3Jz09nSuuuILOxUz66dChA5dffjlt27blwgsv5KSgbxNDhw7l5JNPpnPnzqQHRmEAffv25emnn6Z9+/b5OosrV67M6NGj6dOnD23atKFcuXLcfPPNYT8XSyluykQVJkyA2bPhgw/Kdq5Ro9xw0NLmZSqJWCX6U3ULJZ1wAnTrFt1re0TjMU96KWRkZGhgfkHAsmXLOC6F16ZNFPY+pZAVK9yyoCLQujV8/TV4S/mWyK5dbtW4iy6CoBq0b9atc9f717+iOkeBKVOge3c39PWqq3y5hIgsVNWQ7XVWkzDGRE9Wlvv9yCOwZAm8807pzvP++/D77/53WAc0aOCWM4125/XTT0OTJtC3b3SvG8SChDEmerKy3ESwhx92TSiPPurG/pfUK69A8+bRS98tEv0RTl9+6dKN3H03HHZY9K5bQNIHiWRpTktW9v6kEFUXJM44wzUxDR3qmp/efLNk51mxwn14XndddEcaRTtIPP001KwZvdpSCEkdJCpXrsymTZvsgyhOqSqbNm2yYbSp4qef3BoPgW//PXtCx47w2GNumGe4Xn3VBZkBA/wpZyitWrnRTYWMGoy41avhvfdcTqoaNfy/XhGSep5E48aNycnJYePGjbEuigmhcuXKNG7cONbFMNEQ6I8IBAkRV5u46CIYPRrCWVZ33z4YM8Z15jZs6FtRCxUYPfjDDy64+en9913N68Yb/b1OGJI6SBx22GGkpaXFuhjGGHBBok4dOP74g9u6dYNTT3XBYsAAKK5WOWUK/PprbJpgghP9+R0kJk2Ctm2haVN/rxOGpG5uMsbEkawstyhQcD+CCPzjH64ZZ8SI4s/xyisu0+uFF/pXzlCaN3fNXH73S/z2m1sTo2dPf68TJgsSxhj/5eTAqlWFj0Y6+2w46yz45z/dsqOhrF3rahLXXBOVZTsPUamSW6vC7wl1H37o0n8E5WiLJQsSxhj/BZJIhhqyOnQorF8PL74Y+hxjxrgPzygt21moaKx3PWkSNG4MHTr4e50wWZAwxvgvK8tNRmvbtvDHO3d2/RNPPunSfxeUl+fScJxzjmv2iZX0dNdx7eUsi7hdu+Djj10twu98VGGyIGGM8V9WFpx+etEpOIYOhc2b4f/9v0MfmznTDQuN8ZwB0tNhzx43nNcPM2a4RIJx0h8BFiSMMX5bv9614xc3Ozojw304PvssbNmS/7FXXnEjoy65xL9yhsPvpUwnTXLzIqI1kzwMFiSMMf4qrj8i2JAhbnGdZ589uG3TJjdv4Kqrih8i6zc/s8Hm5cF//+tGbnnrusQDCxLGGH9lZUG1auF1xJ54Ilx+uVslLDAJ9s033Yzs667zt5zhqFcP6tb1pybx5Zeu1hVHTU1gQcIY47esLDjttPCT1A0e7Dpwn3zSzTp+5RU4+WRo08bXYobNrxxOkya5ob2xmANSBAsSxhj/bNoE331Xsjb29HS48ko3HHbSJHd8rDusg/kZJM44A2rXjvy5y8DXICEi3UTkexFZKSIPFrHfZSKiIpIRtO2v3nHfi8gFfpbTGOOTOXPc75J2xD7yiEshfsUVrqnq8ssjX7bSSk+HDRsO7VwvixUrYNmyuGtqAh+DhIiUB14ELgRaA/1EpHUh+9UA7gTmB21rDfQFjge6AS955zPGJJKsLNfZHLTkbliaN3czq3ftcgvuxDgTaj5+dF5Pnux+p1KQADoBK1V1laruBcYBhb0CQ4Engd1B23oC41R1j6quBlZ65zPGJJKsLDjllNKN1nnkEdeXcdddkS9XWfgxDDaQ0O+YYyJ3zgjxM0g0An4Jup/jbTtARDoATVT1o5Ie6x1/o4hki0i2pQM3xgcPPuhm/5ZmTZatW2Hx4tKP+W/c2CW6O+GE0h3vl7Q01wkfqSARZwn9CopZx7WIlAOeA+4t7TlUdaSqZqhqRv369SNXOGOMW0N62DA3dn/atJIfP3euCy5xNDEsIipUgBYtIhck4iyhX0F+Bom1QJOg+429bQE1gBOAWSKyBjgFmOx1Xhd3rDHGb2+95foEatd2a1GXtDaRleW+cZ9yij/li6VWrSLXJzF5clwl9CvIzyCxAGghImkiUhHXET058KCqblXVeqraVFWbAl8AF6tqtrdfXxGpJCJpQAvgSx/LaowJpurWd+jQwa21vGABfFSwVbgYWVnQqRNUqeJPGWMpPR1WrnQr5ZXFrl0wfXpcJfQryLcgoaq5wG3AdGAZ8I6qLhGRISJSZL1KVZcA7wBLgWnArarqU9pFY8wh5s+Hb791S4pefbVbR6EktYkdO2DhwuRragpIT3dDdFetKtt54jChX0G+9kmo6hRVbamqzVX1cW/bI6o6uZB9u3q1iMD9x73jWqnqVD/LaUxS+Ne/4K9/jcy5Ro508xP69XNNRg8/DIsWHRyqWZx581w67WQOElD2fok4TOhXkM24NiYZTJ8Od9wBTzzhcgCVxe+/w7hxbiJbYH7ClVfCsce62kReXvHnyMpyacFPO61sZYlXkZgrEacJ/QqyIGFMovvf/1yG1BNOcOm0hwwp2/kCHdY33XRwW4UKbt7C11/DxInFnyMry6X+rl69bGWJVzVrQoMGZatJxGlCv4IsSBiTyPbvh/793drQ77wD997rOpgXLCjd+YI7rDt2zP9Yv37QsqVLwFdUbWLXLvcBeMYZpStDoihrDqdAQr+LLopcmXxgQcKYRDZ0KMyaBS+/DMcdB7fdVrbaRHCHdUEVKrjmpm+/hffeC32OL75wo37iuJ09IgJBojQTDcEFiTPPhFq1IluuCLMgYUyi+vRTFwwGDHAjkMCtI33PPW6C1sKFJT9ncId1YS6/3AWjwYNDr/OclQXlyrnlSpNZerpL8vfbbyU/NpDQL04n0AWzIGFMKHl57pvia6+5oYrxZP1618zUqhX8+9/5H7v9djcB7rHHSnbOwjqsCypf3tUmli6FCRMK3ycrC9q1c+32yawsI5ziOKFfQRYkjAnYsMGNNnnoITjvPNdsc9xxMHAg9OpV9olTkZKX5zqqf//d9UMU7BwO1Cb++183bDVchXVYF6ZPHzj+eBeECtYm9uxxzU3J3h8BB0c4lSZIxHFCv4IsSJjUtWgRPP+8S0WdlgZHHumq/0884ZoQ+vaFV191S2lu2+ZyEcWDJ56ATz5xeZVCrdZ2++2urTvcvomiOqwLKlfONTctX+5qHsEWLIDdu5O/PwLg6KNdGvSSBok4T+h3CFVNip+OHTuqMWH7/ntV99GoevTRqr17qz79tOrs2ao7duTfd/t21YoVVe+5JzZlDTZ7tmq5cqp9+6rm5RW975Ah7vktWlT8eT//3O07fHh45di/X/XEE1VbtlTdt+/g9n/8w53nt9/CO0+ia9tW9aKLSnbM6NHuNcrO9qVIJQVkaxGfrVaTMKlp+nT3e/Fi+Okn177+l79Aly6u4zZY9erQtWvJcxdF2m+/uQ7lZs3ct/7icv3ccUf4tYlAh/UVV4RXlkBt4ocfYOzYg9tnz3a1m7p1wztPoktPL/mEujhP6FeQBQmTmjIz3epnbduGt3+PHu7DYOVKf8sVSl6e6xvZuBHGj3f9DsWpWdMt2DNxoguGoYTTYV2YSy6B9u3dMNzcXNdn89lnqdHUFNCqFaxe7ZrYwpEACf0KsiBhUs++fTBzJpx7bvjHdO/ufkeqNvGvf7kU2rfc4vo9vv3WfdCG8vzz7trPPluyb6B33umCRVG1iXA7rAsScbWJlSvhzTddH88ff6RGp3VAeroL4OF+eUiAhH6HKKotKpF+rE/ChO2zz1yb8IQJJTvuuONUzz237NfPzVVt0ED1iCNUDz/8YN9I1aqqnTur3nmn6ptvqi5f7tr+P/9ctUIF1V69iu+HKMyjj7rzL1586GN5eapt2qh26FC655KXp9qxo2pa2sH+iF9/Ld25EtGiReH/La1bp3r22ao1aqju2eN/2cKE9UkYU0BmpvsWfNZZJTuuRw83B2D79rJdf9Ys+PVXePFFNxlr+XJ44w244QYXLkaOdAn10tPdfIcLL3Rt2KNGla6J4s47XfNUYbWJwAzrG28s3XMRcUNhV692o67S090osVTRsqX7XVS/xB9/uCa5Y491fTaPPQYVK0anfJFQVARJpB+rSZiwdenivv2W1KxZ7lvje++V7frXXuu+Te7cWfjj+/apfvON6qhRqoMGqZ51luqCBWW75iOPuLJ//XX+7ddco1qtmuq2baU/d16eaqdO7vw33VS2ciaio49WvfLKQ7fn5rr3sGFD99pcdpnqDz9Ev3zFoJiaRMw/3CP1Y0HChGX7dtd08+CDJT92717VWrXcB2tp7dqlWrOm6oABpT9HaWze7Jq2Lrvs4LYtW1SrVFG94Yayn3/69NI14SWD885TzcjIv236dNeMB6onn6w6d25syhaG4oKENTeZ1DJ7tusgLkmndcBhh8EFF8CUKeGtqVCYqVNh69bQuZH8Uru2GxL73nuueQkOdliXtqkp2Pnnw3ffwWWXlf1ciSY40d8330C3bu7vZMcONyP+8zS384IAAB5qSURBVM+hc+dYl7LULEiY1JKZ6WbJlvaftkcPlzepNMnzwM0pqF8fzjmndMeXxd13uyGuQ4fmn2GdkRGZ8x9/fMIM64yo9HQXEPr2dTmrvvwSnnvOJfDr0yfhXxMLEia1ZGa67KSVK5fu+G7d3ESyDz8s+bHbtrnjLr/cpd2Otjp1XG1iwoSDw24jUYtIdYFEfx984ALxypXudxyvNlcSFiRM6vj1V/fBWJqmpoB69dz8htLMl5g40U26CndWsx/uvtvNIL/pppLNsDahnXmmG6m2fLmbx1KnTqxLFFEWJEzqCKT7LkuQANfktHAhrFtXsuPGjoWmTV2QiZW6dV1tYv/+ks+wNoUrX95NimzWLNYl8YUFCZM6MjPdt7x27cp2nsDs6ylTwj9m/Xp3/SuuiH0b9b33Qu/eLleVMcWwIGFSg6r7kD7nHPfNryzatIEmTUrWLzFhwsFv77FWp44rT2AimDFFsCBhUsMPP0BOTtmbmsDVBHr0cGs67NkT3jFjx8KJJ7oRQMYkEAsSJjVkZrrfkQgS4Jqc/vjDpekozurVbqx8tOdGGBMBFiRMasjMdKvPRapz8eyzoUqV8JqcAqu39e0bmWsbE0UWJEzyy80teWrw4lSp4gLFhx+6/o6ijB3rJu81bRq56xsTJRYkTPJbuNClwohkkADXL7F6ddFrHH/7rUtXEQ8d1saUggUJk/w++cT9PvvsyJ43MBS2qCansWPdaKo+fSJ7bWOixIJEKlM9uFJWMsvMdMts1qsX2fM2aeJGLIWafZ2XB2+/7ZLf1a8f2WsbEyVhBQkReV9EuouIBZVkMnKka4J5881Yl8Q/f/wB8+bBeef5c/4ePWDuXLd4UEGffw4//WRNTSahhfuh/xJwBbBCRJ4QkVY+lslEw6JFLj0DwIoVsS2Ln+bMcWtaR7o/IqBHDzdJ7uOPD33s7bddB3cirWdsTAFhBQlVzVTV/kAHYA2QKSLzROQaETnMzwIaH2zd6trIjzjCLYu5enWsS+SfzEyXjfP00/05f6dOrhmrYL/Evn1uLYE//cnyI5mEFnbzkYjUBQYC1wNfAf8PFzQ+8aVkxh+qcO218PPPMH68mwGc7EGic2f3jd4P5cu7NainTnU1ioAZM2DjRmtqMgkv3D6JD4A5QFXgT6p6saqOV9Xbgep+FtBE2LBh8P778OSTcNppboJZsgaJDRvg66/9a2oK6N4dNm2C+fMPbhs7FmrVcutPGJPAwq1JDFPV1qr6T1XNlx9ZVSO0rJXx3RdfuMyfPXu6dQXABYktW1wTVLL59FP32+8gccEFrkYRaHLaudMtQNO7d9IsPGNSV7hBorWI1ArcEZHaInKLT2Uyfti0Cf78Zzdsc8yYg+mqA2kqkrE2kZnpvs136ODvdWrVgi5dDgaJDz90y1laU5NJAuEGiRtU9ffAHVXdAtzgT5FMxOXlwdVXuzUNJkxwH2oBaWnud7IFCVU3ie7ss8ueGjwc3bu72dU//+yamho2hDPO8P+6xvgs3CBRXuTgSikiUh6o6E+RTMQ99ZRbIOeFF6Bjx/yPJWuQWLnSfWD7NT+ioB493O+33nKd2H37Ric4GeOzcIPENGC8iJwjIucAb3vbiiQi3UTkexFZKSIPFvL4zSLyrYgsFpG5ItLa295URHZ52xeLyPCSPCkTJCsL/v5396F1882HPl67Nhx+ePIFiUinBi9Oq1au6W7oUNi715qaTNIIN0g8AMwEBnk/M4D7izrAq228CFwItAb6BYJAkLGq2kZV2wFPAc8FPfajqrbzfgr5dDPFWr/erWFw7LFudnVhy2aKJOcIp8xMOOYYaN48OtcLLES0axe0aOF/P4gxURLuZLo8VX1ZVXt7PyNUdX8xh3UCVqrqKlXdC4wD8k09VdVtQXerAcXkXDZhCyyVuWULvPtu0RO6ki1I7N/vRjade25015MONDnFwzrWxkRIuPMkWojIuyKyVERWBX6KOawR8EvQ/RxvW8Fz3yoiP+JqEncEPZQmIl+JSJaIdAlRrhtFJFtEsjdu3BjOU0kdQ4a4D8qXXnJrMhclLQ3WrCl+XYREsWgR/P579JqaAs4+2/X73HlndK9rjI/CbW4aDbwM5AJnAa8DEckKp6ovqmpzXJPWQ97mdcDRqtoeuAcYKyKHF3LsSFXNUNWM+pZl86Bp01zb+MCBcM01xe+flubG9m/Y4HvRoiLQHxHp1ODFKV/eBYjataN7XWN8FG6QqKKqMwBR1Z9UdTDQvZhj1gJNgu439raFMg64BEBV96jqJu/2QuBHoGWYZU1ts2ZBr16u9vDii+Edk2wjnDIzoW1bl5vKGFMm4QaJPV6a8BUicpuIXErx6TgWAC1EJE1EKgJ9gcnBO4hIi6C73YEV3vb6Xsc3ItIMaAEU17xlsrLceP20NDdHoGrV8I5LpiCxc6dL3R3tpiZjklSFMPe7E5e36Q5gKK7JaUBRB6hqrojcBkwHygOvquoSERkCZKvqZOA2ETkX2AdsCTrnGcAQEdkH5AE3q+rmkj21FDN7Nlx0kVtH+dNPS/YtOrD28qokiMNz57ohqNGaH2FMkis2SHjf6C9X1b8AO4AwGrkdVZ0CTCmw7ZGg24X28Knqe8B74V4n5c2Z4wLEMce4AHHkkSU7vlo1F1SSoSaRmQkVK/qXGtyYFFNsc5M31NX+4+LV3LkuVXWTJqULEAHJMgz2449ddttq1WJdEmOSQrjNTV+JyGRgAvBHYKOqvu9LqUx45s1zAaJxYxcgGjQo/bnS0vKnuk5E69a51OBPPBHrkhiTNMINEpWBTUDwmEIFLEjEyuefu7UKGjaEmTPhqKPKdr5mzVzyv9xcqBDun0WcCSwhesEFsS2HMUkkrE8DVQ27H8JEwRdfuA/CBg0iEyDA1ST274ecnIMd2Ylm+nTX3HbiibEuiTFJI6wgISKjKSRlhqpeG/ESmaLNn+8CxJFHugDRsGFkzhs8DDYRg8T+/a4mcdFFUC7sVXmNMcUI97/pQ+Aj72cGcDhupJOJpi+/hPPPh/r1XYBodEiWk9JL9LkSixa5hZVsuVBjIirc5qZ8w1FF5G1gri8lMoUL1CDq1XMBonHjyJ6/SRP3DTxRg8T06S6pns2PMCaiSlsvbwFYzoNomTfPffgFAkSTJsUfU1KHHebOm8hBokMHV8syxkRMuH0S28nfJ/ErLiGf8VtgotxRR0W+iamgRJ0rsXWrG+31gP1JGhNp4TY3FbEYgfHNzJlujYKjj3bzICIxiqkoaWkug2yimTHDdVxbf4QxERfuehKXikjNoPu1ROQS/4plyMx0yfqaNnWZXf0OEOCCxLp1bnW1RDJ9ultU6ZRTYl0SY5JOuH0Sj6rq1sAdVf0deNSfIhmmTXM1iGOPdQGitKk2Siowwumnn6JzvUhQdUHinHNcv4oxJqLCDRKF7Zeg03Lj3EcfQc+ecNxxrokpmh2xiTgM9ocfXFCzWdbG+CLcIJEtIs+JSHPv5zlgoZ8FS0mTJsGll7oFg2bMcKOZoikQJBIpZXigD8WChDG+CDdI3A7sBcbjVpDbDdzqV6FS0nvvQe/e0L6964+oUyf6ZWjQACpVSqyaxPTp0LLlwQBnjImocEc3/QE86HNZUtf48dC/P3TqBFOnQs2axR/jh3LlXEd5ogSJ3btdn83118e6JMYkrXBHN30iIrWC7tcWken+FSuFTJoEV1zh1kCYPj12ASKgWbPECRJz57qRWNbUZIxvwm1uqueNaAJAVbdgM67LThX+9jdo3drVIGrEwXSURJpQN326W4Wua9dYl8SYpBVukMgTkaMDd0SkKYVkhTUlNHcuLF0K99wTPyuppaXB77+7n3g3bRp06RI/r50xSSjcYax/B+aKSBYgQBfgRt9KlSqGD3fNS5dfHuuSHBQ8DLZ9+9iWpShr18J338HVV8e6JMYktbBqEqo6DcgAvgfeBu4FEmxabpzZuBHefRcGDICqVWNdmoMSZa6ErUJnTFSEm+DveuBOoDGwGDgF+Jz8y5makhgzBvbuhZtuinVJ8kuUIDF9uktV0qZNrEtiTFILt0/iTuAk4CdVPQtoDyRAo3WcysuDESPgjDNcp3U8qV3bNYHFc5AIrEJ3wQVuDQljjG/CDRK7VXU3gIhUUtXlQCv/ipXkZsyAH3+Em2+OdUkKF+8jnLKzYcsWa2oyJgrC7bjO8eZJTAQ+EZEtQAJlgYszw4e7lBu9esW6JIVLS4Ply2NditBsFTpjoibcGdeXejcHi8hMoCaQgAsPxIH//c9NoLv3XpcCIx4F1pVQjc/mnOnTISMD6taNdUmMSXolXr5UVbNUdbKq7vWjQElv1CjXpn5jHI8gTktzM5nXr491SQ61ZQt88YU1NRkTJaVd49qURm4ujBwJ558PzZvHujShxfMIpxkzXMe/rUJnTFRYkIimqVMhJyd+O6wD4jlleCC/1cknx7okxqQECxLRNHw4NGzoVp2LZ02but/xVpMIXoWugq15ZUw0WJCIljVrXE3i+uvjf5nNqlXdkqnxFiSWLYNffrH+CGOiyIJEtPznP26kUKKsfRCPKcOne9npLUgYEzUWJKJh71545RXXzNSkSaxLE55oTKjbsAHmz3fNSOGYPh3S0+GYY/wtlzHmAAsS0TBxovtAHDQo1iUJX1qaa9rJzfXvGnfdBaecAscdB88/D5s3h9531y7IyrJahDFRZkEiGoYPd53B558f65KELy3Nzef45Rf/rvHZZy4deZ06bk2NRo1g4EA3D6Jg7WLOHLdcqQUJY6LKgoTfli+HmTNdttdyCfRy+z1X4tdf4eef4aqrYN48WLzYBYj33oNTT4UOHVwSxO3b3f7TprkZ6mee6U95jDGFSqBPrQQ1cqQbzXTNNbEuScn4HSTmz3e/A/Md2raFl192aUuGD3c1iZtvdkOGBw2CyZNd1tx4WnvDmBRgQcJPu3a5dSN69XJDShNJkyZQvry/QaJChUNXv6tRw9W6vvoKPv8cLrvMvYY//mizrI2JAQsSfpowweUaivcZ1oWpUMEFCr+CxBdfuNpDlSqFPy7iOrXHjHFLlb79dmK+jsYkOF+DhIh0E5HvRWSliDxYyOM3i8i3IrJYROaKSOugx/7qHfe9iCRmb+Xw4dCqVeK2o/s1DHb/fliwIPzUGnXqQN++1tRkTAz4FiREpDzwInAh0BroFxwEPGNVtY2qtgOeAp7zjm0N9AWOB7oBL3nnSxxff+2aS26+OT7TbYfDryCxbBns2GH5l4xJAH7WJDoBK1V1lZdWfBzQM3gHVd0WdLcaEBj32BMYp6p7VHU1sNI7X+IYMQIqV4arr451SUovLc2NQtq1K7LnLdhpbYyJW34GiUZA8CD7HG9bPiJyq4j8iKtJ3FHCY28UkWwRyd64cWPECl5m27bBm2/C5Ze7ppJEFRjhtGZNZM87f75bS7tFi8ie1xgTcTHvuFbVF1W1OfAA8FAJjx2pqhmqmlG/fn1/ClgaL7/sxvfffnusS1I2fqUMnz8fOnVKrHkjxqQoP/9L1wLBiYoae9tCGQdcUspj48euXfDcc25mcMeOsS5N2fgxV2LHDvjuO2tqMiZB+BkkFgAtRCRNRCriOqInB+8gIsHtDd2BFd7tyUBfEakkImlAC+BLH8saOaNGuTxNf/tbrEtSdg0auH6VSAaJhQvdynIWJIxJCL6t3KKquSJyGzAdKA+8qqpLRGQIkK2qk4HbRORcYB+wBRjgHbtERN4BlgK5wK2qut+vskbM3r3w1FPQuTN06RLr0pSdSORHOH3xhfvdKbHGIRiTqnxd3ktVpwBTCmx7JOj2nUUc+zjwuH+l88HYsS4h3ogRiTvstaBIB4n589363vXqRe6cxhjfWM9hpOzfD//8J7Rrl1zpI/wIEtbUZEzCsIWCI+X99+GHH+Cdd5KnFgEuSGzd6tKL1K5dtnPl5LgEfhYkjEkYVpOIBFX4v/9zKTh69Yp1aSIrkiOcApPoTjml7OcyxkSFBYlImDbNrYfw4IMuc2oyiXSQqFjRJfYzxiQECxJlpQqPPw5HHw39+8e6NJEX6SDRvr1bPMgYkxAsSJTVnDluGc777nOLCyWbWrXcT1mDRG4uZGdbf4QxCcaCRFn93//BEUfAddfFuiT+icQIpyVLYOdOCxLGJBgLEmWRnQ3Tp8M994RePCcZRCJIBCbRWZAwJqFYkCiLf/4TatZ0azAns7Q0lwlWtdhdQ5o/302ga9YsYsUyxvjPgkRpLV3q5kbcfjscfnisS+OvtDTYvdutLVFagcyvyTSHxJgUYEGitJ54wi2neWfIzCLJo6wpw7dtc6vR2fwIYxKOBYnSWL3a5Wm66abUyEEUaCIqbb/EggWuqcr6I4xJOBYkSuPpp92COffeG+uSREfTpu53aYNEYKa1ZX41JuFYkCipdevg1Vdh4EBodMiKqsmpcmU46qiyBYlWrdx8C2NMQrEgUVLPPQf79sEDD8S6JNFV2mGwqpb51ZgEZkGiJDZvdutX9+3r1kRIJc2bw7ffuglxJfHTT7B+vQUJYxKUBYmSePFF+OMPl8gv1dx4I2zaBM88U7LjAv0RFiSMSUgWJMKVl+fWrz7vPGjTJtalib7TT4c+feDJJ2Ht2vCPmz/f9WmceKJ/ZTPG+MaCRLhmzXJNJ9dcE+uSxM6TT7pEfX//e/jHzJ8PHTsmZ/JDY1KABYlwjRnjZlZfckmsSxI7aWlw113w2muwcGHx++/bB4sWWVOTMQnMgkQ4tm2Dd991HdbJnMgvHH//O9SvD3ffXXwup2++cek8LEgYk7AsSIRjwgTYtSu1m5oCDj8chg5162i8/37R+1qntTEJz4JEOMaMcZPB7MPOue46OOEEuP9+2LMn9H7z58ORR7pV+4wxCcmCRHFWroS5c10twjKYOhUquEmFq1bBsGGh9/viCxdY7XUzJmFZkCjOmDEuT9OVV8a6JPHlvPOge3f4xz9gw4ZDH9+yBX74wWpfxiQ4CxJF2b/fjeQ5//zUydNUEs8842ZgP/rooY99+aX7bUHCmIRmQaIoM2dCTo51WIeSnu5W5Rs5Er77Lv9j8+e7ZqaTTopN2YwxEWFBoiijR7vMpRdfHOuSxK9HH3VLuN57b/4hsfPnQ+vWyb9qnzFJzoJEKFu3uiGe/fq5tBKmcHXrwiOPwMcfw9SpbptlfjUmaViQCOWdd9xEMGtqKt4tt0CLFq42sW+fG/W0aZMFCWOSgAWJUEaPds0lGRmxLkn8q1jRdWIvXw4jRtgkOmOSiAWJwnz/PXz+uVt9zsb4h+dPf4Kzz3Z9FNOmQdWqcPzxsS6VMaaMLEgU5rXXoHx5mxtREiJugt2WLfDGG64GVqFCrEtljCkjCxIF7d8Pr78O3bq5dZ1N+Nq2dSk7wJqajEkSFiQKysx0i+oMHBjrkiSmoUNdgOjVK9YlMcZEgLUHFDRmDNSp49rYTck1aOByNhljkoLVJIJt2QIffABXXAGVKsW6NMYYE3MWJIKNH+9SX1tTkzHGABYk8hszBtq0gQ4dYl0SY4yJC74GCRHpJiLfi8hKEXmwkMfvEZGlIvKNiMwQkWOCHtsvIou9n8l+lhOAZcvcJDCbG2GMMQf41nEtIuWBF4HzgBxggYhMVtWlQbt9BWSo6k4RGQQ8BVzuPbZLVdv5Vb5DjBnj5kb07x+1SxpjTLzzsybRCVipqqtUdS8wDugZvIOqzlTVnd7dL4DGPpYntNxcNwGse3e33KYxxhjA3yDRCPgl6H6Oty2U64CpQfcri0i2iHwhIpcUdoCI3Ojtk71x48bSl/STT2DdOuuwNsaYAuJinoSIXAlkAGcGbT5GVdeKSDPgUxH5VlV/DD5OVUcCIwEyMjKU0ho9GurVczUJY4wxB/hZk1gLNAm639jblo+InAv8HbhYVfcEtqvqWu/3KmAW0N6XUm7eDJMmub6IihV9uYQxxiQqP4PEAqCFiKSJSEWgL5BvlJKItAdG4ALEhqDttUWkkne7HtAZCO7wjhwReOghuP56X05vjDGJzLfmJlXNFZHbgOlAeeBVVV0iIkOAbFWdDDwNVAcmiBt2+rOqXgwcB4wQkTxcIHuiwKioyKldGx5+2JdTG2NMohPV0jflx5OMjAzNzs6OdTGMMSahiMhCVQ25uprNuDbGGBOSBQljjDEhWZAwxhgTUlzMk4il/fvh559jXYrYOuwwqFzZZUevVMndL0n6qtxclzx39273e+9eCLerq1y5g9cNlKFcCb66qLprBv/k5oZ/vDHJoFIlaNjQn3OnfJDYvBmaNYt1KeJPcNAIfICL5P8wDgSFvLzIXrtChfxBo1IlN4WlYDAKBCRjUt3JJ/u31lfKB4kaNVxuv1SlCvv2HfrhW9j9vLxDA0dh9ytWDL82sH9/0dcMrp1UqBD6msH3K6T8X7VJNfXq+XfulP93qlwZBgyIdSmMMSY+Wce1McaYkCxIGGOMCcmChDHGmJAsSBhjjAnJgoQxxpiQLEgYY4wJyYKEMcaYkCxIGGOMCSlp1pMQkY3AT2U4RT3gtwgVJx4k2/OB5HtOyfZ8IPmeU7I9Hzj0OR2jqvVD7Zw0QaKsRCS7qIU3Ek2yPR9IvueUbM8Hku85JdvzgZI/J2tuMsYYE5IFCWOMMSFZkDhoZKwLEGHJ9nwg+Z5Tsj0fSL7nlGzPB0r4nKxPwhhjTEhWkzDGGBOSBQljjDEhpXyQEJFuIvK9iKwUkQdjXZ5IEJE1IvKtiCwWkexYl6ekRORVEdkgIt8FbasjIp+IyArvd+1YlrGkQjynwSKy1nufFovIRbEsY0mISBMRmSkiS0VkiYjc6W1PyPepiOeTyO9RZRH5UkS+9p7TY972NBGZ733mjReRikWeJ5X7JESkPPADcB6QAywA+qnq0pgWrIxEZA2QoaoJOQlIRM4AdgCvq+oJ3rangM2q+oQXzGur6gOxLGdJhHhOg4EdqvpMLMtWGiJyFHCUqi4SkRrAQuASYCAJ+D4V8Xz+TOK+RwJUU9UdInIYMBe4E7gHeF9Vx4nIcOBrVX051HlSvSbRCVipqqtUdS8wDugZ4zKlPFWdDWwusLkn8Jp3+zXcP3DCCPGcEpaqrlPVRd7t7cAyoBEJ+j4V8XwSljo7vLuHeT8KnA28620v9j1K9SDRCPgl6H4OCf6H4VHgYxFZKCI3xrowEXKkqq7zbv8KHBnLwkTQbSLyjdcclRBNMwWJSFOgPTCfJHifCjwfSOD3SETKi8hiYAPwCfAj8Luq5nq7FPuZl+pBIlmdrqodgAuBW72mjqShro00GdpJXwaaA+2AdcCzsS1OyYlIdeA94C5V3Rb8WCK+T4U8n4R+j1R1v6q2AxrjWk7SS3qOVA8Sa4EmQfcbe9sSmqqu9X5vAD7A/XEkuvVeu3Gg/XhDjMtTZqq63vsnzgP+Q4K9T14793vAW6r6vrc5Yd+nwp5Por9HAar6OzATOBWoJSIVvIeK/cxL9SCxAGjh9fZXBPoCk2NcpjIRkWpexxsiUg04H/iu6KMSwmRggHd7ADAphmWJiMCHqedSEuh98jpFRwHLVPW5oIcS8n0K9XwS/D2qLyK1vNtVcAN0luGCRW9vt2Lfo5Qe3QTgDWl7ASgPvKqqj8e4SGUiIs1wtQeACsDYRHtOIvI20BWX0ng98CgwEXgHOBqXEv7PqpowHcEhnlNXXDOGAmuAm4La8+OaiJwOzAG+BfK8zX/DteMn3PtUxPPpR+K+RyfiOqbL4yoE76jqEO8zYhxQB/gKuFJV94Q8T6oHCWOMMaGlenOTMcaYIliQMMYYE5IFCWOMMSFZkDDGGBOSBQljjDEhWZAwJg6ISFcR+TDW5TCmIAsSxhhjQrIgYUwJiMiVXo7+xSIywkugtkNEnvdy9s8Qkfrevu1E5AsvOdwHgeRwInKsiGR6ef4XiUhz7/TVReRdEVkuIm95s4CNiSkLEsaESUSOAy4HOntJ0/YD/YFqQLaqHg9k4WZTA7wOPKCqJ+Jm8ga2vwW8qKptgdNwiePAZR69C2gNNAM6+/6kjClGheJ3McZ4zgE6Agu8L/lVcAns8oDx3j5vAu+LSE2glqpmedtfAyZ4ebUaqeoHAKq6G8A735eqmuPdXww0xS0UY0zMWJAwJnwCvKaqf823UeThAvuVNtdNcP6c/dj/p4kD1txkTPhmAL1F5Ag4sJ7zMbj/o0BWzSuAuaq6FdgiIl287VcBWd6qZzkicol3jkoiUjWqz8KYErBvKsaESVWXishDuFX/ygH7gFuBP4BO3mMbcP0W4NIwD/eCwCrgGm/7VcAIERninaNPFJ+GMSViWWCNKSMR2aGq1WNdDmP8YM1NxhhjQrKahDHGmJCsJmGMMSYkCxLGGGNCsiBhjDEmJAsSxhhjQrIgYYwxJqT/DynBQ1vSfx9hAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}