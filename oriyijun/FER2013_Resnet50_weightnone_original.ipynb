{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FER2013_Resnet50_weightnone_nodropout.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-Qn1jsBTIBl0b7myLQxqa8WjCcfbamqM",
      "authorship_tag": "ABX9TyMLhC7Q9tWVmXvI+rV/WLXn"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b86nukQOxN7l"
      },
      "source": [
        "Resnet-50 From Scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p8gxtGy0TWP",
        "outputId": "d71d0a17-2049-4d42-c44e-e7a0c025cd61"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "inputFolder = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth' \n",
        "for root, directories, filenames in os.walk(inputFolder): \n",
        "    for filename in filenames: print(os.path.join(root,filename))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe4.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsiscWIMBDX2",
        "outputId": "86d8b0f3-a584-4fb4-85d1-a36677092ba3"
      },
      "source": [
        "%cd /content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "wLMSe510xNCJ",
        "outputId": "3da9f6f5-cb75-4f61-d978-1e7de9a074fc"
      },
      "source": [
        "#Create a directory to save our generated models.\n",
        "\n",
        "#os.mkdir(\"./modelscracth\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-cf55f19f3613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#os.mkdir(\"./modelscracth\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ls' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_kluusLxM1B",
        "outputId": "78ad7b63-9c92-42f0-dbc5-4bf69e7e3a15"
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:400: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfUSF_tAxNMP"
      },
      "source": [
        "#Define the identity block helper function.\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "   \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VdYtzhn1F0I"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path \n",
        "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b',padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd-O8ZMx1GAW"
      },
      "source": [
        "\"\"\"def ResNet50(input_shape = (48,48,1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    #X = ZeroPadding2D((1, 1))(X_input)\n",
        "    X = X_input\n",
        "    # Stage 1\n",
        "\n",
        "    X = Conv2D(8, (3, 3), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # removed maxpool\n",
        "    #X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='c')\n",
        "\n",
        "\n",
        "    # Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [64,64,256], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL . \n",
        "    X = AveragePooling2D((2,2), name='avg_pool')(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(512, activation = 'relu', name='fc1024' , kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model\"\"\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GKsSwtp-GuL"
      },
      "source": [
        "def ResNet50ori(input_shape = (48, 48, 1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50ori')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oWTDXlyBHM2"
      },
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        " \n",
        "dataset_path = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv'\n",
        "image_size=(48,48)\n",
        "#batch_size = 64\n",
        "\n",
        "def load_fer2013():\n",
        "    data = pd.read_csv(dataset_path)\n",
        "    data = (data[data['pixels'].notnull()])\n",
        "    pixels = data['pixels'].tolist()\n",
        "    width, height = 48, 48\n",
        "    faces = []\n",
        "    for pixel_sequence in pixels:\n",
        "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "        face = np.asarray(face).reshape(width, height)\n",
        "        face = cv2.resize(face.astype('uint8'),image_size)\n",
        "        faces.append(face.astype('float32'))\n",
        "    faces = np.asarray(faces)\n",
        "    faces = np.expand_dims(faces, -1)\n",
        "    emotions = (data['emotion'])#.values\n",
        "    return faces, emotions\n",
        " \n",
        "def preprocess_input(x, v2=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if v2:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x\n",
        " \n",
        "faces, emotions = load_fer2013()\n",
        "faces = preprocess_input(faces)\n",
        "#xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
        "#Data Augumentation\n",
        "\"\"\"data_generator = ImageDataGenerator(\n",
        "                        rotation_range=10,\n",
        "                        shear_range = 10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True)\"\"\"\n",
        "data_generator = ImageDataGenerator( )\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWLhavr-rSF5"
      },
      "source": [
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.1, train_size=0.9)\n",
        "x_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1, train_size=0.9)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH9Q-TegBR26"
      },
      "source": [
        "#hyperparameter and callback\n",
        "batch_size = 64\n",
        "num_epochs = 60\n",
        "input_shape = (48, 48, 1)\n",
        "num_classes = 7\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGsscQRJBR-h"
      },
      "source": [
        "#Compile the model.\n",
        "\n",
        "\n",
        "from keras.optimizers import Adam, SGD\n",
        "model = ResNet50ori(input_shape = (48, 48, 1), classes = 7)\n",
        "optimizer = Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-7)\n",
        "model.compile(optimizer= optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rodttDWeT2yP"
      },
      "source": [
        "#kita mau save model callbacks\n",
        "import os\n",
        "try:\n",
        "  os.mkdir('scratchcheckpoint')\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV29sTjET28U"
      },
      "source": [
        "file_name = 'Best_Model_resnet50Scracth_oriyijungan3.h5'\n",
        "\n",
        "checkpoint_path = os.path.join('checkpoint',file_name)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_S6wUaPT3Jx"
      },
      "source": [
        "call_back = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
        "                                               monitor='val_accuracy',\n",
        "                                               verbose=1,\n",
        "                                               save_freq='epoch',\n",
        "                                               save_best_only=True,\n",
        "                                               save_weights_only=False,\n",
        "                                               mode='max')"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy53DHMGB-Mr",
        "outputId": "c4d9ccc5-32fa-4719-c185-0bf29ecf5448"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50ori\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPadding2D (None, 54, 54, 1)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 24, 24, 64)   3200        zero_padding2d_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 24, 24, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_196 (Activation)     (None, 24, 24, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 11, 11, 64)   0           activation_196[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 11, 11, 64)   4160        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_197 (Activation)     (None, 11, 11, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_197[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_198 (Activation)     (None, 11, 11, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 11, 11, 256)  16640       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 11, 11, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_64 (Add)                    (None, 11, 11, 256)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_199 (Activation)     (None, 11, 11, 256)  0           add_64[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 11, 11, 64)   16448       activation_199[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_200 (Activation)     (None, 11, 11, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_200[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_201 (Activation)     (None, 11, 11, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_201[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_65 (Add)                    (None, 11, 11, 256)  0           activation_199[0][0]             \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_202 (Activation)     (None, 11, 11, 256)  0           add_65[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 11, 11, 64)   16448       activation_202[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_203 (Activation)     (None, 11, 11, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_203[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_204 (Activation)     (None, 11, 11, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_204[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_66 (Add)                    (None, 11, 11, 256)  0           activation_202[0][0]             \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_205 (Activation)     (None, 11, 11, 256)  0           add_66[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 6, 6, 128)    32896       activation_205[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_206 (Activation)     (None, 6, 6, 128)    0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_206[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_207 (Activation)     (None, 6, 6, 128)    0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 6, 6, 512)    131584      activation_205[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_207[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 6, 6, 512)    2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_67 (Add)                    (None, 6, 6, 512)    0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_208 (Activation)     (None, 6, 6, 512)    0           add_67[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_208[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_209 (Activation)     (None, 6, 6, 128)    0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_209[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_210 (Activation)     (None, 6, 6, 128)    0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_210[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_68 (Add)                    (None, 6, 6, 512)    0           activation_208[0][0]             \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_211 (Activation)     (None, 6, 6, 512)    0           add_68[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_211[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_212 (Activation)     (None, 6, 6, 128)    0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_212[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_213 (Activation)     (None, 6, 6, 128)    0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_213[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_69 (Add)                    (None, 6, 6, 512)    0           activation_211[0][0]             \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_214 (Activation)     (None, 6, 6, 512)    0           add_69[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_214[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_215 (Activation)     (None, 6, 6, 128)    0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_215[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_216 (Activation)     (None, 6, 6, 128)    0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_216[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_70 (Add)                    (None, 6, 6, 512)    0           activation_214[0][0]             \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_217 (Activation)     (None, 6, 6, 512)    0           add_70[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 3, 3, 256)    131328      activation_217[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_218 (Activation)     (None, 3, 3, 256)    0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_218[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_219 (Activation)     (None, 3, 3, 256)    0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 3, 3, 1024)   525312      activation_217[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_219[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 3, 3, 1024)   4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_71 (Add)                    (None, 3, 3, 1024)   0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_220 (Activation)     (None, 3, 3, 1024)   0           add_71[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_220[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_221 (Activation)     (None, 3, 3, 256)    0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_221[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_222 (Activation)     (None, 3, 3, 256)    0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_222[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_72 (Add)                    (None, 3, 3, 1024)   0           activation_220[0][0]             \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_223 (Activation)     (None, 3, 3, 1024)   0           add_72[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_223[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_224 (Activation)     (None, 3, 3, 256)    0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_224[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_225 (Activation)     (None, 3, 3, 256)    0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_225[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_73 (Add)                    (None, 3, 3, 1024)   0           activation_223[0][0]             \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_226 (Activation)     (None, 3, 3, 1024)   0           add_73[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_226[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_227 (Activation)     (None, 3, 3, 256)    0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_227[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_228 (Activation)     (None, 3, 3, 256)    0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_228[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_74 (Add)                    (None, 3, 3, 1024)   0           activation_226[0][0]             \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_229 (Activation)     (None, 3, 3, 1024)   0           add_74[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_229[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_230 (Activation)     (None, 3, 3, 256)    0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_230[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_231 (Activation)     (None, 3, 3, 256)    0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_75 (Add)                    (None, 3, 3, 1024)   0           activation_229[0][0]             \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_232 (Activation)     (None, 3, 3, 1024)   0           add_75[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_232[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_233 (Activation)     (None, 3, 3, 256)    0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_233[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_234 (Activation)     (None, 3, 3, 256)    0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_234[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_76 (Add)                    (None, 3, 3, 1024)   0           activation_232[0][0]             \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_235 (Activation)     (None, 3, 3, 1024)   0           add_76[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 2, 2, 512)    524800      activation_235[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_236 (Activation)     (None, 2, 2, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_236[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_237 (Activation)     (None, 2, 2, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 2, 2, 2048)   2099200     activation_235[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_237[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 2, 2, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_77 (Add)                    (None, 2, 2, 2048)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_238 (Activation)     (None, 2, 2, 2048)   0           add_77[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_238[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_239 (Activation)     (None, 2, 2, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_239[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_240 (Activation)     (None, 2, 2, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_240[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_78 (Add)                    (None, 2, 2, 2048)   0           activation_238[0][0]             \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_241 (Activation)     (None, 2, 2, 2048)   0           add_78[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_241[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_242 (Activation)     (None, 2, 2, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_242[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_243 (Activation)     (None, 2, 2, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_243[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_79 (Add)                    (None, 2, 2, 2048)   0           activation_241[0][0]             \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_244 (Activation)     (None, 2, 2, 2048)   0           add_79[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_244[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 2048)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            14343       flatten_4[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 23,595,783\n",
            "Trainable params: 23,542,663\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgxCecVwCGEr",
        "outputId": "8988e6bf-b434-4650-c46f-22f92303943d"
      },
      "source": [
        "\"\"\"history = model.fit(data_generator.flow(xtrain, ytrain,),\n",
        "                        steps_per_epoch=len(xtrain) / batch_size,\n",
        "                        epochs=num_epochs, verbose=1,callbacks=call_back,\n",
        "                        validation_data= (xtest,ytest))\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "448/448 [==============================] - 65s 122ms/step - loss: 2.2711 - accuracy: 0.2151 - val_loss: 1.8425 - val_accuracy: 0.2538\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.25383, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 1.8064 - accuracy: 0.2511 - val_loss: 1.8161 - val_accuracy: 0.2594\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.25383 to 0.25940, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 3/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.7689 - accuracy: 0.2632 - val_loss: 1.7616 - val_accuracy: 0.2795\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.25940 to 0.27947, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 4/50\n",
            "448/448 [==============================] - 57s 126ms/step - loss: 1.7297 - accuracy: 0.3022 - val_loss: 1.7276 - val_accuracy: 0.2990\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.27947 to 0.29897, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 5/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.6804 - accuracy: 0.3269 - val_loss: 1.6247 - val_accuracy: 0.3504\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.29897 to 0.35038, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 6/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.6096 - accuracy: 0.3661 - val_loss: 1.5590 - val_accuracy: 0.3823\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.35038 to 0.38228, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 7/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.5340 - accuracy: 0.4051 - val_loss: 1.5257 - val_accuracy: 0.4087\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.38228 to 0.40875, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 8/50\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 1.5127 - accuracy: 0.4046 - val_loss: 1.5014 - val_accuracy: 0.4139\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.40875 to 0.41390, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 9/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.4779 - accuracy: 0.4241 - val_loss: 1.4280 - val_accuracy: 0.4503\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.41390 to 0.45026, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 10/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.4282 - accuracy: 0.4475 - val_loss: 1.4991 - val_accuracy: 0.4154\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.45026\n",
            "Epoch 11/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.4105 - accuracy: 0.4555 - val_loss: 1.3838 - val_accuracy: 0.4620\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.45026 to 0.46197, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 12/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.3500 - accuracy: 0.4850 - val_loss: 1.3392 - val_accuracy: 0.4799\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.46197 to 0.47994, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 13/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 1.3333 - accuracy: 0.4895 - val_loss: 1.3158 - val_accuracy: 0.4946\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.47994 to 0.49457, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 14/50\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 1.2905 - accuracy: 0.5087 - val_loss: 1.3923 - val_accuracy: 0.4912\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.49457\n",
            "Epoch 15/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.2800 - accuracy: 0.5112 - val_loss: 1.2229 - val_accuracy: 0.5344\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.49457 to 0.53441, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 16/50\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 1.2456 - accuracy: 0.5286 - val_loss: 1.2321 - val_accuracy: 0.5258\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.53441\n",
            "Epoch 17/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.2397 - accuracy: 0.5268 - val_loss: 1.2038 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.53441 to 0.53845, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 18/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.2112 - accuracy: 0.5434 - val_loss: 1.2470 - val_accuracy: 0.5208\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.53845\n",
            "Epoch 19/50\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 1.1876 - accuracy: 0.5505 - val_loss: 1.2147 - val_accuracy: 0.5336\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.53845\n",
            "Epoch 20/50\n",
            "448/448 [==============================] - 51s 115ms/step - loss: 1.1875 - accuracy: 0.5495 - val_loss: 1.1693 - val_accuracy: 0.5511\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.53845 to 0.55113, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 21/50\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 1.1622 - accuracy: 0.5580 - val_loss: 1.2089 - val_accuracy: 0.5344\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.55113\n",
            "Epoch 22/50\n",
            "448/448 [==============================] - 56s 126ms/step - loss: 1.1420 - accuracy: 0.5658 - val_loss: 1.1683 - val_accuracy: 0.5574\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.55113 to 0.55740, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 23/50\n",
            "448/448 [==============================] - 51s 115ms/step - loss: 1.1426 - accuracy: 0.5670 - val_loss: 1.1895 - val_accuracy: 0.5475\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.55740\n",
            "Epoch 24/50\n",
            "448/448 [==============================] - 57s 126ms/step - loss: 1.1447 - accuracy: 0.5654 - val_loss: 1.1481 - val_accuracy: 0.5698\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.55740 to 0.56980, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 25/50\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 1.0988 - accuracy: 0.5806 - val_loss: 1.0838 - val_accuracy: 0.5938\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.56980 to 0.59376, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 26/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.0941 - accuracy: 0.5851 - val_loss: 1.2003 - val_accuracy: 0.5529\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.59376\n",
            "Epoch 27/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 1.0957 - accuracy: 0.5909 - val_loss: 1.1363 - val_accuracy: 0.5758\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.59376\n",
            "Epoch 28/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.0562 - accuracy: 0.6027 - val_loss: 1.1244 - val_accuracy: 0.5738\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.59376\n",
            "Epoch 29/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 1.0445 - accuracy: 0.6041 - val_loss: 1.0976 - val_accuracy: 0.5861\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.59376\n",
            "Epoch 30/50\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 1.0413 - accuracy: 0.5992 - val_loss: 1.1102 - val_accuracy: 0.5867\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.59376\n",
            "Epoch 31/50\n",
            "448/448 [==============================] - 56s 126ms/step - loss: 1.0303 - accuracy: 0.6060 - val_loss: 1.0553 - val_accuracy: 0.6056\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.59376 to 0.60560, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 32/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 1.0454 - accuracy: 0.6025 - val_loss: 1.0681 - val_accuracy: 0.5988\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.60560\n",
            "Epoch 33/50\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 1.0070 - accuracy: 0.6213 - val_loss: 1.0881 - val_accuracy: 0.5949\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.60560\n",
            "Epoch 34/50\n",
            "448/448 [==============================] - 57s 127ms/step - loss: 1.0123 - accuracy: 0.6159 - val_loss: 1.1018 - val_accuracy: 0.5897\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.60560\n",
            "Epoch 35/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 0.9944 - accuracy: 0.6208 - val_loss: 1.0713 - val_accuracy: 0.5999\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.60560\n",
            "Epoch 36/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 1.0049 - accuracy: 0.6201 - val_loss: 1.0473 - val_accuracy: 0.6127\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.60560 to 0.61271, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 37/50\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 0.9791 - accuracy: 0.6334 - val_loss: 1.0589 - val_accuracy: 0.6043\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.61271\n",
            "Epoch 38/50\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 0.9641 - accuracy: 0.6281 - val_loss: 1.0680 - val_accuracy: 0.5972\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.61271\n",
            "Epoch 39/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 0.9775 - accuracy: 0.6277 - val_loss: 1.2166 - val_accuracy: 0.5575\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.61271\n",
            "Epoch 40/50\n",
            "448/448 [==============================] - 56s 124ms/step - loss: 0.9695 - accuracy: 0.6381 - val_loss: 1.0728 - val_accuracy: 0.5947\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.61271\n",
            "Epoch 41/50\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 0.9418 - accuracy: 0.6410 - val_loss: 1.0668 - val_accuracy: 0.5978\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.61271\n",
            "Epoch 42/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 0.9483 - accuracy: 0.6383 - val_loss: 1.0436 - val_accuracy: 0.6160\n",
            "\n",
            "Epoch 00042: val_accuracy improved from 0.61271 to 0.61605, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 43/50\n",
            "448/448 [==============================] - 56s 126ms/step - loss: 0.9589 - accuracy: 0.6440 - val_loss: 1.0460 - val_accuracy: 0.6101\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.61605\n",
            "Epoch 44/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 0.9422 - accuracy: 0.6480 - val_loss: 1.0838 - val_accuracy: 0.5991\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.61605\n",
            "Epoch 45/50\n",
            "448/448 [==============================] - 51s 115ms/step - loss: 0.9410 - accuracy: 0.6449 - val_loss: 1.0646 - val_accuracy: 0.5995\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.61605\n",
            "Epoch 46/50\n",
            "448/448 [==============================] - 56s 124ms/step - loss: 0.9130 - accuracy: 0.6571 - val_loss: 1.0363 - val_accuracy: 0.6148\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.61605\n",
            "Epoch 47/50\n",
            "448/448 [==============================] - 51s 115ms/step - loss: 0.9051 - accuracy: 0.6632 - val_loss: 1.0098 - val_accuracy: 0.6296\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.61605 to 0.62956, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 48/50\n",
            "448/448 [==============================] - 56s 126ms/step - loss: 0.9064 - accuracy: 0.6556 - val_loss: 1.0776 - val_accuracy: 0.6002\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.62956\n",
            "Epoch 49/50\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 0.9066 - accuracy: 0.6624 - val_loss: 1.0612 - val_accuracy: 0.6158\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.62956\n",
            "Epoch 50/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 0.9066 - accuracy: 0.6581 - val_loss: 1.0227 - val_accuracy: 0.6211\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.62956\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2muXWns0sJSH",
        "outputId": "00c4da10-44c4-4422-8d2e-4b2062953a9a"
      },
      "source": [
        "history = model.fit(\n",
        "    data_generator.flow(xtrain, ytrain,),\n",
        "    steps_per_epoch=len(xtrain) / batch_size,\n",
        "    epochs=num_epochs, \n",
        "    verbose=1,\n",
        "    callbacks=call_back,\n",
        "    validation_data= (x_val,y_val))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "504/504 [==============================] - 54s 82ms/step - loss: 4.2246 - accuracy: 0.2255 - val_loss: 1.7816 - val_accuracy: 0.2570\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.25697, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/60\n",
            "504/504 [==============================] - 39s 77ms/step - loss: 1.7964 - accuracy: 0.2531 - val_loss: 1.8361 - val_accuracy: 0.2594\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.25697 to 0.25944, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "Epoch 3/60\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 1.7286 - accuracy: 0.3006 - val_loss: 1.7841 - val_accuracy: 0.3375\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.25944 to 0.33746, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "Epoch 4/60\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 1.6560 - accuracy: 0.3436 - val_loss: 1.5930 - val_accuracy: 0.3715\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.33746 to 0.37152, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "Epoch 5/60\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 1.6192 - accuracy: 0.3658 - val_loss: 1.6690 - val_accuracy: 0.3669\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.37152\n",
            "Epoch 6/60\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 1.5768 - accuracy: 0.3818 - val_loss: 2.5628 - val_accuracy: 0.3808\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.37152 to 0.38080, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "Epoch 7/60\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 1.5173 - accuracy: 0.4003 - val_loss: 1.5155 - val_accuracy: 0.4050\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.38080 to 0.40495, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "Epoch 8/60\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 1.5036 - accuracy: 0.4068 - val_loss: 1.6281 - val_accuracy: 0.3471\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.40495\n",
            "Epoch 9/60\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 1.5852 - accuracy: 0.3709 - val_loss: 2.8865 - val_accuracy: 0.3938\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.40495\n",
            "Epoch 10/60\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 1.4598 - accuracy: 0.4281 - val_loss: 1.6124 - val_accuracy: 0.4297\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.40495 to 0.42972, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "Epoch 11/60\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 1.3965 - accuracy: 0.4541 - val_loss: 1.3437 - val_accuracy: 0.4827\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.42972 to 0.48266, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "Epoch 12/60\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 1.4176 - accuracy: 0.4509 - val_loss: 1.3600 - val_accuracy: 0.4774\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.48266\n",
            "Epoch 13/60\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 1.3667 - accuracy: 0.4733 - val_loss: 3.7693 - val_accuracy: 0.3254\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.48266\n",
            "Epoch 14/60\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 1.3035 - accuracy: 0.4992 - val_loss: 1.2940 - val_accuracy: 0.5077\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.48266 to 0.50774, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "Epoch 15/60\n",
            "504/504 [==============================] - 39s 77ms/step - loss: 1.2706 - accuracy: 0.5111 - val_loss: 1.2415 - val_accuracy: 0.5204\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.50774 to 0.52043, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "Epoch 16/60\n",
            "504/504 [==============================] - 39s 77ms/step - loss: 1.2569 - accuracy: 0.5150 - val_loss: 6.3169 - val_accuracy: 0.3783\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.52043\n",
            "Epoch 17/60\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 1.2539 - accuracy: 0.5178 - val_loss: 3.0567 - val_accuracy: 0.4000\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.52043\n",
            "Epoch 18/60\n",
            "504/504 [==============================] - 39s 77ms/step - loss: 1.2898 - accuracy: 0.5061 - val_loss: 1.2308 - val_accuracy: 0.5183\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.52043\n",
            "Epoch 19/60\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 1.1856 - accuracy: 0.5479 - val_loss: 1.5557 - val_accuracy: 0.4796\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.52043\n",
            "Epoch 20/60\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 1.1741 - accuracy: 0.5552 - val_loss: 1.1029 - val_accuracy: 0.5780\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.52043 to 0.57802, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "Epoch 21/60\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 1.1260 - accuracy: 0.5761 - val_loss: 1.0866 - val_accuracy: 0.5882\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.57802 to 0.58824, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "Epoch 22/60\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 1.0935 - accuracy: 0.5880 - val_loss: 1.0886 - val_accuracy: 0.5802\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.58824\n",
            "Epoch 23/60\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 1.0385 - accuracy: 0.6032 - val_loss: 0.9891 - val_accuracy: 0.6254\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.58824 to 0.62539, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "Epoch 24/60\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 1.0294 - accuracy: 0.6163 - val_loss: 1.0222 - val_accuracy: 0.6282\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.62539 to 0.62817, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "Epoch 25/60\n",
            "504/504 [==============================] - 39s 78ms/step - loss: 0.9951 - accuracy: 0.6226 - val_loss: 1.0008 - val_accuracy: 0.6102\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.62817\n",
            "Epoch 26/60\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.9607 - accuracy: 0.6449 - val_loss: 1.0633 - val_accuracy: 0.6303\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.62817 to 0.63034, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "Epoch 27/60\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 0.9336 - accuracy: 0.6499 - val_loss: 0.8949 - val_accuracy: 0.6703\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.63034 to 0.67028, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "Epoch 28/60\n",
            "504/504 [==============================] - 39s 77ms/step - loss: 0.9143 - accuracy: 0.6592 - val_loss: 0.9748 - val_accuracy: 0.6474\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.67028\n",
            "Epoch 29/60\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.9324 - accuracy: 0.6565 - val_loss: 0.8455 - val_accuracy: 0.6851\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.67028 to 0.68514, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "Epoch 30/60\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 0.8317 - accuracy: 0.6954 - val_loss: 0.7239 - val_accuracy: 0.7440\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.68514 to 0.74396, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "Epoch 31/60\n",
            "504/504 [==============================] - 39s 77ms/step - loss: 0.7619 - accuracy: 0.7229 - val_loss: 0.7711 - val_accuracy: 0.7105\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.74396\n",
            "Epoch 32/60\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.7336 - accuracy: 0.7355 - val_loss: 0.7360 - val_accuracy: 0.7291\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.74396\n",
            "Epoch 33/60\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.6890 - accuracy: 0.7524 - val_loss: 0.7487 - val_accuracy: 0.7276\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.74396\n",
            "Epoch 34/60\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.6726 - accuracy: 0.7580 - val_loss: 0.6130 - val_accuracy: 0.7851\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.74396 to 0.78514, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "Epoch 35/60\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 0.6373 - accuracy: 0.7634 - val_loss: 0.5559 - val_accuracy: 0.8071\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.78514 to 0.80712, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "Epoch 36/60\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.6072 - accuracy: 0.7881 - val_loss: 0.6408 - val_accuracy: 0.7771\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.80712\n",
            "Epoch 37/60\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.5807 - accuracy: 0.7935 - val_loss: 0.5332 - val_accuracy: 0.8050\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.80712\n",
            "Epoch 38/60\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 0.4866 - accuracy: 0.8248 - val_loss: 0.4314 - val_accuracy: 0.8588\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.80712 to 0.85882, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "Epoch 39/60\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 0.4639 - accuracy: 0.8373 - val_loss: 0.4097 - val_accuracy: 0.8610\n",
            "\n",
            "Epoch 00039: val_accuracy improved from 0.85882 to 0.86099, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "Epoch 40/60\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 0.4338 - accuracy: 0.8517 - val_loss: 0.4358 - val_accuracy: 0.8533\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.86099\n",
            "Epoch 41/60\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 0.4370 - accuracy: 0.8459 - val_loss: 0.3589 - val_accuracy: 0.8774\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.86099 to 0.87740, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "Epoch 42/60\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 0.4139 - accuracy: 0.8559 - val_loss: 0.3881 - val_accuracy: 0.8653\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.87740\n",
            "Epoch 43/60\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 0.4738 - accuracy: 0.8358 - val_loss: 0.3516 - val_accuracy: 0.8836\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.87740 to 0.88359, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "Epoch 44/60\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 0.3443 - accuracy: 0.8812 - val_loss: 0.3218 - val_accuracy: 0.8923\n",
            "\n",
            "Epoch 00044: val_accuracy improved from 0.88359 to 0.89226, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "Epoch 45/60\n",
            "504/504 [==============================] - 39s 77ms/step - loss: 0.3381 - accuracy: 0.8815 - val_loss: 0.3183 - val_accuracy: 0.8913\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.89226\n",
            "Epoch 46/60\n",
            "504/504 [==============================] - 39s 76ms/step - loss: 0.3020 - accuracy: 0.8937 - val_loss: 0.3972 - val_accuracy: 0.8604\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.89226\n",
            "Epoch 47/60\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 0.2952 - accuracy: 0.8968 - val_loss: 0.3080 - val_accuracy: 0.8898\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.89226\n",
            "Epoch 48/60\n",
            "504/504 [==============================] - 39s 76ms/step - loss: 0.2548 - accuracy: 0.9121 - val_loss: 0.3192 - val_accuracy: 0.8861\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.89226\n",
            "Epoch 49/60\n",
            "504/504 [==============================] - 39s 77ms/step - loss: 0.2600 - accuracy: 0.9101 - val_loss: 0.2573 - val_accuracy: 0.9053\n",
            "\n",
            "Epoch 00049: val_accuracy improved from 0.89226 to 0.90526, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "Epoch 50/60\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 0.2548 - accuracy: 0.9110 - val_loss: 0.3031 - val_accuracy: 0.8991\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.90526\n",
            "Epoch 51/60\n",
            "504/504 [==============================] - 39s 78ms/step - loss: 0.2288 - accuracy: 0.9212 - val_loss: 0.2225 - val_accuracy: 0.9198\n",
            "\n",
            "Epoch 00051: val_accuracy improved from 0.90526 to 0.91981, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "Epoch 52/60\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 0.2050 - accuracy: 0.9289 - val_loss: 0.2702 - val_accuracy: 0.9077\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91981\n",
            "Epoch 53/60\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 0.2191 - accuracy: 0.9262 - val_loss: 0.1918 - val_accuracy: 0.9402\n",
            "\n",
            "Epoch 00053: val_accuracy improved from 0.91981 to 0.94025, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "Epoch 54/60\n",
            "504/504 [==============================] - 39s 78ms/step - loss: 0.2239 - accuracy: 0.9226 - val_loss: 0.5527 - val_accuracy: 0.8204\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.94025\n",
            "Epoch 55/60\n",
            "504/504 [==============================] - 39s 77ms/step - loss: 0.2854 - accuracy: 0.9072 - val_loss: 0.1948 - val_accuracy: 0.9328\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.94025\n",
            "Epoch 56/60\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 0.1720 - accuracy: 0.9426 - val_loss: 0.1506 - val_accuracy: 0.9492\n",
            "\n",
            "Epoch 00056: val_accuracy improved from 0.94025 to 0.94923, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "Epoch 57/60\n",
            "504/504 [==============================] - 39s 76ms/step - loss: 0.1678 - accuracy: 0.9443 - val_loss: 0.1791 - val_accuracy: 0.9381\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.94923\n",
            "Epoch 58/60\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 0.1735 - accuracy: 0.9421 - val_loss: 0.2723 - val_accuracy: 0.9037\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.94923\n",
            "Epoch 59/60\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 0.2065 - accuracy: 0.9287 - val_loss: 0.1528 - val_accuracy: 0.9471\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.94923\n",
            "Epoch 60/60\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 0.1710 - accuracy: 0.9428 - val_loss: 0.1691 - val_accuracy: 0.9424\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.94923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "GaXUP-8fDWRN",
        "outputId": "186da7be-76a0-4615-c0df-91c4c5a0a332"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "#gffhgffkjkjdskjjkjkjkj\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "num_epochs = range(len(accuracy))\n",
        "plt.plot(num_epochs, accuracy, 'r', label='Training acc')\n",
        "plt.plot(num_epochs, val_accuracy, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(num_epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(num_epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_LxatO5J-pp",
        "outputId": "d8a200de-b589-488a-af96-d508cf642726"
      },
      "source": [
        "testloss = model.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "trainloss = model.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(trainloss[0]))\n",
        "print(\"Train Acc: \" + str(trainloss[1]))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 2s 19ms/step - loss: 2.2125 - accuracy: 0.5715\n",
            "Test Loss 2.2125039100646973\n",
            "Test Acc: 0.5714683532714844\n",
            "1010/1010 [==============================] - 19s 19ms/step - loss: 0.1732 - accuracy: 0.9409\n",
            "Train Loss 0.1731949895620346\n",
            "Train Acc: 0.9408941864967346\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swoRERVdKQ1-",
        "outputId": "b4312e78-41e2-47d1-89f7-539e2a6b4112"
      },
      "source": [
        "testlosz = model.evaluate(x_val, y_val) \n",
        "print(\"Test Loss \" + str(testlosz[0]))\n",
        "print(\"Test Acc: \" + str(testlosz[1]))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101/101 [==============================] - 2s 19ms/step - loss: 0.1691 - accuracy: 0.9424\n",
            "Test Loss 0.16907408833503723\n",
            "Test Acc: 0.9424148797988892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "tdU7uU3PYCnA",
        "outputId": "45a1b325-be10-45e2-813d-9161321f9bcc"
      },
      "source": [
        ""
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-de436fa85c3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_sequence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_sequence' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J11OOgMKYHJV"
      },
      "source": [
        "confusion_matrix = tf.math.confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}