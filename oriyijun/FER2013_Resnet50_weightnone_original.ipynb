{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FER2013_Resnet50_weightnone_nodropout.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-Qn1jsBTIBl0b7myLQxqa8WjCcfbamqM",
      "authorship_tag": "ABX9TyNOaX0RLbeJGaDj+WZwSQVX"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b86nukQOxN7l"
      },
      "source": [
        "Resnet-50 From Scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p8gxtGy0TWP",
        "outputId": "d71d0a17-2049-4d42-c44e-e7a0c025cd61"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "inputFolder = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth' \n",
        "for root, directories, filenames in os.walk(inputFolder): \n",
        "    for filename in filenames: print(os.path.join(root,filename))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe4.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsiscWIMBDX2",
        "outputId": "86d8b0f3-a584-4fb4-85d1-a36677092ba3"
      },
      "source": [
        "%cd /content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "wLMSe510xNCJ",
        "outputId": "3da9f6f5-cb75-4f61-d978-1e7de9a074fc"
      },
      "source": [
        "#Create a directory to save our generated models.\n",
        "\n",
        "#os.mkdir(\"./modelscracth\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-cf55f19f3613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#os.mkdir(\"./modelscracth\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ls' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_kluusLxM1B",
        "outputId": "78ad7b63-9c92-42f0-dbc5-4bf69e7e3a15"
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:400: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfUSF_tAxNMP"
      },
      "source": [
        "#Define the identity block helper function.\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "   \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VdYtzhn1F0I"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path \n",
        "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b',padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd-O8ZMx1GAW"
      },
      "source": [
        "\"\"\"def ResNet50(input_shape = (48,48,1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    #X = ZeroPadding2D((1, 1))(X_input)\n",
        "    X = X_input\n",
        "    # Stage 1\n",
        "\n",
        "    X = Conv2D(8, (3, 3), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # removed maxpool\n",
        "    #X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='c')\n",
        "\n",
        "\n",
        "    # Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [64,64,256], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL . \n",
        "    X = AveragePooling2D((2,2), name='avg_pool')(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(512, activation = 'relu', name='fc1024' , kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model\"\"\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GKsSwtp-GuL"
      },
      "source": [
        "def ResNet50ori(input_shape = (48, 48, 1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50ori')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oWTDXlyBHM2"
      },
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        " \n",
        "dataset_path = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv'\n",
        "image_size=(48,48)\n",
        "#batch_size = 64\n",
        "\n",
        "def load_fer2013():\n",
        "    data = pd.read_csv(dataset_path)\n",
        "    data = (data[data['pixels'].notnull()])\n",
        "    pixels = data['pixels'].tolist()\n",
        "    width, height = 48, 48\n",
        "    faces = []\n",
        "    for pixel_sequence in pixels:\n",
        "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "        face = np.asarray(face).reshape(width, height)\n",
        "        face = cv2.resize(face.astype('uint8'),image_size)\n",
        "        faces.append(face.astype('float32'))\n",
        "    faces = np.asarray(faces)\n",
        "    faces = np.expand_dims(faces, -1)\n",
        "    emotions = (data['emotion'])#.values\n",
        "    return faces, emotions\n",
        " \n",
        "def preprocess_input(x, v2=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if v2:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x\n",
        " \n",
        "faces, emotions = load_fer2013()\n",
        "faces = preprocess_input(faces)\n",
        "#xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
        "#Data Augumentation\n",
        "\"\"\"data_generator = ImageDataGenerator(\n",
        "                        rotation_range=10,\n",
        "                        shear_range = 10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True)\"\"\"\n",
        "data_generator = ImageDataGenerator( )\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWLhavr-rSF5"
      },
      "source": [
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.1, train_size=0.9)\n",
        "x_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1, train_size=0.9)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH9Q-TegBR26"
      },
      "source": [
        "#hyperparameter and callback\n",
        "batch_size = 64\n",
        "num_epochs = 30\n",
        "input_shape = (48, 48, 1)\n",
        "num_classes = 7\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGsscQRJBR-h"
      },
      "source": [
        "#Compile the model.\n",
        "\n",
        "\n",
        "from keras.optimizers import Adam, SGD\n",
        "model = ResNet50ori(input_shape = (48, 48, 1), classes = 7)\n",
        "optimizer = Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-7)\n",
        "model.compile(optimizer= optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rodttDWeT2yP"
      },
      "source": [
        "#kita mau save model callbacks\n",
        "import os\n",
        "try:\n",
        "  os.mkdir('scratchcheckpoint')\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV29sTjET28U"
      },
      "source": [
        "file_name = 'Best_Model_resnet50Scracth_oriyijungan2.h5'\n",
        "\n",
        "checkpoint_path = os.path.join('checkpoint',file_name)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_S6wUaPT3Jx"
      },
      "source": [
        "call_back = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
        "                                               monitor='val_accuracy',\n",
        "                                               verbose=1,\n",
        "                                               save_freq='epoch',\n",
        "                                               save_best_only=True,\n",
        "                                               save_weights_only=False,\n",
        "                                               mode='max')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy53DHMGB-Mr",
        "outputId": "48298d75-037d-4964-e0c8-e3b39c1d0b47"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50ori\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 54, 54, 1)    0           input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 24, 24, 64)   3200        zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 24, 24, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 24, 24, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 11, 11, 64)   0           activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 11, 11, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 11, 11, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 11, 11, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 11, 11, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 11, 11, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_48 (Add)                    (None, 11, 11, 256)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 11, 11, 256)  0           add_48[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 11, 11, 64)   16448       activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 11, 11, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 11, 11, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_49 (Add)                    (None, 11, 11, 256)  0           activation_150[0][0]             \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 11, 11, 256)  0           add_49[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 11, 11, 64)   16448       activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 11, 11, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 11, 11, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_50 (Add)                    (None, 11, 11, 256)  0           activation_153[0][0]             \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 11, 11, 256)  0           add_50[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 6, 6, 128)    32896       activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 6, 6, 128)    0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_157[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 6, 6, 128)    0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 6, 6, 512)    131584      activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 6, 6, 512)    2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_51 (Add)                    (None, 6, 6, 512)    0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 6, 6, 512)    0           add_51[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 6, 6, 128)    0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 6, 6, 128)    0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_52 (Add)                    (None, 6, 6, 512)    0           activation_159[0][0]             \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 6, 6, 512)    0           add_52[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_162[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 6, 6, 128)    0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 6, 6, 128)    0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_53 (Add)                    (None, 6, 6, 512)    0           activation_162[0][0]             \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 6, 6, 512)    0           add_53[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 6, 6, 128)    0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 6, 6, 128)    0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_54 (Add)                    (None, 6, 6, 512)    0           activation_165[0][0]             \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 6, 6, 512)    0           add_54[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 3, 3, 256)    131328      activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 3, 3, 256)    0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_169[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 3, 3, 256)    0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 3, 3, 1024)   525312      activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_170[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 3, 3, 1024)   4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_55 (Add)                    (None, 3, 3, 1024)   0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 3, 3, 1024)   0           add_55[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 3, 3, 256)    0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_172[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 3, 3, 256)    0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_56 (Add)                    (None, 3, 3, 1024)   0           activation_171[0][0]             \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 3, 3, 1024)   0           add_56[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 3, 3, 256)    0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 3, 3, 256)    0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_176[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_57 (Add)                    (None, 3, 3, 1024)   0           activation_174[0][0]             \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 3, 3, 1024)   0           add_57[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 3, 3, 256)    0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 3, 3, 256)    0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_179[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_58 (Add)                    (None, 3, 3, 1024)   0           activation_177[0][0]             \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 3, 3, 1024)   0           add_58[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 3, 3, 256)    0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 3, 3, 256)    0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_59 (Add)                    (None, 3, 3, 1024)   0           activation_180[0][0]             \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 3, 3, 1024)   0           add_59[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 3, 3, 256)    0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 3, 3, 256)    0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_185[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_60 (Add)                    (None, 3, 3, 1024)   0           activation_183[0][0]             \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 3, 3, 1024)   0           add_60[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 2, 2, 512)    524800      activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 2, 2, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_187[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 2, 2, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 2, 2, 2048)   2099200     activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 2, 2, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_61 (Add)                    (None, 2, 2, 2048)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_189 (Activation)     (None, 2, 2, 2048)   0           add_61[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_190 (Activation)     (None, 2, 2, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_190[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_191 (Activation)     (None, 2, 2, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_191[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_62 (Add)                    (None, 2, 2, 2048)   0           activation_189[0][0]             \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_192 (Activation)     (None, 2, 2, 2048)   0           add_62[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_192[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_193 (Activation)     (None, 2, 2, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_193[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_194 (Activation)     (None, 2, 2, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_194[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_63 (Add)                    (None, 2, 2, 2048)   0           activation_192[0][0]             \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_195 (Activation)     (None, 2, 2, 2048)   0           add_63[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_195[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 2048)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            14343       flatten_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 23,595,783\n",
            "Trainable params: 23,542,663\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgxCecVwCGEr",
        "outputId": "8988e6bf-b434-4650-c46f-22f92303943d"
      },
      "source": [
        "\"\"\"history = model.fit(data_generator.flow(xtrain, ytrain,),\n",
        "                        steps_per_epoch=len(xtrain) / batch_size,\n",
        "                        epochs=num_epochs, verbose=1,callbacks=call_back,\n",
        "                        validation_data= (xtest,ytest))\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "448/448 [==============================] - 65s 122ms/step - loss: 2.2711 - accuracy: 0.2151 - val_loss: 1.8425 - val_accuracy: 0.2538\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.25383, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 1.8064 - accuracy: 0.2511 - val_loss: 1.8161 - val_accuracy: 0.2594\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.25383 to 0.25940, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 3/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.7689 - accuracy: 0.2632 - val_loss: 1.7616 - val_accuracy: 0.2795\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.25940 to 0.27947, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 4/50\n",
            "448/448 [==============================] - 57s 126ms/step - loss: 1.7297 - accuracy: 0.3022 - val_loss: 1.7276 - val_accuracy: 0.2990\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.27947 to 0.29897, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 5/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.6804 - accuracy: 0.3269 - val_loss: 1.6247 - val_accuracy: 0.3504\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.29897 to 0.35038, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 6/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.6096 - accuracy: 0.3661 - val_loss: 1.5590 - val_accuracy: 0.3823\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.35038 to 0.38228, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 7/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.5340 - accuracy: 0.4051 - val_loss: 1.5257 - val_accuracy: 0.4087\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.38228 to 0.40875, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 8/50\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 1.5127 - accuracy: 0.4046 - val_loss: 1.5014 - val_accuracy: 0.4139\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.40875 to 0.41390, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 9/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.4779 - accuracy: 0.4241 - val_loss: 1.4280 - val_accuracy: 0.4503\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.41390 to 0.45026, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 10/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.4282 - accuracy: 0.4475 - val_loss: 1.4991 - val_accuracy: 0.4154\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.45026\n",
            "Epoch 11/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.4105 - accuracy: 0.4555 - val_loss: 1.3838 - val_accuracy: 0.4620\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.45026 to 0.46197, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 12/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.3500 - accuracy: 0.4850 - val_loss: 1.3392 - val_accuracy: 0.4799\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.46197 to 0.47994, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 13/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 1.3333 - accuracy: 0.4895 - val_loss: 1.3158 - val_accuracy: 0.4946\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.47994 to 0.49457, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 14/50\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 1.2905 - accuracy: 0.5087 - val_loss: 1.3923 - val_accuracy: 0.4912\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.49457\n",
            "Epoch 15/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.2800 - accuracy: 0.5112 - val_loss: 1.2229 - val_accuracy: 0.5344\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.49457 to 0.53441, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 16/50\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 1.2456 - accuracy: 0.5286 - val_loss: 1.2321 - val_accuracy: 0.5258\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.53441\n",
            "Epoch 17/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.2397 - accuracy: 0.5268 - val_loss: 1.2038 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.53441 to 0.53845, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 18/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.2112 - accuracy: 0.5434 - val_loss: 1.2470 - val_accuracy: 0.5208\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.53845\n",
            "Epoch 19/50\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 1.1876 - accuracy: 0.5505 - val_loss: 1.2147 - val_accuracy: 0.5336\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.53845\n",
            "Epoch 20/50\n",
            "448/448 [==============================] - 51s 115ms/step - loss: 1.1875 - accuracy: 0.5495 - val_loss: 1.1693 - val_accuracy: 0.5511\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.53845 to 0.55113, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 21/50\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 1.1622 - accuracy: 0.5580 - val_loss: 1.2089 - val_accuracy: 0.5344\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.55113\n",
            "Epoch 22/50\n",
            "448/448 [==============================] - 56s 126ms/step - loss: 1.1420 - accuracy: 0.5658 - val_loss: 1.1683 - val_accuracy: 0.5574\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.55113 to 0.55740, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 23/50\n",
            "448/448 [==============================] - 51s 115ms/step - loss: 1.1426 - accuracy: 0.5670 - val_loss: 1.1895 - val_accuracy: 0.5475\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.55740\n",
            "Epoch 24/50\n",
            "448/448 [==============================] - 57s 126ms/step - loss: 1.1447 - accuracy: 0.5654 - val_loss: 1.1481 - val_accuracy: 0.5698\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.55740 to 0.56980, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 25/50\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 1.0988 - accuracy: 0.5806 - val_loss: 1.0838 - val_accuracy: 0.5938\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.56980 to 0.59376, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 26/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.0941 - accuracy: 0.5851 - val_loss: 1.2003 - val_accuracy: 0.5529\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.59376\n",
            "Epoch 27/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 1.0957 - accuracy: 0.5909 - val_loss: 1.1363 - val_accuracy: 0.5758\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.59376\n",
            "Epoch 28/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.0562 - accuracy: 0.6027 - val_loss: 1.1244 - val_accuracy: 0.5738\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.59376\n",
            "Epoch 29/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 1.0445 - accuracy: 0.6041 - val_loss: 1.0976 - val_accuracy: 0.5861\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.59376\n",
            "Epoch 30/50\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 1.0413 - accuracy: 0.5992 - val_loss: 1.1102 - val_accuracy: 0.5867\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.59376\n",
            "Epoch 31/50\n",
            "448/448 [==============================] - 56s 126ms/step - loss: 1.0303 - accuracy: 0.6060 - val_loss: 1.0553 - val_accuracy: 0.6056\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.59376 to 0.60560, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 32/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 1.0454 - accuracy: 0.6025 - val_loss: 1.0681 - val_accuracy: 0.5988\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.60560\n",
            "Epoch 33/50\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 1.0070 - accuracy: 0.6213 - val_loss: 1.0881 - val_accuracy: 0.5949\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.60560\n",
            "Epoch 34/50\n",
            "448/448 [==============================] - 57s 127ms/step - loss: 1.0123 - accuracy: 0.6159 - val_loss: 1.1018 - val_accuracy: 0.5897\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.60560\n",
            "Epoch 35/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 0.9944 - accuracy: 0.6208 - val_loss: 1.0713 - val_accuracy: 0.5999\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.60560\n",
            "Epoch 36/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 1.0049 - accuracy: 0.6201 - val_loss: 1.0473 - val_accuracy: 0.6127\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.60560 to 0.61271, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 37/50\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 0.9791 - accuracy: 0.6334 - val_loss: 1.0589 - val_accuracy: 0.6043\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.61271\n",
            "Epoch 38/50\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 0.9641 - accuracy: 0.6281 - val_loss: 1.0680 - val_accuracy: 0.5972\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.61271\n",
            "Epoch 39/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 0.9775 - accuracy: 0.6277 - val_loss: 1.2166 - val_accuracy: 0.5575\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.61271\n",
            "Epoch 40/50\n",
            "448/448 [==============================] - 56s 124ms/step - loss: 0.9695 - accuracy: 0.6381 - val_loss: 1.0728 - val_accuracy: 0.5947\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.61271\n",
            "Epoch 41/50\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 0.9418 - accuracy: 0.6410 - val_loss: 1.0668 - val_accuracy: 0.5978\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.61271\n",
            "Epoch 42/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 0.9483 - accuracy: 0.6383 - val_loss: 1.0436 - val_accuracy: 0.6160\n",
            "\n",
            "Epoch 00042: val_accuracy improved from 0.61271 to 0.61605, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 43/50\n",
            "448/448 [==============================] - 56s 126ms/step - loss: 0.9589 - accuracy: 0.6440 - val_loss: 1.0460 - val_accuracy: 0.6101\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.61605\n",
            "Epoch 44/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 0.9422 - accuracy: 0.6480 - val_loss: 1.0838 - val_accuracy: 0.5991\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.61605\n",
            "Epoch 45/50\n",
            "448/448 [==============================] - 51s 115ms/step - loss: 0.9410 - accuracy: 0.6449 - val_loss: 1.0646 - val_accuracy: 0.5995\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.61605\n",
            "Epoch 46/50\n",
            "448/448 [==============================] - 56s 124ms/step - loss: 0.9130 - accuracy: 0.6571 - val_loss: 1.0363 - val_accuracy: 0.6148\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.61605\n",
            "Epoch 47/50\n",
            "448/448 [==============================] - 51s 115ms/step - loss: 0.9051 - accuracy: 0.6632 - val_loss: 1.0098 - val_accuracy: 0.6296\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.61605 to 0.62956, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 48/50\n",
            "448/448 [==============================] - 56s 126ms/step - loss: 0.9064 - accuracy: 0.6556 - val_loss: 1.0776 - val_accuracy: 0.6002\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.62956\n",
            "Epoch 49/50\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 0.9066 - accuracy: 0.6624 - val_loss: 1.0612 - val_accuracy: 0.6158\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.62956\n",
            "Epoch 50/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 0.9066 - accuracy: 0.6581 - val_loss: 1.0227 - val_accuracy: 0.6211\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.62956\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2muXWns0sJSH",
        "outputId": "3b09ee61-aa3c-4795-f4f8-fc3fe8eaac81"
      },
      "source": [
        "history = model.fit(\n",
        "    data_generator.flow(xtrain, ytrain,),\n",
        "    steps_per_epoch=len(xtrain) / batch_size,\n",
        "    epochs=num_epochs, \n",
        "    verbose=1,\n",
        "    callbacks=call_back,\n",
        "    validation_data= (x_val,y_val))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "504/504 [==============================] - 54s 84ms/step - loss: 3.8854 - accuracy: 0.2252 - val_loss: 1.8589 - val_accuracy: 0.2554\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.25542, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/30\n",
            "504/504 [==============================] - 39s 77ms/step - loss: 1.8027 - accuracy: 0.2478 - val_loss: 1.7843 - val_accuracy: 0.2632\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.25542 to 0.26316, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "Epoch 3/30\n",
            "504/504 [==============================] - 39s 76ms/step - loss: 1.7920 - accuracy: 0.2444 - val_loss: 1.7603 - val_accuracy: 0.2731\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.26316 to 0.27307, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "Epoch 4/30\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 1.7478 - accuracy: 0.2781 - val_loss: 1.7350 - val_accuracy: 0.2969\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.27307 to 0.29690, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "Epoch 5/30\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 1.7094 - accuracy: 0.3116 - val_loss: 1.7225 - val_accuracy: 0.3520\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.29690 to 0.35201, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "Epoch 6/30\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 1.6320 - accuracy: 0.3482 - val_loss: 11.9367 - val_accuracy: 0.2904\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.35201\n",
            "Epoch 7/30\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 1.5717 - accuracy: 0.3939 - val_loss: 1.4860 - val_accuracy: 0.4266\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.35201 to 0.42663, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "Epoch 8/30\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 1.5909 - accuracy: 0.3679 - val_loss: 1.5654 - val_accuracy: 0.3981\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.42663\n",
            "Epoch 9/30\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 1.5435 - accuracy: 0.4081 - val_loss: 1.5749 - val_accuracy: 0.3966\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.42663\n",
            "Epoch 10/30\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 1.4641 - accuracy: 0.4287 - val_loss: 1.4947 - val_accuracy: 0.4291\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.42663 to 0.42910, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "Epoch 11/30\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 1.4354 - accuracy: 0.4421 - val_loss: 1.4470 - val_accuracy: 0.4486\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.42910 to 0.44861, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "Epoch 12/30\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 1.4144 - accuracy: 0.4570 - val_loss: 1.3840 - val_accuracy: 0.4638\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.44861 to 0.46378, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "Epoch 13/30\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 1.3875 - accuracy: 0.4604 - val_loss: 1.4220 - val_accuracy: 0.4625\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.46378\n",
            "Epoch 14/30\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 1.3630 - accuracy: 0.4743 - val_loss: 1.3742 - val_accuracy: 0.4635\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.46378\n",
            "Epoch 15/30\n",
            "504/504 [==============================] - 39s 76ms/step - loss: 1.3086 - accuracy: 0.4936 - val_loss: 1.4007 - val_accuracy: 0.4523\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.46378\n",
            "Epoch 16/30\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 1.2971 - accuracy: 0.4943 - val_loss: 1.3221 - val_accuracy: 0.5059\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.46378 to 0.50588, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "Epoch 17/30\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 1.2493 - accuracy: 0.5194 - val_loss: 1.3410 - val_accuracy: 0.4898\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.50588\n",
            "Epoch 18/30\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 1.2485 - accuracy: 0.5142 - val_loss: 1.2726 - val_accuracy: 0.4997\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.50588\n",
            "Epoch 19/30\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 1.2193 - accuracy: 0.5255 - val_loss: 1.1890 - val_accuracy: 0.5412\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.50588 to 0.54118, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "Epoch 20/30\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 1.1789 - accuracy: 0.5446 - val_loss: 1.1654 - val_accuracy: 0.5437\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.54118 to 0.54365, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "Epoch 21/30\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 1.1617 - accuracy: 0.5597 - val_loss: 1.1434 - val_accuracy: 0.5613\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.54365 to 0.56130, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "Epoch 22/30\n",
            "504/504 [==============================] - 38s 75ms/step - loss: 1.1420 - accuracy: 0.5700 - val_loss: 1.1350 - val_accuracy: 0.5675\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.56130 to 0.56749, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "Epoch 23/30\n",
            "504/504 [==============================] - 39s 77ms/step - loss: 1.1123 - accuracy: 0.5759 - val_loss: 1.0548 - val_accuracy: 0.6009\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.56749 to 0.60093, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "Epoch 24/30\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 1.0717 - accuracy: 0.5931 - val_loss: 1.1360 - val_accuracy: 0.6087\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.60093 to 0.60867, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "Epoch 25/30\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 1.0360 - accuracy: 0.6114 - val_loss: 1.1249 - val_accuracy: 0.5944\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.60867\n",
            "Epoch 26/30\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 1.0274 - accuracy: 0.6082 - val_loss: 0.9950 - val_accuracy: 0.6344\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.60867 to 0.63437, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "Epoch 27/30\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 0.9837 - accuracy: 0.6301 - val_loss: 0.8814 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.63437 to 0.67245, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "Epoch 28/30\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 0.9493 - accuracy: 0.6429 - val_loss: 0.9200 - val_accuracy: 0.6486\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.67245\n",
            "Epoch 29/30\n",
            "504/504 [==============================] - 38s 76ms/step - loss: 0.8978 - accuracy: 0.6699 - val_loss: 0.8426 - val_accuracy: 0.6873\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.67245 to 0.68731, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "Epoch 30/30\n",
            "504/504 [==============================] - 39s 76ms/step - loss: 0.8742 - accuracy: 0.6757 - val_loss: 0.8031 - val_accuracy: 0.7019\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.68731 to 0.70186, saving model to checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "GaXUP-8fDWRN",
        "outputId": "47d051dc-db58-47b8-a48e-83e098b19127"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "#gffhgffkjkjdskjj\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "num_epochs = range(len(accuracy))\n",
        "plt.plot(num_epochs, accuracy, 'r', label='Training acc')\n",
        "plt.plot(num_epochs, val_accuracy, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(num_epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(num_epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}