{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER2013_Resnet50_90weightnoneSEEDSP3_noAUG3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "18Zj-Yp1YlH0QWcuD4e7ugx8zCCcRS0jg",
      "authorship_tag": "ABX9TyPKVOcH4rsI2ADR611DjSEU"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eWeoD7MRFlN",
        "outputId": "81612257-e558-4e6d-ba35-573386aed570"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "inputFolder = '/content/drive/MyDrive/Fer2013_backup/' \n",
        "for root, directories, filenames in os.walk(inputFolder): \n",
        "    for filename in filenames: print(os.path.join(root,filename))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Fer2013_backup/backUpfer2013.csv\n",
            "/content/drive/MyDrive/Fer2013_backup/icml_face_data.csv\n",
            "/content/drive/MyDrive/Fer2013_backup/test.csv\n",
            "/content/drive/MyDrive/Fer2013_backup/train.csv\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/best_model_resnet50_modelB2_170false.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/best_model_resnet50_modelD2_170false.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50Scracth_tipe7.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50Scracth_tipe8.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50oriAUGScracthSGD2.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50oriAUGScracthSGD3.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50AUGScracthadam2.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50AUGScracthAdam1sp.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50AUGScracthSGD4sp.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50AUGScracthSGD5sp.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50AUGScracthSGD6sp.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP1_30_noAug1.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP2_30_noAug2.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP3_30_noAug3.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP4_30_noAug4.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP5_30_noAug5.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP6_30_noAug6.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP1_90_noAug1.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP2_90_noAug2.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP3_90_noAug3.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/fixcheckpoint/Best_Model_resnet50oriAUGScracthSGD2.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH8iEUJiRQS7",
        "outputId": "952dd437-8a5f-4693-c845-6924e93d04ae"
      },
      "source": [
        "%cd /content/drive/MyDrive/Fer2013_backup/\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Fer2013_backup\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xfSSuZCuutf",
        "outputId": "d1d40456-b5d4-46eb-ae16-e7f629d58c3e"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "dataread =pd.read_csv('/content/drive/MyDrive/Fer2013_backup/backUpfer2013.csv')\n",
        "dataread['Usage'].value_counts()\n",
        "dataread['emotion'].value_counts()\n",
        "\n",
        "#print(dataread.duplicated().value_counts)\n",
        "#(df[df.duplicated()])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    8989\n",
              "6    6198\n",
              "4    6077\n",
              "2    5121\n",
              "0    4953\n",
              "5    4002\n",
              "1     547\n",
              "Name: emotion, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqZOFwxxRQaa",
        "outputId": "b9572ff4-23d3-4f5f-94da-1ad82fd0b455"
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:400: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUX-dSAgRQh4"
      },
      "source": [
        "#Define the identity block helper function.\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "   \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbdQH3mkRQra"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path \n",
        "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b',padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33XH76oKRQvh"
      },
      "source": [
        "def ResNet50(input_shape = (48,48,1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    #X = ZeroPadding2D((1, 1))(X_input)\n",
        "    X = X_input\n",
        "    # Stage 1\n",
        "\n",
        "    X = Conv2D(8, (3, 3), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # removed maxpool\n",
        "    #X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='c')\n",
        "\n",
        "\n",
        "    # Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [64,64,256], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL . \n",
        "    X = AveragePooling2D((2,2), name='avg_pool')(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(512, activation = 'relu', name='fc1024' , kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWuYK_f2zGJF"
      },
      "source": [
        "\"\"\"def ResNet50ori(input_shape = (48, 48, 1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50ori')\n",
        "\n",
        "    return model\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QQOxN2cRQy3"
      },
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        " \n",
        "dataset_path = '/content/drive/MyDrive/Fer2013_backup/backUpfer2013.csv'\n",
        "image_size=(48,48)\n",
        "\n",
        "def load_fer2013():\n",
        "    data = pd.read_csv(dataset_path)\n",
        "    data = (data[data['pixels'].notnull()])\n",
        "    pixels = data['pixels'].tolist()\n",
        "    width, height = 48, 48\n",
        "    faces = []\n",
        "    for pixel_sequence in pixels:\n",
        "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "        face = np.asarray(face).reshape(width, height)\n",
        "        face = cv2.resize(face.astype('uint8'),image_size)\n",
        "        faces.append(face.astype('float32'))\n",
        "    faces = np.asarray(faces)\n",
        "    faces = np.expand_dims(faces, -1)\n",
        "    emotions = (data['emotion'])#.values\n",
        "    return faces, emotions\n",
        " \n",
        "def preprocess_input(x, v2=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if v2:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x\n",
        " \n",
        "faces, emotions = load_fer2013()\n",
        "faces = preprocess_input(faces)\n",
        "#xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
        "#Data Augumentationfgf\n",
        "\"\"\"data_generator = ImageDataGenerator(\n",
        "                        rotation_range=10,\n",
        "                        shear_range = 10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        vertical_flip=True,\n",
        "                        )\"\"\"\n",
        "data_generator = ImageDataGenerator ()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "8zCkwVdnKTm5",
        "outputId": "af8761ea-fa2c-4280-f389-bad7caeaf26e"
      },
      "source": [
        "train_ratio = 0.80\n",
        "validation_ratio = 0.10\n",
        "test_ratio = 0.10\n",
        "\n",
        "# train is now 75% of the entire data set\n",
        "# the _junk suffix means that we drop that variable completely # the _junk suffix means that we drop that variable completely\n",
        "#x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=1 - train_ratio,random_state=42)\n",
        "\n",
        "# test is now 10% of the initial data set\n",
        "# validation is now 15% of the initial data set\n",
        "#x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "x_val, xtest, y_val, ytest = train_test_split(xtest, ytest, test_size=test_ratio/(test_ratio + validation_ratio), random_state=42) \n",
        "\n",
        "#print(xtrain, x_val, xtest)\n",
        "\n",
        "\"\"\"X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2\"\"\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\\n\\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t--o7TREKTu2",
        "outputId": "c295c546-2b5d-4179-9fb9-408916844525"
      },
      "source": [
        "print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validasi (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "test (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "train (28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ofOj3-fRREN"
      },
      "source": [
        "#hyperparameter and callback\n",
        "batch_size = 64\n",
        "num_epochs = 90\n",
        "input_shape = (48, 48, 1)\n",
        "num_classes = 7\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXikieAnRbYs"
      },
      "source": [
        "#Compile the model.\n",
        "\n",
        "\n",
        "from keras.optimizers import Adam, SGD\n",
        "model = ResNet50(input_shape = (48, 48, 1), classes = 7)\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "model.compile(optimizer= optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5JTFulCRbiX"
      },
      "source": [
        "\"\"\"#kita mau save model callbacks\n",
        "import os\n",
        "try:\n",
        "  os.mkdir('/content/drive/MyDrive/Fer2013_backup/scratchcheckpoint')\n",
        "except:\n",
        "  pass\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkceBySwRgFO"
      },
      "source": [
        "\"\"\"file_name = 'Best_Model_resnet50oriScracth_aug_tipe2.h5'\n",
        "\n",
        "checkpoint_path = os.path.join('checkpoint',file_name)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an3sDjjGRgO1"
      },
      "source": [
        "\"\"\"call_back = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
        "                                               monitor='val_accuracy',\n",
        "                                               verbose=1,\n",
        "                                               save_freq='epoch',\n",
        "                                               save_best_only=True,\n",
        "                                               save_weights_only=False,\n",
        "                                               mode='max')\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nefC0ZE8RgX5",
        "outputId": "5760271c-2dc1-4a13-fcba-50bc79715927"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 46, 46, 128)  0           add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_33 (Add)                    (None, 46, 46, 128)  0           activation_101[0][0]             \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 46, 46, 128)  0           add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, 46, 46, 128)  0           activation_104[0][0]             \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 46, 46, 128)  0           add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_35 (Add)                    (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 23, 23, 256)  0           add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_36 (Add)                    (None, 23, 23, 256)  0           activation_110[0][0]             \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 23, 23, 256)  0           add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_37 (Add)                    (None, 23, 23, 256)  0           activation_113[0][0]             \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 23, 23, 256)  0           add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_38 (Add)                    (None, 23, 23, 256)  0           activation_116[0][0]             \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 23, 23, 256)  0           add_38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_39 (Add)                    (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 12, 12, 512)  0           add_39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_40 (Add)                    (None, 12, 12, 512)  0           activation_122[0][0]             \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 12, 12, 512)  0           add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_41 (Add)                    (None, 12, 12, 512)  0           activation_125[0][0]             \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 12, 12, 512)  0           add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_42 (Add)                    (None, 12, 12, 512)  0           activation_128[0][0]             \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 12, 12, 512)  0           add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_43 (Add)                    (None, 12, 12, 512)  0           activation_131[0][0]             \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 12, 12, 512)  0           add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_44 (Add)                    (None, 12, 12, 512)  0           activation_134[0][0]             \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 12, 12, 512)  0           add_44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_45 (Add)                    (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 6, 6, 1024)   0           add_45[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_46 (Add)                    (None, 6, 6, 1024)   0           activation_140[0][0]             \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 6, 6, 1024)   0           add_46[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_47 (Add)                    (None, 6, 6, 1024)   0           activation_143[0][0]             \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 6, 6, 1024)   0           add_47[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVvpTr7-RkdR"
      },
      "source": [
        "\"\"\"history = model.fit(data_generator.flow(xtrain, ytrain,),\n",
        "                        steps_per_epoch=len(xtrain) / batch_size,\n",
        "                        epochs=num_epochs, verbose=1,callbacks=call_back,\n",
        "                        validation_data= (xtest,ytest))huhuhuh\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_tXyjuSz_IP",
        "outputId": "d1a75304-09c6-45d2-f2f8-d8ef191b8d57"
      },
      "source": [
        "history = model.fit(\n",
        "    data_generator.flow(xtrain, ytrain,),\n",
        "    steps_per_epoch=len(xtrain) / batch_size,\n",
        "    epochs=num_epochs,\n",
        "    shuffle=False,\n",
        "    verbose=1,\n",
        "    validation_data= (x_val,y_val))\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/90\n",
            "448/448 [==============================] - 61s 112ms/step - loss: 17.0275 - accuracy: 0.2292 - val_loss: 1.7605 - val_accuracy: 0.2758\n",
            "Epoch 2/90\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.7606 - accuracy: 0.2790 - val_loss: 1.7186 - val_accuracy: 0.2984\n",
            "Epoch 3/90\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.7134 - accuracy: 0.3079 - val_loss: 1.7055 - val_accuracy: 0.3026\n",
            "Epoch 4/90\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.6690 - accuracy: 0.3339 - val_loss: 1.6430 - val_accuracy: 0.3293\n",
            "Epoch 5/90\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.6307 - accuracy: 0.3560 - val_loss: 767138.0625 - val_accuracy: 0.1521\n",
            "Epoch 6/90\n",
            "448/448 [==============================] - 45s 101ms/step - loss: 1.8362 - accuracy: 0.2380 - val_loss: 1.8058 - val_accuracy: 0.2458\n",
            "Epoch 7/90\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.8113 - accuracy: 0.2486 - val_loss: 1.8025 - val_accuracy: 0.2458\n",
            "Epoch 8/90\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 1.8071 - accuracy: 0.2516 - val_loss: 1.7935 - val_accuracy: 0.2391\n",
            "Epoch 9/90\n",
            "448/448 [==============================] - 46s 103ms/step - loss: 1.7931 - accuracy: 0.2568 - val_loss: 1.7683 - val_accuracy: 0.2561\n",
            "Epoch 10/90\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.7620 - accuracy: 0.2753 - val_loss: 1.7532 - val_accuracy: 0.2831\n",
            "Epoch 11/90\n",
            "448/448 [==============================] - 46s 103ms/step - loss: 1.7161 - accuracy: 0.3155 - val_loss: 1.6973 - val_accuracy: 0.3229\n",
            "Epoch 12/90\n",
            "448/448 [==============================] - 46s 103ms/step - loss: 1.6816 - accuracy: 0.3326 - val_loss: 1.7751 - val_accuracy: 0.2817\n",
            "Epoch 13/90\n",
            "448/448 [==============================] - 49s 109ms/step - loss: 1.6518 - accuracy: 0.3371 - val_loss: 1.6740 - val_accuracy: 0.3296\n",
            "Epoch 14/90\n",
            "448/448 [==============================] - 49s 109ms/step - loss: 1.5973 - accuracy: 0.3658 - val_loss: 1.5662 - val_accuracy: 0.3656\n",
            "Epoch 15/90\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.5769 - accuracy: 0.3758 - val_loss: 325.1637 - val_accuracy: 0.1705\n",
            "Epoch 16/90\n",
            "448/448 [==============================] - 46s 103ms/step - loss: 1.6687 - accuracy: 0.3346 - val_loss: 1.6249 - val_accuracy: 0.3463\n",
            "Epoch 17/90\n",
            "448/448 [==============================] - 46s 103ms/step - loss: 1.6052 - accuracy: 0.3626 - val_loss: 1.8765 - val_accuracy: 0.2427\n",
            "Epoch 18/90\n",
            "448/448 [==============================] - 46s 103ms/step - loss: 1.6622 - accuracy: 0.3268 - val_loss: 1.5899 - val_accuracy: 0.3675\n",
            "Epoch 19/90\n",
            "448/448 [==============================] - 46s 103ms/step - loss: 1.5974 - accuracy: 0.3739 - val_loss: 1.5878 - val_accuracy: 0.3619\n",
            "Epoch 20/90\n",
            "448/448 [==============================] - 46s 103ms/step - loss: 1.5581 - accuracy: 0.3904 - val_loss: 1.5351 - val_accuracy: 0.3801\n",
            "Epoch 21/90\n",
            "448/448 [==============================] - 46s 103ms/step - loss: 1.5374 - accuracy: 0.3945 - val_loss: 1.5101 - val_accuracy: 0.4001\n",
            "Epoch 22/90\n",
            "448/448 [==============================] - 46s 103ms/step - loss: 1.5116 - accuracy: 0.4022 - val_loss: 1.5523 - val_accuracy: 0.3801\n",
            "Epoch 23/90\n",
            "448/448 [==============================] - 46s 103ms/step - loss: 1.5114 - accuracy: 0.4164 - val_loss: 1.4777 - val_accuracy: 0.4177\n",
            "Epoch 24/90\n",
            "448/448 [==============================] - 46s 103ms/step - loss: 1.4817 - accuracy: 0.4230 - val_loss: 1.4769 - val_accuracy: 0.4126\n",
            "Epoch 25/90\n",
            "448/448 [==============================] - 46s 103ms/step - loss: 1.4215 - accuracy: 0.4372 - val_loss: 1.4707 - val_accuracy: 0.4182\n",
            "Epoch 26/90\n",
            "448/448 [==============================] - 46s 103ms/step - loss: 1.4009 - accuracy: 0.4523 - val_loss: 1.4149 - val_accuracy: 0.4419\n",
            "Epoch 27/90\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.4035 - accuracy: 0.4439 - val_loss: 1.5371 - val_accuracy: 0.3748\n",
            "Epoch 28/90\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.5520 - accuracy: 0.3829 - val_loss: 1.6109 - val_accuracy: 0.3330\n",
            "Epoch 29/90\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.5124 - accuracy: 0.4013 - val_loss: 1.5022 - val_accuracy: 0.3859\n",
            "Epoch 30/90\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.4721 - accuracy: 0.4200 - val_loss: 1.4195 - val_accuracy: 0.4380\n",
            "Epoch 31/90\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.4042 - accuracy: 0.4440 - val_loss: 1.8066 - val_accuracy: 0.2237\n",
            "Epoch 32/90\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.5309 - accuracy: 0.3884 - val_loss: 1.4736 - val_accuracy: 0.4138\n",
            "Epoch 33/90\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.4982 - accuracy: 0.4034 - val_loss: 1.5841 - val_accuracy: 0.3580\n",
            "Epoch 34/90\n",
            "448/448 [==============================] - 45s 101ms/step - loss: 1.6093 - accuracy: 0.3499 - val_loss: 1.6756 - val_accuracy: 0.3837\n",
            "Epoch 35/90\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.5236 - accuracy: 0.3969 - val_loss: 2.7232 - val_accuracy: 0.3486\n",
            "Epoch 36/90\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.5612 - accuracy: 0.3901 - val_loss: 1.5178 - val_accuracy: 0.3982\n",
            "Epoch 37/90\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.4841 - accuracy: 0.4165 - val_loss: 1.4466 - val_accuracy: 0.4283\n",
            "Epoch 38/90\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.4384 - accuracy: 0.4243 - val_loss: 1.4039 - val_accuracy: 0.4489\n",
            "Epoch 39/90\n",
            "448/448 [==============================] - 46s 103ms/step - loss: 1.3855 - accuracy: 0.4480 - val_loss: 1.4568 - val_accuracy: 0.3990\n",
            "Epoch 40/90\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.3483 - accuracy: 0.4690 - val_loss: 1.5990 - val_accuracy: 0.3413\n",
            "Epoch 41/90\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.3653 - accuracy: 0.4562 - val_loss: 1.4541 - val_accuracy: 0.4118\n",
            "Epoch 42/90\n",
            "448/448 [==============================] - 46s 103ms/step - loss: 1.3320 - accuracy: 0.4712 - val_loss: 1.3748 - val_accuracy: 0.4625\n",
            "Epoch 43/90\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 1.4153 - accuracy: 0.4441 - val_loss: 1.5903 - val_accuracy: 0.3773\n",
            "Epoch 44/90\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.3842 - accuracy: 0.4534 - val_loss: 1.3911 - val_accuracy: 0.4547\n",
            "Epoch 45/90\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.3283 - accuracy: 0.4760 - val_loss: 1.5227 - val_accuracy: 0.4062\n",
            "Epoch 46/90\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.3028 - accuracy: 0.4876 - val_loss: 1.3502 - val_accuracy: 0.4700\n",
            "Epoch 47/90\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.2857 - accuracy: 0.4946 - val_loss: 1.6415 - val_accuracy: 0.3215\n",
            "Epoch 48/90\n",
            "448/448 [==============================] - 46s 103ms/step - loss: 1.3629 - accuracy: 0.4660 - val_loss: 1.3760 - val_accuracy: 0.4570\n",
            "Epoch 49/90\n",
            "448/448 [==============================] - 46s 103ms/step - loss: 1.3048 - accuracy: 0.4835 - val_loss: 1.3928 - val_accuracy: 0.4492\n",
            "Epoch 50/90\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 1.3159 - accuracy: 0.4837 - val_loss: 1.3801 - val_accuracy: 0.4575\n",
            "Epoch 51/90\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.2733 - accuracy: 0.4988 - val_loss: 1.3490 - val_accuracy: 0.4776\n",
            "Epoch 52/90\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 1.2279 - accuracy: 0.5202 - val_loss: 1.3912 - val_accuracy: 0.4519\n",
            "Epoch 53/90\n",
            "448/448 [==============================] - 46s 103ms/step - loss: 1.2538 - accuracy: 0.5074 - val_loss: 1.3425 - val_accuracy: 0.4873\n",
            "Epoch 54/90\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.8171 - accuracy: 0.2864 - val_loss: 1.8062 - val_accuracy: 0.2458\n",
            "Epoch 55/90\n",
            "448/448 [==============================] - 45s 101ms/step - loss: 1.8088 - accuracy: 0.2543 - val_loss: 1.8067 - val_accuracy: 0.2458\n",
            "Epoch 56/90\n",
            "448/448 [==============================] - 45s 101ms/step - loss: 1.8122 - accuracy: 0.2572 - val_loss: 1.8053 - val_accuracy: 0.2458\n",
            "Epoch 57/90\n",
            "448/448 [==============================] - 45s 101ms/step - loss: 1.8034 - accuracy: 0.2553 - val_loss: 1.8066 - val_accuracy: 0.2458\n",
            "Epoch 58/90\n",
            "448/448 [==============================] - 46s 101ms/step - loss: 1.8196 - accuracy: 0.2420 - val_loss: 1.8056 - val_accuracy: 0.2458\n",
            "Epoch 59/90\n",
            "448/448 [==============================] - 46s 101ms/step - loss: 1.8073 - accuracy: 0.2497 - val_loss: 1.8054 - val_accuracy: 0.2458\n",
            "Epoch 60/90\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.8141 - accuracy: 0.2535 - val_loss: 1.8050 - val_accuracy: 0.2458\n",
            "Epoch 61/90\n",
            "448/448 [==============================] - 46s 101ms/step - loss: 1.8040 - accuracy: 0.2600 - val_loss: 1.8053 - val_accuracy: 0.2458\n",
            "Epoch 62/90\n",
            "448/448 [==============================] - 45s 101ms/step - loss: 1.8110 - accuracy: 0.2522 - val_loss: 1.8055 - val_accuracy: 0.2458\n",
            "Epoch 63/90\n",
            "448/448 [==============================] - 45s 101ms/step - loss: 1.8092 - accuracy: 0.2512 - val_loss: 1.8053 - val_accuracy: 0.2458\n",
            "Epoch 64/90\n",
            "448/448 [==============================] - 45s 101ms/step - loss: 1.8085 - accuracy: 0.2513 - val_loss: 1.8067 - val_accuracy: 0.2458\n",
            "Epoch 65/90\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.8092 - accuracy: 0.2567 - val_loss: 1.8069 - val_accuracy: 0.2458\n",
            "Epoch 66/90\n",
            "448/448 [==============================] - 45s 101ms/step - loss: 1.8104 - accuracy: 0.2460 - val_loss: 1.8054 - val_accuracy: 0.2458\n",
            "Epoch 67/90\n",
            "448/448 [==============================] - 45s 101ms/step - loss: 1.8082 - accuracy: 0.2558 - val_loss: 1.8052 - val_accuracy: 0.2458\n",
            "Epoch 68/90\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.8074 - accuracy: 0.2532 - val_loss: 1.8059 - val_accuracy: 0.2458\n",
            "Epoch 69/90\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.8133 - accuracy: 0.2530 - val_loss: 1.8054 - val_accuracy: 0.2458\n",
            "Epoch 70/90\n",
            "448/448 [==============================] - 45s 101ms/step - loss: 1.8140 - accuracy: 0.2515 - val_loss: 1.8057 - val_accuracy: 0.2458\n",
            "Epoch 71/90\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.8172 - accuracy: 0.2480 - val_loss: 1.8050 - val_accuracy: 0.2458\n",
            "Epoch 72/90\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.8038 - accuracy: 0.2591 - val_loss: 1.8065 - val_accuracy: 0.2458\n",
            "Epoch 73/90\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.8147 - accuracy: 0.2460 - val_loss: 1.8049 - val_accuracy: 0.2458\n",
            "Epoch 74/90\n",
            "448/448 [==============================] - 45s 101ms/step - loss: 1.8130 - accuracy: 0.2520 - val_loss: 1.8055 - val_accuracy: 0.2458\n",
            "Epoch 75/90\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.8107 - accuracy: 0.2608 - val_loss: 1.8055 - val_accuracy: 0.2458\n",
            "Epoch 76/90\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.8025 - accuracy: 0.2581 - val_loss: 1.8059 - val_accuracy: 0.2458\n",
            "Epoch 77/90\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.8098 - accuracy: 0.2564 - val_loss: 1.8051 - val_accuracy: 0.2458\n",
            "Epoch 78/90\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.8026 - accuracy: 0.2583 - val_loss: 1.8061 - val_accuracy: 0.2458\n",
            "Epoch 79/90\n",
            "448/448 [==============================] - 45s 101ms/step - loss: 1.8168 - accuracy: 0.2519 - val_loss: 1.8073 - val_accuracy: 0.2458\n",
            "Epoch 80/90\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.8116 - accuracy: 0.2523 - val_loss: 1.8075 - val_accuracy: 0.2458\n",
            "Epoch 81/90\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.8153 - accuracy: 0.2531 - val_loss: 1.8074 - val_accuracy: 0.2458\n",
            "Epoch 82/90\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.8125 - accuracy: 0.2504 - val_loss: 1.8060 - val_accuracy: 0.2458\n",
            "Epoch 83/90\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.8098 - accuracy: 0.2535 - val_loss: 1.8058 - val_accuracy: 0.2458\n",
            "Epoch 84/90\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.8131 - accuracy: 0.2468 - val_loss: 1.8060 - val_accuracy: 0.2458\n",
            "Epoch 85/90\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.8093 - accuracy: 0.2572 - val_loss: 1.8055 - val_accuracy: 0.2458\n",
            "Epoch 86/90\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.8151 - accuracy: 0.2487 - val_loss: 1.8085 - val_accuracy: 0.2458\n",
            "Epoch 87/90\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.8179 - accuracy: 0.2508 - val_loss: 1.8099 - val_accuracy: 0.2458\n",
            "Epoch 88/90\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.8076 - accuracy: 0.2554 - val_loss: 1.8046 - val_accuracy: 0.2458\n",
            "Epoch 89/90\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.8119 - accuracy: 0.2554 - val_loss: 1.8056 - val_accuracy: 0.2458\n",
            "Epoch 90/90\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.8107 - accuracy: 0.2539 - val_loss: 1.8055 - val_accuracy: 0.2458\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "cZvluWhSRkq4",
        "outputId": "15cc8b67-20f8-48f6-89e3-8d46c4f35fe8"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "model.save('/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP3_90_noAug3.h5')\n",
        "\n",
        "#ffddfs\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "num_epochs = range(len(accuracy))\n",
        "plt.plot(num_epochs, accuracy, 'r', label='Training acc')\n",
        "plt.plot(num_epochs, val_accuracy, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(num_epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(num_epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Pzozx-30LSe",
        "outputId": "60a38fa3-f8e8-4799-9a6c-d9c961dca994"
      },
      "source": [
        "testloss = model.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "trainloss = model.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(trainloss[0]))\n",
        "print(\"Train Acc: \" + str(trainloss[1]))\n",
        "vallosz = model.evaluate(x_val, y_val) \n",
        "print(\"val Loss \" + str(vallosz[0]))\n",
        "print(\"val Acc: \" + str(vallosz[1]))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 3s 25ms/step - loss: 1.8161 - accuracy: 0.2460\n",
            "Test Loss 1.8160868883132935\n",
            "Test Acc: 0.2460295408964157\n",
            "898/898 [==============================] - 23s 25ms/step - loss: 1.8116 - accuracy: 0.2516\n",
            "Train Loss 1.8116334676742554\n",
            "Train Acc: 0.25162839889526367\n",
            "113/113 [==============================] - 3s 25ms/step - loss: 1.8055 - accuracy: 0.2458\n",
            "val Loss 1.8055087327957153\n",
            "val Acc: 0.24575090408325195\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ6YCHax59vt",
        "outputId": "962ebe2d-6913-4453-98c8-f2b9d56d5b3e"
      },
      "source": [
        "from keras.models import load_model\n",
        "model_load = load_model('/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP3_90_noAug3.h5')\n",
        "\n",
        "model_load.summary()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 46, 46, 128)  0           add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_33 (Add)                    (None, 46, 46, 128)  0           activation_101[0][0]             \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 46, 46, 128)  0           add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, 46, 46, 128)  0           activation_104[0][0]             \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 46, 46, 128)  0           add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_35 (Add)                    (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 23, 23, 256)  0           add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_36 (Add)                    (None, 23, 23, 256)  0           activation_110[0][0]             \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 23, 23, 256)  0           add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_37 (Add)                    (None, 23, 23, 256)  0           activation_113[0][0]             \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 23, 23, 256)  0           add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_38 (Add)                    (None, 23, 23, 256)  0           activation_116[0][0]             \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 23, 23, 256)  0           add_38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_39 (Add)                    (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 12, 12, 512)  0           add_39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_40 (Add)                    (None, 12, 12, 512)  0           activation_122[0][0]             \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 12, 12, 512)  0           add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_41 (Add)                    (None, 12, 12, 512)  0           activation_125[0][0]             \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 12, 12, 512)  0           add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_42 (Add)                    (None, 12, 12, 512)  0           activation_128[0][0]             \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 12, 12, 512)  0           add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_43 (Add)                    (None, 12, 12, 512)  0           activation_131[0][0]             \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 12, 12, 512)  0           add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_44 (Add)                    (None, 12, 12, 512)  0           activation_134[0][0]             \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 12, 12, 512)  0           add_44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_45 (Add)                    (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 6, 6, 1024)   0           add_45[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_46 (Add)                    (None, 6, 6, 1024)   0           activation_140[0][0]             \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 6, 6, 1024)   0           add_46[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_47 (Add)                    (None, 6, 6, 1024)   0           activation_143[0][0]             \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 6, 6, 1024)   0           add_47[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fpz7ehkO6Cat",
        "outputId": "3f4f1bbe-10d6-4724-853c-bdcf74ff64f3"
      },
      "source": [
        "testloss = model_load.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "\n",
        "trainloss = model_load.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(trainloss[0]))\n",
        "print(\"Train Acc: \" + str(trainloss[1]))\n",
        "\n",
        "vallosz = model_load.evaluate(x_val, y_val) \n",
        "print(\"val Loss \" + str(vallosz[0]))\n",
        "print(\"val Acc: \" + str(vallosz[1]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 49s 27ms/step - loss: 1.8161 - accuracy: 0.2460\n",
            "Test Loss 1.8160868883132935\n",
            "Test Acc: 0.2460295408964157\n",
            "898/898 [==============================] - 23s 26ms/step - loss: 1.8116 - accuracy: 0.2516\n",
            "Train Loss 1.8116334676742554\n",
            "Train Acc: 0.25162839889526367\n",
            "113/113 [==============================] - 3s 26ms/step - loss: 1.8055 - accuracy: 0.2458\n",
            "val Loss 1.8055087327957153\n",
            "val Acc: 0.24575090408325195\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDwmru9p0gyj",
        "outputId": "234e3ebd-fc41-4179-a1ff-431d4f786bc0"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "#y_pred = model_load.predict(xtest)g\n",
        "\n",
        "test_prob = model_load.predict(xtest)\n",
        "test_pred = np.argmax(test_prob, axis=1)\n",
        "test_accuracy = np.mean(test_pred == ytest)\n",
        "\n",
        "print(test_accuracy)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2460295346893285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpHHR7Q6y9uU"
      },
      "source": [
        "emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "-0ha8DW80028",
        "outputId": "5f5a57cb-aa9e-45de-8358-b038b1c79221"
      },
      "source": [
        "conf_mat = confusion_matrix(ytest, test_pred)\n",
        "##\n",
        "pd.DataFrame(conf_mat, columns=emotions.values(), index=emotions.values())\n",
        "\n",
        "fig, ax = plot_confusion_matrix(conf_mat=conf_mat,show_normed=True,show_absolute=False,figsize=(9, 9))\n",
        "fig.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDC2YQsIywNO",
        "outputId": "ff8af487-41d5-469e-c174-75816cdf7b97"
      },
      "source": [
        "print(classification_report(ytest, test_pred, target_names=emotions.values()))\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry       0.00      0.00      0.00       480\n",
            "     Disgust       0.00      0.00      0.00        60\n",
            "        Fear       0.00      0.00      0.00       515\n",
            "       Happy       0.25      1.00      0.39       883\n",
            "         Sad       0.00      0.00      0.00       597\n",
            "    Surprise       0.00      0.00      0.00       397\n",
            "     Neutral       0.00      0.00      0.00       657\n",
            "\n",
            "    accuracy                           0.25      3589\n",
            "   macro avg       0.04      0.14      0.06      3589\n",
            "weighted avg       0.06      0.25      0.10      3589\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}