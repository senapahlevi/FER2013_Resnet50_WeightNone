{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER2013_Resnet50_60weightnoneSEEDSP4_noAUG4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "18Zj-Yp1YlH0QWcuD4e7ugx8zCCcRS0jg",
      "authorship_tag": "ABX9TyNJrj1rJjBIpN+6wc9lUo9X"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eWeoD7MRFlN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d789e592-4359-49eb-bf50-081e6dc207ff"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "inputFolder = '/content/drive/MyDrive/Fer2013_backup/' \n",
        "for root, directories, filenames in os.walk(inputFolder): \n",
        "    for filename in filenames: print(os.path.join(root,filename))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Fer2013_backup/backUpfer2013.csv\n",
            "/content/drive/MyDrive/Fer2013_backup/icml_face_data.csv\n",
            "/content/drive/MyDrive/Fer2013_backup/test.csv\n",
            "/content/drive/MyDrive/Fer2013_backup/train.csv\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/best_model_resnet50_modelB2_170false.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/best_model_resnet50_modelD2_170false.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50Scracth_tipe7.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50Scracth_tipe8.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50oriAUGScracthSGD2.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50oriAUGScracthSGD3.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50AUGScracthadam2.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50AUGScracthAdam1sp.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50AUGScracthSGD4sp.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50AUGScracthSGD5sp.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50AUGScracthSGD6sp.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP1_30_noAug1.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP2_30_noAug2.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP3_30_noAug3.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP4_30_noAug4.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP5_30_noAug5.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP6_30_noAug6.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP1_90_noAug1.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP2_90_noAug2.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP3_90_noAug3.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP4_90_noAug4.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP4_60_noAug1.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP5_60_noAug5.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP5_90_noAug5.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP1_60_noAug1.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP2_60_noAug2.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP3_60_noAug3.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/fixcheckpoint/Best_Model_resnet50oriAUGScracthSGD2.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH8iEUJiRQS7",
        "outputId": "865cfbd2-947f-4b30-cd99-43d4c1f46273"
      },
      "source": [
        "%cd /content/drive/MyDrive/Fer2013_backup/\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Fer2013_backup\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqZOFwxxRQaa",
        "outputId": "84c38b1f-3531-41cf-8b05-55f442a79122"
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:400: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUX-dSAgRQh4"
      },
      "source": [
        "#Define the identity block helper function.\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "   \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbdQH3mkRQra"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path \n",
        "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b',padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33XH76oKRQvh"
      },
      "source": [
        "def ResNet50(input_shape = (48,48,1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    #X = ZeroPadding2D((1, 1))(X_input)\n",
        "    X = X_input\n",
        "    # Stage 1\n",
        "\n",
        "    X = Conv2D(8, (3, 3), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # removed maxpool\n",
        "    #X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='c')\n",
        "\n",
        "\n",
        "    # Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [64,64,256], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL . \n",
        "    X = AveragePooling2D((2,2), name='avg_pool')(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(512, activation = 'relu', name='fc1024' , kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWuYK_f2zGJF"
      },
      "source": [
        "\"\"\"def ResNet50ori(input_shape = (48, 48, 1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50ori')\n",
        "\n",
        "    return model\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QQOxN2cRQy3"
      },
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        " \n",
        "dataset_path = '/content/drive/MyDrive/Fer2013_backup/backUpfer2013.csv'\n",
        "image_size=(48,48)\n",
        "\n",
        "def load_fer2013():\n",
        "    data = pd.read_csv(dataset_path)\n",
        "    data = (data[data['pixels'].notnull()])\n",
        "    pixels = data['pixels'].tolist()\n",
        "    width, height = 48, 48\n",
        "    faces = []\n",
        "    for pixel_sequence in pixels:\n",
        "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "        face = np.asarray(face).reshape(width, height)\n",
        "        face = cv2.resize(face.astype('uint8'),image_size)\n",
        "        faces.append(face.astype('float32'))\n",
        "    faces = np.asarray(faces)\n",
        "    faces = np.expand_dims(faces, -1)\n",
        "    emotions = (data['emotion'])#.values\n",
        "    return faces, emotions\n",
        " \n",
        "def preprocess_input(x, v2=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if v2:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x\n",
        " \n",
        "faces, emotions = load_fer2013()\n",
        "faces = preprocess_input(faces)\n",
        "#xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
        "#Data Augumentationfgf\n",
        "\"\"\"data_generator = ImageDataGenerator(\n",
        "                        rotation_range=10,\n",
        "                        shear_range = 10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        vertical_flip=True,\n",
        "                        )\"\"\"\n",
        "data_generator = ImageDataGenerator ()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "8zCkwVdnKTm5",
        "outputId": "4adf21fc-440e-49c1-c3aa-349e06e1d0e9"
      },
      "source": [
        "train_ratio = 0.80\n",
        "validation_ratio = 0.10\n",
        "test_ratio = 0.10\n",
        "\n",
        "# train is now 75% of the entire data set\n",
        "# the _junk suffix means that we drop that variable completely # the _junk suffix means that we drop that variable completely\n",
        "#x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=1 - train_ratio,random_state=42)\n",
        "\n",
        "# test is now 10% of the initial data set\n",
        "# validation is now 15% of the initial data set\n",
        "#x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "x_val, xtest, y_val, ytest = train_test_split(xtest, ytest, test_size=test_ratio/(test_ratio + validation_ratio), random_state=42) \n",
        "\n",
        "#print(xtrain, x_val, xtest)\n",
        "\n",
        "\"\"\"X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2\"\"\""
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\\n\\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t--o7TREKTu2",
        "outputId": "8c3ca4ac-6c20-4f9a-8213-7ec7e75dfe1e"
      },
      "source": [
        "print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validasi (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "test (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "train (28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ofOj3-fRREN"
      },
      "source": [
        "#hyperparameter and callback\n",
        "batch_size = 64\n",
        "num_epochs = 60\n",
        "input_shape = (48, 48, 1)\n",
        "num_classes = 7\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXikieAnRbYs"
      },
      "source": [
        "#Compile the model.\n",
        "\n",
        "\n",
        "from keras.optimizers import Adam, SGD\n",
        "model = ResNet50(input_shape = (48, 48, 1), classes = 7)\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "model.compile(optimizer= optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nefC0ZE8RgX5",
        "outputId": "83f8fecb-6eb8-435c-fd37-1328a93c71e8"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 46, 46, 128)  0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 46, 46, 128)  0           activation_52[0][0]              \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 46, 46, 128)  0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 46, 46, 128)  0           activation_55[0][0]              \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 46, 46, 128)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 23, 23, 256)  0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 23, 23, 256)  0           activation_61[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 23, 23, 256)  0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 23, 23, 256)  0           activation_64[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 23, 23, 256)  0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 23, 23, 256)  0           activation_67[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 23, 23, 256)  0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 12, 12, 512)  0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 12, 12, 512)  0           activation_73[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 12, 12, 512)  0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 12, 12, 512)  0           activation_76[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 12, 12, 512)  0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 12, 12, 512)  0           activation_79[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 12, 12, 512)  0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 12, 12, 512)  0           activation_82[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 12, 12, 512)  0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 12, 12, 512)  0           activation_85[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 12, 12, 512)  0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 6, 6, 1024)   0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 6, 6, 1024)   0           activation_91[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 6, 6, 1024)   0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 6, 6, 1024)   0           activation_94[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 6, 6, 1024)   0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_tXyjuSz_IP",
        "outputId": "d6dd2604-8209-4bfd-f6e0-0fc264d2b200"
      },
      "source": [
        "history = model.fit(\n",
        "    data_generator.flow(xtrain, ytrain,),\n",
        "    steps_per_epoch=len(xtrain) / batch_size,\n",
        "    epochs=num_epochs,\n",
        "    shuffle=False,\n",
        "    verbose=1,\n",
        "    validation_data= (x_val,y_val))\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "448/448 [==============================] - 60s 109ms/step - loss: 17.1245 - accuracy: 0.2215 - val_loss: 1.8032 - val_accuracy: 0.2458\n",
            "Epoch 2/60\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 1.8107 - accuracy: 0.2466 - val_loss: 1.7819 - val_accuracy: 0.2524\n",
            "Epoch 3/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7894 - accuracy: 0.2560 - val_loss: 1.7547 - val_accuracy: 0.2630\n",
            "Epoch 4/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.7610 - accuracy: 0.2770 - val_loss: 1.7313 - val_accuracy: 0.2862\n",
            "Epoch 5/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 1.7530 - accuracy: 0.2839 - val_loss: 1.7545 - val_accuracy: 0.2750\n",
            "Epoch 6/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7232 - accuracy: 0.3000 - val_loss: 1.6942 - val_accuracy: 0.3101\n",
            "Epoch 7/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.6839 - accuracy: 0.3163 - val_loss: 1.6679 - val_accuracy: 0.3160\n",
            "Epoch 8/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.6531 - accuracy: 0.3428 - val_loss: 1.6511 - val_accuracy: 0.3285\n",
            "Epoch 9/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.6177 - accuracy: 0.3661 - val_loss: 1.5896 - val_accuracy: 0.3725\n",
            "Epoch 10/60\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.5837 - accuracy: 0.3773 - val_loss: 1.7171 - val_accuracy: 0.2870\n",
            "Epoch 11/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.6042 - accuracy: 0.3648 - val_loss: 1.6046 - val_accuracy: 0.3592\n",
            "Epoch 12/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.6706 - accuracy: 0.3425 - val_loss: 1.6713 - val_accuracy: 0.3238\n",
            "Epoch 13/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.6046 - accuracy: 0.3653 - val_loss: 1.5724 - val_accuracy: 0.3748\n",
            "Epoch 14/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 1.5294 - accuracy: 0.4045 - val_loss: 1.5607 - val_accuracy: 0.3792\n",
            "Epoch 15/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.5073 - accuracy: 0.4000 - val_loss: 1.4602 - val_accuracy: 0.4322\n",
            "Epoch 16/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.4492 - accuracy: 0.4436 - val_loss: 1.5477 - val_accuracy: 0.3814\n",
            "Epoch 17/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.4612 - accuracy: 0.4287 - val_loss: 1.5645 - val_accuracy: 0.3845\n",
            "Epoch 18/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.4402 - accuracy: 0.4386 - val_loss: 1.8109 - val_accuracy: 0.1962\n",
            "Epoch 19/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.4305 - accuracy: 0.4386 - val_loss: 1.5786 - val_accuracy: 0.3801\n",
            "Epoch 20/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.4321 - accuracy: 0.4413 - val_loss: 1.8058 - val_accuracy: 0.2458\n",
            "Epoch 21/60\n",
            "448/448 [==============================] - 46s 103ms/step - loss: 1.8147 - accuracy: 0.2498 - val_loss: 1.8061 - val_accuracy: 0.2458\n",
            "Epoch 22/60\n",
            "448/448 [==============================] - 46s 104ms/step - loss: 1.8026 - accuracy: 0.2623 - val_loss: 1.8056 - val_accuracy: 0.2458\n",
            "Epoch 23/60\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.8134 - accuracy: 0.2528 - val_loss: 1.8051 - val_accuracy: 0.2458\n",
            "Epoch 24/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.8184 - accuracy: 0.2497 - val_loss: 1.8063 - val_accuracy: 0.2458\n",
            "Epoch 25/60\n",
            "448/448 [==============================] - 46s 103ms/step - loss: 1.8113 - accuracy: 0.2520 - val_loss: 1.8063 - val_accuracy: 0.2458\n",
            "Epoch 26/60\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.8083 - accuracy: 0.2494 - val_loss: 1.8052 - val_accuracy: 0.2458\n",
            "Epoch 27/60\n",
            "448/448 [==============================] - 46s 103ms/step - loss: 1.8032 - accuracy: 0.2531 - val_loss: 1.8056 - val_accuracy: 0.2458\n",
            "Epoch 28/60\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.8143 - accuracy: 0.2549 - val_loss: 1.8048 - val_accuracy: 0.2458\n",
            "Epoch 29/60\n",
            "448/448 [==============================] - 46s 103ms/step - loss: 1.8157 - accuracy: 0.2525 - val_loss: 1.8057 - val_accuracy: 0.2458\n",
            "Epoch 30/60\n",
            "448/448 [==============================] - 46s 103ms/step - loss: 1.8070 - accuracy: 0.2624 - val_loss: 1.8054 - val_accuracy: 0.2458\n",
            "Epoch 31/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.8113 - accuracy: 0.2497 - val_loss: 1.8060 - val_accuracy: 0.2458\n",
            "Epoch 32/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.8196 - accuracy: 0.2445 - val_loss: 1.8050 - val_accuracy: 0.2458\n",
            "Epoch 33/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.8094 - accuracy: 0.2584 - val_loss: 1.8056 - val_accuracy: 0.2458\n",
            "Epoch 34/60\n",
            "448/448 [==============================] - 46s 103ms/step - loss: 1.8102 - accuracy: 0.2588 - val_loss: 1.8049 - val_accuracy: 0.2458\n",
            "Epoch 35/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.8136 - accuracy: 0.2479 - val_loss: 1.8054 - val_accuracy: 0.2458\n",
            "Epoch 36/60\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.8145 - accuracy: 0.2574 - val_loss: 1.8055 - val_accuracy: 0.2458\n",
            "Epoch 37/60\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.8041 - accuracy: 0.2570 - val_loss: 1.8065 - val_accuracy: 0.2458\n",
            "Epoch 38/60\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.8148 - accuracy: 0.2500 - val_loss: 1.8056 - val_accuracy: 0.2458\n",
            "Epoch 39/60\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.8060 - accuracy: 0.2556 - val_loss: 1.8061 - val_accuracy: 0.2458\n",
            "Epoch 40/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.8113 - accuracy: 0.2564 - val_loss: 1.8056 - val_accuracy: 0.2458\n",
            "Epoch 41/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.8139 - accuracy: 0.2524 - val_loss: 1.8069 - val_accuracy: 0.2458\n",
            "Epoch 42/60\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.8174 - accuracy: 0.2495 - val_loss: 1.8053 - val_accuracy: 0.2458\n",
            "Epoch 43/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.8192 - accuracy: 0.2509 - val_loss: 1.8063 - val_accuracy: 0.2458\n",
            "Epoch 44/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.8135 - accuracy: 0.2502 - val_loss: 1.8048 - val_accuracy: 0.2458\n",
            "Epoch 45/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.8137 - accuracy: 0.2499 - val_loss: 1.8055 - val_accuracy: 0.2458\n",
            "Epoch 46/60\n",
            "448/448 [==============================] - 46s 103ms/step - loss: 1.8123 - accuracy: 0.2496 - val_loss: 1.8054 - val_accuracy: 0.2458\n",
            "Epoch 47/60\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.8112 - accuracy: 0.2514 - val_loss: 1.8053 - val_accuracy: 0.2458\n",
            "Epoch 48/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.8077 - accuracy: 0.2528 - val_loss: 1.8052 - val_accuracy: 0.2458\n",
            "Epoch 49/60\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.8078 - accuracy: 0.2529 - val_loss: 1.8055 - val_accuracy: 0.2458\n",
            "Epoch 50/60\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.8046 - accuracy: 0.2504 - val_loss: 1.8056 - val_accuracy: 0.2458\n",
            "Epoch 51/60\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.8099 - accuracy: 0.2542 - val_loss: 1.8045 - val_accuracy: 0.2458\n",
            "Epoch 52/60\n",
            "448/448 [==============================] - 46s 103ms/step - loss: 1.8014 - accuracy: 0.2575 - val_loss: 1.8059 - val_accuracy: 0.2458\n",
            "Epoch 53/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.8080 - accuracy: 0.2576 - val_loss: 1.8060 - val_accuracy: 0.2458\n",
            "Epoch 54/60\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.8157 - accuracy: 0.2483 - val_loss: 1.8059 - val_accuracy: 0.2458\n",
            "Epoch 55/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.8087 - accuracy: 0.2543 - val_loss: 1.8066 - val_accuracy: 0.2458\n",
            "Epoch 56/60\n",
            "448/448 [==============================] - 46s 103ms/step - loss: 1.8122 - accuracy: 0.2572 - val_loss: 1.8053 - val_accuracy: 0.2458\n",
            "Epoch 57/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.8033 - accuracy: 0.2553 - val_loss: 1.8066 - val_accuracy: 0.2458\n",
            "Epoch 58/60\n",
            "448/448 [==============================] - 46s 102ms/step - loss: 1.8196 - accuracy: 0.2420 - val_loss: 1.8056 - val_accuracy: 0.2458\n",
            "Epoch 59/60\n",
            "448/448 [==============================] - 46s 103ms/step - loss: 1.8073 - accuracy: 0.2497 - val_loss: 1.8054 - val_accuracy: 0.2458\n",
            "Epoch 60/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.8141 - accuracy: 0.2535 - val_loss: 1.8050 - val_accuracy: 0.2458\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "cZvluWhSRkq4",
        "outputId": "bcc02a9a-809a-4209-a0ea-369e89335280"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "model.save('/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP4_60_noAug4.h5')\n",
        "\n",
        "#ffddfsgyghuuih\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "num_epochs = range(len(accuracy))\n",
        "plt.plot(num_epochs, accuracy, 'r', label='Training acc')\n",
        "plt.plot(num_epochs, val_accuracy, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(num_epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(num_epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Pzozx-30LSe",
        "outputId": "9186de09-7d1c-4941-80ee-c3142c2bfc17"
      },
      "source": [
        "testloss = model.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "trainloss = model.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(trainloss[0]))\n",
        "print(\"Train Acc: \" + str(trainloss[1]))\n",
        "vallosz = model.evaluate(x_val, y_val) \n",
        "print(\"val Loss \" + str(vallosz[0]))\n",
        "print(\"val Acc: \" + str(vallosz[1]))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 3s 26ms/step - loss: 1.8147 - accuracy: 0.2460\n",
            "Test Loss 1.814675211906433\n",
            "Test Acc: 0.2460295408964157\n",
            "898/898 [==============================] - 23s 25ms/step - loss: 1.8113 - accuracy: 0.2516\n",
            "Train Loss 1.8113089799880981\n",
            "Train Acc: 0.25162839889526367\n",
            "113/113 [==============================] - 3s 26ms/step - loss: 1.8050 - accuracy: 0.2458\n",
            "val Loss 1.8050291538238525\n",
            "val Acc: 0.24575090408325195\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ6YCHax59vt",
        "outputId": "5275e724-fd82-4526-bf70-cb587744d039"
      },
      "source": [
        "from keras.models import load_model\n",
        "model_load = load_model('/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP4_60_noAug4.h5')\n",
        "\n",
        "model_load.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 46, 46, 128)  0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 46, 46, 128)  0           activation_52[0][0]              \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 46, 46, 128)  0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 46, 46, 128)  0           activation_55[0][0]              \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 46, 46, 128)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 23, 23, 256)  0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 23, 23, 256)  0           activation_61[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 23, 23, 256)  0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 23, 23, 256)  0           activation_64[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 23, 23, 256)  0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 23, 23, 256)  0           activation_67[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 23, 23, 256)  0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 12, 12, 512)  0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 12, 12, 512)  0           activation_73[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 12, 12, 512)  0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 12, 12, 512)  0           activation_76[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 12, 12, 512)  0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 12, 12, 512)  0           activation_79[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 12, 12, 512)  0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 12, 12, 512)  0           activation_82[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 12, 12, 512)  0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 12, 12, 512)  0           activation_85[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 12, 12, 512)  0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 6, 6, 1024)   0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 6, 6, 1024)   0           activation_91[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 6, 6, 1024)   0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 6, 6, 1024)   0           activation_94[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 6, 6, 1024)   0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fpz7ehkO6Cat",
        "outputId": "81adda19-5216-4247-ae9d-2b90cadfc344"
      },
      "source": [
        "testloss = model_load.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "\n",
        "trainloss = model_load.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(trainloss[0]))\n",
        "print(\"Train Acc: \" + str(trainloss[1]))\n",
        "\n",
        "vallosz = model_load.evaluate(x_val, y_val) \n",
        "print(\"val Loss \" + str(vallosz[0]))\n",
        "print(\"val Acc: \" + str(vallosz[1]))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 6s 26ms/step - loss: 1.8147 - accuracy: 0.2460\n",
            "Test Loss 1.814675211906433\n",
            "Test Acc: 0.2460295408964157\n",
            "898/898 [==============================] - 23s 25ms/step - loss: 1.8113 - accuracy: 0.2516\n",
            "Train Loss 1.8113089799880981\n",
            "Train Acc: 0.25162839889526367\n",
            "113/113 [==============================] - 3s 26ms/step - loss: 1.8050 - accuracy: 0.2458\n",
            "val Loss 1.8050291538238525\n",
            "val Acc: 0.24575090408325195\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDwmru9p0gyj",
        "outputId": "b6e2e75f-1431-4b88-ac8c-2f6e1bb5d2f2"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "#y_pred = model_load.predict(xtest)g\n",
        "\n",
        "test_prob = model_load.predict(xtest)\n",
        "test_pred = np.argmax(test_prob, axis=1)\n",
        "test_accuracy = np.mean(test_pred == ytest)\n",
        "\n",
        "print(test_accuracy)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2460295346893285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpHHR7Q6y9uU"
      },
      "source": [
        "emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "-0ha8DW80028",
        "outputId": "37e979ac-6f53-4b86-e4ff-75e36aaf50be"
      },
      "source": [
        "conf_mat = confusion_matrix(ytest, test_pred)\n",
        "##\n",
        "pd.DataFrame(conf_mat, columns=emotions.values(), index=emotions.values())\n",
        "\n",
        "fig, ax = plot_confusion_matrix(conf_mat=conf_mat,show_normed=True,show_absolute=False,figsize=(9, 9))\n",
        "fig.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDC2YQsIywNO",
        "outputId": "9caf2777-ce57-45c3-a4bb-16c93d2d6e5e"
      },
      "source": [
        "print(classification_report(ytest, test_pred, target_names=emotions.values()))\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry       0.00      0.00      0.00       480\n",
            "     Disgust       0.00      0.00      0.00        60\n",
            "        Fear       0.00      0.00      0.00       515\n",
            "       Happy       0.25      1.00      0.39       883\n",
            "         Sad       0.00      0.00      0.00       597\n",
            "    Surprise       0.00      0.00      0.00       397\n",
            "     Neutral       0.00      0.00      0.00       657\n",
            "\n",
            "    accuracy                           0.25      3589\n",
            "   macro avg       0.04      0.14      0.06      3589\n",
            "weighted avg       0.06      0.25      0.10      3589\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xfSSuZCuutf",
        "outputId": "a135ff76-f577-4614-f706-230ba80f73c0"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "dataread =pd.read_csv('/content/drive/MyDrive/Fer2013_backup/backUpfer2013.csv')\n",
        "\n",
        "#print(dataread.duplicated().value_counts)\n",
        "#(df[df.duplicated()])s\n",
        "\"\"\"dataread['Usage'].value_counts()\n",
        "dataread['emotion'].value_counts()\n",
        "\"\"\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    8989\n",
              "6    6198\n",
              "4    6077\n",
              "2    5121\n",
              "0    4953\n",
              "5    4002\n",
              "1     547\n",
              "Name: emotion, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncIVy0SZ_WgH"
      },
      "source": [
        "from numpy import expand_dims\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from matplotlib import pyplot\n",
        "#meload gambar\n",
        "img = load_img('')\n",
        "\n",
        "data = img_to_array(img)\n",
        "#meningkatkan dimension ke satu sampel\n",
        "sampels = \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2bP0roK-WpE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}