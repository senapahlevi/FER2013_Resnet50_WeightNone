{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER2013_Resnet50_weightnone_fixTrainTestVal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-Qn1jsBTIBl0b7myLQxqa8WjCcfbamqM",
      "authorship_tag": "ABX9TyM+0NBikJosw5fQvj6XliWQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/senapahlevi/FER2013_Resnet50_WeightNone/blob/master/FER2013_Resnet50_weightnone_fixTrainTestVal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b86nukQOxN7l"
      },
      "source": [
        "Resnet-50 From Scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p8gxtGy0TWP",
        "outputId": "ddceb0de-41cf-4e97-af65-37103c2a941e"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "inputFolder = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth' \n",
        "for root, directories, filenames in os.walk(inputFolder): \n",
        "    for filename in filenames: print(os.path.join(root,filename))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Best_Model_resnet50Scracth1again.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe4.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth1again.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50ScracthSGD1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50AUGScracthadam3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD1try2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD4.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50oriSGD1st.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50SGD5stori.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editSGD5st.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editAdamst120epochBS128.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editAdamst120epochBS128_1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editAdamst120epochBS128+aug:vf_2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50oriScracth_sena2.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsiscWIMBDX2",
        "outputId": "08c7006e-8e42-4126-83c4-13b0cd23449f"
      },
      "source": [
        "%cd /content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "wLMSe510xNCJ",
        "outputId": "3da9f6f5-cb75-4f61-d978-1e7de9a074fc"
      },
      "source": [
        "#Create a directory to save our generated models.dasdas\n",
        "\n",
        "#os.mkdir(\"./modelscracth\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-cf55f19f3613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#os.mkdir(\"./modelscracth\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ls' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_kluusLxM1B",
        "outputId": "721a0c31-2651-44ba-ea71-224c32b105d4"
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:400: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfUSF_tAxNMP"
      },
      "source": [
        "#Define the identity block helper function.\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "   \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VdYtzhn1F0I"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path \n",
        "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b',padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd-O8ZMx1GAW"
      },
      "source": [
        "\"\"\"def ResNet50(input_shape = (48,48,1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    #X = ZeroPadding2D((1, 1))(X_input)\n",
        "    X = X_input\n",
        "    # Stage 1\n",
        "\n",
        "    X = Conv2D(8, (3, 3), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # removed maxpool\n",
        "    #X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='c')\n",
        "\n",
        "\n",
        "    # Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [64,64,256], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL . \n",
        "    X = AveragePooling2D((2,2), name='avg_pool')(X)\n",
        "    \n",
        "    # output layerds\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(512, activation = 'relu', name='fc1024' , kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GKsSwtp-GuL"
      },
      "source": [
        "def ResNet50ori(input_shape = (48, 48, 1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns: dsdsf\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50ori')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3oWTDXlyBHM2",
        "outputId": "3df0c868-9ea8-4f51-a95a-1e82c81de965"
      },
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        " \n",
        "dataset_path = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv'\n",
        "image_size=(48,48)\n",
        "#batch_size = 64\n",
        "\n",
        "def load_fer2013():\n",
        "    data = pd.read_csv(dataset_path)\n",
        "    data = (data[data['pixels'].notnull()])\n",
        "    pixels = data['pixels'].tolist()\n",
        "    width, height = 48, 48\n",
        "    faces = []\n",
        "    for pixel_sequence in pixels:\n",
        "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "        face = np.asarray(face).reshape(width, height)\n",
        "        face = cv2.resize(face.astype('uint8'),image_size)\n",
        "        faces.append(face.astype('float32'))\n",
        "    faces = np.asarray(faces)\n",
        "    faces = np.expand_dims(faces, -1)\n",
        "    emotions = (data['emotion'])#.values\n",
        "    return faces, emotions\n",
        " \n",
        "def preprocess_input(x, v2=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if v2:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x\n",
        " \n",
        "faces, emotions = load_fer2013()\n",
        "faces = preprocess_input(faces)\n",
        "#xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
        "#Data Augumentation\n",
        "data_generator = ImageDataGenerator(\n",
        "                        rotation_range=10,\n",
        "                        shear_range = 10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True,\n",
        "                        )\n",
        "\"\"\"data_generator = ImageDataGenerator( )\n",
        "\"\"\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'data_generator = ImageDataGenerator( )\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWLhavr-rSF5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "895f7f85-9930-46ca-c552-cbb571846a4e"
      },
      "source": [
        "\"\"\"\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.1,)\n",
        "x_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1,)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nxtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.1,)\\nx_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1,)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "RGhnYFXgaqL9",
        "outputId": "0e60da2f-3a44-4d06-910b-2e0f2fa4191a"
      },
      "source": [
        "\"\"\"print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (y_train.shape)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'print (\"validasi\",x_val.shape)\\nprint (y_val.shape)\\nprint (\"test\",xtest.shape)\\nprint (ytest.shape)\\nprint (\"train\",xtrain.shape)\\nprint (y_train.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rDS3hqhDSteM",
        "outputId": "1adfc428-4546-4640-f44d-6e639572e683"
      },
      "source": [
        "train_ratio = 0.80\n",
        "validation_ratio = 0.10\n",
        "test_ratio = 0.10\n",
        "\n",
        "# train is now 75% of the entire data set\n",
        "# the _junk suffix means that we drop that variable completely # the _junk suffix means that we drop that variable completely\n",
        "#x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=1 - train_ratio)\n",
        "\n",
        "# test is now 10% of the initial data set\n",
        "# validation is now 15% of the initial data set\n",
        "#x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "x_val, xtest, y_val, ytest = train_test_split(xtest, ytest, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "\n",
        "print(xtrain, x_val, xtest)\n",
        "\n",
        "\"\"\"X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2\"\"\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[-0.30196077]\n",
            "   [-0.3333333 ]\n",
            "   [-0.26274508]\n",
            "   ...\n",
            "   [ 0.23921573]\n",
            "   [ 0.3803922 ]\n",
            "   [ 0.36470592]]\n",
            "\n",
            "  [[-0.35686272]\n",
            "   [-0.3098039 ]\n",
            "   [-0.27058822]\n",
            "   ...\n",
            "   [ 0.35686278]\n",
            "   [ 0.4039216 ]\n",
            "   [ 0.36470592]]\n",
            "\n",
            "  [[-0.25490195]\n",
            "   [-0.27058822]\n",
            "   [-0.27843136]\n",
            "   ...\n",
            "   [ 0.52156866]\n",
            "   [ 0.49803925]\n",
            "   [ 0.4666667 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.35686278]\n",
            "   [ 0.20000005]\n",
            "   [ 0.11372554]\n",
            "   ...\n",
            "   [-0.3098039 ]\n",
            "   [-0.3098039 ]\n",
            "   [-0.29411763]]\n",
            "\n",
            "  [[ 0.18431377]\n",
            "   [ 0.04313731]\n",
            "   [-0.00392157]\n",
            "   ...\n",
            "   [-0.34117645]\n",
            "   [-0.32549018]\n",
            "   [-0.3098039 ]]\n",
            "\n",
            "  [[-0.01176471]\n",
            "   [-0.09019607]\n",
            "   [-0.18431371]\n",
            "   ...\n",
            "   [-0.3490196 ]\n",
            "   [-0.34117645]\n",
            "   [-0.32549018]]]\n",
            "\n",
            "\n",
            " [[[-0.92941177]\n",
            "   [-0.9137255 ]\n",
            "   [-0.90588236]\n",
            "   ...\n",
            "   [-0.827451  ]\n",
            "   [-0.827451  ]\n",
            "   [-0.7176471 ]]\n",
            "\n",
            "  [[-0.92941177]\n",
            "   [-0.9372549 ]\n",
            "   [-0.8901961 ]\n",
            "   ...\n",
            "   [-0.78039217]\n",
            "   [-0.7882353 ]\n",
            "   [-0.7490196 ]]\n",
            "\n",
            "  [[-0.9607843 ]\n",
            "   [-0.94509804]\n",
            "   [-0.90588236]\n",
            "   ...\n",
            "   [-0.69411767]\n",
            "   [-0.7490196 ]\n",
            "   [-0.77254903]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.19215691]\n",
            "   [ 0.20784318]\n",
            "   [ 0.22352946]\n",
            "   ...\n",
            "   [ 0.26274514]\n",
            "   [ 0.23921573]\n",
            "   [ 0.22352946]]\n",
            "\n",
            "  [[ 0.19215691]\n",
            "   [ 0.20784318]\n",
            "   [ 0.22352946]\n",
            "   ...\n",
            "   [ 0.254902  ]\n",
            "   [ 0.24705887]\n",
            "   [ 0.2313726 ]]\n",
            "\n",
            "  [[ 0.18431377]\n",
            "   [ 0.20784318]\n",
            "   [ 0.21568632]\n",
            "   ...\n",
            "   [ 0.254902  ]\n",
            "   [ 0.24705887]\n",
            "   [ 0.2313726 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.9529412 ]\n",
            "   [ 0.94509804]\n",
            "   [ 0.94509804]\n",
            "   ...\n",
            "   [ 0.9529412 ]\n",
            "   [ 0.9529412 ]\n",
            "   [ 0.9529412 ]]\n",
            "\n",
            "  [[ 0.94509804]\n",
            "   [ 0.9372549 ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 0.9529412 ]\n",
            "   [ 0.9529412 ]\n",
            "   [ 0.9529412 ]]\n",
            "\n",
            "  [[ 0.9372549 ]\n",
            "   [ 1.        ]\n",
            "   [ 0.48235297]\n",
            "   ...\n",
            "   [ 0.9529412 ]\n",
            "   [ 0.9529412 ]\n",
            "   [ 0.9529412 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.8745098 ]\n",
            "   [-0.92941177]\n",
            "   [-0.9607843 ]\n",
            "   ...\n",
            "   [ 0.92941177]\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.96862745]]\n",
            "\n",
            "  [[-0.77254903]\n",
            "   [-0.92156863]\n",
            "   [-0.90588236]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 0.9607843 ]\n",
            "   [ 0.9764706 ]]\n",
            "\n",
            "  [[-0.54509807]\n",
            "   [-0.9137255 ]\n",
            "   [-0.9372549 ]\n",
            "   ...\n",
            "   [ 0.7647059 ]\n",
            "   [ 0.99215686]\n",
            "   [ 0.96862745]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 0.8901961 ]\n",
            "   [ 0.8745098 ]\n",
            "   [ 0.96862745]\n",
            "   ...\n",
            "   [ 0.8509804 ]\n",
            "   [ 0.8117647 ]\n",
            "   [ 0.827451  ]]\n",
            "\n",
            "  [[ 0.8901961 ]\n",
            "   [ 0.8901961 ]\n",
            "   [ 0.9137255 ]\n",
            "   ...\n",
            "   [ 0.90588236]\n",
            "   [ 0.79607844]\n",
            "   [ 0.827451  ]]\n",
            "\n",
            "  [[ 0.8901961 ]\n",
            "   [ 0.90588236]\n",
            "   [ 0.8509804 ]\n",
            "   ...\n",
            "   [ 0.9372549 ]\n",
            "   [ 0.79607844]\n",
            "   [ 0.81960785]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.92156863]\n",
            "   [ 0.92156863]\n",
            "   [ 0.92156863]\n",
            "   ...\n",
            "   [ 0.8745098 ]\n",
            "   [ 0.8666667 ]\n",
            "   [ 0.85882354]]\n",
            "\n",
            "  [[ 0.92156863]\n",
            "   [ 0.92156863]\n",
            "   [ 0.92156863]\n",
            "   ...\n",
            "   [ 0.8745098 ]\n",
            "   [ 0.8666667 ]\n",
            "   [ 0.85882354]]\n",
            "\n",
            "  [[ 0.92156863]\n",
            "   [ 0.92941177]\n",
            "   [ 0.92941177]\n",
            "   ...\n",
            "   [ 0.8666667 ]\n",
            "   [ 0.8666667 ]\n",
            "   [ 0.85882354]]]\n",
            "\n",
            "\n",
            " [[[-0.46666664]\n",
            "   [-0.5764706 ]\n",
            "   [-0.6392157 ]\n",
            "   ...\n",
            "   [ 0.6313726 ]\n",
            "   [ 0.7176471 ]\n",
            "   [ 0.6862745 ]]\n",
            "\n",
            "  [[-0.4980392 ]\n",
            "   [-0.5686275 ]\n",
            "   [-0.654902  ]\n",
            "   ...\n",
            "   [ 0.64705884]\n",
            "   [ 0.6862745 ]\n",
            "   [ 0.654902  ]]\n",
            "\n",
            "  [[-0.5529412 ]\n",
            "   [-0.5921569 ]\n",
            "   [-0.6156863 ]\n",
            "   ...\n",
            "   [ 0.7411765 ]\n",
            "   [ 0.654902  ]\n",
            "   [ 0.6862745 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.64705884]\n",
            "   [-0.64705884]\n",
            "   [-0.88235295]\n",
            "   ...\n",
            "   [-0.35686272]\n",
            "   [-0.1372549 ]\n",
            "   [ 0.22352946]]\n",
            "\n",
            "  [[-0.5686275 ]\n",
            "   [-0.6       ]\n",
            "   [-0.6392157 ]\n",
            "   ...\n",
            "   [-0.23921567]\n",
            "   [-0.06666666]\n",
            "   [ 0.18431377]]\n",
            "\n",
            "  [[-0.5921569 ]\n",
            "   [-0.6       ]\n",
            "   [-0.58431375]\n",
            "   ...\n",
            "   [ 0.23921573]\n",
            "   [ 0.22352946]\n",
            "   [ 0.2941177 ]]]\n",
            "\n",
            "\n",
            " [[[-0.27058822]\n",
            "   [-0.27843136]\n",
            "   [-0.27058822]\n",
            "   ...\n",
            "   [-0.5921569 ]\n",
            "   [-0.6392157 ]\n",
            "   [-0.70980394]]\n",
            "\n",
            "  [[-0.27058822]\n",
            "   [-0.27843136]\n",
            "   [-0.26274508]\n",
            "   ...\n",
            "   [-0.5294118 ]\n",
            "   [-0.6       ]\n",
            "   [-0.6392157 ]]\n",
            "\n",
            "  [[-0.27058822]\n",
            "   [-0.27843136]\n",
            "   [-0.26274508]\n",
            "   ...\n",
            "   [-0.41960782]\n",
            "   [-0.52156866]\n",
            "   [-0.6313726 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.73333335]\n",
            "   [-0.7490196 ]\n",
            "   [-0.7647059 ]\n",
            "   ...\n",
            "   [-0.1607843 ]\n",
            "   [-0.15294117]\n",
            "   [-0.15294117]]\n",
            "\n",
            "  [[-0.46666664]\n",
            "   [-0.27058822]\n",
            "   [-0.09803921]\n",
            "   ...\n",
            "   [-0.16862744]\n",
            "   [-0.16862744]\n",
            "   [-0.16862744]]\n",
            "\n",
            "  [[ 0.5294118 ]\n",
            "   [ 0.62352943]\n",
            "   [ 0.70980394]\n",
            "   ...\n",
            "   [-0.18431371]\n",
            "   [-0.18431371]\n",
            "   [-0.17647058]]]] [[[[ 0.6       ]\n",
            "   [ 0.7411765 ]\n",
            "   [ 0.8039216 ]\n",
            "   ...\n",
            "   [-0.8901961 ]\n",
            "   [-0.8901961 ]\n",
            "   [-0.8980392 ]]\n",
            "\n",
            "  [[ 0.5529412 ]\n",
            "   [ 0.73333335]\n",
            "   [ 0.8117647 ]\n",
            "   ...\n",
            "   [-0.8901961 ]\n",
            "   [-0.8980392 ]\n",
            "   [-0.8980392 ]]\n",
            "\n",
            "  [[ 0.5294118 ]\n",
            "   [ 0.73333335]\n",
            "   [ 0.81960785]\n",
            "   ...\n",
            "   [-0.90588236]\n",
            "   [-0.90588236]\n",
            "   [-0.9137255 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.3098039 ]\n",
            "   [-0.24705881]\n",
            "   [-0.19215685]\n",
            "   ...\n",
            "   [-0.5372549 ]\n",
            "   [-0.5686275 ]\n",
            "   [-0.73333335]]\n",
            "\n",
            "  [[-0.3490196 ]\n",
            "   [-0.27843136]\n",
            "   [-0.2235294 ]\n",
            "   ...\n",
            "   [-0.5686275 ]\n",
            "   [-0.56078434]\n",
            "   [-0.69411767]]\n",
            "\n",
            "  [[-0.36470586]\n",
            "   [-0.32549018]\n",
            "   [-0.2862745 ]\n",
            "   ...\n",
            "   [-0.6392157 ]\n",
            "   [-0.5921569 ]\n",
            "   [-0.69411767]]]\n",
            "\n",
            "\n",
            " [[[-0.7882353 ]\n",
            "   [-0.827451  ]\n",
            "   [-0.84313726]\n",
            "   ...\n",
            "   [-0.60784316]\n",
            "   [-0.60784316]\n",
            "   [-0.60784316]]\n",
            "\n",
            "  [[-0.7882353 ]\n",
            "   [-0.827451  ]\n",
            "   [-0.84313726]\n",
            "   ...\n",
            "   [-0.6       ]\n",
            "   [-0.62352943]\n",
            "   [-0.6156863 ]]\n",
            "\n",
            "  [[-0.7882353 ]\n",
            "   [-0.827451  ]\n",
            "   [-0.8509804 ]\n",
            "   ...\n",
            "   [-0.4980392 ]\n",
            "   [-0.64705884]\n",
            "   [-0.6156863 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.9764706 ]\n",
            "   [-0.9764706 ]\n",
            "   [-0.9843137 ]\n",
            "   ...\n",
            "   [-0.4352941 ]\n",
            "   [-0.41176468]\n",
            "   [-0.36470586]]\n",
            "\n",
            "  [[-0.9764706 ]\n",
            "   [-0.9764706 ]\n",
            "   [-0.9764706 ]\n",
            "   ...\n",
            "   [-0.49019605]\n",
            "   [-0.46666664]\n",
            "   [-0.36470586]]\n",
            "\n",
            "  [[-0.96862745]\n",
            "   [-0.9764706 ]\n",
            "   [-0.9764706 ]\n",
            "   ...\n",
            "   [-0.45098037]\n",
            "   [-0.49019605]\n",
            "   [-0.4352941 ]]]\n",
            "\n",
            "\n",
            " [[[-0.27058822]\n",
            "   [-0.19215685]\n",
            "   [-0.32549018]\n",
            "   ...\n",
            "   [ 0.81960785]\n",
            "   [ 0.8039216 ]\n",
            "   [ 0.8039216 ]]\n",
            "\n",
            "  [[-0.25490195]\n",
            "   [-0.38039213]\n",
            "   [-0.30196077]\n",
            "   ...\n",
            "   [ 0.827451  ]\n",
            "   [ 0.8117647 ]\n",
            "   [ 0.8117647 ]]\n",
            "\n",
            "  [[-0.23921567]\n",
            "   [-0.4823529 ]\n",
            "   [-0.3098039 ]\n",
            "   ...\n",
            "   [ 0.81960785]\n",
            "   [ 0.827451  ]\n",
            "   [ 0.81960785]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.654902  ]\n",
            "   [-0.7647059 ]\n",
            "   [-0.73333335]\n",
            "   ...\n",
            "   [ 0.8352941 ]\n",
            "   [ 0.827451  ]\n",
            "   [ 0.827451  ]]\n",
            "\n",
            "  [[-0.7882353 ]\n",
            "   [-0.79607844]\n",
            "   [-0.6784314 ]\n",
            "   ...\n",
            "   [ 0.827451  ]\n",
            "   [ 0.827451  ]\n",
            "   [ 0.827451  ]]\n",
            "\n",
            "  [[-0.7882353 ]\n",
            "   [-0.77254903]\n",
            "   [-0.62352943]\n",
            "   ...\n",
            "   [ 0.81960785]\n",
            "   [ 0.827451  ]\n",
            "   [ 0.827451  ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 0.827451  ]\n",
            "   [ 0.827451  ]\n",
            "   [ 0.8039216 ]\n",
            "   ...\n",
            "   [-0.19215685]\n",
            "   [-0.2235294 ]\n",
            "   [-0.3333333 ]]\n",
            "\n",
            "  [[ 0.827451  ]\n",
            "   [ 0.81960785]\n",
            "   [ 0.8039216 ]\n",
            "   ...\n",
            "   [-0.14509803]\n",
            "   [-0.19215685]\n",
            "   [-0.21568626]]\n",
            "\n",
            "  [[ 0.8039216 ]\n",
            "   [ 0.8117647 ]\n",
            "   [ 0.8039216 ]\n",
            "   ...\n",
            "   [-0.1372549 ]\n",
            "   [-0.1372549 ]\n",
            "   [-0.14509803]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.6627451 ]\n",
            "   [ 0.6627451 ]\n",
            "   [ 0.41176474]\n",
            "   ...\n",
            "   [-0.46666664]\n",
            "   [-0.46666664]\n",
            "   [-0.4823529 ]]\n",
            "\n",
            "  [[ 0.6313726 ]\n",
            "   [ 0.6       ]\n",
            "   [ 0.3803922 ]\n",
            "   ...\n",
            "   [-0.4352941 ]\n",
            "   [-0.49019605]\n",
            "   [-0.5529412 ]]\n",
            "\n",
            "  [[ 0.60784316]\n",
            "   [ 0.5686275 ]\n",
            "   [ 0.35686278]\n",
            "   ...\n",
            "   [-0.5058824 ]\n",
            "   [-0.5529412 ]\n",
            "   [-0.6156863 ]]]\n",
            "\n",
            "\n",
            " [[[-0.92156863]\n",
            "   [-0.92941177]\n",
            "   [-0.92156863]\n",
            "   ...\n",
            "   [-0.8901961 ]\n",
            "   [-0.9137255 ]\n",
            "   [-0.90588236]]\n",
            "\n",
            "  [[-0.92156863]\n",
            "   [-0.92156863]\n",
            "   [-0.92941177]\n",
            "   ...\n",
            "   [-0.8745098 ]\n",
            "   [-0.92941177]\n",
            "   [-0.90588236]]\n",
            "\n",
            "  [[-0.92941177]\n",
            "   [-0.90588236]\n",
            "   [-0.94509804]\n",
            "   ...\n",
            "   [-0.8980392 ]\n",
            "   [-0.8901961 ]\n",
            "   [-0.92941177]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.05882353]\n",
            "   [-0.01176471]\n",
            "   [-0.09019607]\n",
            "   ...\n",
            "   [-0.9372549 ]\n",
            "   [-0.92941177]\n",
            "   [-0.9137255 ]]\n",
            "\n",
            "  [[ 0.12156868]\n",
            "   [ 0.16078436]\n",
            "   [ 0.13725495]\n",
            "   ...\n",
            "   [-0.92156863]\n",
            "   [-0.9529412 ]\n",
            "   [-0.9372549 ]]\n",
            "\n",
            "  [[ 0.41176474]\n",
            "   [ 0.43529415]\n",
            "   [ 0.41960788]\n",
            "   ...\n",
            "   [-0.92941177]\n",
            "   [-0.92156863]\n",
            "   [-0.92941177]]]\n",
            "\n",
            "\n",
            " [[[-0.00392157]\n",
            "   [-0.0745098 ]\n",
            "   [ 0.00392163]\n",
            "   ...\n",
            "   [ 0.9764706 ]\n",
            "   [ 0.9764706 ]\n",
            "   [ 0.9843137 ]]\n",
            "\n",
            "  [[ 0.11372554]\n",
            "   [-0.0745098 ]\n",
            "   [-0.12156862]\n",
            "   ...\n",
            "   [ 0.9372549 ]\n",
            "   [ 0.9529412 ]\n",
            "   [ 0.9607843 ]]\n",
            "\n",
            "  [[ 0.09803927]\n",
            "   [ 0.16078436]\n",
            "   [-0.1372549 ]\n",
            "   ...\n",
            "   [ 0.8901961 ]\n",
            "   [ 0.9137255 ]\n",
            "   [ 0.9137255 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.7490196 ]\n",
            "   [-0.827451  ]\n",
            "   [-0.88235295]\n",
            "   ...\n",
            "   [-0.4980392 ]\n",
            "   [-0.18431371]\n",
            "   [ 0.6627451 ]]\n",
            "\n",
            "  [[-0.92156863]\n",
            "   [-0.9764706 ]\n",
            "   [-0.96862745]\n",
            "   ...\n",
            "   [-0.5686275 ]\n",
            "   [-0.12156862]\n",
            "   [ 0.7647059 ]]\n",
            "\n",
            "  [[-0.64705884]\n",
            "   [-0.9529412 ]\n",
            "   [-0.8745098 ]\n",
            "   ...\n",
            "   [-0.6       ]\n",
            "   [-0.0745098 ]\n",
            "   [ 0.827451  ]]]] [[[[-0.05098039]\n",
            "   [-0.1372549 ]\n",
            "   [-0.18431371]\n",
            "   ...\n",
            "   [ 0.13725495]\n",
            "   [ 0.15294123]\n",
            "   [ 0.09019613]]\n",
            "\n",
            "  [[-0.15294117]\n",
            "   [-0.21568626]\n",
            "   [-0.23921567]\n",
            "   ...\n",
            "   [ 0.22352946]\n",
            "   [ 0.23921573]\n",
            "   [ 0.09803927]]\n",
            "\n",
            "  [[-0.20784312]\n",
            "   [-0.12941176]\n",
            "   [-0.23921567]\n",
            "   ...\n",
            "   [ 0.33333337]\n",
            "   [ 0.27843142]\n",
            "   [ 0.11372554]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.37254906]\n",
            "   [ 0.37254906]\n",
            "   [ 0.37254906]\n",
            "   ...\n",
            "   [ 0.37254906]\n",
            "   [ 0.3411765 ]\n",
            "   [ 0.3176471 ]]\n",
            "\n",
            "  [[ 0.35686278]\n",
            "   [ 0.34901965]\n",
            "   [ 0.35686278]\n",
            "   ...\n",
            "   [ 0.35686278]\n",
            "   [ 0.32549024]\n",
            "   [ 0.30196083]]\n",
            "\n",
            "  [[ 0.3411765 ]\n",
            "   [ 0.34901965]\n",
            "   [ 0.34901965]\n",
            "   ...\n",
            "   [ 0.3411765 ]\n",
            "   [ 0.3176471 ]\n",
            "   [ 0.2941177 ]]]\n",
            "\n",
            "\n",
            " [[[-0.41960782]\n",
            "   [-0.03529412]\n",
            "   [ 0.03529418]\n",
            "   ...\n",
            "   [-0.79607844]\n",
            "   [-0.7882353 ]\n",
            "   [-0.75686276]]\n",
            "\n",
            "  [[-0.35686272]\n",
            "   [-0.05098039]\n",
            "   [ 0.02745104]\n",
            "   ...\n",
            "   [-0.79607844]\n",
            "   [-0.8039216 ]\n",
            "   [-0.79607844]]\n",
            "\n",
            "  [[-0.26274508]\n",
            "   [-0.04313725]\n",
            "   [ 0.03529418]\n",
            "   ...\n",
            "   [-0.79607844]\n",
            "   [-0.8039216 ]\n",
            "   [-0.8039216 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.22352946]\n",
            "   [ 0.22352946]\n",
            "   [ 0.20784318]\n",
            "   ...\n",
            "   [-0.3960784 ]\n",
            "   [-0.5137255 ]\n",
            "   [-0.6156863 ]]\n",
            "\n",
            "  [[ 0.22352946]\n",
            "   [ 0.22352946]\n",
            "   [ 0.22352946]\n",
            "   ...\n",
            "   [-0.38039213]\n",
            "   [-0.5058824 ]\n",
            "   [-0.6156863 ]]\n",
            "\n",
            "  [[ 0.22352946]\n",
            "   [ 0.22352946]\n",
            "   [ 0.21568632]\n",
            "   ...\n",
            "   [-0.3960784 ]\n",
            "   [-0.5137255 ]\n",
            "   [-0.6       ]]]\n",
            "\n",
            "\n",
            " [[[-0.78039217]\n",
            "   [-0.81960785]\n",
            "   [-0.7254902 ]\n",
            "   ...\n",
            "   [-0.15294117]\n",
            "   [-0.1372549 ]\n",
            "   [-0.14509803]]\n",
            "\n",
            "  [[-0.81960785]\n",
            "   [-0.7254902 ]\n",
            "   [-0.5921569 ]\n",
            "   ...\n",
            "   [-0.12941176]\n",
            "   [-0.12941176]\n",
            "   [-0.14509803]]\n",
            "\n",
            "  [[-0.6862745 ]\n",
            "   [-0.62352943]\n",
            "   [-0.5372549 ]\n",
            "   ...\n",
            "   [-0.12156862]\n",
            "   [-0.14509803]\n",
            "   [-0.1372549 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.1372549 ]\n",
            "   [-0.04313725]\n",
            "   [ 0.03529418]\n",
            "   ...\n",
            "   [-0.21568626]\n",
            "   [-0.26274508]\n",
            "   [-0.01176471]]\n",
            "\n",
            "  [[-0.20784312]\n",
            "   [-0.06666666]\n",
            "   [ 0.03529418]\n",
            "   ...\n",
            "   [-0.41960782]\n",
            "   [-0.3490196 ]\n",
            "   [-0.03529412]]\n",
            "\n",
            "  [[-0.19215685]\n",
            "   [-0.12941176]\n",
            "   [ 0.01176476]\n",
            "   ...\n",
            "   [-0.44313723]\n",
            "   [-0.5294118 ]\n",
            "   [-0.14509803]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.0745098 ]\n",
            "   [-0.00392157]\n",
            "   [ 0.01176476]\n",
            "   ...\n",
            "   [ 0.16078436]\n",
            "   [ 0.12156868]\n",
            "   [ 0.10588241]]\n",
            "\n",
            "  [[-0.01176471]\n",
            "   [ 0.00392163]\n",
            "   [ 0.0196079 ]\n",
            "   ...\n",
            "   [ 0.16078436]\n",
            "   [ 0.16078436]\n",
            "   [ 0.18431377]]\n",
            "\n",
            "  [[-0.01176471]\n",
            "   [ 0.01176476]\n",
            "   [ 0.01176476]\n",
            "   ...\n",
            "   [ 0.19215691]\n",
            "   [ 0.2313726 ]\n",
            "   [ 0.23921573]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.6627451 ]\n",
            "   [-0.654902  ]\n",
            "   [-0.4823529 ]\n",
            "   ...\n",
            "   [ 0.96862745]\n",
            "   [ 0.94509804]\n",
            "   [ 0.94509804]]\n",
            "\n",
            "  [[-0.5764706 ]\n",
            "   [-0.6627451 ]\n",
            "   [-0.60784316]\n",
            "   ...\n",
            "   [ 0.9607843 ]\n",
            "   [ 0.9372549 ]\n",
            "   [ 0.8509804 ]]\n",
            "\n",
            "  [[-0.3490196 ]\n",
            "   [-0.6862745 ]\n",
            "   [-0.67058825]\n",
            "   ...\n",
            "   [ 0.94509804]\n",
            "   [ 0.8745098 ]\n",
            "   [ 0.7647059 ]]]\n",
            "\n",
            "\n",
            " [[[-0.79607844]\n",
            "   [-0.7882353 ]\n",
            "   [-0.78039217]\n",
            "   ...\n",
            "   [-0.6784314 ]\n",
            "   [-0.6392157 ]\n",
            "   [-0.64705884]]\n",
            "\n",
            "  [[-0.7882353 ]\n",
            "   [-0.78039217]\n",
            "   [-0.78039217]\n",
            "   ...\n",
            "   [-0.654902  ]\n",
            "   [-0.6       ]\n",
            "   [-0.6313726 ]]\n",
            "\n",
            "  [[-0.7882353 ]\n",
            "   [-0.7882353 ]\n",
            "   [-0.78039217]\n",
            "   ...\n",
            "   [-0.62352943]\n",
            "   [-0.6156863 ]\n",
            "   [-0.6313726 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.34117645]\n",
            "   [-0.41176468]\n",
            "   [-0.54509807]\n",
            "   ...\n",
            "   [-0.11372548]\n",
            "   [-0.4352941 ]\n",
            "   [-0.46666664]]\n",
            "\n",
            "  [[-0.38039213]\n",
            "   [-0.42745095]\n",
            "   [-0.5921569 ]\n",
            "   ...\n",
            "   [-0.2862745 ]\n",
            "   [-0.4823529 ]\n",
            "   [-0.5686275 ]]\n",
            "\n",
            "  [[-0.3960784 ]\n",
            "   [-0.42745095]\n",
            "   [-0.5921569 ]\n",
            "   ...\n",
            "   [-0.4352941 ]\n",
            "   [-0.41960782]\n",
            "   [-0.4588235 ]]]\n",
            "\n",
            "\n",
            " [[[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.92156863]\n",
            "   [-1.        ]\n",
            "   [-0.99215686]]\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-0.99215686]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.8666667 ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]]\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-0.9843137 ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.75686276]\n",
            "   [-1.        ]\n",
            "   [-0.99215686]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.6392157 ]\n",
            "   [-0.62352943]\n",
            "   [-0.6       ]\n",
            "   ...\n",
            "   [-0.7176471 ]\n",
            "   [-0.69411767]\n",
            "   [-0.7647059 ]]\n",
            "\n",
            "  [[-0.654902  ]\n",
            "   [-0.6392157 ]\n",
            "   [-0.6392157 ]\n",
            "   ...\n",
            "   [-0.7490196 ]\n",
            "   [-0.77254903]\n",
            "   [-0.81960785]]\n",
            "\n",
            "  [[-0.6784314 ]\n",
            "   [-0.6862745 ]\n",
            "   [-0.6862745 ]\n",
            "   ...\n",
            "   [-0.81960785]\n",
            "   [-0.81960785]\n",
            "   [-0.81960785]]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\\n\\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKvEv321Stt5",
        "outputId": "6fa512c8-fab5-4cd0-8ded-b97bef16d84b"
      },
      "source": [
        "print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validasi (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "test (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "train (28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH9Q-TegBR26"
      },
      "source": [
        "#hyperparameter and callback\n",
        "batch_size = 128\n",
        "num_epochs = 120\n",
        "input_shape = (48, 48, 1)\n",
        "num_classes = 7\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGsscQRJBR-h"
      },
      "source": [
        "#Compile the model.\n",
        "\n",
        "\n",
        "from keras.optimizers import Adam, SGD\n",
        "model = ResNet50ori(input_shape = (48, 48, 1), classes = 7)\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "model.compile(optimizer= optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rodttDWeT2yP"
      },
      "source": [
        "#kita mau save model callbackshuhuhuhuhhg\n",
        "\"\"\"import os\n",
        "try:\n",
        "  os.mkdir('scratchcheckpoint')\n",
        "except:\n",
        "  pass\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV29sTjET28U"
      },
      "source": [
        "\"\"\"file_name = 'Best_Model_resnet50Scracth_sena1.h5'\n",
        "\n",
        "checkpoint_path = os.path.join('checkpoint',file_name)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_S6wUaPT3Jx"
      },
      "source": [
        "\"\"\"call_back = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
        "                                               monitor='val_accuracy',\n",
        "                                               verbose=1,\n",
        "                                               save_freq='epoch',\n",
        "                                               save_best_only=True,\n",
        "                                               save_weights_only=False,\n",
        "                                               mode='max')\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy53DHMGB-Mr",
        "outputId": "d2a65a90-540b-47f8-eb34-ec692568c27d"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50ori\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2D)  (None, 54, 54, 1)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 24, 24, 64)   3200        zero_padding2d[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 24, 24, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 24, 24, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 11, 11, 64)   0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 11, 11, 64)   4160        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 11, 11, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 11, 11, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 11, 11, 256)  16640       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 11, 11, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 11, 11, 256)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 11, 11, 256)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 11, 11, 64)   16448       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 11, 11, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 11, 11, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 11, 11, 256)  0           activation_3[0][0]               \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 11, 11, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 11, 11, 64)   16448       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 11, 11, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 11, 11, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 11, 11, 256)  0           activation_6[0][0]               \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 11, 11, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 6, 6, 128)    32896       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 6, 6, 128)    0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 6, 6, 128)    0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 6, 6, 512)    131584      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 6, 6, 512)    2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 6, 6, 512)    0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 6, 6, 512)    0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 6, 6, 128)    0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 6, 6, 128)    0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 6, 6, 512)    0           activation_12[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 6, 6, 512)    0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 6, 6, 128)    0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 6, 6, 128)    0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 6, 6, 512)    0           activation_15[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 6, 6, 512)    0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 6, 6, 128)    0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 6, 6, 128)    0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 6, 6, 512)    0           activation_18[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 6, 6, 512)    0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 3, 3, 256)    131328      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 3, 3, 256)    0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 3, 3, 256)    0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 3, 3, 1024)   525312      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 3, 3, 1024)   4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 3, 3, 1024)   0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 3, 3, 1024)   0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 3, 3, 256)    0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 3, 3, 256)    0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 3, 3, 1024)   0           activation_24[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 3, 3, 1024)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 3, 3, 256)    0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 3, 3, 256)    0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 3, 3, 1024)   0           activation_27[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 3, 3, 1024)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 3, 3, 256)    0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 3, 3, 256)    0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 3, 3, 1024)   0           activation_30[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 3, 3, 1024)   0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 3, 3, 256)    0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 3, 3, 256)    0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 3, 3, 1024)   0           activation_33[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 3, 3, 1024)   0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 3, 3, 256)    0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 3, 3, 256)    0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 3, 3, 1024)   0           activation_36[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 3, 3, 1024)   0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 2, 2, 512)    524800      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 2, 2, 2048)   2099200     activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 2, 2, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 2, 2, 2048)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 2, 2, 2048)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 2, 2, 2048)   0           activation_42[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 2, 2, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 2, 2, 2048)   0           activation_45[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 2, 2, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 2048)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            14343       flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,595,783\n",
            "Trainable params: 23,542,663\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgxCecVwCGEr"
      },
      "source": [
        "\"\"\"history = model.fit(data_generator.flow(xtrain, ytrain,),\n",
        "                        steps_per_epoch=len(xtrain) / batch_size,\n",
        "                        epochs=num_epochs, verbose=1,callbacks=call_back,\n",
        "                        validation_data= (xtest,ytest))\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2muXWns0sJSH",
        "outputId": "e10b2e19-1608-4e48-e449-6d32d62f8c0b"
      },
      "source": [
        "history = model.fit(\n",
        "    data_generator.flow(xtrain, ytrain,),\n",
        "    steps_per_epoch=len(xtrain) / batch_size,\n",
        "    epochs=num_epochs, \n",
        "    verbose=1,\n",
        "    validation_data= (x_val,y_val))\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/120\n",
            "224/224 [==============================] - 94s 153ms/step - loss: 5.8654 - accuracy: 0.1946 - val_loss: 1.8736 - val_accuracy: 0.2307\n",
            "Epoch 2/120\n",
            "224/224 [==============================] - 29s 129ms/step - loss: 1.9278 - accuracy: 0.2460 - val_loss: 1.9070 - val_accuracy: 0.2435\n",
            "Epoch 3/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.8093 - accuracy: 0.2411 - val_loss: 1.8356 - val_accuracy: 0.2399\n",
            "Epoch 4/120\n",
            "224/224 [==============================] - 31s 140ms/step - loss: 1.7918 - accuracy: 0.2577 - val_loss: 1.8081 - val_accuracy: 0.2379\n",
            "Epoch 5/120\n",
            "224/224 [==============================] - 29s 129ms/step - loss: 1.8027 - accuracy: 0.2376 - val_loss: 1.8321 - val_accuracy: 0.2416\n",
            "Epoch 6/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.7989 - accuracy: 0.2506 - val_loss: 1.7827 - val_accuracy: 0.2524\n",
            "Epoch 7/120\n",
            "224/224 [==============================] - 29s 129ms/step - loss: 1.7893 - accuracy: 0.2532 - val_loss: 1.7917 - val_accuracy: 0.2510\n",
            "Epoch 8/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.7821 - accuracy: 0.2605 - val_loss: 1.7927 - val_accuracy: 0.2502\n",
            "Epoch 9/120\n",
            "224/224 [==============================] - 31s 138ms/step - loss: 1.7715 - accuracy: 0.2808 - val_loss: 1.7543 - val_accuracy: 0.2848\n",
            "Epoch 10/120\n",
            "224/224 [==============================] - 29s 129ms/step - loss: 1.7601 - accuracy: 0.2767 - val_loss: 1.8443 - val_accuracy: 0.2756\n",
            "Epoch 11/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.7601 - accuracy: 0.2708 - val_loss: 1.7094 - val_accuracy: 0.2914\n",
            "Epoch 12/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.7383 - accuracy: 0.2952 - val_loss: 1.8090 - val_accuracy: 0.3029\n",
            "Epoch 13/120\n",
            "224/224 [==============================] - 29s 129ms/step - loss: 1.7227 - accuracy: 0.2972 - val_loss: 1.7032 - val_accuracy: 0.3059\n",
            "Epoch 14/120\n",
            "224/224 [==============================] - 29s 129ms/step - loss: 1.7223 - accuracy: 0.2911 - val_loss: 1.6962 - val_accuracy: 0.2987\n",
            "Epoch 15/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.7192 - accuracy: 0.2980 - val_loss: 1.6780 - val_accuracy: 0.3182\n",
            "Epoch 16/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.7166 - accuracy: 0.2994 - val_loss: 1.6691 - val_accuracy: 0.3299\n",
            "Epoch 17/120\n",
            "224/224 [==============================] - 29s 129ms/step - loss: 1.6933 - accuracy: 0.3160 - val_loss: 1.7503 - val_accuracy: 0.2953\n",
            "Epoch 18/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.6614 - accuracy: 0.3354 - val_loss: 1.7220 - val_accuracy: 0.3112\n",
            "Epoch 19/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.6298 - accuracy: 0.3517 - val_loss: 1.6552 - val_accuracy: 0.3483\n",
            "Epoch 20/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.6163 - accuracy: 0.3647 - val_loss: 1.6270 - val_accuracy: 0.3497\n",
            "Epoch 21/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.6612 - accuracy: 0.3337 - val_loss: 20.3604 - val_accuracy: 0.2003\n",
            "Epoch 22/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.7545 - accuracy: 0.2873 - val_loss: 1.8245 - val_accuracy: 0.2708\n",
            "Epoch 23/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.7009 - accuracy: 0.3078 - val_loss: 1.8718 - val_accuracy: 0.2795\n",
            "Epoch 24/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.6724 - accuracy: 0.3260 - val_loss: 1.7125 - val_accuracy: 0.3048\n",
            "Epoch 25/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.6230 - accuracy: 0.3565 - val_loss: 4.8221 - val_accuracy: 0.3413\n",
            "Epoch 26/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.6157 - accuracy: 0.3604 - val_loss: 1.7656 - val_accuracy: 0.3199\n",
            "Epoch 27/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.5729 - accuracy: 0.3868 - val_loss: 2.8280 - val_accuracy: 0.2823\n",
            "Epoch 28/120\n",
            "224/224 [==============================] - 30s 131ms/step - loss: 1.5490 - accuracy: 0.3932 - val_loss: 1.7175 - val_accuracy: 0.3672\n",
            "Epoch 29/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.5479 - accuracy: 0.3947 - val_loss: 1.5488 - val_accuracy: 0.3856\n",
            "Epoch 30/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.5049 - accuracy: 0.4205 - val_loss: 1.5925 - val_accuracy: 0.3904\n",
            "Epoch 31/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.4766 - accuracy: 0.4368 - val_loss: 1.4490 - val_accuracy: 0.4408\n",
            "Epoch 32/120\n",
            "224/224 [==============================] - 31s 140ms/step - loss: 1.4712 - accuracy: 0.4289 - val_loss: 1.8425 - val_accuracy: 0.3608\n",
            "Epoch 33/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.4620 - accuracy: 0.4310 - val_loss: 1.6216 - val_accuracy: 0.4040\n",
            "Epoch 34/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.4474 - accuracy: 0.4599 - val_loss: 1.3981 - val_accuracy: 0.4687\n",
            "Epoch 35/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.4325 - accuracy: 0.4465 - val_loss: 1.5387 - val_accuracy: 0.3909\n",
            "Epoch 36/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.4132 - accuracy: 0.4580 - val_loss: 1.5123 - val_accuracy: 0.4210\n",
            "Epoch 37/120\n",
            "224/224 [==============================] - 30s 131ms/step - loss: 1.4191 - accuracy: 0.4476 - val_loss: 1.4156 - val_accuracy: 0.4687\n",
            "Epoch 38/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.3973 - accuracy: 0.4607 - val_loss: 12.7229 - val_accuracy: 0.3330\n",
            "Epoch 39/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.3961 - accuracy: 0.4666 - val_loss: 1.9504 - val_accuracy: 0.4316\n",
            "Epoch 40/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.3966 - accuracy: 0.4675 - val_loss: 1.5552 - val_accuracy: 0.4004\n",
            "Epoch 41/120\n",
            "224/224 [==============================] - 30s 131ms/step - loss: 1.3724 - accuracy: 0.4769 - val_loss: 1.4804 - val_accuracy: 0.4335\n",
            "Epoch 42/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.3497 - accuracy: 0.4879 - val_loss: 1.5256 - val_accuracy: 0.4461\n",
            "Epoch 43/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.3628 - accuracy: 0.4763 - val_loss: 1.7175 - val_accuracy: 0.3748\n",
            "Epoch 44/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.4490 - accuracy: 0.4495 - val_loss: 3.3475 - val_accuracy: 0.3569\n",
            "Epoch 45/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.3735 - accuracy: 0.4727 - val_loss: 1.3151 - val_accuracy: 0.4965\n",
            "Epoch 46/120\n",
            "224/224 [==============================] - 30s 131ms/step - loss: 1.3508 - accuracy: 0.4903 - val_loss: 1.3977 - val_accuracy: 0.4714\n",
            "Epoch 47/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.3453 - accuracy: 0.4786 - val_loss: 1.4329 - val_accuracy: 0.4483\n",
            "Epoch 48/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.3240 - accuracy: 0.4940 - val_loss: 1.4475 - val_accuracy: 0.4422\n",
            "Epoch 49/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.3326 - accuracy: 0.4873 - val_loss: 1.3752 - val_accuracy: 0.4784\n",
            "Epoch 50/120\n",
            "224/224 [==============================] - 32s 140ms/step - loss: 1.2853 - accuracy: 0.5057 - val_loss: 1.3629 - val_accuracy: 0.4820\n",
            "Epoch 51/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.3066 - accuracy: 0.4982 - val_loss: 1.3698 - val_accuracy: 0.4845\n",
            "Epoch 52/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.3167 - accuracy: 0.4947 - val_loss: 2.1607 - val_accuracy: 0.4581\n",
            "Epoch 53/120\n",
            "224/224 [==============================] - 32s 141ms/step - loss: 1.2862 - accuracy: 0.5040 - val_loss: 2.4495 - val_accuracy: 0.3931\n",
            "Epoch 54/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.3003 - accuracy: 0.5002 - val_loss: 1.3811 - val_accuracy: 0.4664\n",
            "Epoch 55/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.2598 - accuracy: 0.5231 - val_loss: 1.3185 - val_accuracy: 0.5152\n",
            "Epoch 56/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.3036 - accuracy: 0.4984 - val_loss: 1.5792 - val_accuracy: 0.3795\n",
            "Epoch 57/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.2787 - accuracy: 0.5127 - val_loss: 1.3578 - val_accuracy: 0.4854\n",
            "Epoch 58/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.2612 - accuracy: 0.5275 - val_loss: 1.2964 - val_accuracy: 0.5021\n",
            "Epoch 59/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.2567 - accuracy: 0.5209 - val_loss: 1.3184 - val_accuracy: 0.5043\n",
            "Epoch 60/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.2640 - accuracy: 0.5274 - val_loss: 1.2878 - val_accuracy: 0.5043\n",
            "Epoch 61/120\n",
            "224/224 [==============================] - 30s 131ms/step - loss: 1.2583 - accuracy: 0.5256 - val_loss: 1.3220 - val_accuracy: 0.5079\n",
            "Epoch 62/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.2260 - accuracy: 0.5302 - val_loss: 1.3241 - val_accuracy: 0.5082\n",
            "Epoch 63/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.2332 - accuracy: 0.5330 - val_loss: 1.2496 - val_accuracy: 0.5208\n",
            "Epoch 64/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.2406 - accuracy: 0.5247 - val_loss: 1.2189 - val_accuracy: 0.5300\n",
            "Epoch 65/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.2230 - accuracy: 0.5449 - val_loss: 1.2611 - val_accuracy: 0.5249\n",
            "Epoch 66/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.2213 - accuracy: 0.5505 - val_loss: 1.3418 - val_accuracy: 0.4859\n",
            "Epoch 67/120\n",
            "224/224 [==============================] - 30s 131ms/step - loss: 1.2038 - accuracy: 0.5570 - val_loss: 1.2986 - val_accuracy: 0.4971\n",
            "Epoch 68/120\n",
            "224/224 [==============================] - 31s 140ms/step - loss: 1.2325 - accuracy: 0.5299 - val_loss: 1.2673 - val_accuracy: 0.5163\n",
            "Epoch 69/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.2094 - accuracy: 0.5461 - val_loss: 1.3064 - val_accuracy: 0.4848\n",
            "Epoch 70/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.2110 - accuracy: 0.5481 - val_loss: 1.2668 - val_accuracy: 0.5283\n",
            "Epoch 71/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.2059 - accuracy: 0.5342 - val_loss: 1.2386 - val_accuracy: 0.5238\n",
            "Epoch 72/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.1867 - accuracy: 0.5540 - val_loss: 1.2831 - val_accuracy: 0.5500\n",
            "Epoch 73/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.2129 - accuracy: 0.5487 - val_loss: 1.2006 - val_accuracy: 0.5389\n",
            "Epoch 74/120\n",
            "224/224 [==============================] - 30s 131ms/step - loss: 1.1889 - accuracy: 0.5484 - val_loss: 1.2341 - val_accuracy: 0.5244\n",
            "Epoch 75/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.1887 - accuracy: 0.5617 - val_loss: 1.3556 - val_accuracy: 0.4946\n",
            "Epoch 76/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.2212 - accuracy: 0.5459 - val_loss: 1.7269 - val_accuracy: 0.4528\n",
            "Epoch 77/120\n",
            "224/224 [==============================] - 31s 140ms/step - loss: 1.1812 - accuracy: 0.5569 - val_loss: 1.2209 - val_accuracy: 0.5347\n",
            "Epoch 78/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.1726 - accuracy: 0.5601 - val_loss: 1.2474 - val_accuracy: 0.5497\n",
            "Epoch 79/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.1480 - accuracy: 0.5697 - val_loss: 1.1745 - val_accuracy: 0.5492\n",
            "Epoch 80/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.1465 - accuracy: 0.5729 - val_loss: 1.1742 - val_accuracy: 0.5584\n",
            "Epoch 81/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.1341 - accuracy: 0.5733 - val_loss: 1.1526 - val_accuracy: 0.5653\n",
            "Epoch 82/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.1366 - accuracy: 0.5728 - val_loss: 1.2071 - val_accuracy: 0.5614\n",
            "Epoch 83/120\n",
            "224/224 [==============================] - 32s 141ms/step - loss: 1.1538 - accuracy: 0.5645 - val_loss: 1.3439 - val_accuracy: 0.4951\n",
            "Epoch 84/120\n",
            "224/224 [==============================] - 30s 131ms/step - loss: 1.2662 - accuracy: 0.5225 - val_loss: 1.2161 - val_accuracy: 0.5400\n",
            "Epoch 85/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.1495 - accuracy: 0.5627 - val_loss: 1.1644 - val_accuracy: 0.5642\n",
            "Epoch 86/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.2140 - accuracy: 0.5502 - val_loss: 1.2254 - val_accuracy: 0.5341\n",
            "Epoch 87/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.1711 - accuracy: 0.5575 - val_loss: 1.1995 - val_accuracy: 0.5511\n",
            "Epoch 88/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.1220 - accuracy: 0.5739 - val_loss: 1.1981 - val_accuracy: 0.5520\n",
            "Epoch 89/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.1477 - accuracy: 0.5699 - val_loss: 1.4026 - val_accuracy: 0.5046\n",
            "Epoch 90/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.1536 - accuracy: 0.5621 - val_loss: 1.2121 - val_accuracy: 0.5372\n",
            "Epoch 91/120\n",
            "224/224 [==============================] - 32s 141ms/step - loss: 1.1304 - accuracy: 0.5812 - val_loss: 1.4018 - val_accuracy: 0.5400\n",
            "Epoch 92/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.1394 - accuracy: 0.5765 - val_loss: 1.2103 - val_accuracy: 0.5414\n",
            "Epoch 93/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.1529 - accuracy: 0.5625 - val_loss: 1.2639 - val_accuracy: 0.5272\n",
            "Epoch 94/120\n",
            "224/224 [==============================] - 30s 133ms/step - loss: 1.1539 - accuracy: 0.5752 - val_loss: 1.2652 - val_accuracy: 0.5347\n",
            "Epoch 95/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.1799 - accuracy: 0.5550 - val_loss: 1.2692 - val_accuracy: 0.5252\n",
            "Epoch 96/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.2201 - accuracy: 0.5479 - val_loss: 1.2444 - val_accuracy: 0.5361\n",
            "Epoch 97/120\n",
            "224/224 [==============================] - 29s 132ms/step - loss: 1.2092 - accuracy: 0.5507 - val_loss: 1.2832 - val_accuracy: 0.5166\n",
            "Epoch 98/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.1557 - accuracy: 0.5650 - val_loss: 1.1874 - val_accuracy: 0.5522\n",
            "Epoch 99/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.1703 - accuracy: 0.5612 - val_loss: 1.3849 - val_accuracy: 0.4859\n",
            "Epoch 100/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.2359 - accuracy: 0.5339 - val_loss: 1.1851 - val_accuracy: 0.5467\n",
            "Epoch 101/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.1641 - accuracy: 0.5659 - val_loss: 1.2120 - val_accuracy: 0.5428\n",
            "Epoch 102/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.1269 - accuracy: 0.5655 - val_loss: 1.1640 - val_accuracy: 0.5531\n",
            "Epoch 103/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.1063 - accuracy: 0.5844 - val_loss: 1.3897 - val_accuracy: 0.5626\n",
            "Epoch 104/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.1173 - accuracy: 0.5771 - val_loss: 1.1306 - val_accuracy: 0.5748\n",
            "Epoch 105/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.0996 - accuracy: 0.5813 - val_loss: 1.2816 - val_accuracy: 0.5185\n",
            "Epoch 106/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.0949 - accuracy: 0.5828 - val_loss: 1.1797 - val_accuracy: 0.5559\n",
            "Epoch 107/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.1140 - accuracy: 0.5880 - val_loss: 1.1490 - val_accuracy: 0.5631\n",
            "Epoch 108/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.1019 - accuracy: 0.5819 - val_loss: 1.0921 - val_accuracy: 0.5854\n",
            "Epoch 109/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.0642 - accuracy: 0.6016 - val_loss: 1.2993 - val_accuracy: 0.5121\n",
            "Epoch 110/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.1011 - accuracy: 0.5809 - val_loss: 1.1771 - val_accuracy: 0.5642\n",
            "Epoch 111/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.1599 - accuracy: 0.5649 - val_loss: 1.2347 - val_accuracy: 0.5391\n",
            "Epoch 112/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.1357 - accuracy: 0.5691 - val_loss: 1.3659 - val_accuracy: 0.5146\n",
            "Epoch 113/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.2366 - accuracy: 0.5502 - val_loss: 1.3344 - val_accuracy: 0.5183\n",
            "Epoch 114/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.1739 - accuracy: 0.5533 - val_loss: 1.1716 - val_accuracy: 0.5614\n",
            "Epoch 115/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.1166 - accuracy: 0.5730 - val_loss: 1.1440 - val_accuracy: 0.5832\n",
            "Epoch 116/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.0988 - accuracy: 0.5832 - val_loss: 1.1717 - val_accuracy: 0.5531\n",
            "Epoch 117/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.0729 - accuracy: 0.5920 - val_loss: 1.1857 - val_accuracy: 0.5486\n",
            "Epoch 118/120\n",
            "224/224 [==============================] - 30s 131ms/step - loss: 1.0724 - accuracy: 0.5943 - val_loss: 1.1137 - val_accuracy: 0.5896\n",
            "Epoch 119/120\n",
            "224/224 [==============================] - 29s 132ms/step - loss: 1.0807 - accuracy: 0.5978 - val_loss: 1.1703 - val_accuracy: 0.5651\n",
            "Epoch 120/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.0792 - accuracy: 0.5982 - val_loss: 1.1715 - val_accuracy: 0.5556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "GaXUP-8fDWRN",
        "outputId": "1d6505c0-fbba-4fa6-b465-285e30cea1a8"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "model.save('/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50oriAdamst120epochBS128_aug1.h5')\n",
        "\n",
        "#gffhgffkjkjdskjjkjkjkjhjhnnnhjhhu\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "num_epochs = range(len(accuracy))\n",
        "plt.plot(num_epochs, accuracy, 'r', label='Training acc')\n",
        "plt.plot(num_epochs, val_accuracy, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(num_epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(num_epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_LxatO5J-pp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "478f6f62-7887-489a-a691-bd6fe6a670b4"
      },
      "source": [
        "testloss = model.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "trainloss = model.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(trainloss[0]))\n",
        "print(\"Train Acc: \" + str(trainloss[1]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 4s 32ms/step - loss: 1.1696 - accuracy: 0.5631\n",
            "Test Loss 1.1695594787597656\n",
            "Test Acc: 0.5631095170974731\n",
            "898/898 [==============================] - 27s 30ms/step - loss: 1.0769 - accuracy: 0.5939\n",
            "Train Loss 1.0768654346466064\n",
            "Train Acc: 0.5938555598258972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swoRERVdKQ1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3befe909-e6cd-4d04-99af-6e55fbe09f60"
      },
      "source": [
        "testlosz = model.evaluate(x_val, y_val) \n",
        "print(\"val Loss \" + str(testlosz[0]))\n",
        "print(\"val Acc: \" + str(testlosz[1]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 4s 31ms/step - loss: 1.1715 - accuracy: 0.5556\n",
            "val Loss 1.1714953184127808\n",
            "val Acc: 0.5555865168571472\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5iaZIU6pPzk",
        "outputId": "8cf80502-8375-4d97-9883-3228c378057d"
      },
      "source": [
        "from keras.models import load_model\n",
        "model_load = load_model('/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50oriAdamst120epochBS128_aug1.h5')\n",
        "\n",
        "model_load.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50ori\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2D)  (None, 54, 54, 1)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 24, 24, 64)   3200        zero_padding2d[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 24, 24, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 24, 24, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 11, 11, 64)   0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 11, 11, 64)   4160        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 11, 11, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 11, 11, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 11, 11, 256)  16640       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 11, 11, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 11, 11, 256)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 11, 11, 256)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 11, 11, 64)   16448       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 11, 11, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 11, 11, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 11, 11, 256)  0           activation_3[0][0]               \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 11, 11, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 11, 11, 64)   16448       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 11, 11, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 11, 11, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 11, 11, 256)  0           activation_6[0][0]               \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 11, 11, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 6, 6, 128)    32896       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 6, 6, 128)    0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 6, 6, 128)    0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 6, 6, 512)    131584      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 6, 6, 512)    2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 6, 6, 512)    0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 6, 6, 512)    0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 6, 6, 128)    0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 6, 6, 128)    0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 6, 6, 512)    0           activation_12[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 6, 6, 512)    0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 6, 6, 128)    0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 6, 6, 128)    0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 6, 6, 512)    0           activation_15[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 6, 6, 512)    0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 6, 6, 128)    0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 6, 6, 128)    0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 6, 6, 512)    0           activation_18[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 6, 6, 512)    0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 3, 3, 256)    131328      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 3, 3, 256)    0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 3, 3, 256)    0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 3, 3, 1024)   525312      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 3, 3, 1024)   4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 3, 3, 1024)   0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 3, 3, 1024)   0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 3, 3, 256)    0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 3, 3, 256)    0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 3, 3, 1024)   0           activation_24[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 3, 3, 1024)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 3, 3, 256)    0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 3, 3, 256)    0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 3, 3, 1024)   0           activation_27[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 3, 3, 1024)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 3, 3, 256)    0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 3, 3, 256)    0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 3, 3, 1024)   0           activation_30[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 3, 3, 1024)   0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 3, 3, 256)    0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 3, 3, 256)    0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 3, 3, 1024)   0           activation_33[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 3, 3, 1024)   0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 3, 3, 256)    0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 3, 3, 256)    0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 3, 3, 1024)   0           activation_36[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 3, 3, 1024)   0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 2, 2, 512)    524800      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 2, 2, 2048)   2099200     activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 2, 2, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 2, 2, 2048)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 2, 2, 2048)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 2, 2, 2048)   0           activation_42[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 2, 2, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 2, 2, 2048)   0           activation_45[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 2, 2, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 2048)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            14343       flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,595,783\n",
            "Trainable params: 23,542,663\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypc8clklx2p8",
        "outputId": "dfea08ec-f8bb-4236-a87a-a93227245857"
      },
      "source": [
        "#loss,acc = model_load.evaluate(xtrain,ytrain)\n",
        "\"\"\"print(\"loss:\",loss)\n",
        "print(\"acc:\",acc)kjjkj\"\"\"\n",
        "\n",
        "\n",
        "testloss = model_load.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "\n",
        "testloss = model_load.evaluate(xtrain, ytrain) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 8s 31ms/step - loss: 1.1696 - accuracy: 0.5631\n",
            "Test Loss 1.1695594787597656\n",
            "Test Acc: 0.5631095170974731\n",
            "898/898 [==============================] - 27s 30ms/step - loss: 1.0769 - accuracy: 0.5939\n",
            "Test Loss 1.0768654346466064\n",
            "Test Acc: 0.5938555598258972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7mSww_U2O_q",
        "outputId": "e6403215-5a86-4d73-8de2-edc858376b10"
      },
      "source": [
        "testlosz = model_load.evaluate(x_val, y_val) \n",
        "print(\"Test Loss \" + str(testlosz[0]))\n",
        "print(\"Test Acc: \" + str(testlosz[1]))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 4s 31ms/step - loss: 1.1715 - accuracy: 0.5556\n",
            "Test Loss 1.1714953184127808\n",
            "Test Acc: 0.5555865168571472\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdU7uU3PYCnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e848c894-33fc-4259-9cfb-b0e02f3eaabb"
      },
      "source": [
        "print (x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3589, 48, 48, 1)\n",
            "(3589,)\n",
            "(3589, 48, 48, 1)\n",
            "(3589,)\n",
            "(28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_Tf1qg8TKnx",
        "outputId": "9da6ebe9-d437-43b5-ded2-dbab09e34e8c"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "#y_pred = model_load.predict(xtest)\n",
        "\n",
        "test_prob = model_load.predict(xtest)\n",
        "test_pred = np.argmax(test_prob, axis=1)\n",
        "test_accuracy = np.mean(test_pred == ytest)\n",
        "\n",
        "print(test_accuracy)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5631095012538312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpwJv9V54_1M"
      },
      "source": [
        "\n",
        "emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "KMe4WL0T5BcJ",
        "outputId": "7677bfcc-a777-479b-98d0-ebb6e2e439cc"
      },
      "source": [
        "conf_mat = confusion_matrix(ytest, test_pred)\n",
        "\n",
        "pd.DataFrame(conf_mat, columns=emotions.values(), index=emotions.values())\n",
        "\n",
        "\n",
        "\n",
        "fig, ax = plot_confusion_matrix(conf_mat=conf_mat,show_normed=True,show_absolute=False,figsize=(8, 8))\n",
        "fig.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW3FZjp-5DgF",
        "outputId": "bd609e06-b605-4a3a-a6c3-f5676dc68369"
      },
      "source": [
        "print(classification_report(ytest, test_pred, target_names=emotions.values()))\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry       0.52      0.52      0.52       487\n",
            "     Disgust       0.60      0.04      0.08        67\n",
            "        Fear       0.36      0.38      0.37       508\n",
            "       Happy       0.84      0.78      0.81       897\n",
            "         Sad       0.40      0.63      0.49       624\n",
            "    Surprise       0.83      0.52      0.64       416\n",
            "     Neutral       0.52      0.43      0.47       590\n",
            "\n",
            "    accuracy                           0.56      3589\n",
            "   macro avg       0.58      0.47      0.48      3589\n",
            "weighted avg       0.60      0.56      0.57      3589\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}