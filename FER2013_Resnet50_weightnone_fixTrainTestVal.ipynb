{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER2013_Resnet50_weightnone_fixTrainTestVal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-Qn1jsBTIBl0b7myLQxqa8WjCcfbamqM",
      "authorship_tag": "ABX9TyNUwF7V9tEvT4zfAgu55TzR"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b86nukQOxN7l"
      },
      "source": [
        "Resnet-50 From Scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p8gxtGy0TWP",
        "outputId": "4e0beae2-cc9c-4611-f040-8fb657db20f6"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "inputFolder = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth' \n",
        "for root, directories, filenames in os.walk(inputFolder): \n",
        "    for filename in filenames: print(os.path.join(root,filename))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Best_Model_resnet50Scracth1again.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe4.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth1again.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50ScracthSGD1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50AUGScracthadam3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD1try2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD4.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50oriSGD1st.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50SGD5stori.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editSGD5st.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editAdamst120epochBS128.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50oriScracth_sena2.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsiscWIMBDX2",
        "outputId": "abff8cc9-0a07-4108-e993-f8ba9201beb4"
      },
      "source": [
        "%cd /content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "wLMSe510xNCJ",
        "outputId": "3da9f6f5-cb75-4f61-d978-1e7de9a074fc"
      },
      "source": [
        "#Create a directory to save our generated models.dasdas\n",
        "\n",
        "#os.mkdir(\"./modelscracth\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-cf55f19f3613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#os.mkdir(\"./modelscracth\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ls' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_kluusLxM1B",
        "outputId": "99532e1b-1620-4f9f-9920-f4a6d96cea5e"
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:400: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfUSF_tAxNMP"
      },
      "source": [
        "#Define the identity block helper function.\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "   \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VdYtzhn1F0I"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path \n",
        "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b',padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd-O8ZMx1GAW"
      },
      "source": [
        "def ResNet50(input_shape = (48,48,1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    #X = ZeroPadding2D((1, 1))(X_input)\n",
        "    X = X_input\n",
        "    # Stage 1\n",
        "\n",
        "    X = Conv2D(8, (3, 3), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # removed maxpool\n",
        "    #X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='c')\n",
        "\n",
        "\n",
        "    # Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [64,64,256], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL . \n",
        "    X = AveragePooling2D((2,2), name='avg_pool')(X)\n",
        "    \n",
        "    # output layerds\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(512, activation = 'relu', name='fc1024' , kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GKsSwtp-GuL"
      },
      "source": [
        "\"\"\"def ResNet50ori(input_shape = (48, 48, 1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns: dsdsf\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50ori')\n",
        "\n",
        "    return model\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3oWTDXlyBHM2",
        "outputId": "bce5d74e-9049-4873-fa4a-5692f8b2d5b2"
      },
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        " \n",
        "dataset_path = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv'\n",
        "image_size=(48,48)\n",
        "#batch_size = 64\n",
        "\n",
        "def load_fer2013():\n",
        "    data = pd.read_csv(dataset_path)\n",
        "    data = (data[data['pixels'].notnull()])\n",
        "    pixels = data['pixels'].tolist()\n",
        "    width, height = 48, 48\n",
        "    faces = []\n",
        "    for pixel_sequence in pixels:\n",
        "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "        face = np.asarray(face).reshape(width, height)\n",
        "        face = cv2.resize(face.astype('uint8'),image_size)\n",
        "        faces.append(face.astype('float32'))\n",
        "    faces = np.asarray(faces)\n",
        "    faces = np.expand_dims(faces, -1)\n",
        "    emotions = (data['emotion'])#.values\n",
        "    return faces, emotions\n",
        " \n",
        "def preprocess_input(x, v2=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if v2:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x\n",
        " \n",
        "faces, emotions = load_fer2013()\n",
        "faces = preprocess_input(faces)\n",
        "#xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
        "#Data Augumentation\n",
        "data_generator = ImageDataGenerator(\n",
        "                        rotation_range=10,\n",
        "                        shear_range = 10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True,\n",
        "                        vertical_flip=True)\n",
        "\"\"\"data_generator = ImageDataGenerator( )\n",
        "\"\"\""
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'data_generator = ImageDataGenerator( )\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWLhavr-rSF5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "895f7f85-9930-46ca-c552-cbb571846a4e"
      },
      "source": [
        "\"\"\"\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.1,)\n",
        "x_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1,)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nxtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.1,)\\nx_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1,)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "RGhnYFXgaqL9",
        "outputId": "0e60da2f-3a44-4d06-910b-2e0f2fa4191a"
      },
      "source": [
        "\"\"\"print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (y_train.shape)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'print (\"validasi\",x_val.shape)\\nprint (y_val.shape)\\nprint (\"test\",xtest.shape)\\nprint (ytest.shape)\\nprint (\"train\",xtrain.shape)\\nprint (y_train.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rDS3hqhDSteM",
        "outputId": "00335427-50b3-4d50-a72e-ebde9875f019"
      },
      "source": [
        "train_ratio = 0.80\n",
        "validation_ratio = 0.10\n",
        "test_ratio = 0.10\n",
        "\n",
        "# train is now 75% of the entire data set\n",
        "# the _junk suffix means that we drop that variable completely # the _junk suffix means that we drop that variable completely\n",
        "#x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=1 - train_ratio)\n",
        "\n",
        "# test is now 10% of the initial data set\n",
        "# validation is now 15% of the initial data set\n",
        "#x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "x_val, xtest, y_val, ytest = train_test_split(xtest, ytest, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "\n",
        "print(xtrain, x_val, xtest)\n",
        "\n",
        "\"\"\"X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2\"\"\""
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[-0.8039216 ]\n",
            "   [-0.7882353 ]\n",
            "   [-0.64705884]\n",
            "   ...\n",
            "   [-0.9372549 ]\n",
            "   [-0.9529412 ]\n",
            "   [-0.8509804 ]]\n",
            "\n",
            "  [[-0.77254903]\n",
            "   [-0.62352943]\n",
            "   [-0.5764706 ]\n",
            "   ...\n",
            "   [-0.92156863]\n",
            "   [-0.9764706 ]\n",
            "   [-0.88235295]]\n",
            "\n",
            "  [[-0.6784314 ]\n",
            "   [-0.45098037]\n",
            "   [-0.41176468]\n",
            "   ...\n",
            "   [-0.9137255 ]\n",
            "   [-0.9764706 ]\n",
            "   [-0.8901961 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.2235294 ]\n",
            "   [-0.2235294 ]\n",
            "   [-0.09803921]\n",
            "   ...\n",
            "   [-0.2235294 ]\n",
            "   [-0.17647058]\n",
            "   [-0.16862744]]\n",
            "\n",
            "  [[-0.18431371]\n",
            "   [-0.17647058]\n",
            "   [-0.17647058]\n",
            "   ...\n",
            "   [-0.20784312]\n",
            "   [-0.17647058]\n",
            "   [-0.20784312]]\n",
            "\n",
            "  [[-0.16862744]\n",
            "   [-0.21568626]\n",
            "   [-0.32549018]\n",
            "   ...\n",
            "   [-0.24705881]\n",
            "   [-0.09803921]\n",
            "   [-0.14509803]]]\n",
            "\n",
            "\n",
            " [[[-0.38823527]\n",
            "   [-0.5294118 ]\n",
            "   [-0.8509804 ]\n",
            "   ...\n",
            "   [ 0.10588241]\n",
            "   [ 0.15294123]\n",
            "   [ 0.15294123]]\n",
            "\n",
            "  [[-0.41176468]\n",
            "   [-0.6784314 ]\n",
            "   [-0.90588236]\n",
            "   ...\n",
            "   [-0.03529412]\n",
            "   [-0.14509803]\n",
            "   [ 0.1686275 ]]\n",
            "\n",
            "  [[-0.4980392 ]\n",
            "   [-0.81960785]\n",
            "   [-0.90588236]\n",
            "   ...\n",
            "   [ 0.082353  ]\n",
            "   [-0.09803921]\n",
            "   [-0.03529412]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.8745098 ]\n",
            "   [-0.8745098 ]\n",
            "   [-0.8666667 ]\n",
            "   ...\n",
            "   [-0.2862745 ]\n",
            "   [-0.42745095]\n",
            "   [-0.35686272]]\n",
            "\n",
            "  [[-0.8117647 ]\n",
            "   [-0.8666667 ]\n",
            "   [-0.8745098 ]\n",
            "   ...\n",
            "   [-0.36470586]\n",
            "   [-0.4352941 ]\n",
            "   [-0.3960784 ]]\n",
            "\n",
            "  [[-0.75686276]\n",
            "   [-0.8039216 ]\n",
            "   [-0.79607844]\n",
            "   ...\n",
            "   [-0.41176468]\n",
            "   [-0.44313723]\n",
            "   [-0.41960782]]]\n",
            "\n",
            "\n",
            " [[[-0.81960785]\n",
            "   [-0.94509804]\n",
            "   [-0.9529412 ]\n",
            "   ...\n",
            "   [-0.9843137 ]\n",
            "   [-0.9843137 ]\n",
            "   [-0.9843137 ]]\n",
            "\n",
            "  [[-0.8901961 ]\n",
            "   [-0.88235295]\n",
            "   [-0.92941177]\n",
            "   ...\n",
            "   [-0.9843137 ]\n",
            "   [-0.9843137 ]\n",
            "   [-0.9843137 ]]\n",
            "\n",
            "  [[-0.8901961 ]\n",
            "   [-0.9607843 ]\n",
            "   [-0.92156863]\n",
            "   ...\n",
            "   [-0.9764706 ]\n",
            "   [-0.9764706 ]\n",
            "   [-0.9843137 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.5764706 ]\n",
            "   [-0.24705881]\n",
            "   [-0.29411763]\n",
            "   ...\n",
            "   [-0.90588236]\n",
            "   [-0.9137255 ]\n",
            "   [-0.9137255 ]]\n",
            "\n",
            "  [[-0.77254903]\n",
            "   [-0.44313723]\n",
            "   [-0.27843136]\n",
            "   ...\n",
            "   [-0.90588236]\n",
            "   [-0.90588236]\n",
            "   [-0.90588236]]\n",
            "\n",
            "  [[-0.84313726]\n",
            "   [-0.73333335]\n",
            "   [-0.5686275 ]\n",
            "   ...\n",
            "   [-0.90588236]\n",
            "   [-0.90588236]\n",
            "   [-0.8980392 ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.58431375]\n",
            "   [-0.6313726 ]\n",
            "   [-0.58431375]\n",
            "   ...\n",
            "   [-0.84313726]\n",
            "   [-0.7254902 ]\n",
            "   [-0.6862745 ]]\n",
            "\n",
            "  [[-0.6313726 ]\n",
            "   [-0.56078434]\n",
            "   [-0.5529412 ]\n",
            "   ...\n",
            "   [-0.8666667 ]\n",
            "   [-0.77254903]\n",
            "   [-0.7490196 ]]\n",
            "\n",
            "  [[-0.5372549 ]\n",
            "   [-0.5764706 ]\n",
            "   [-0.58431375]\n",
            "   ...\n",
            "   [-0.90588236]\n",
            "   [-0.8745098 ]\n",
            "   [-0.8352941 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.6313726 ]\n",
            "   [ 0.60784316]\n",
            "   [ 0.6       ]\n",
            "   ...\n",
            "   [-0.9764706 ]\n",
            "   [-0.9137255 ]\n",
            "   [-0.8352941 ]]\n",
            "\n",
            "  [[ 0.64705884]\n",
            "   [ 0.6392157 ]\n",
            "   [ 0.6156863 ]\n",
            "   ...\n",
            "   [-0.99215686]\n",
            "   [-0.94509804]\n",
            "   [-0.84313726]]\n",
            "\n",
            "  [[ 0.67058825]\n",
            "   [ 0.6627451 ]\n",
            "   [ 0.6392157 ]\n",
            "   ...\n",
            "   [-0.99215686]\n",
            "   [-0.9529412 ]\n",
            "   [-0.8666667 ]]]\n",
            "\n",
            "\n",
            " [[[-0.2235294 ]\n",
            "   [-0.19999999]\n",
            "   [-0.2235294 ]\n",
            "   ...\n",
            "   [-0.5137255 ]\n",
            "   [-0.67058825]\n",
            "   [-0.5764706 ]]\n",
            "\n",
            "  [[-0.14509803]\n",
            "   [-0.1372549 ]\n",
            "   [-0.1607843 ]\n",
            "   ...\n",
            "   [-0.4980392 ]\n",
            "   [-0.6784314 ]\n",
            "   [-0.6       ]]\n",
            "\n",
            "  [[-0.12156862]\n",
            "   [-0.0745098 ]\n",
            "   [-0.11372548]\n",
            "   ...\n",
            "   [-0.47450978]\n",
            "   [-0.654902  ]\n",
            "   [-0.5921569 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.54509807]\n",
            "   [ 0.6627451 ]\n",
            "   [ 0.88235295]\n",
            "   ...\n",
            "   [ 0.52156866]\n",
            "   [ 0.70980394]\n",
            "   [ 0.7490196 ]]\n",
            "\n",
            "  [[ 0.70980394]\n",
            "   [ 0.92156863]\n",
            "   [ 0.827451  ]\n",
            "   ...\n",
            "   [ 0.52156866]\n",
            "   [ 0.69411767]\n",
            "   [ 0.75686276]]\n",
            "\n",
            "  [[ 0.70980394]\n",
            "   [ 0.85882354]\n",
            "   [ 0.827451  ]\n",
            "   ...\n",
            "   [ 0.5058824 ]\n",
            "   [ 0.7176471 ]\n",
            "   [ 0.78039217]]]\n",
            "\n",
            "\n",
            " [[[ 0.4666667 ]\n",
            "   [ 0.41176474]\n",
            "   [ 0.4666667 ]\n",
            "   ...\n",
            "   [-0.2862745 ]\n",
            "   [-0.44313723]\n",
            "   [-0.4588235 ]]\n",
            "\n",
            "  [[ 0.43529415]\n",
            "   [ 0.32549024]\n",
            "   [ 0.4901961 ]\n",
            "   ...\n",
            "   [-0.2862745 ]\n",
            "   [-0.41176468]\n",
            "   [-0.4980392 ]]\n",
            "\n",
            "  [[ 0.39607847]\n",
            "   [ 0.3176471 ]\n",
            "   [ 0.5294118 ]\n",
            "   ...\n",
            "   [-0.29411763]\n",
            "   [-0.3960784 ]\n",
            "   [-0.45098037]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.827451  ]\n",
            "   [ 0.827451  ]\n",
            "   [ 0.827451  ]\n",
            "   ...\n",
            "   [-0.42745095]\n",
            "   [-0.5529412 ]\n",
            "   [-0.56078434]]\n",
            "\n",
            "  [[ 0.827451  ]\n",
            "   [ 0.827451  ]\n",
            "   [ 0.827451  ]\n",
            "   ...\n",
            "   [-0.4980392 ]\n",
            "   [-0.40392154]\n",
            "   [-0.19215685]]\n",
            "\n",
            "  [[ 0.827451  ]\n",
            "   [ 0.827451  ]\n",
            "   [ 0.827451  ]\n",
            "   ...\n",
            "   [-0.8352941 ]\n",
            "   [-0.38039213]\n",
            "   [ 0.4666667 ]]]] [[[[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 0.96862745]\n",
            "   [ 1.        ]\n",
            "   [ 0.99215686]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 0.10588241]\n",
            "   [ 1.        ]\n",
            "   [ 0.9764706 ]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [-0.67058825]\n",
            "   [ 0.5686275 ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [-0.58431375]\n",
            "   [-0.4980392 ]\n",
            "   [-0.4980392 ]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [-0.6392157 ]\n",
            "   [-0.5372549 ]\n",
            "   [-0.52156866]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [-0.7411765 ]\n",
            "   [-0.58431375]\n",
            "   [-0.54509807]]]\n",
            "\n",
            "\n",
            " [[[ 0.9843137 ]\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.99215686]\n",
            "   ...\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.9843137 ]]\n",
            "\n",
            "  [[ 0.9843137 ]\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.99215686]\n",
            "   ...\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.9843137 ]]\n",
            "\n",
            "  [[ 0.9843137 ]\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.99215686]\n",
            "   ...\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.9843137 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.6862745 ]\n",
            "   [-0.54509807]\n",
            "   [-0.12941176]\n",
            "   ...\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.9843137 ]]\n",
            "\n",
            "  [[-0.6313726 ]\n",
            "   [-0.7490196 ]\n",
            "   [-0.5294118 ]\n",
            "   ...\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.9843137 ]]\n",
            "\n",
            "  [[-0.62352943]\n",
            "   [-0.7176471 ]\n",
            "   [-0.81960785]\n",
            "   ...\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.9843137 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.78039217]\n",
            "   [ 0.79607844]\n",
            "   [ 0.7882353 ]\n",
            "   ...\n",
            "   [ 0.6627451 ]\n",
            "   [ 0.7019608 ]\n",
            "   [ 0.6862745 ]]\n",
            "\n",
            "  [[ 0.7647059 ]\n",
            "   [ 0.7882353 ]\n",
            "   [ 0.78039217]\n",
            "   ...\n",
            "   [ 0.69411767]\n",
            "   [ 0.69411767]\n",
            "   [ 0.69411767]]\n",
            "\n",
            "  [[ 0.78039217]\n",
            "   [ 0.7882353 ]\n",
            "   [ 0.77254903]\n",
            "   ...\n",
            "   [ 0.7019608 ]\n",
            "   [ 0.69411767]\n",
            "   [ 0.7019608 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.79607844]\n",
            "   [ 0.8509804 ]\n",
            "   [ 0.90588236]\n",
            "   ...\n",
            "   [ 0.35686278]\n",
            "   [-0.08235294]\n",
            "   [-0.47450978]]\n",
            "\n",
            "  [[ 0.827451  ]\n",
            "   [ 0.84313726]\n",
            "   [ 0.8980392 ]\n",
            "   ...\n",
            "   [ 0.41960788]\n",
            "   [ 0.14509809]\n",
            "   [-0.26274508]]\n",
            "\n",
            "  [[ 0.85882354]\n",
            "   [ 0.8666667 ]\n",
            "   [ 0.90588236]\n",
            "   ...\n",
            "   [ 0.49803925]\n",
            "   [ 0.37254906]\n",
            "   [ 0.01176476]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.5764706 ]\n",
            "   [-0.6       ]\n",
            "   [-0.6627451 ]\n",
            "   ...\n",
            "   [-0.8352941 ]\n",
            "   [-0.8039216 ]\n",
            "   [-0.8039216 ]]\n",
            "\n",
            "  [[-0.70980394]\n",
            "   [-0.6       ]\n",
            "   [-0.6784314 ]\n",
            "   ...\n",
            "   [-0.8509804 ]\n",
            "   [-0.7882353 ]\n",
            "   [-0.7647059 ]]\n",
            "\n",
            "  [[-0.8509804 ]\n",
            "   [-0.75686276]\n",
            "   [-0.81960785]\n",
            "   ...\n",
            "   [-0.8901961 ]\n",
            "   [-0.84313726]\n",
            "   [-0.8117647 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.372549  ]\n",
            "   [-0.4980392 ]\n",
            "   [-0.5137255 ]\n",
            "   ...\n",
            "   [-0.9137255 ]\n",
            "   [-0.90588236]\n",
            "   [-0.92941177]]\n",
            "\n",
            "  [[-0.26274508]\n",
            "   [-0.42745095]\n",
            "   [-0.58431375]\n",
            "   ...\n",
            "   [-0.88235295]\n",
            "   [-0.9137255 ]\n",
            "   [-0.92941177]]\n",
            "\n",
            "  [[-0.2862745 ]\n",
            "   [-0.38039213]\n",
            "   [-0.52156866]\n",
            "   ...\n",
            "   [-0.88235295]\n",
            "   [-0.9137255 ]\n",
            "   [-0.9137255 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.99215686]\n",
            "   [ 0.9764706 ]\n",
            "   [ 0.99215686]\n",
            "   ...\n",
            "   [ 0.01176476]\n",
            "   [ 1.        ]\n",
            "   [ 0.9764706 ]]\n",
            "\n",
            "  [[ 0.99215686]\n",
            "   [ 0.9764706 ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [-0.44313723]\n",
            "   [ 0.9137255 ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 0.9607843 ]\n",
            "   [ 1.        ]\n",
            "   [ 0.8666667 ]\n",
            "   ...\n",
            "   [-0.6784314 ]\n",
            "   [ 0.6       ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.26274508]\n",
            "   [-0.8509804 ]\n",
            "   [-0.9843137 ]\n",
            "   ...\n",
            "   [-0.67058825]\n",
            "   [-0.372549  ]\n",
            "   [-0.3490196 ]]\n",
            "\n",
            "  [[-0.21568626]\n",
            "   [-0.60784316]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.49019605]\n",
            "   [-0.3333333 ]\n",
            "   [-0.38039213]]\n",
            "\n",
            "  [[-0.40392154]\n",
            "   [-0.38823527]\n",
            "   [-0.96862745]\n",
            "   ...\n",
            "   [-0.38039213]\n",
            "   [-0.3333333 ]\n",
            "   [-0.4352941 ]]]\n",
            "\n",
            "\n",
            " [[[ 1.        ]\n",
            "   [ 0.9764706 ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 0.9843137 ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 0.99215686]\n",
            "   [ 1.        ]\n",
            "   [ 0.84313726]\n",
            "   ...\n",
            "   [ 0.99215686]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.99215686]\n",
            "   [ 0.99215686]\n",
            "   [ 0.94509804]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 0.99215686]\n",
            "   [ 0.99215686]]\n",
            "\n",
            "  [[ 0.9843137 ]\n",
            "   [ 0.90588236]\n",
            "   [ 0.8039216 ]\n",
            "   ...\n",
            "   [ 0.99215686]\n",
            "   [ 0.99215686]\n",
            "   [ 0.99215686]]\n",
            "\n",
            "  [[ 0.8745098 ]\n",
            "   [ 0.81960785]\n",
            "   [ 0.79607844]\n",
            "   ...\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.99215686]\n",
            "   [ 0.9843137 ]]]] [[[[-0.45098037]\n",
            "   [-0.49019605]\n",
            "   [-0.5921569 ]\n",
            "   ...\n",
            "   [ 0.09019613]\n",
            "   [ 0.13725495]\n",
            "   [ 0.41176474]]\n",
            "\n",
            "  [[-0.7019608 ]\n",
            "   [-0.78039217]\n",
            "   [-0.67058825]\n",
            "   ...\n",
            "   [ 0.12941182]\n",
            "   [ 0.3176471 ]\n",
            "   [ 0.5372549 ]]\n",
            "\n",
            "  [[-0.7254902 ]\n",
            "   [-0.56078434]\n",
            "   [-0.19215685]\n",
            "   ...\n",
            "   [ 0.30980396]\n",
            "   [ 0.45882356]\n",
            "   [ 0.5686275 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.16078436]\n",
            "   [ 0.1686275 ]\n",
            "   [ 0.1686275 ]\n",
            "   ...\n",
            "   [ 0.7647059 ]\n",
            "   [ 0.7647059 ]\n",
            "   [ 0.77254903]]\n",
            "\n",
            "  [[ 0.19215691]\n",
            "   [ 0.20000005]\n",
            "   [ 0.20000005]\n",
            "   ...\n",
            "   [ 0.70980394]\n",
            "   [ 0.7176471 ]\n",
            "   [ 0.70980394]]\n",
            "\n",
            "  [[ 0.20000005]\n",
            "   [ 0.20000005]\n",
            "   [ 0.20784318]\n",
            "   ...\n",
            "   [ 0.6156863 ]\n",
            "   [ 0.6627451 ]\n",
            "   [ 0.6313726 ]]]\n",
            "\n",
            "\n",
            " [[[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [-0.54509807]\n",
            "   [-0.5372549 ]\n",
            "   [-0.2235294 ]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [-0.6156863 ]\n",
            "   [-0.60784316]\n",
            "   [-0.5921569 ]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [-0.6862745 ]\n",
            "   [-0.6784314 ]\n",
            "   [-0.654902  ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [-0.5372549 ]\n",
            "   [-0.5686275 ]\n",
            "   [-0.5294118 ]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [-0.5294118 ]\n",
            "   [-0.52156866]\n",
            "   [-0.5058824 ]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [-0.5294118 ]\n",
            "   [-0.5294118 ]\n",
            "   [-0.5137255 ]]]\n",
            "\n",
            "\n",
            " [[[-0.6392157 ]\n",
            "   [-0.7411765 ]\n",
            "   [-0.6862745 ]\n",
            "   ...\n",
            "   [-0.9607843 ]\n",
            "   [-0.9529412 ]\n",
            "   [-0.9529412 ]]\n",
            "\n",
            "  [[-0.78039217]\n",
            "   [-0.7019608 ]\n",
            "   [-0.60784316]\n",
            "   ...\n",
            "   [-0.9372549 ]\n",
            "   [-0.9529412 ]\n",
            "   [-0.9529412 ]]\n",
            "\n",
            "  [[-0.6313726 ]\n",
            "   [-0.6862745 ]\n",
            "   [-0.654902  ]\n",
            "   ...\n",
            "   [-0.92941177]\n",
            "   [-0.94509804]\n",
            "   [-0.9529412 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.17647058]\n",
            "   [-0.17647058]\n",
            "   [-0.19215685]\n",
            "   ...\n",
            "   [-0.8980392 ]\n",
            "   [-0.8980392 ]\n",
            "   [-0.8901961 ]]\n",
            "\n",
            "  [[-0.19999999]\n",
            "   [-0.19215685]\n",
            "   [-0.17647058]\n",
            "   ...\n",
            "   [-0.8980392 ]\n",
            "   [-0.8980392 ]\n",
            "   [-0.8901961 ]]\n",
            "\n",
            "  [[-0.20784312]\n",
            "   [-0.17647058]\n",
            "   [-0.16862744]\n",
            "   ...\n",
            "   [-0.8980392 ]\n",
            "   [-0.8980392 ]\n",
            "   [-0.8901961 ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 0.37254906]\n",
            "   [ 0.39607847]\n",
            "   [ 0.37254906]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 0.3803922 ]\n",
            "   [ 0.3411765 ]\n",
            "   [ 0.3411765 ]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 0.24705887]\n",
            "   [ 0.30196083]\n",
            "   [ 0.38823533]\n",
            "   ...\n",
            "   [ 0.99215686]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.082353  ]\n",
            "   [ 0.09803927]\n",
            "   [-0.18431371]\n",
            "   ...\n",
            "   [ 0.92941177]\n",
            "   [ 1.        ]\n",
            "   [ 0.99215686]]\n",
            "\n",
            "  [[ 0.07450986]\n",
            "   [ 0.0196079 ]\n",
            "   [-0.00392157]\n",
            "   ...\n",
            "   [ 0.90588236]\n",
            "   [ 1.        ]\n",
            "   [ 0.9843137 ]]\n",
            "\n",
            "  [[ 0.04313731]\n",
            "   [-0.05098039]\n",
            "   [ 0.06666672]\n",
            "   ...\n",
            "   [ 0.9137255 ]\n",
            "   [ 1.        ]\n",
            "   [ 0.99215686]]]\n",
            "\n",
            "\n",
            " [[[-0.27843136]\n",
            "   [-0.34117645]\n",
            "   [-0.9372549 ]\n",
            "   ...\n",
            "   [-0.8666667 ]\n",
            "   [-0.9137255 ]\n",
            "   [-0.6313726 ]]\n",
            "\n",
            "  [[-0.27843136]\n",
            "   [-0.47450978]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.6627451 ]\n",
            "   [-0.8901961 ]\n",
            "   [-0.70980394]]\n",
            "\n",
            "  [[-0.30196077]\n",
            "   [-0.56078434]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.42745095]\n",
            "   [-0.60784316]\n",
            "   [-0.7490196 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.26274508]\n",
            "   [-0.26274508]\n",
            "   [-0.25490195]\n",
            "   ...\n",
            "   [ 0.67058825]\n",
            "   [ 0.6784314 ]\n",
            "   [ 0.7019608 ]]\n",
            "\n",
            "  [[-0.26274508]\n",
            "   [-0.29411763]\n",
            "   [-0.24705881]\n",
            "   ...\n",
            "   [ 0.69411767]\n",
            "   [ 0.69411767]\n",
            "   [ 0.70980394]]\n",
            "\n",
            "  [[-0.26274508]\n",
            "   [-0.01176471]\n",
            "   [ 0.35686278]\n",
            "   ...\n",
            "   [ 0.7176471 ]\n",
            "   [ 0.7176471 ]\n",
            "   [ 0.70980394]]]\n",
            "\n",
            "\n",
            " [[[-0.92941177]\n",
            "   [-0.9372549 ]\n",
            "   [-0.75686276]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[-0.92941177]\n",
            "   [-0.94509804]\n",
            "   [-0.7411765 ]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[-0.92941177]\n",
            "   [-0.92156863]\n",
            "   [-0.77254903]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.7647059 ]\n",
            "   [-0.69411767]\n",
            "   [-0.5921569 ]\n",
            "   ...\n",
            "   [ 0.9137255 ]\n",
            "   [ 0.90588236]\n",
            "   [ 0.8980392 ]]\n",
            "\n",
            "  [[-0.81960785]\n",
            "   [-0.78039217]\n",
            "   [-0.73333335]\n",
            "   ...\n",
            "   [ 0.9764706 ]\n",
            "   [ 0.9764706 ]\n",
            "   [ 0.9843137 ]]\n",
            "\n",
            "  [[-0.8352941 ]\n",
            "   [-0.8117647 ]\n",
            "   [-0.7647059 ]\n",
            "   ...\n",
            "   [ 0.96862745]\n",
            "   [ 0.9764706 ]\n",
            "   [ 0.9529412 ]]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\\n\\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKvEv321Stt5",
        "outputId": "fb61d5d0-3880-4965-8608-cf1c1cb35a3a"
      },
      "source": [
        "print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validasi (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "test (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "train (28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH9Q-TegBR26"
      },
      "source": [
        "#hyperparameter and callback\n",
        "batch_size = 128\n",
        "num_epochs = 120\n",
        "input_shape = (48, 48, 1)\n",
        "num_classes = 7\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGsscQRJBR-h"
      },
      "source": [
        "#Compile the model.\n",
        "\n",
        "\n",
        "from keras.optimizers import Adam, SGD\n",
        "model = ResNet50(input_shape = (48, 48, 1), classes = 7)\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer= optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rodttDWeT2yP"
      },
      "source": [
        "#kita mau save model callbackshuhuhuhuhhg\n",
        "\"\"\"import os\n",
        "try:\n",
        "  os.mkdir('scratchcheckpoint')\n",
        "except:\n",
        "  pass\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV29sTjET28U"
      },
      "source": [
        "\"\"\"file_name = 'Best_Model_resnet50Scracth_sena1.h5'\n",
        "\n",
        "checkpoint_path = os.path.join('checkpoint',file_name)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_S6wUaPT3Jx"
      },
      "source": [
        "\"\"\"call_back = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
        "                                               monitor='val_accuracy',\n",
        "                                               verbose=1,\n",
        "                                               save_freq='epoch',\n",
        "                                               save_best_only=True,\n",
        "                                               save_weights_only=False,\n",
        "                                               mode='max')\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy53DHMGB-Mr",
        "outputId": "c4277781-8da9-4d97-9951-8712dcac8467"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 46, 46, 128)  0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 46, 46, 128)  0           activation_52[0][0]              \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 46, 46, 128)  0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 46, 46, 128)  0           activation_55[0][0]              \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 46, 46, 128)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 23, 23, 256)  0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 23, 23, 256)  0           activation_61[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 23, 23, 256)  0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 23, 23, 256)  0           activation_64[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 23, 23, 256)  0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 23, 23, 256)  0           activation_67[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 23, 23, 256)  0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 12, 12, 512)  0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 12, 12, 512)  0           activation_73[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 12, 12, 512)  0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 12, 12, 512)  0           activation_76[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 12, 12, 512)  0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 12, 12, 512)  0           activation_79[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 12, 12, 512)  0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 12, 12, 512)  0           activation_82[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 12, 12, 512)  0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 12, 12, 512)  0           activation_85[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 12, 12, 512)  0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 6, 6, 1024)   0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 6, 6, 1024)   0           activation_91[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 6, 6, 1024)   0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 6, 6, 1024)   0           activation_94[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 6, 6, 1024)   0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgxCecVwCGEr"
      },
      "source": [
        "\"\"\"history = model.fit(data_generator.flow(xtrain, ytrain,),\n",
        "                        steps_per_epoch=len(xtrain) / batch_size,\n",
        "                        epochs=num_epochs, verbose=1,callbacks=call_back,\n",
        "                        validation_data= (xtest,ytest))\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2muXWns0sJSH",
        "outputId": "2ff29477-3ef9-4d26-cbbc-504aa44da867"
      },
      "source": [
        "history = model.fit(\n",
        "    data_generator.flow(xtrain, ytrain,),\n",
        "    steps_per_epoch=len(xtrain) / batch_size,\n",
        "    epochs=num_epochs, \n",
        "    verbose=1,\n",
        "    validation_data= (x_val,y_val))\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/120\n",
            "224/224 [==============================] - 39s 125ms/step - loss: 4.6436 - accuracy: 0.2107 - val_loss: 1.8556 - val_accuracy: 0.2393\n",
            "Epoch 2/120\n",
            "224/224 [==============================] - 25s 111ms/step - loss: 1.8348 - accuracy: 0.2513 - val_loss: 1.8177 - val_accuracy: 0.2382\n",
            "Epoch 3/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.7803 - accuracy: 0.2618 - val_loss: 1.8535 - val_accuracy: 0.2471\n",
            "Epoch 4/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.7666 - accuracy: 0.2669 - val_loss: 1.7980 - val_accuracy: 0.2499\n",
            "Epoch 5/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.7466 - accuracy: 0.2899 - val_loss: 1.8045 - val_accuracy: 0.2536\n",
            "Epoch 6/120\n",
            "224/224 [==============================] - 25s 111ms/step - loss: 1.7093 - accuracy: 0.3062 - val_loss: 1.7991 - val_accuracy: 0.2594\n",
            "Epoch 7/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.7049 - accuracy: 0.3111 - val_loss: 1.8103 - val_accuracy: 0.2722\n",
            "Epoch 8/120\n",
            "224/224 [==============================] - 25s 111ms/step - loss: 1.6489 - accuracy: 0.3307 - val_loss: 1.6360 - val_accuracy: 0.3505\n",
            "Epoch 9/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.6228 - accuracy: 0.3560 - val_loss: 1.6062 - val_accuracy: 0.3670\n",
            "Epoch 10/120\n",
            "224/224 [==============================] - 25s 111ms/step - loss: 1.5879 - accuracy: 0.3737 - val_loss: 2.2565 - val_accuracy: 0.3151\n",
            "Epoch 11/120\n",
            "224/224 [==============================] - 27s 121ms/step - loss: 1.5422 - accuracy: 0.3953 - val_loss: 1.9272 - val_accuracy: 0.2552\n",
            "Epoch 12/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 1.4863 - accuracy: 0.4148 - val_loss: 1.5143 - val_accuracy: 0.3884\n",
            "Epoch 13/120\n",
            "224/224 [==============================] - 25s 111ms/step - loss: 1.4741 - accuracy: 0.4327 - val_loss: 1.4874 - val_accuracy: 0.4149\n",
            "Epoch 14/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 1.4563 - accuracy: 0.4389 - val_loss: 1.8840 - val_accuracy: 0.3341\n",
            "Epoch 15/120\n",
            "224/224 [==============================] - 25s 111ms/step - loss: 1.4456 - accuracy: 0.4358 - val_loss: 1.4980 - val_accuracy: 0.4143\n",
            "Epoch 16/120\n",
            "224/224 [==============================] - 27s 122ms/step - loss: 1.4232 - accuracy: 0.4397 - val_loss: 1.7546 - val_accuracy: 0.3207\n",
            "Epoch 17/120\n",
            "224/224 [==============================] - 27s 122ms/step - loss: 1.4081 - accuracy: 0.4562 - val_loss: 1.4676 - val_accuracy: 0.4444\n",
            "Epoch 18/120\n",
            "224/224 [==============================] - 25s 111ms/step - loss: 1.4020 - accuracy: 0.4543 - val_loss: 1.4434 - val_accuracy: 0.4349\n",
            "Epoch 19/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.3939 - accuracy: 0.4614 - val_loss: 1.4797 - val_accuracy: 0.4218\n",
            "Epoch 20/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.3189 - accuracy: 0.4907 - val_loss: 1.3222 - val_accuracy: 0.4831\n",
            "Epoch 21/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.3319 - accuracy: 0.4833 - val_loss: 1.8325 - val_accuracy: 0.3586\n",
            "Epoch 22/120\n",
            "224/224 [==============================] - 25s 111ms/step - loss: 1.3369 - accuracy: 0.4807 - val_loss: 1.6192 - val_accuracy: 0.4246\n",
            "Epoch 23/120\n",
            "224/224 [==============================] - 27s 122ms/step - loss: 1.3128 - accuracy: 0.5001 - val_loss: 1.6040 - val_accuracy: 0.4087\n",
            "Epoch 24/120\n",
            "224/224 [==============================] - 25s 111ms/step - loss: 1.2997 - accuracy: 0.5050 - val_loss: 1.5780 - val_accuracy: 0.4079\n",
            "Epoch 25/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.3112 - accuracy: 0.4885 - val_loss: 1.3601 - val_accuracy: 0.4817\n",
            "Epoch 26/120\n",
            "224/224 [==============================] - 27s 122ms/step - loss: 1.3245 - accuracy: 0.4879 - val_loss: 1.3647 - val_accuracy: 0.4653\n",
            "Epoch 27/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.2901 - accuracy: 0.5090 - val_loss: 1.4148 - val_accuracy: 0.4681\n",
            "Epoch 28/120\n",
            "224/224 [==============================] - 28s 123ms/step - loss: 1.2846 - accuracy: 0.5080 - val_loss: 1.3588 - val_accuracy: 0.4776\n",
            "Epoch 29/120\n",
            "224/224 [==============================] - 27s 121ms/step - loss: 1.2772 - accuracy: 0.5017 - val_loss: 1.2794 - val_accuracy: 0.5132\n",
            "Epoch 30/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.2489 - accuracy: 0.5252 - val_loss: 1.4119 - val_accuracy: 0.4670\n",
            "Epoch 31/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.2446 - accuracy: 0.5213 - val_loss: 1.2963 - val_accuracy: 0.5099\n",
            "Epoch 32/120\n",
            "224/224 [==============================] - 25s 111ms/step - loss: 1.2459 - accuracy: 0.5275 - val_loss: 1.2665 - val_accuracy: 0.5082\n",
            "Epoch 33/120\n",
            "224/224 [==============================] - 28s 123ms/step - loss: 1.2225 - accuracy: 0.5328 - val_loss: 1.2882 - val_accuracy: 0.5116\n",
            "Epoch 34/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.2306 - accuracy: 0.5394 - val_loss: 1.2711 - val_accuracy: 0.5274\n",
            "Epoch 35/120\n",
            "224/224 [==============================] - 25s 111ms/step - loss: 1.2217 - accuracy: 0.5357 - val_loss: 1.3535 - val_accuracy: 0.4745\n",
            "Epoch 36/120\n",
            "224/224 [==============================] - 28s 123ms/step - loss: 1.2279 - accuracy: 0.5357 - val_loss: 1.2441 - val_accuracy: 0.5230\n",
            "Epoch 37/120\n",
            "224/224 [==============================] - 25s 111ms/step - loss: 1.2114 - accuracy: 0.5301 - val_loss: 1.2111 - val_accuracy: 0.5361\n",
            "Epoch 38/120\n",
            "224/224 [==============================] - 25s 111ms/step - loss: 1.1940 - accuracy: 0.5415 - val_loss: 1.2034 - val_accuracy: 0.5400\n",
            "Epoch 39/120\n",
            "224/224 [==============================] - 28s 123ms/step - loss: 1.1979 - accuracy: 0.5495 - val_loss: 1.2014 - val_accuracy: 0.5397\n",
            "Epoch 40/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.1757 - accuracy: 0.5599 - val_loss: 1.3028 - val_accuracy: 0.5038\n",
            "Epoch 41/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.1571 - accuracy: 0.5564 - val_loss: 1.2732 - val_accuracy: 0.5065\n",
            "Epoch 42/120\n",
            "224/224 [==============================] - 25s 111ms/step - loss: 1.1578 - accuracy: 0.5594 - val_loss: 1.2092 - val_accuracy: 0.5350\n",
            "Epoch 43/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.1755 - accuracy: 0.5537 - val_loss: 1.2455 - val_accuracy: 0.5286\n",
            "Epoch 44/120\n",
            "224/224 [==============================] - 28s 123ms/step - loss: 1.1747 - accuracy: 0.5583 - val_loss: 1.2263 - val_accuracy: 0.5297\n",
            "Epoch 45/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.1509 - accuracy: 0.5585 - val_loss: 1.2595 - val_accuracy: 0.5247\n",
            "Epoch 46/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.1891 - accuracy: 0.5420 - val_loss: 1.1954 - val_accuracy: 0.5525\n",
            "Epoch 47/120\n",
            "224/224 [==============================] - 28s 123ms/step - loss: 1.1170 - accuracy: 0.5754 - val_loss: 1.1447 - val_accuracy: 0.5626\n",
            "Epoch 48/120\n",
            "224/224 [==============================] - 27s 122ms/step - loss: 1.1516 - accuracy: 0.5667 - val_loss: 1.1440 - val_accuracy: 0.5612\n",
            "Epoch 49/120\n",
            "224/224 [==============================] - 28s 123ms/step - loss: 1.1610 - accuracy: 0.5490 - val_loss: 1.2209 - val_accuracy: 0.5366\n",
            "Epoch 50/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.1194 - accuracy: 0.5718 - val_loss: 1.2331 - val_accuracy: 0.5475\n",
            "Epoch 51/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.1141 - accuracy: 0.5822 - val_loss: 1.2088 - val_accuracy: 0.5442\n",
            "Epoch 52/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 1.1190 - accuracy: 0.5784 - val_loss: 1.2438 - val_accuracy: 0.5316\n",
            "Epoch 53/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.1281 - accuracy: 0.5742 - val_loss: 1.1543 - val_accuracy: 0.5665\n",
            "Epoch 54/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.1173 - accuracy: 0.5750 - val_loss: 1.1846 - val_accuracy: 0.5600\n",
            "Epoch 55/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 1.0965 - accuracy: 0.5898 - val_loss: 1.1236 - val_accuracy: 0.5798\n",
            "Epoch 56/120\n",
            "224/224 [==============================] - 25s 111ms/step - loss: 1.0980 - accuracy: 0.5856 - val_loss: 1.1971 - val_accuracy: 0.5531\n",
            "Epoch 57/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.0917 - accuracy: 0.5885 - val_loss: 1.1296 - val_accuracy: 0.5642\n",
            "Epoch 58/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 1.1030 - accuracy: 0.5832 - val_loss: 1.2420 - val_accuracy: 0.5350\n",
            "Epoch 59/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.1031 - accuracy: 0.5903 - val_loss: 1.1925 - val_accuracy: 0.5456\n",
            "Epoch 60/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.0687 - accuracy: 0.5907 - val_loss: 1.1689 - val_accuracy: 0.5648\n",
            "Epoch 61/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.0901 - accuracy: 0.5857 - val_loss: 1.3071 - val_accuracy: 0.4996\n",
            "Epoch 62/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 1.1066 - accuracy: 0.5814 - val_loss: 1.1344 - val_accuracy: 0.5773\n",
            "Epoch 63/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.0752 - accuracy: 0.5916 - val_loss: 1.2246 - val_accuracy: 0.5525\n",
            "Epoch 64/120\n",
            "224/224 [==============================] - 28s 123ms/step - loss: 1.0957 - accuracy: 0.5905 - val_loss: 1.1195 - val_accuracy: 0.5818\n",
            "Epoch 65/120\n",
            "224/224 [==============================] - 27s 122ms/step - loss: 1.0793 - accuracy: 0.5879 - val_loss: 1.2068 - val_accuracy: 0.5408\n",
            "Epoch 66/120\n",
            "224/224 [==============================] - 25s 111ms/step - loss: 1.0691 - accuracy: 0.5967 - val_loss: 1.1114 - val_accuracy: 0.5812\n",
            "Epoch 67/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.0950 - accuracy: 0.5896 - val_loss: 1.1957 - val_accuracy: 0.5442\n",
            "Epoch 68/120\n",
            "224/224 [==============================] - 25s 111ms/step - loss: 1.0770 - accuracy: 0.5963 - val_loss: 1.1200 - val_accuracy: 0.5743\n",
            "Epoch 69/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 1.0585 - accuracy: 0.5997 - val_loss: 1.1257 - val_accuracy: 0.5768\n",
            "Epoch 70/120\n",
            "224/224 [==============================] - 27s 122ms/step - loss: 1.0562 - accuracy: 0.5963 - val_loss: 1.4032 - val_accuracy: 0.4915\n",
            "Epoch 71/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.0753 - accuracy: 0.5926 - val_loss: 1.1161 - val_accuracy: 0.5737\n",
            "Epoch 72/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.0500 - accuracy: 0.6030 - val_loss: 1.1146 - val_accuracy: 0.5846\n",
            "Epoch 73/120\n",
            "224/224 [==============================] - 28s 123ms/step - loss: 1.0480 - accuracy: 0.6115 - val_loss: 1.1135 - val_accuracy: 0.5779\n",
            "Epoch 74/120\n",
            "224/224 [==============================] - 27s 122ms/step - loss: 1.0444 - accuracy: 0.5938 - val_loss: 1.1135 - val_accuracy: 0.5809\n",
            "Epoch 75/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.0235 - accuracy: 0.6178 - val_loss: 1.1090 - val_accuracy: 0.5784\n",
            "Epoch 76/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 1.0591 - accuracy: 0.5905 - val_loss: 1.1376 - val_accuracy: 0.5779\n",
            "Epoch 77/120\n",
            "224/224 [==============================] - 27s 122ms/step - loss: 1.0476 - accuracy: 0.6031 - val_loss: 1.1355 - val_accuracy: 0.5821\n",
            "Epoch 78/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.0226 - accuracy: 0.6223 - val_loss: 1.0671 - val_accuracy: 0.5971\n",
            "Epoch 79/120\n",
            "224/224 [==============================] - 27s 122ms/step - loss: 1.0462 - accuracy: 0.6061 - val_loss: 1.1280 - val_accuracy: 0.5756\n",
            "Epoch 80/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.0264 - accuracy: 0.6187 - val_loss: 1.1497 - val_accuracy: 0.5779\n",
            "Epoch 81/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.0304 - accuracy: 0.6126 - val_loss: 1.2460 - val_accuracy: 0.5461\n",
            "Epoch 82/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.0369 - accuracy: 0.6069 - val_loss: 1.1418 - val_accuracy: 0.5759\n",
            "Epoch 83/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 1.0302 - accuracy: 0.6007 - val_loss: 1.0612 - val_accuracy: 0.5924\n",
            "Epoch 84/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.0345 - accuracy: 0.6052 - val_loss: 1.2094 - val_accuracy: 0.5444\n",
            "Epoch 85/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.0204 - accuracy: 0.6132 - val_loss: 1.1335 - val_accuracy: 0.5709\n",
            "Epoch 86/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 1.0199 - accuracy: 0.6133 - val_loss: 1.2305 - val_accuracy: 0.5497\n",
            "Epoch 87/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 0.9864 - accuracy: 0.6213 - val_loss: 1.1315 - val_accuracy: 0.5740\n",
            "Epoch 88/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.9980 - accuracy: 0.6173 - val_loss: 1.0848 - val_accuracy: 0.5885\n",
            "Epoch 89/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 1.0036 - accuracy: 0.6235 - val_loss: 1.0717 - val_accuracy: 0.5960\n",
            "Epoch 90/120\n",
            "224/224 [==============================] - 28s 123ms/step - loss: 0.9944 - accuracy: 0.6303 - val_loss: 1.0639 - val_accuracy: 0.5979\n",
            "Epoch 91/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.9725 - accuracy: 0.6343 - val_loss: 1.1179 - val_accuracy: 0.5907\n",
            "Epoch 92/120\n",
            "224/224 [==============================] - 28s 124ms/step - loss: 0.9990 - accuracy: 0.6255 - val_loss: 1.1054 - val_accuracy: 0.5876\n",
            "Epoch 93/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 1.0046 - accuracy: 0.6162 - val_loss: 1.0198 - val_accuracy: 0.6063\n",
            "Epoch 94/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 1.0088 - accuracy: 0.6161 - val_loss: 1.1143 - val_accuracy: 0.5843\n",
            "Epoch 95/120\n",
            "224/224 [==============================] - 28s 124ms/step - loss: 1.0151 - accuracy: 0.6134 - val_loss: 1.0425 - val_accuracy: 0.6127\n",
            "Epoch 96/120\n",
            "224/224 [==============================] - 28s 123ms/step - loss: 1.0053 - accuracy: 0.6295 - val_loss: 1.0638 - val_accuracy: 0.5971\n",
            "Epoch 97/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.9968 - accuracy: 0.6184 - val_loss: 1.1690 - val_accuracy: 0.5648\n",
            "Epoch 98/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.9692 - accuracy: 0.6305 - val_loss: 1.0454 - val_accuracy: 0.6135\n",
            "Epoch 99/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.9982 - accuracy: 0.6207 - val_loss: 1.1927 - val_accuracy: 0.5559\n",
            "Epoch 100/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.9841 - accuracy: 0.6297 - val_loss: 1.0905 - val_accuracy: 0.5957\n",
            "Epoch 101/120\n",
            "224/224 [==============================] - 25s 114ms/step - loss: 0.9868 - accuracy: 0.6306 - val_loss: 1.0636 - val_accuracy: 0.6027\n",
            "Epoch 102/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 0.9821 - accuracy: 0.6315 - val_loss: 1.0614 - val_accuracy: 0.6007\n",
            "Epoch 103/120\n",
            "224/224 [==============================] - 28s 124ms/step - loss: 0.9791 - accuracy: 0.6182 - val_loss: 1.1018 - val_accuracy: 0.5999\n",
            "Epoch 104/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.9549 - accuracy: 0.6451 - val_loss: 1.1587 - val_accuracy: 0.5497\n",
            "Epoch 105/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 0.9941 - accuracy: 0.6220 - val_loss: 1.0591 - val_accuracy: 0.6035\n",
            "Epoch 106/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.9472 - accuracy: 0.6378 - val_loss: 1.0940 - val_accuracy: 0.5854\n",
            "Epoch 107/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.9838 - accuracy: 0.6296 - val_loss: 1.1272 - val_accuracy: 0.5784\n",
            "Epoch 108/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.9786 - accuracy: 0.6323 - val_loss: 1.0577 - val_accuracy: 0.6024\n",
            "Epoch 109/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.9887 - accuracy: 0.6162 - val_loss: 1.0562 - val_accuracy: 0.6046\n",
            "Epoch 110/120\n",
            "224/224 [==============================] - 28s 124ms/step - loss: 0.9428 - accuracy: 0.6409 - val_loss: 1.1096 - val_accuracy: 0.5876\n",
            "Epoch 111/120\n",
            "224/224 [==============================] - 28s 124ms/step - loss: 0.9652 - accuracy: 0.6353 - val_loss: 1.1798 - val_accuracy: 0.5801\n",
            "Epoch 112/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.9499 - accuracy: 0.6453 - val_loss: 1.1018 - val_accuracy: 0.5826\n",
            "Epoch 113/120\n",
            "224/224 [==============================] - 26s 114ms/step - loss: 0.9680 - accuracy: 0.6289 - val_loss: 1.0174 - val_accuracy: 0.6138\n",
            "Epoch 114/120\n",
            "224/224 [==============================] - 28s 123ms/step - loss: 0.9452 - accuracy: 0.6504 - val_loss: 1.0243 - val_accuracy: 0.6166\n",
            "Epoch 115/120\n",
            "224/224 [==============================] - 26s 114ms/step - loss: 0.9372 - accuracy: 0.6396 - val_loss: 1.0547 - val_accuracy: 0.6030\n",
            "Epoch 116/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.9547 - accuracy: 0.6453 - val_loss: 1.0602 - val_accuracy: 0.6021\n",
            "Epoch 117/120\n",
            "224/224 [==============================] - 26s 114ms/step - loss: 0.9793 - accuracy: 0.6333 - val_loss: 1.0468 - val_accuracy: 0.6024\n",
            "Epoch 118/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.9758 - accuracy: 0.6260 - val_loss: 1.0858 - val_accuracy: 0.5893\n",
            "Epoch 119/120\n",
            "224/224 [==============================] - 28s 124ms/step - loss: 0.9498 - accuracy: 0.6395 - val_loss: 1.0678 - val_accuracy: 0.6082\n",
            "Epoch 120/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.9539 - accuracy: 0.6404 - val_loss: 1.0889 - val_accuracy: 0.5893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "GaXUP-8fDWRN",
        "outputId": "c5a5da14-b2ca-4435-d5e2-4d21af359a61"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "model.save('/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editAdamst120epochBS128+aug:vf_2.h5')\n",
        "\n",
        "#gffhgffkjkjdskjjkjkjkjhjhnnnhjhhu\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "num_epochs = range(len(accuracy))\n",
        "plt.plot(num_epochs, accuracy, 'r', label='Training acc')\n",
        "plt.plot(num_epochs, val_accuracy, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(num_epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(num_epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeXgUVdaH30MgIBCQTZRNYAQUkDWAiiJuCLjgLogLAwo47ruMG+rnjI7rMC7IgKAjDKgobrggLoi4AQqCgLKOUZBNNtkScr4/Tle6k3QnnaSbEDzv8/RTXbduVd3qSupX55x7zxVVxXEcx3HyUq60G+A4juPsm7hAOI7jOFFxgXAcx3Gi4gLhOI7jRMUFwnEcx4mKC4TjOI4TFRcIZ68gIu+IyGWJrluaiMhKETk5CcdVETks9H2kiNwVT91inKe/iLxf3HYWcNzuIpKR6OM6e5/ypd0AZ99FRLZFrFYGdgF7QutDVHV8vMdS1V7JqLu/o6pDE3EcEWkMrAAqqGpW6NjjgbjvofPHwwXCiYmqVg2+i8hK4HJV/SBvPREpHzx0HMfZf3AXk1NkAheCiNwmImuAsSJSQ0TeEpF1IvJb6HuDiH0+FpHLQ98HiMhMEXkkVHeFiPQqZt0mIjJDRLaKyAci8pSIvBij3fG08X4R+Sx0vPdFpHbE9ktEZJWIbBCROwr4fbqIyBoRSYkoO1tE5oe+dxaRz0Vkk4isFpEnRSQ1xrHGicj/RazfEtrnFxEZmKfuaSLyjYhsEZGfRGR4xOYZoeUmEdkmIkcHv23E/seIyNcisjm0PCbe36YgROSI0P6bRGShiJwZsa23iHwfOubPInJzqLx26P5sEpGNIvKpiPjzai/jP7hTXA4GagKHAoOxv6WxofVGwA7gyQL27wIsAWoD/wDGiIgUo+4E4CugFjAcuKSAc8bTxouAPwMHAalA8MBqCTwTOn690PkaEAVV/RL4HTgxz3EnhL7vAW4IXc/RwEnAXwpoN6E29Ay15xSgGZA3/vE7cClwIHAacKWInBXa1i20PFBVq6rq53mOXRN4GxgRurbHgLdFpFaea8j32xTS5grAm8D7of2uAcaLSItQlTGYuzINaA18GCq/CcgA6gB1gb8CnhdoL+MC4RSXbOAeVd2lqjtUdYOqTlbV7aq6FXgAOL6A/Vep6r9VdQ/wPHAI9iCIu66INAI6AXer6m5VnQm8EeuEcbZxrKr+oKo7gJeAdqHy84C3VHWGqu4C7gr9BrH4L9APQETSgN6hMlR1jqp+oapZqroSeDZKO6JxQah9C1T1d0wQI6/vY1X9TlWzVXV+6HzxHBdMUH5U1f+E2vVfYDFwRkSdWL9NQRwFVAUeDN2jD4G3CP02QCbQUkSqqepvqjo3ovwQ4FBVzVTVT9UTx+11XCCc4rJOVXcGKyJSWUSeDblgtmAujQMj3Sx5WBN8UdXtoa9Vi1i3HrAxogzgp1gNjrONayK+b49oU73IY4ce0BtinQuzFs4RkYrAOcBcVV0VakfzkPtkTagdf8OsicLI1QZgVZ7r6yIiH4VcaJuBoXEeNzj2qjxlq4D6EeuxfptC26yqkWIaedxzMfFcJSKfiMjRofKHgaXA+yKyXERuj+8ynETiAuEUl7xvczcBLYAuqlqNsEsjltsoEawGaopI5YiyhgXUL0kbV0ceO3TOWrEqq+r32IOwF7ndS2CuqsVAs1A7/lqcNmBuskgmYBZUQ1WtDoyMOG5hb9+/YK63SBoBP8fRrsKO2zBP/CDnuKr6tar2wdxPUzDLBFXdqqo3qWpT4EzgRhE5qYRtcYqIC4STKNIwn/6mkD/7nmSfMPRGPhsYLiKpobfPMwrYpSRtfAU4XUSODQWU76Pw/58JwHWYEL2cpx1bgG0icjhwZZxteAkYICItQwKVt/1pmEW1U0Q6Y8IUsA5ziTWNceypQHMRuUhEyovIhUBLzB1UEr7ErI1bRaSCiHTH7tHE0D3rLyLVVTUT+02yAUTkdBE5LBRr2ozFbQpy6TlJwAXCSRRPAAcA64EvgHf30nn7Y4HeDcD/AZOw8RrRKHYbVXUhcBX20F8N/IYFUQsiiAF8qKrrI8pvxh7eW4F/h9ocTxveCV3Dh5j75cM8Vf4C3CciW4G7Cb2Nh/bdjsVcPgv1DDoqz7E3AKdjVtYG4Fbg9DztLjKquhsThF7Y7/40cKmqLg5VuQRYGXK1DcXuJ1gQ/gNgG/A58LSqflSStjhFRzzu4+xPiMgkYLGqJt2CcZz9HbcgnDKNiHQSkT+JSLlQN9A+mC/bcZwS4iOpnbLOwcCrWMA4A7hSVb8p3SY5zv6Bu5gcx3GcqLiLyXEcx4nKfuViql27tjZu3Li0m+E4jlNmmDNnznpVrRNt234lEI0bN2b27Nml3QzHcZwyg4jkHUGfg7uYHMdxnKi4QDiO4zhRcYFwHMdxopK0GISINARewFI4KzBKVf+Zp84thIfWlweOAOqo6kaxGcy2YjlYslQ1PVltdRyneGRmZpKRkcHOnTsLr+yUKpUqVaJBgwZUqFAh7n2SGaTOAm5S1bmhfPhzRGRaKMslAKr6MJbWFxE5A7hBVTdGHOOEkuaCcRwneWRkZJCWlkbjxo2JPd+TU9qoKhs2bCAjI4MmTZrEvV/SXEyqujqY/CM0OcsicueWz0s/QhOqOI5TNti5cye1atVycdjHERFq1apVZEtvr8QgRKQx0B5L/Rtte2WgJzA5olixyULmiMjgZLfRcZzi4eJQNijOfUq6QIhIVezBf72qbolR7QzgszzupWNVtQOWJvgqEekWbUcRGSwis0Vk9rp164rXyPvvh/feK96+juM4+ylJFYjQhOWTgfGq+moBVfuSx72kqsGMU2uB14DO0XZU1VGqmq6q6XXqRB0MWDgPPQTTphVvX8dxSo0NGzbQrl072rVrx8EHH0z9+vVz1nfv3l3gvrNnz+baa68t9BzHHHNMQtr68ccfc/rppyfkWHuLZPZiEmAMsEhVHyugXnVsUpWLI8qqAOVUdWvoew9sBq/kkJoKu2LNMeM4zr5KrVq1+PbbbwEYPnw4VatW5eabb87ZnpWVRfny0R9z6enppKcX3jly1qxZiWlsGSSZFkRXbLaoE0Xk29Cnt4gMFZGhEfXOBt4PTQIfUBeYKSLzgK+At1U1eTOUpaZCIW8bjuOUDQYMGMDQoUPp0qULt956K1999RVHH3007du355hjjmHJkiVA7jf64cOHM3DgQLp3707Tpk0ZMWJEzvGqVq2aU7979+6cd955HH744fTv358gG/bUqVM5/PDD6dixI9dee22hlsLGjRs566yzaNOmDUcddRTz588H4JNPPsmxgNq3b8/WrVtZvXo13bp1o127drRu3ZpPP/004b9ZLJJmQajqTOKYiF1VxwHj8pQtB9ompWHRqFjRLQjHKSnXXw+ht/mE0a4dPPFEkXfLyMhg1qxZpKSksGXLFj799FPKly/PBx98wF//+lcmT56cb5/Fixfz0UcfsXXrVlq0aMGVV16Zb8zAN998w8KFC6lXrx5du3bls88+Iz09nSFDhjBjxgyaNGlCv379Cm3fPffcQ/v27ZkyZQoffvghl156Kd9++y2PPPIITz31FF27dmXbtm1UqlSJUaNGceqpp3LHHXewZ88etm/fXuTfo7jsV8n6io1bEI6zX3H++eeTkpICwObNm7nsssv48ccfEREyMzOj7nPaaadRsWJFKlasyEEHHcSvv/5KgwYNctXp3LlzTlm7du1YuXIlVatWpWnTpjnjC/r168eoUaMKbN/MmTNzROrEE09kw4YNbNmyha5du3LjjTfSv39/zjnnHBo0aECnTp0YOHAgmZmZnHXWWbRr165Ev01RcIEAsyBcIBynZBTjTT9ZVKlSJef7XXfdxQknnMBrr73GypUr6d69e9R9KlasmPM9JSWFrKysYtUpCbfffjunnXYaU6dOpWvXrrz33nt069aNGTNm8PbbbzNgwABuvPFGLr300oSeNxaeiwk8SO04+zGbN2+mfn0boztu3LiEH79FixYsX76clStXAjBp0qRC9znuuOMYP348YLGN2rVrU61aNZYtW8aRRx7JbbfdRqdOnVi8eDGrVq2ibt26XHHFFVx++eXMnTs34dcQCxcIcAvCcfZjbr31VoYNG0b79u0T/sYPcMABB/D000/Ts2dPOnbsSFpaGtWrVy9wn+HDhzNnzhzatGnD7bffzvPPPw/AE088QevWrWnTpg0VKlSgV69efPzxx7Rt25b27dszadIkrrvuuoRfQyz2qzmp09PTtVgTBh1/PIjAxx8nvE2Osz+zaNEijjjiiNJuRqmzbds2qlatiqpy1VVX0axZM2644YbSblY+ot0vEZkTKxmqWxDgQWrHcUrEv//9b9q1a0erVq3YvHkzQ4YMKe0mJQQPUoO5mH77rbRb4ThOGeWGG27YJy2GkuIWBHiQ2nEcJwouEOBBasdxnCi4QIBbEI7jOFFwgQAPUjuO40TBBQLcxeQ4ZZQTTjiB9/LM5fLEE09w5ZVXxtyne/fuBN3he/fuzaZNm/LVGT58OI888kiB554yZQrff58zgzJ33303H3zwQVGaH5V9KS24CwS4i8lxyij9+vVj4sSJucomTpwYV8I8sCysBx54YLHOnVcg7rvvPk4++eRiHWtfxQUC3IJwnDLKeeedx9tvv50zOdDKlSv55ZdfOO6447jyyitJT0+nVatW3HPPPVH3b9y4MevXrwfggQceoHnz5hx77LE5KcHBxjh06tSJtm3bcu6557J9+3ZmzZrFG2+8wS233EK7du1YtmwZAwYM4JVXXgFg+vTptG/fniOPPJKBAweyK/QC2rhxY+655x46dOjAkUceyeLFiwu8vtJOC+7jICAcg1C1EdWO4xSZ0sj2XbNmTTp37sw777xDnz59mDhxIhdccAEiwgMPPEDNmjXZs2cPJ510EvPnz6dNmzZRjzNnzhwmTpzIt99+S1ZWFh06dKBjx44AnHPOOVxxxRUA3HnnnYwZM4ZrrrmGM888k9NPP53zzjsv17F27tzJgAEDmD59Os2bN+fSSy/lmWee4frrrwegdu3azJ07l6effppHHnmE0aNHx7y+0k4L7hYEmAUBECMNsOM4+y6RbqZI99JLL71Ehw4daN++PQsXLszlDsrLp59+ytlnn03lypWpVq0aZ555Zs62BQsWcNxxx3HkkUcyfvx4Fi5cWGB7lixZQpMmTWjevDkAl112GTNmzMjZfs455wDQsWPHnAR/sZg5cyaXXHIJED0t+IgRI9i0aRPly5enU6dOjB07luHDh/Pdd9+RlpZW4LHjwS0IMAsCLA4RfHccp0iUVrbvPn36cMMNNzB37ly2b99Ox44dWbFiBY888ghff/01NWrUYMCAAezcubNYxx8wYABTpkyhbdu2jBs3jo9LmLMtSBleknTheystuFsQEBYFj0M4TpmjatWqnHDCCQwcODDHetiyZQtVqlShevXq/Prrr7zzzjsFHqNbt25MmTKFHTt2sHXrVt58882cbVu3buWQQw4hMzMzJ0U3QFpaGlu3bs13rBYtWrBy5UqWLl0KwH/+8x+OP/74Yl1baacFdwsCwi4mFwjHKZP069ePs88+O8fVFKTHPvzww2nYsCFdu3YtcP8OHTpw4YUX0rZtWw466CA6deqUs+3++++nS5cu1KlThy5duuSIQt++fbniiisYMWJETnAaoFKlSowdO5bzzz+frKwsOnXqxNChQ4t1XcFc2W3atKFy5cq50oJ/9NFHlCtXjlatWtGrVy8mTpzIww8/TIUKFahatSovvPBCsc4ZSdLSfYtIQ+AFoC6gwChV/WeeOt2B14EVoaJXVfW+0LaewD+BFGC0qj5Y2DmLne577FgYOBBWrIDGjYu+v+P8QfF032WLoqb7TqYFkQXcpKpzRSQNmCMi01Q1b6ToU1XNNSpERFKAp4BTgAzgaxF5I8q+icEtCMdxnHwkLQahqqtVdW7o+1ZgEVA/zt07A0tVdbmq7gYmAn2S01JyB6kdx3EcYC8FqUWkMdAe+DLK5qNFZJ6IvCMirUJl9YGfIupkEENcRGSwiMwWkdnr1q0rXgM9SO04xWZ/mpVyf6Y49ynpAiEiVYHJwPWquiXP5rnAoaraFvgXMKWox1fVUaqarqrpderUKV4j3cXkOMWiUqVKbNiwwUViH0dV2bBhA5UqVSrSfkntxSQiFTBxGK+qr+bdHikYqjpVRJ4WkdrAz0DDiKoNQmXJwV1MjlMsGjRoQEZGBsW23p29RqVKlWjQoEGR9kmaQIiIAGOARar6WIw6BwO/qqqKSGfMotkAbAKaiUgTTBj6Ahclq61uQThO8ahQoQJNmjQp7WY4SSKZFkRX4BLgOxEJMrT8FWgEoKojgfOAK0UkC9gB9FWzVbNE5GrgPayb63OqWvD49pLgFoTjOE4+kiYQqjoTKDDznao+CTwZY9tUYGoSmpYftyAcx3Hy4ak2wC0Ix3GcKLhAgHdzdRzHiYILBLiLyXEcJwouEOAuJsdxnCi4QIBbEI7jOFFwgQC3IBzHcaLgAgFQoYIt3YJwHMfJwQUCoFw5EwkXCMdxnBxcIAJSU93F5DiOE4ELREDFim5BOI7jROACEeAWhOM4Ti5cIALcgnAcx8mFC0SAWxCO4zi5cIEISE11C8JxHCcCF4gAdzE5juPkwgUiwF1MjuM4uXCBCHALwnEcJxcuEAFuQTiO4+QiaQIhIg1F5CMR+V5EForIdVHq9BeR+SLynYjMEpG2EdtWhsq/FZHZyWpnDh6kdhzHyUXS5qQGsoCbVHWuiKQBc0Rkmqp+H1FnBXC8qv4mIr2AUUCXiO0nqOr6JLYxjLuYHMdxcpE0C0JVV6vq3ND3rcAioH6eOrNU9bfQ6hdAg2S1p1CS5GL6859h8uSEH9ZxHCfp7JUYhIg0BtoDXxZQbRDwTsS6Au+LyBwRGZy81oVIkgUxcSK8+27CD+s4jpN0kuliAkBEqgKTgetVdUuMOidgAnFsRPGxqvqziBwETBORxao6I8q+g4HBAI0aNSp+Q5NgQajCzp2wcWNCD+s4jrNXSKoFISIVMHEYr6qvxqjTBhgN9FHVDUG5qv4cWq4FXgM6R9tfVUeparqqptepU6f4jU2CBbFzpy1dIBzHKYsksxeTAGOARar6WIw6jYBXgUtU9YeI8iqhwDYiUgXoASxIVluBpPRi2rHDli4QjuOURZLpYuoKXAJ8JyLfhsr+CjQCUNWRwN1ALeBp0xOyVDUdqAu8FiorD0xQ1eR68pPgYnKBcBynLJM0gVDVmYAUUudy4PIo5cuBtvn3SCIVK0JmpgUOpMBmx8327bZ0gXAcpyziI6kDUlNtmUA3U2BBbN8ejkc4juOUFVwgAipWtGUSBALgt99i13Mcx9kXcYEICCyIBMYhIgXC3UyO45Q1XCACkuhiAhcIx3HKHi4QAUl2MblAOI5T1nCBCHAXk+M4Ti5cIAKSYEEE3VwBNmyIXc9xHGdfxAUiwC0Ix3GcXLhABCQxBlG1qguE4zhlDxeIgCT2YqpXzwXCcZyyhwtEQJJcTBUrQu3aLhCO45Q9XCACkuRiOuAAqFnTBcJxnLKHC0RAkiwIFwjHccoqLhABSerm6gLhOE5ZxQUiIMkWxNatlk3ccRynrOACEZCkXkyVK5tAgGd0dRynbOECEZDEIHWtWrbubibHccoSLhABSXYxgQuE4zhlCxeIgCR3cwUXCMdxyhZJEwgRaSgiH4nI9yKyUESui1JHRGSEiCwVkfki0iFi22Ui8mPoc1my2plDhQq2dAvCcRwHgPJJPHYWcJOqzhWRNGCOiExT1e8j6vQCmoU+XYBngC4iUhO4B0gHNLTvG6qavDCviLmZktTNFVwgHMcpWyTNglDV1ao6N/R9K7AIqJ+nWh/gBTW+AA4UkUOAU4FpqroxJArTgJ7JamsOCRaIwIKoVg3KlXOBcBynbLFXYhAi0hhoD3yZZ1N94KeI9YxQWazyaMceLCKzRWT2unXrStbQ1NSEu5gqVzZxqFHDBcJxnLJF0gVCRKoCk4HrVXVLoo+vqqNUNV1V0+vUqVOyg1WsmDALQhV27jQLAnw0teM4ZY+kCoSIVMDEYbyqvhqlys9Aw4j1BqGyWOXJJYEWxM6dtnSBcBynrJLMXkwCjAEWqepjMaq9AVwa6s10FLBZVVcD7wE9RKSGiNQAeoTKkksCLYhgLohIgfBpRx3HKUsksxdTV+AS4DsR+TZU9legEYCqjgSmAr2BpcB24M+hbRtF5H7g69B+96lq8t+/E2hBRBOIJUsScmjHcZy9QtIEQlVnAlJIHQWuirHtOeC5JDQtNgnsxbR9uy3dxeQ4TlnFR1JHkmQX06ZNsGdPQg7vOI6TdFwgIkmCi6lyZVsGg+U2bUrI4R3HcZKOC0QkSbQgatSwpaf8dhynrOACEUkSg9TVqtlyS8JHgjiO4yQHF4hIkmhBVK9uSxcIx3HKCi4QkSSwF1MsC2Lz5oQc3nEcJ+nEJRAicp2IVAsNaBsjInNFpEeyG7fXSaCLKW8318JcTE8/DQ88kJBTO47jJIR4LYiBoTxKPYAa2AC4B5PWqtKiFF1ML70EEyYk5NSO4zgJIV6BCAa89Qb+o6oLKWQQXJkkid1cC3Mxbd7s7ifHcfYt4hWIOSLyPiYQ74UmAMpOXrP2Hlu2wPnnw8SJ5LIgpk+H+fOLf9xAICpVsmXFivaJZUG4QDiOs68Rr0AMAm4HOqnqdqACobxJZZ0qVWDFCrjhBticnQa7d/P999C7N1x8saXtLg47dpgglIv4hatViy0CW7bAtm2QlVW88zmO4ySaeAXiaGCJqm4SkYuBO4H94n03JQVGjoRff4W7PzuVPZl7GDRIycyE776DmTOLd9xgNrlIqlWLbkGohoWjpN1gd+xI6JxHjuP8gYlXIJ4BtotIW+AmYBnwQtJatZdJT4crr4Qnv+7MUEbyxRfCyJEWWH7qqeIdM5pAVK8eXQB27AhbDiVNxXH22XYtjuM4JSVegcgKZV7tAzypqk8Baclr1t7ngQegTtUdjOYKevfI5Ior4M9/hsmTYfXqoh9v+/boFkQ0F1NkWUnjECtWlCx24jiOExCvQGwVkWFY99a3RaQcFofYbzjwQBh54ce04xtG/mMrIvCXv9ib/b//bXWysnL3gt2wAe69F/7xj/zHK4oFkUiB+P13yMgo2TEcx3EgfoG4ENiFjYdYg00B+nDSWlVKnNVrF9/QgYavjQCgWTPo0cMGsZ19tmVkrVYNjj0WBgyAxo1h+HATibzB7B07wl1cA+KxIErqYtq2zeIpCRrO4TjOH5i4BCIkCuOB6iJyOrBTVfebGEQOZ59tT/5774VnngHgxhvtgfvNN9CvH1x1lc3pMHkynHkmXHONuZPWrs19qKIEqRNlQaiaQAD88kvxj+M4jgNxzignIhdgFsPH2AC5f4nILar6ShLbtvcRMX/S+vWmBBUqcOqgQWzYINSoYZvzMnUq/OtfsHw51K0bLt+xI5ziOyBwManmPlaiBGL37vCERBkZZuE4juMUl3hdTHdgYyAuU9VLgc7AXclrVilSvjxMmgTdu8MVV0CPHtTcuDSqOAA0bWrLZctyl8eyILKywoPoAhLlYgqsB/A4hOM4JSdegSinqpFOlA2F7Ssiz4nIWhFZEGP7LSLybeizQET2iEjN0LaVIvJdaNvsONuYOCpXhmnT4Mkn4csv4cgj4bPPolYN3tKXL89dHitIDfndTIFAiJTMgnCBcBwnkcQrEO+KyHsiMkBEBgBvA1ML2Wcc0DPWRlV9WFXbqWo7YBjwiapujKhyQmh7epxtTCwpKeZmWrwYGjSACy/MH2jAUmnUr59fIGJ1c4XoAiECBx+c24KYN8+MmXj5/ffwdxcIx3FKSrxB6luAUUCb0GeUqt5WyD4zgI0F1YmgH/DfOOvuXerVg5dftrhE//5hJ38ETZvGZ0HESti3eTOkpVnMInLb44/DkCHxNzXSgvj55/j3cxzHiUbcEwap6mRVvTH0eS1RDRCRypilMTnydMD7IjJHRAYXsv9gEZktIrPXrVuXqGblpl07czd98AHcf3++zbEEIm8314JcTNWr2ydSINassfV4u6wGAlGxolsQjuOUnMLiCFtFZEuUz1YRSdTkmWcAn+VxLx2rqh2AXsBVItIt1s6qOkpV01U1vU6dOglqUhQGDYJLL4X77oOPP861qWlTe2PfuTNok30vigVRvboN1ot0Ma1ZY8v16+NrYuBiat7cBcJxnJJToECoapqqVovySVPVaglqQ1/yuJdU9efQci3wGtZrqnQRscRMzZqZqyniqR30ZFq50paBUBQlSB3Ngvj1V1vGKxCBBXH44ZYexDPDOo5TEkp1TmoRqQ4cD7weUVYlNN8EIlIFm8Uuak+ovU7VqjZxxPr1MHBgzvDpQCACN1Pe2eQCCgpS5xWI7GwIPGbxes4CgWjRwkIlgcA4juMUh6QJhIj8F/gcaCEiGSIySESGisjQiGpnA++rakT/G+oCM0VkHvAV8LaqvpusdhaZ9u3h4YfhzTfhkktg27a4BSItlN4wHhfThg3heHi8AhG4mA4/3JbuZnIcpyTENZK6OKhqvzjqjMO6w0aWLQfaJqdVCeKaa+ypfs89MHcudV96mcqVW+UIxPbttswrEBUqWOC6IAti925zUUW+/RfVxdSihS0zMqBLl6JdmuM4TkCpupjKLCJw1102mG7DBqTHKTRtkl2oBQH5E/YFkwUFFgSYFREpEEWxIFJTw4P33IJwHKckuECUhJNOgrFjYfVqmh6wOifdRiAQebu5Qv6U3zt3QmZm2IIAE4ygBxMULQZRtSrUqmVdXX0shOM4JcEFoqSceio0akTTXz9n+XKzCAqzICIFIrAm8gpEYEHUrVs0F1PVqmbgNGjgFoTjOCXDBaKkpKTAFVfQ9KdPctJ+F8XFFCkQeV1Mqalw2GFFczFVqWLfXSAcxykpLhCJYNAgmpZbBVhPpoIEIq+LqSAL4qCD7FNUFxO4QDiOU3JcIBLBIYfQ9MTGACxbvLvYFkRegahbF+rUKZ5A1Du9s1AAACAASURBVK9vMYjs7KJfjuM4DrhAJIym151Bbdbxj7u25sQMimpB5HUxHXww1K5tYyLiedDndTHt3h1//MJxHCcvLhAJomLvk3jxyH+w4Oca3Hu35bgoKEgdzGEdKRBVq0K5cuFeTIEFsWdPfBMJ5XUxAcze+7NpOI6zn+ACkSjKlePU6bdyX/XH+G2LjT+M1s21WrXcc0dHCoSILX/7zYLdgUBAfG6mbdvCFsQxx8Ahh9i82XfeCbt2lfD6HMf5w+ECkUjq1OGvH53C6eWmUqXcdiqlZOarkjdhXyAQQRqO6tVhxQqzGiIFIh5X0e+/hy2IunVh4ULLBvLAA3DccbB1awmuzXGcPxwuEAmmXPu2TH5+G/OzW1Pu4Yfybc+bsC+YLCglxdarV4clS+x73boWg4DCLYjAKgkEAmwCorFj4ZVXYO5cOP98G5TnOI4TDy4QSSD14gto2reLzR0xb16ubZE9lYJlUAYWqF6xwr4XxcW0a5dZHYGLKZJzz4Vnn4X33oPLLw/HPxzHcQrCBSJZPPmk5by47LJcU8JFsyAiBaJ69XCPpaAXExTuYgoyuUZaEJEMGgT33gsvvACvvx69juM4TiQuEMmiVi17bZ83D669Nuepn3dWuWgWREDdutYTqkqVwi2IIOgdSyAAbrzRlosXF+E6HMf5w+ICkUzOPBNuu82EYtAgyMqKGqTOa0GApQavUcO+xzNYLhCIaC6mgKpV7fiexM9xnHhI2nwQToi//936u95zD2zbRrVnJwIpuQSiWbNw9UAgDjrIur1CfAJRmIspoH59T8HhOE58uEAkGxG4+27LvDdsGGnnvwacV6iLqW7dcFmdOoVPHxqPiwlsAJ1bEI7jxIO7mPYWt9wCzZtT7sG/kZamhbqYIgWidu34LYiCXEwQztHkOI5TGMmck/o5EVkrIgtibO8uIptF5NvQ5+6IbT1FZImILBWR25PVxr1KSgrcfjt88w3VUnexebNNFrR7d3SBOPjgcFlRYhDxuJjWrIGsrKJfguM4fyySaUGMA3oWUudTVW0X+twHICIpwFNAL6Al0E9EWiaxnXuP/v2hYUNq7cxg9uyw2ygeF9OOHeG5rqNRFIHIzs49Y53jOE40kiYQqjoD2FiMXTsDS1V1uaruBiYCfRLauNIiNRVuuYW7f7+N+fPhoousOB4XExRsRcTrYgqS+LmbyXGcwijtGMTRIjJPRN4RkVahsvrATxF1MkJlURGRwSIyW0Rmr4t34oTSZNAgzq3zKf849ClmzbKiSIFo2NC6uB5xRLgsntHU8XRzBbMgwAXCcZzCKU2BmAscqqptgX8BU4pzEFUdparpqppeJ3iS7stUrgyPPsrNq65mSJdvAevSGnDIIbB6NfToES6LJRA//BBOA75tG1SsaOJSEC4QjuPES6kJhKpuUdVtoe9TgQoiUhv4GWgYUbVBqGz/4eKLkXPO4cm5x/DJc8vo3Dn35lq1wmMgIHq6jaVLoW1buOsuW4+cLKggatc2T5ePhXAcpzBKTSBE5GARewyKSOdQWzYAXwPNRKSJiKQCfYE3SqudSUEERo6kfI00uv3zXGTjhgKrBxbGl1/aUhWGDLFeUAtCfcTyZnKNRblyUK+eWxCO4xRO0gbKich/ge5AbRHJAO4BKgCo6kjgPOBKEckCdgB9VVWBLBG5GngPSAGeU9WFyWpnqVGnDowZA336QOPGcPXVcNNNYXMhgurVLVPHU09Z1Vq14MMPreoPP1ideAUCfCyE4zjxIbof5X5OT0/X2WVtjs2FC+H+++Gll6zr0pQp0KVLvmpZWdZL9qWXLIFfx45w6qnmYtq6FS64wFxQX31V+Cn79rX5IQJxcRznj4uIzFHV9GjbSrsXk9OqFUycaE/sAw6A44+HCRPyVStfHl580fL/Afz733D44fZ96dKiWxAZGT4vhOM4BeMCsa/Qrp29/h91lJkKvXvD9Om5nuIVKsBrr8FPP5k4BEn+fvih6AKxY0e4B5TjOE40XCD2JWrXhvfft0mk586Fk0+Go4+G77/PqVKunMUgAA47zJY//BB/LyaI3dU1Oxt++62E1+A4zn6DC8S+Rmoq/PWvsHKl+ZGWLYMOHeDxx8NTzYWoUsVGRv/4Y9EsiFijqR96CBo1ip059v774YkninY5juOUXVwg9lUqVbIJpBcssFFzN95o8YklS3JVa968eC4myD0WYvt2ePRRO87o0dH3e/ppeOaZYlyLk1SmT4ezzsr3/uA4JcYFYl+nbl2bRHrcOOvx1LYt3HEHfPABrF9Ps2amGUVxMdWrZ8tIC+K552DDButG++yz+bO9rl9vCf5++CE8G56zb/D++/Yn4u5BJ9G4QJQFROCyyywWceaZ8Le/wSmnQJ06NF/zCb/9Bnv2xG9BpKba4LtAILKyzHo45hh47DELgr/9du59vvsu/H3u3MRclpMYghQsZSEVmVO2cIEoSxx8sA2EWLsWpk2DLl1oPmtczuZ4BQJyD5Z76SULedx2G5xxhm17+unc9SMFYs6cYl+BkwRcIJxk4QJRFqlTx3o4/eUvNFs3K6c4XhcTmAgsWWIxhXvuseyxp59u4y2GDDG3xY8/husvWGC9pxo2dIHY11i71paRubocJxG4QJRl+vShSeovpMgeoGgWRJMmNsDuL3+xaU8ffdS60ILFxsuXt05UAd99B0ceCenpUJTB6jNnwsbizArixI1bEE6ycIEoy1SvTmrvk2lSbhVQNIG480544w1Ytcq6tfbqFd52yCFw0kkW+ATrHbNggQlEx45mWWzeXPg51q2zjld//3sRrskpMoEF4QLhJBoXiLJO374037MIyONiCiLNMSafPuggizc0apQ7tXjAaadZj6WlS01Etm2D1q3NgoD4AtXTppm4fP55Ea/JiZvt28OzCbqLyUk0LhBlndNPp1n5lQBU3b7WTIOWLe3Jf/rpcP31xTps7962fPvtcIA6sCAgvjjEu+/acu5cyMwsVjOcQoi0GtyCcBJN0tJ9O3uJKlVo0bYSzIG0048H/QFOPNHygy9fbjnCW7SAa64p0mH/9Cfb7e23oXt3K2vdGtLS4NBDC49DZGebQBx4oOV8WrjQ0k05icUFwkkmLhD7Af3vbQ79h3HYgJ5w3VSLQIMNjvj5Z7Mi1q2zz9Kl1h2paVPo3Nnmo4jmY8LcTE8+aVOZNm5s4gBmRRRmQXzzjZ1u+HD7fPXVH1sgduywketBgsVEEcQfatVygXASj7uY9gOqnXYcV276O/LE42FxAEhJsRzh7dtbIqWJE20Y9Jw58PDDcPbZ0K0bzJsX9binnQa7d5sVceSR4fL0dNOZgrLBBu6loUMtB2EwG15hrF8PPXvCt9/GV7+s8OijJpC7diX2uIEotGzpMQgn8bhA7O9UrWpP59Wrrb/pl19aN6QdO6wf66JFlgwwPR369bOMfaHX0mOPNatB1dxLAZ062fKVV3KfatUqM1rABKJjR8sU0rlzfBMZBfu9955p14aCZ2ItU8yZYwHlVasSe9zAgmjZ0sTC5/hwEokLxB+BlBQbhR3pSipf3gY8/PADDBsWfs2//XYLcA8ZQurqVfToYdUjLYju3e1z7bUwf76V/fOf5oY68USLN3z+uVkCYAKxcKHNfFcYn31m8yb98otNixEITllnYWjS3GXLEnvcdevMBdi0qc1RHvRocpxE4ALxR6dmTfi//7NX9+XLYfFiGDAAnn8e2rTh7EO+QCTcvRVMWyZOhBo14JxzTF+uvx6OO87elNu3twd7pECoxtfzadYsO86IEWZJ3HdfUq56r7JzZ1gYli9P7LHXrbOB9XXqhNcdJ1EkTSBE5DkRWSsiC2Js7y8i80XkOxGZJSJtI7atDJV/KyJlbJLpMk6LFjBypAlFq1Zc9OTRLDn3rzSrmzuFa9268PLL5jJ58EHTlA8/NBFo2dJSeRx1lNUNXFKFuZk2b7YutV27wuDBcOGFFiqJx/LYl10rixeHU3EnWiDWrrUxLbVr27rHIZxEkkwLYhzQs4DtK4DjVfVI4H5gVJ7tJ6hqu1iTaTtJpnFj+OQTZNgwmk1+0ObOzpPi9ZhjbPrshx6CMWPMsmjRwkRi0SJbB3t4/elPhQvEF1/Yg/6YY8wbdu21Fip59dWC9/vXv+wNel99OC4IvSIdcEByXExuQTjJImkCoaozgJhZeFR1lqoGGey/ABokqy1OMalQwVKLz5oF1avbwLvevS1HR1YWrFrF+dvGcmurt3PyOIGFPIIusQHxBKpnzbJ8UF262PrRR5uw/Oc/4TrLl1vHrOCNfP58uPlmC2hPmlSyy926NRxTKQ7bt0cvX7jQxPL445NnQexNgdi0ySY43F/iQ05s9pUYxCDgnYh1Bd4XkTkiMrigHUVksIjMFpHZ6/z1KTkcdZQNhw7myu7TxwSjcWMYONDmqHgn4vZlZuZ7nT/uOMv+8eabsU/z2Wc2H1IgLiJw8cXmusrIsC63ffrAJZdA3742Qc7FF1sspHlzE4542b3b0ocEqMIFF5iQxePSysvKldaOyZPzb1u40Np3+OEmEIl0h+W1IPaGFTV2rE1wOHNm8s/llC6lLhAicgImELdFFB+rqh2AXsBVItIt1v6qOkpV01U1vU7wX+IknmCu7J9+gilT7Mk8YoT5k9q0sSf299/bEOu2be2JddxxNj3dzJkMbP8N7VpnMmhQ9Dmvs7LMxXTMMbnLL77YHqj//a/FIxYsMIF45RXrufPdd+beuvxy2z8yRXk0srKsd2/TpnDYYdaJC2zCvnfftXEKxXnwzZhhonPfffkFYOFC89A1bWq9jIKuqarW+7i4/P67WS0HHWSiWqHC3rEgZsywZVFybE2ebHNeOWUMVU3aB2gMLChgextgGdC8gDrDgZvjOV/Hjh3VKQX+9z/VunVVDzpINSVFtX591WHDVI84QtWeg6qgC8u30UqpWdq7t2p2du5DzJ1r1SZMyH/4o45SPfRQ1dRU1QsusLK33lKtVk31mmtsPSNDVUT17rtjN3PDBtWWLe08Xbqo1qmj2qCB6syZqtWrq3btaue46aai/wRXXx2+1KlTw+W//27tGj5c9e23bftnn9m2//xHtUIF+/mKw4oVdrwxY2y9Xj3VgQOLd6x4yc5WrVXLznvmmfHv16OH7fPTT8lrm1M8gNka45laahaEiDQCXgUuUdUfIsqriEha8B3oAUTtCeXsIzRsaFbFzp1w0UX2mv+3v9mr84IFltZ1yhRadq7Kw5k3MHUqXHFFOCgN5l6C/BYEmMWwahVUrmzjLcBGef/6a3i9fn1LUf7ii7FdOK++akbOiy/a2++0afYWfuyx9vb//PN2/g8/LPpP8PXXFjNp2NB6dQUsWmTtCSwICMch3n7bvHF5LZZ44xSBJXLQQbasUyf5FsSiRRbvSUuz3zDabz1njnVRDsjKsvgShO+zU0aIpRwl/QD/BVYDmUAG5kYaCgwNbR8N/AZ8G/rMDpU3BeaFPguBO+I9p1sQpUxWVsHbt27V7OO76xBGampKpoLqwQebhdCokRkeeS0LVdX1682CePHFgg8/blzuN/S8nHmmHSfyHF9+aW149llbv+8+e+Nfv77gc/36a/j7rl2qFSua5fHEE7nb8Pzztv7996o7dtix773X2nDQQbbt2mvDx5o2reBriOStt6zuF1/Y+kknqR59dOH7lYRnnrFz3nKLLZcuzV+nRw/VAw9U3b3b1r/+OmxdXX11ctvnFB1Kw4JQ1X6qeoiqVlDVBqo6RlVHqurI0PbLVbWGWlfWnO6sqrpcVduGPq1U9YFktdFJMCkpBW+vWhV5ZyojL/yItXtq8UK5AZyS+glpW37mwMq7uHLADmT+PPj001xdZGrVsiBw//4FH/6cc6wr6bhx+bft2GEWwxln5B5Q3rmzjdoeHOoKcdJJ9ij7+OPY55k2zQamB/mlFiyw2EWnThYLqVnTYhHZ2WZEVahg8Y5KlczSWbbMLJm1a63XVqQvP+hJPG1auOyXX2zcyUcf5W5HYC3sTQtixgybUOrii209Whxi0SLr6fTpp7YeLFu2LN3A9rp1ltQ4Vm8zJz+lHqR2/mAccABMnEj1H+dwyfW1eGHnBbz/fQPmLa7EHQ9Utox23bpZl6IiZrZLS7MH13/+E3a/BEyfbiJxxhn594sUjE6dbOKlwM306afm4op8qEyYYCISdL/9+uvc+959t7lYrrzSxKNFCxMJMDfT8uXh459/vmW+3bHD1j/4wJaffBI+31tv2fW88ELudgfXGPTNSLZAqJpAdOtmLrPAzRTJtm3WjwGsNzTYb9i0qV3r/PnxzUaYDN54w7ITv//+3j/3li3h36Us4QLhlA6HHWYpTtessdfsp5+2bkovv2ypP1591Z7mv/5q/9EPPph7IMW2bTB+fHgUWoibbjJdefLJ3Kd7803LW3j88QU3q0IFewBOn25da885x2IWwWC9rKxwV92XX7b12bPNygkS6V57rXX4GjUKpk61h2nAn/5kFsSHH1r9fv3sGHPn2k+xYIG18/PPLS4C4QfaW2/lHnuwbp1ZJcFMgrVr28M32C/RrFxp2eO7dTNjsXPn/AIR9AqrXNkeyKomEMcdZ7Ge7GyLPe0N8sZHFi+2ZRAP2ZtceaWN7ylzY0di+Z7K4sdjEPsRzz2nWq5c2HkdfE46yRzgNWrYekqKOf83bVL99lvVMWP0rJO3aM2aqtu22aH27LEePuedF9+pH3nEDt22rWqVKhYbOeEE2/bRR7atXz9bTptm9U49NfcxsrPDfvr/+79w+f33W1m1aqqDBqmuWWPrDz9sMRZQveOOcBwiM9P8+QcfbGWffho+1qWXWuwm4Omnrc4vvxT5146LIMbz3Xe2fued9vMHv7Oq6vjxVue662z50ku2HD1adetWq3/nnclpXyQvv2x/Ips3h8tOO83a0rVr8s8fye+/q1aubOeeNWvvnjse2Bd7MTlOgfz5z/bqPHy4LX/5xSyMhQvhkUcsney0aTZz3qOP2ii1du1g0CBu+fJ8Nm6E556zQ83972J++QXOaL0irlFwJ55oy3nzYPRom9Pio49gxQp47TXLnjpihLlYnnvO3vqDfFMBIpaCZMoUe3sMCHoybdli56lb1yyJzz8391LNmuHJ/2bMMPfVpk02nUeFCmG3DYQHyQUkezT1jBnWvpYtbf3oo+2NOHCxgb2lp6TADTfY+rBhtuzWzSyj9u3DMYlk8tZbNpDym29ytw3M4ovXe/n882b9BCP3i8M774RdlG+9VfzjlAqxlKMsftyC+AOwY4fq2rW5y2bNUr3tNnsFnzFDtXZt7Vrpaz20YZY+d/YbehHjtRxZuo5aNvBgypQCT7Fnj2rz5qo33mjr//tfeIxFo0aqZ5xh5ZdcYuVQ6CFz+OKLsDEUvOlfdJHqIYfYmIzzz7eyli1Ve/a08RMiNobjlFOsXQEdO6r26hVeD6ybDz6Iry1FISPDrJjIsQ8bNtj5/va3cNl556k2a2bfO3e27XXrhnuOXX+9aqVK1vMrmbRoYed+4glb37HDDNIjj7Tyzz8v/Bh79qj+6U9Wf+HC4rflwgtVa9dWPfZYO/++BgVYEKX+UE/kxwXCUVXVzz7TqeXPyOWZOrHTFtXJk1XbtbORXqtXF3iIvN1te/RQrVrVjvXcc1YWDHwD1Z9/jq9pa9da/SOOCJeNGBE+TtDd9sorVdPS7CHbubOVPfmk1Vm82NYbNTI3U8CCBbZ94sT42qJq7o877jAv3cMP53ZhBfz4o2rjxtaevA/Www9X7d07vN66dVhAH3jA2hPp2nvllfgf0MUlEC5QHTDAyubPt/XHH7flI48Ufpz33st/X4rK9u3mphw8OOy6XLmyeMdKFgUJhLuYnP2PY46h14RLWF/nCFY8MIHvFyqvf5hmEecJE2x03BVX5I5irlpl/WirVYMqVZCqVSzf+P/+B5jHa9s265Z6xhmAKiefbC6XevXsEw+1a1s30V69wmVHHx3+fvLJtuzWzbxhX31FzqRNZ55py9dfNxdVkKgvoKguJlXz0D3wADz1FNxyC5xySm4v3I8/motl61YLrAcp3ANOOsm6BO/cae6mH36wnFNgebMATjghXL9rV1tOnx5fG4tD0P34wAPDLqbAvdS9u7n54glUjxxp96tOndjdcz/8MDwZVDTefdf+3M47z3JdQr6kyPs2sZSjLH7cgnDiIhjNdsst9v0vf7GRbgccoHrFFfY6PWSIrR9wgOp99+mOLbu1Ro1QsHrUKIuAPvusjhplb/ZFYc0ac3kE7N5tbpcmTcJlP/8cfnuNfKtv397eSIP4feS5MzOtbPBgszLWrDELIdrgQ1XVBx/UHBdRdrbqhx/a+vjx4TqXXGKWQywXS2BFvfeeDZqLTP2haoPkggFzASeeaO6q7dsL/p3mzDG3Waz2x+Kuu+z3ufpq8yju2hUeAPn776oXX2znL+i4GRkWUL/1VtVzzlFt2jR/nblz7fgFDU686CIzWDMz7XyHHZbbLbgvgLuYHCeCPXvCyYGCnlCXXJI/KdKqVRYUANWjjtLZb/6iy+58ztZr17bl0KEJcajfeKO5PyI57DB7OEc+YCdMsI5cd91lsYY9e3Lv06BB+LKCT7lypn8VK5q4pKer9u9vD8wLLww/KPfssf2DOMOmTaaPQ4bEbvfvv5u4XXddeGR3YaPAP/5Yc8UHorFrl8VlwET5yy9zb9+40XJpTZ6cf99TTjFP4sSJtv8339iDunFj2x6MBl++PPb5hw+3OsuWqT72mOZzI27fnjvVWLR8Wjt22P27/PJw2fXX232I7PlV2rhAOE5esrJUf/jBcmoUliJk0iTrl1qliv3LnHOOPSFuu83WGzWyJ+7jj6v+85/mfJ8woeivvnkYO7bgh2g0Vqywt/oXXzTr4qGHrFvpbbfZ57rr7A2+Rg3V7t3tAR/JDTdYwsLffjNDCfI/nPPSs6cFzwMfe2FpSlTt3IccktuSimTCBDvWFVeYEOTtIvrqq1Z22mm599uzx27V0KFmRYH9ju3bWztVVefNs/JYqVt277auzUHX5S+/1JwuuwHXXmtlTz2lObGNvARpViI7DUyfbmWvvVbgz7NXcYFwnJKybJnq8cfb62BmZrj8tddMMILX3chPnz75n5YLFqged5y9Su7cuVcvIZJY2hX0sho3znJktWpVuM4FQfbu3e1hHg9Bj6sRI6JvP+oo6w21Z49ZC6mpqjffHN4ejLNITc091iEI1D//vOl+5cqW8bdyZfvJVa08Lc06AkQjCGQHWXl37zZL6rrrbD3IlxXk0GrXLr+bKTvbROmII3L/frt2WWeHoUPj+pniYt061U8+Kf7+LhCOk2yysy2D3/r19lr8+OPmoK5f30bKffSRvW5WqmSvuKDaoYM90RYsUH39desutA9cRuPGYfdJPL19fvwxrInHHRf/ubp1sy6wH3+cuzx4Y48UjxNOsAGJAe3ahZMdRsZM/v1vK1uyxNaPOspiO3l7Ip11lonG7Nm5z712raV+79Ej94P9hBOsW/HmzWYwHn54OIYS9NaKdDPNmGFlI0fmv+4zz7Q2FcfAvOkm6yUWdMJbudKst1q1bCBicXCBcJzSYM4cc/hHWhU9e1r0+PXXw6PBg09qqqV63bXLfD/vvWdO9qVL8wcbksitt1pzype3psZD8+aa4xKKl7lzVRs2tP3OOssC2tnZ5q1LS1PdsiVc929/s3pr1phFEYxLqVfPDLiAQYNUa9YMP3yHDg3/vJFv2atXW2bfgw+2UFPA0KEWksoblA9GjffvbzGdyG66P/xgx3/ssXDZuefa7c3rwlMNd1cu6vvAp5+Gr+WQQ8x1Vq+ejbSfObNox4rEBcJxSpMNGyww8OqruR/0q1bZ4IPx4+0/PMjfUa+eiUWkeKSlqZ59tvlOMjIKFoxdu8zBPniw5ZyI5eiPwZw5muMhi5fA5fPoo0U6lW7fbm/gwRiTP/3JDK/AnRMwe7bmxA3eeMO+f/SR6lVXmftn2zYThSOOyD0u49lnwz9hZIp2VTPcqlc3N9ro0eZWC3o/5eXdd8PHiXR1BbRvb9aKqsWBypWzmE80AovrqacK/m127gzf5sxM1TZtTFA//9w6MIAZqAsWFHycwnCBcJyywptv2hPullvsqfTll+Y3GTzYngbBU6pCBet7+fDD4SD79u3mzqpb1+pUqmTLatXsaRVnzCM723JGzZ8ff7ODLrLTpxfjmtU0dPRoc+0cfHD+eSb27DE3ymWXmZslNdUuNwj6Tppkva3ydv0N3FWRVkUkH3wQ7nsQ1IsWZN+82R76zZtH754bWDjHHmuDBVNSYs8UmJ1tLqZoM/KtW2e3vksXs+AOO8wE8V//suO//LLV27RJ9e9/z239FBcXCMfZH8jONj/MU0+p3n679XcFC56PHWvBA7CO9u+9Z6+d06aFLZN27VQXLbIuSvPnq77wgvlk2rY1P83jj0d/HY3TvTVvXok7bhXIBReYayU9PRzryMw04Qge8sOG5W7D77/bg/2YY2Ifd+dO8+V/8UXBXV8nTAiPYs/LmjXWvu7d7eccNqzgaxkyxKymyC7MmZl2K8uXN6G56SaLdQRdlU8+OTm/rwuE4+yPZGebMKSl2b9y69bmd4nG66+Hx25EfmrUsIEDQSQXrB/sq6+avyhITZLXKf/77xaBbd3aXoWL6MYqDqNHh5sYmRF28GDNFwOIpEePgucqLw2CbrozZoTLhg2zshdeCJft3m09pzt3ji1OJcUFwnH2Z1assNfbvEOW8/LLL6r33GNdkyZNslf+SOvgp59U//GP3KPtOnWy7kJNmlgXn0CUatWy7a1aWcT41FNNJL7/3p7I6ekJz229alW4WdOmhcu3bLHBcGWJTZvMDXXHHbYeDDIsSpA/UZSaQADPAWuBBTG2CzACWArMBzpEbLsMJ6Oo5AAAC3dJREFU+DH0uSye87lAOE4C2L1b9Z13wq+sX3xh8Yxjj7Wh10F/1hkzTDDGjDGRaN3aYiPVq4fjJYMGWXbDcePMPVYcdu60eMyaNdqihblg9qWRyMWla1cLOnfpYj9f+/Z7xRDLR2kKRDegQwEC0Rt4JyQURwFfhsprAstDyxqh7zUKO58LhOMkiUmT7HGRkmLdjvKOPh8zxp7cl11m3YW2bjUnekpK+LW/XLncr/6qJkbr1tlAxMgRb6pm3UyYEI6tlCunz7R4TK8/8dvcKVG3bMndJ7aM8OijdlmdO1uuqLy9rPYWpepiAhoXIBDPAv0i1pcAhwD9gGdj1Yv1cYFwnCTyxhvWBzYW0XJSbdxoD/MlS8zCqFHDuiht3Wqj0oMJNYJP48YWjW3fPuzGatvWEivddVd4wAXY98BSqVw594i5aEyZYv1og65ApcyePcUf3JZIChKI8glJCVt86gORU3lnhMpiledDRAYDgwEaNWqUnFY6jhPKc14Aqan5y2rUsA9YnvJOnSzvdWYmLF8OQ4bYFHXVqtmsgfPmWXm9ejbpdbdu0Lev5VkHuPdeyyk+dapN81ejBrRoYdO29e9vU/MdcYRNHL56tc02eNJJVt63r00Nd/75cMcdcP31lqt83jzbN8hTHg1Vm8HwiCOgYcNi/Xx5KVfOZtnbp4mlHIn6ULAF8RZwbMT6dCAduBm4M6L8LuDmws7lFoTj7ONMn25up0MPzd2Fp6Ts3m2ZBgPr4rDD7CNiyZhq1bL1n35SHTgwt9USjGK/777oVtCPP1pPL7Bhy8H0gevWWcD/5pvN7fbwwxZlPvpoa0th3YO3bLFux6UM7mJyHGefYcmS5PlW5syxh252tkWyBw2yx1zt2uHcFtnZ5o667z7LTZ6REQ6+V6pk3YarV7dBF82bW37uatUsNW7HjprTFbhixfA+gdDUqmU5tiDcRSkaH35oEeqUFOsEEI2dO3NHrRcutOvJO9hDNXcCySJSkECIbU8eItIYeEtVW0fZdhpwNRas7gKMUNXOIlITmIMFuAHmAh1VdWNB50pPT9fZs2cnsPWO45R5PvjA3EItWhRc7913zY2UnW2f7dttKr1ateDOO20qwF274NZbYdIkOPtsuPpqaNXKptTbscOmsQMYPBhGj4Zx4+zco0eba6xRI3PFTZoEzZvbPhUr2tR3kf6mTZugSxdYtsxccDVrwiefQEqKTd03diwMGGB1//EPeP99eOstqFSpyD+PiMxR1fSoG2MpRyI+wH+B1UAmFkcYBAwFhoa2C/AUsAz4DkiP2Hcg1v11KfDneM7nFoTjOPsEu3eblRFYFgceaONDWra0QP1VV9lgw08+MTfY4MHhfffssZSt5ctbUqpevWy8yb33Wlen7t0tKP/991YGqn37Fj4OJgaUpgWxN3ELwnGcfYbffoO77rKJvM89Fw44IHq922+Hhx6yuhdfDC+/bBbLiBFwzTX56//yC7Rta5bEb7+ZJTF6tFkXxaAgC8IFwnEcpzTZvRvOOst6YgVcdBG8+CKIRN/n3XfhtNPMlfXUU+FeXsWgIIEo7W6ujuM4f2xSU63b7v/+B1OmwI8/woMPxhYHgJ49Yd066+ZbUL0S4gLhOI6zL9CoEVx7bfz1a9ZMXltCFN8ucRzHcfZrXCAcx3GcqLhAOI7jOFFxgXAcx3Gi4gLhOI7jRMUFwnEcx4mKC4TjOI4TFRcIx3EcJyr7VaoNEVkHrCrm7rWB9QlsTmni17Jv4tey77I/XU9Rr+VQVa0TbcN+JRAlQURmx8pHUtbwa9k38WvZd9mfrieR1+IuJsdxHCcqLhCO4zhOVFwgwowq7QYkEL+WfRO/ln2X/el6EnYtHoNwHMdxouIWhOM4jhMVFwjHcRwnKn94gRCRniKyRESWisjtpd2eoiAiDUXkIxH5XkQWish1ofKaIjJNRH4MLWuUdlvjRURSROQbEXkrtN5ERL4M3Z9JIpJa2m2MFxE5UEReEZHFIrJIRI4uq/dGRG4I/Y0tEJH/ikilsnJvROQ5EVkrIgsiyqLeBzFGhK5pvoh0KL2W5yfGtTwc+hubLyKviciBEduGha5liYicWtTz/aEFQkRSgKeAXkBLoJ+ItCzdVhWJLOAmVW0JHAVcFWr/7cB0VW0GTA+tlxWuAxZFrD8EPK6qhwG/AYNKpVXF45/Au6p6ONAWu64yd29EpD5wLZCuqq2BFKAvZefejAN65imLdR96Ac1Cn8HAM3upjfEyjvzXMg1oraptgB+AYQChZ0FfoFVon6dDz7y4+UMLBNAZWKqqy1V1NzAR6FPKbYobVV2tqnND37diD6D62DU8H6r2PHBW6bSwaIhIA+A0YHRoXYATgVdCVcrStVQHugFjAFR1t6puoozeG2x64gNEpDxQGVhNGbk3qjoD2JinONZ96AO8oMYXwIEicsjeaWnhRLsWVX1fVbNCq18ADULf+wATVXWXqq4AlmLPvLj5owtEfeCniPWMUFmZQ0QaA+2BL4G6qro6tGkNULeUmlVUngBuBbJD67WATRF//GXp/jQB1gFjQy6z0SJShTJ4b1T1Z+AR4H+YMGwG5lB27w3Evg9l/ZkwEHgn9L3E1/JHF4j9AhGpCkwGrlfVLZHb1Pox7/N9mUXkdGCtqs4p7bYkiPJAB+AZVW0P/E4ed1IZujc1sLfRJkA9oAr53RxllrJyHwpDRO7A3M7jE3XMP7pA/Aw0jFhvECorM4hIBUwcxqvqq6HiXwOzOLRcW1rtKwJdgTNFZCXm6jsR8+EfGHJrQNm6PxlAhqp+GVp/BROMsnhvTgZWqOo6Vc0EXsXuV1m9NxD7PpTJZ4KIDABOB/preHBbia/ljy4QXwPNQr0xUrGAzhul3Ka4CfnoxwCLVPWxiE1vAJeFvl8GvL6321ZUVHWYqjZQ1cbYffhQVfsDHwHnhaqViWsBUNU1wE8i0iJUdBLwPWXw3mCupaNEpHLoby64ljJ5b0LEug9vAJeGejMdBWyOcEXtk4hIT8w1e6aqbo/Y9AbQV0QqikgTLPD+VZEOrqp/6A/QG4v8LwPuKO32FLHtx2Km8Xzg29CnN+a7nw78CHwA1CztthbxuroDb4W+Nw39US8FXgYqlnb7inAd7YDZofszBahRVu8NcC+wGFgA/AeoWFbuDfBfLHaSiVl2g2LdB0Cwno3LgO+wnlulfg2FXMtSLNYQPANGRtS/I3QtS4BeRT2fp9pwHMdxovJHdzE5juM4MXCBcBzHcaLiAuE4juNExQXCcRzHiYoLhOM4jhMVFwjH2QcQke5BBlvH2VdwgXAcx/n/9u6fNaogCsP484ogSgQbbSwUtRELA4KFYuUXsFAENYW1jZ0IiuAXsBJMGTGFCNqLKQIpJBGJCJZWqWxESKFFPBYzkVUuuP7LNs+v2p2dHXaKy7n3Lvc9GmSBkH5DkitJlpOsJpnt/SvWk9zr/RIWkuztc6eTvBzJ6d/sOXAkyYskb5K8TnK4Lz810j9ivj+1LE2MBUIaU5KjwEXgdFVNAxvAZVp43auqOgYsAnf6Vx4CN6rl9L8dGZ8H7lfVceAU7clYaGm812m9SQ7R8o6kidn+6ymSurPACWCln9zvpIW8fQUe9zmPgKe9H8Seqlrs43PAkyS7gf1V9Qygqj4D9PWWq2qtv18FDgJL/39b0jALhDS+AHNVdfOHweT2T/P+NL/my8jrDTw+NWHeYpLGtwCcT7IPvvc1PkA7jjZTTS8BS1X1CfiY5EwfnwEWq3X+W0tyrq+xI8muLd2FNCbPUKQxVdW7JLeA50m20RI1r9GaAZ3sn32g/U8BLUb6QS8A74GrfXwGmE1yt69xYQu3IY3NNFfpLyVZr6qpSf8O6V/zFpMkaZBXEJKkQV5BSJIGWSAkSYMsEJKkQRYISdIgC4QkadA3LRhk7UDDeAcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_LxatO5J-pp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "577a5114-cc07-4fd0-a321-cef7eea0aa33"
      },
      "source": [
        "testloss = model.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "trainloss = model.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(trainloss[0]))\n",
        "print(\"Train Acc: \" + str(trainloss[1]))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 3s 25ms/step - loss: 1.0788 - accuracy: 0.5913\n",
            "Test Loss 1.0787876844406128\n",
            "Test Acc: 0.591251015663147\n",
            "898/898 [==============================] - 23s 25ms/step - loss: 0.9884 - accuracy: 0.6276\n",
            "Train Loss 0.9883797764778137\n",
            "Train Acc: 0.6275732517242432\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swoRERVdKQ1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf858495-28c2-458e-8762-08ec93ca70fb"
      },
      "source": [
        "testlosz = model.evaluate(x_val, y_val) \n",
        "print(\"val Loss \" + str(testlosz[0]))\n",
        "print(\"val Acc: \" + str(testlosz[1]))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 3s 26ms/step - loss: 1.0889 - accuracy: 0.5893\n",
            "val Loss 1.0888645648956299\n",
            "val Acc: 0.5893006324768066\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5iaZIU6pPzk",
        "outputId": "b99483aa-71b2-4a90-fe5a-88e8e94eef13"
      },
      "source": [
        "from keras.models import load_model\n",
        "model_load = load_model('/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editAdamst120epochBS128+aug:vf_2.h5')\n",
        "\n",
        "model_load.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 46, 46, 128)  0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 46, 46, 128)  0           activation_52[0][0]              \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 46, 46, 128)  0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 46, 46, 128)  0           activation_55[0][0]              \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 46, 46, 128)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 23, 23, 256)  0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 23, 23, 256)  0           activation_61[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 23, 23, 256)  0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 23, 23, 256)  0           activation_64[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 23, 23, 256)  0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 23, 23, 256)  0           activation_67[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 23, 23, 256)  0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 12, 12, 512)  0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 12, 12, 512)  0           activation_73[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 12, 12, 512)  0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 12, 12, 512)  0           activation_76[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 12, 12, 512)  0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 12, 12, 512)  0           activation_79[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 12, 12, 512)  0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 12, 12, 512)  0           activation_82[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 12, 12, 512)  0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 12, 12, 512)  0           activation_85[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 12, 12, 512)  0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 6, 6, 1024)   0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 6, 6, 1024)   0           activation_91[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 6, 6, 1024)   0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 6, 6, 1024)   0           activation_94[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 6, 6, 1024)   0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypc8clklx2p8",
        "outputId": "86680de1-5aba-47ef-bde7-c641502f9107"
      },
      "source": [
        "#loss,acc = model_load.evaluate(xtrain,ytrain)\n",
        "\"\"\"print(\"loss:\",loss)\n",
        "print(\"acc:\",acc)kjjkj\"\"\"\n",
        "\n",
        "\n",
        "testloss = model_load.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "\n",
        "testloss = model_load.evaluate(xtrain, ytrain) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 6s 25ms/step - loss: 1.0788 - accuracy: 0.5913\n",
            "Test Loss 1.0787876844406128\n",
            "Test Acc: 0.591251015663147\n",
            "898/898 [==============================] - 23s 25ms/step - loss: 0.9884 - accuracy: 0.6276\n",
            "Test Loss 0.9883797764778137\n",
            "Test Acc: 0.6275732517242432\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7mSww_U2O_q",
        "outputId": "4ec4f2dc-c816-4e73-cade-d7bad32dd8b8"
      },
      "source": [
        "testlosz = model_load.evaluate(x_val, y_val) \n",
        "print(\"Test Loss \" + str(testlosz[0]))\n",
        "print(\"Test Acc: \" + str(testlosz[1]))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 3s 26ms/step - loss: 1.0889 - accuracy: 0.5893\n",
            "Test Loss 1.0888645648956299\n",
            "Test Acc: 0.5893006324768066\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdU7uU3PYCnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5fcd39b-c7ac-4800-c8cc-5c12ea7cf31c"
      },
      "source": [
        "print (x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3589, 48, 48, 1)\n",
            "(3589,)\n",
            "(3589, 48, 48, 1)\n",
            "(3589,)\n",
            "(28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_Tf1qg8TKnx",
        "outputId": "9f4b4d86-7428-49d2-d4a1-7d7acb84fdaf"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "#y_pred = model_load.predict(xtest)\n",
        "\n",
        "test_prob = model_load.predict(xtest)\n",
        "test_pred = np.argmax(test_prob, axis=1)\n",
        "test_accuracy = np.mean(test_pred == ytest)\n",
        "\n",
        "print(test_accuracy)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5912510448592923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpwJv9V54_1M"
      },
      "source": [
        "\n",
        "emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "KMe4WL0T5BcJ",
        "outputId": "69063f2a-4349-4528-bd7c-bc62dd04da69"
      },
      "source": [
        "conf_mat = confusion_matrix(ytest, test_pred)\n",
        "\n",
        "pd.DataFrame(conf_mat, columns=emotions.values(), index=emotions.values())\n",
        "\n",
        "\n",
        "\n",
        "fig, ax = plot_confusion_matrix(conf_mat=conf_mat,show_normed=True,show_absolute=False,figsize=(8, 8))\n",
        "fig.show()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW3FZjp-5DgF",
        "outputId": "6ae97fce-e715-4432-8095-4116982333ec"
      },
      "source": [
        "print(classification_report(ytest, test_pred, target_names=emotions.values()))\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry       0.43      0.68      0.53       517\n",
            "     Disgust       0.67      0.08      0.14        53\n",
            "        Fear       0.47      0.23      0.31       496\n",
            "       Happy       0.92      0.73      0.81       899\n",
            "         Sad       0.46      0.57      0.51       600\n",
            "    Surprise       0.63      0.82      0.71       391\n",
            "     Neutral       0.58      0.54      0.56       633\n",
            "\n",
            "    accuracy                           0.59      3589\n",
            "   macro avg       0.60      0.52      0.51      3589\n",
            "weighted avg       0.62      0.59      0.59      3589\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}