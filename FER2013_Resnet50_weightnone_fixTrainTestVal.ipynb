{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER2013_Resnet50_weightnone_fixTrainTestVal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-Qn1jsBTIBl0b7myLQxqa8WjCcfbamqM",
      "authorship_tag": "ABX9TyOY75QBA0cjIBSeFy8IkvRH"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b86nukQOxN7l"
      },
      "source": [
        "Resnet-50 From Scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p8gxtGy0TWP",
        "outputId": "4ee339c4-1dcc-484e-994a-94f1c910c1eb"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "inputFolder = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth' \n",
        "for root, directories, filenames in os.walk(inputFolder): \n",
        "    for filename in filenames: print(os.path.join(root,filename))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Best_Model_resnet50Scracth1again.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe4.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth1again.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50ScracthSGD1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50AUGScracthadam3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD1try2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD4.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50oriSGD1st.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50SGD5stori.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editSGD5st.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editAdamst120epochBS128.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editAdamst120epochBS128_1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editAdamst120epochBS128+aug:vf_2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50oriAdamst120epochBS128_aug1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50oriAdamst120epochBS128_noaug1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50oriScracth_sena2.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsiscWIMBDX2",
        "outputId": "2ddf6187-19ab-442d-84cc-25714f8c7c8b"
      },
      "source": [
        "%cd /content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "wLMSe510xNCJ",
        "outputId": "3da9f6f5-cb75-4f61-d978-1e7de9a074fc"
      },
      "source": [
        "#Create a directory to save our generated models.dasdas\n",
        "\n",
        "#os.mkdir(\"./modelscracth\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-cf55f19f3613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#os.mkdir(\"./modelscracth\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ls' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_kluusLxM1B",
        "outputId": "49545241-642e-480c-e9d2-18b1f6cbce95"
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:400: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfUSF_tAxNMP"
      },
      "source": [
        "#Define the identity block helper function.\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "   \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VdYtzhn1F0I"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path \n",
        "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b',padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd-O8ZMx1GAW"
      },
      "source": [
        "def ResNet50(input_shape = (48,48,1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    #X = ZeroPadding2D((1, 1))(X_input)\n",
        "    X = X_input\n",
        "    # Stage 1\n",
        "\n",
        "    X = Conv2D(8, (3, 3), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # removed maxpool\n",
        "    #X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='c')\n",
        "\n",
        "\n",
        "    # Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [64,64,256], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL . \n",
        "    X = AveragePooling2D((2,2), name='avg_pool')(X)\n",
        "    \n",
        "    # output layerds\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(512, activation = 'relu', name='fc1024' , kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GKsSwtp-GuL"
      },
      "source": [
        "\"\"\"def ResNet50ori(input_shape = (48, 48, 1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns: dsdsf\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50ori')\n",
        "\n",
        "    return model\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oWTDXlyBHM2"
      },
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        " \n",
        "dataset_path = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv'\n",
        "image_size=(48,48)\n",
        "#batch_size = 64\n",
        "\n",
        "def load_fer2013():\n",
        "    data = pd.read_csv(dataset_path)\n",
        "    data = (data[data['pixels'].notnull()])\n",
        "    pixels = data['pixels'].tolist()\n",
        "    width, height = 48, 48\n",
        "    faces = []\n",
        "    for pixel_sequence in pixels:\n",
        "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "        face = np.asarray(face).reshape(width, height)\n",
        "        face = cv2.resize(face.astype('uint8'),image_size)\n",
        "        faces.append(face.astype('float32'))\n",
        "    faces = np.asarray(faces)\n",
        "    faces = np.expand_dims(faces, -1)\n",
        "    emotions = (data['emotion'])#.values\n",
        "    return faces, emotions\n",
        " \n",
        "def preprocess_input(x, v2=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if v2:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x\n",
        " \n",
        "faces, emotions = load_fer2013()\n",
        "faces = preprocess_input(faces)\n",
        "#xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
        "#Data Augumentation\n",
        "\"\"\"data_generator = ImageDataGenerator(\n",
        "                        rotation_range=10,\n",
        "                        shear_range = 10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True,\n",
        "                        )\"\"\"\n",
        "data_generator = ImageDataGenerator( )\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWLhavr-rSF5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "895f7f85-9930-46ca-c552-cbb571846a4e"
      },
      "source": [
        "\"\"\"\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.1,)\n",
        "x_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1,)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nxtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.1,)\\nx_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1,)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "RGhnYFXgaqL9",
        "outputId": "0e60da2f-3a44-4d06-910b-2e0f2fa4191a"
      },
      "source": [
        "\"\"\"print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (y_train.shape)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'print (\"validasi\",x_val.shape)\\nprint (y_val.shape)\\nprint (\"test\",xtest.shape)\\nprint (ytest.shape)\\nprint (\"train\",xtrain.shape)\\nprint (y_train.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rDS3hqhDSteM",
        "outputId": "0ad25186-35ec-48ab-b4ba-8b55309ddd0b"
      },
      "source": [
        "train_ratio = 0.80\n",
        "validation_ratio = 0.10\n",
        "test_ratio = 0.10\n",
        "\n",
        "# train is now 75% of the entire data set\n",
        "# the _junk suffix means that we drop that variable completely # the _junk suffix means that we drop that variable completely\n",
        "#x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=1 - train_ratio)\n",
        "\n",
        "# test is now 10% of the initial data set\n",
        "# validation is now 15% of the initial data set\n",
        "#x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "x_val, xtest, y_val, ytest = train_test_split(xtest, ytest, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "\n",
        "print(xtrain, x_val, xtest)\n",
        "\n",
        "\"\"\"X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2\"\"\""
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[-0.8901961 ]\n",
            "   [-0.8901961 ]\n",
            "   [-0.8901961 ]\n",
            "   ...\n",
            "   [-0.8980392 ]\n",
            "   [-0.8980392 ]\n",
            "   [-0.8980392 ]]\n",
            "\n",
            "  [[-0.88235295]\n",
            "   [-0.88235295]\n",
            "   [-0.8901961 ]\n",
            "   ...\n",
            "   [-0.8980392 ]\n",
            "   [-0.8980392 ]\n",
            "   [-0.8980392 ]]\n",
            "\n",
            "  [[-0.8901961 ]\n",
            "   [-0.88235295]\n",
            "   [-0.8901961 ]\n",
            "   ...\n",
            "   [-0.8980392 ]\n",
            "   [-0.8980392 ]\n",
            "   [-0.8901961 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.8352941 ]\n",
            "   [-0.8352941 ]\n",
            "   [-0.8352941 ]\n",
            "   ...\n",
            "   [-0.8352941 ]\n",
            "   [-0.8352941 ]\n",
            "   [-0.84313726]]\n",
            "\n",
            "  [[-0.8352941 ]\n",
            "   [-0.8352941 ]\n",
            "   [-0.84313726]\n",
            "   ...\n",
            "   [-0.8352941 ]\n",
            "   [-0.8352941 ]\n",
            "   [-0.827451  ]]\n",
            "\n",
            "  [[-0.827451  ]\n",
            "   [-0.8352941 ]\n",
            "   [-0.84313726]\n",
            "   ...\n",
            "   [-0.8352941 ]\n",
            "   [-0.8352941 ]\n",
            "   [-0.8352941 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.5921569 ]\n",
            "   [ 0.58431375]\n",
            "   [ 0.5686275 ]\n",
            "   ...\n",
            "   [-0.4823529 ]\n",
            "   [-0.41176468]\n",
            "   [-0.3490196 ]]\n",
            "\n",
            "  [[ 0.56078434]\n",
            "   [ 0.5372549 ]\n",
            "   [ 0.52156866]\n",
            "   ...\n",
            "   [-0.46666664]\n",
            "   [-0.38823527]\n",
            "   [-0.38823527]]\n",
            "\n",
            "  [[ 0.5921569 ]\n",
            "   [ 0.5058824 ]\n",
            "   [ 0.43529415]\n",
            "   ...\n",
            "   [-0.38823527]\n",
            "   [-0.36470586]\n",
            "   [-0.29411763]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.73333335]\n",
            "   [ 0.77254903]\n",
            "   [ 0.79607844]\n",
            "   ...\n",
            "   [ 0.8352941 ]\n",
            "   [ 0.81960785]\n",
            "   [ 0.8039216 ]]\n",
            "\n",
            "  [[ 0.5058824 ]\n",
            "   [ 0.54509807]\n",
            "   [ 0.62352943]\n",
            "   ...\n",
            "   [ 0.8039216 ]\n",
            "   [ 0.7882353 ]\n",
            "   [ 0.77254903]]\n",
            "\n",
            "  [[ 0.45882356]\n",
            "   [ 0.45098042]\n",
            "   [ 0.48235297]\n",
            "   ...\n",
            "   [ 0.77254903]\n",
            "   [ 0.75686276]\n",
            "   [ 0.7490196 ]]]\n",
            "\n",
            "\n",
            " [[[-0.81960785]\n",
            "   [-0.7176471 ]\n",
            "   [-0.24705881]\n",
            "   ...\n",
            "   [-0.62352943]\n",
            "   [-0.8039216 ]\n",
            "   [-0.78039217]]\n",
            "\n",
            "  [[-0.78039217]\n",
            "   [-0.5529412 ]\n",
            "   [ 0.06666672]\n",
            "   ...\n",
            "   [-0.54509807]\n",
            "   [-0.69411767]\n",
            "   [-0.81960785]]\n",
            "\n",
            "  [[-0.70980394]\n",
            "   [-0.38039213]\n",
            "   [ 0.26274514]\n",
            "   ...\n",
            "   [-0.5294118 ]\n",
            "   [-0.6156863 ]\n",
            "   [-0.7411765 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.07450986]\n",
            "   [ 0.09019613]\n",
            "   [ 0.14509809]\n",
            "   ...\n",
            "   [-0.52156866]\n",
            "   [-0.44313723]\n",
            "   [-0.46666664]]\n",
            "\n",
            "  [[ 0.11372554]\n",
            "   [ 0.09803927]\n",
            "   [ 0.30980396]\n",
            "   ...\n",
            "   [-0.4823529 ]\n",
            "   [-0.45098037]\n",
            "   [-0.46666664]]\n",
            "\n",
            "  [[ 0.10588241]\n",
            "   [ 0.07450986]\n",
            "   [ 0.3411765 ]\n",
            "   ...\n",
            "   [-0.44313723]\n",
            "   [-0.4588235 ]\n",
            "   [-0.45098037]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.67058825]\n",
            "   [-0.654902  ]\n",
            "   [-0.6627451 ]\n",
            "   ...\n",
            "   [ 0.81960785]\n",
            "   [ 0.20784318]\n",
            "   [-0.7019608 ]]\n",
            "\n",
            "  [[-0.6627451 ]\n",
            "   [-0.67058825]\n",
            "   [-0.6627451 ]\n",
            "   ...\n",
            "   [ 0.27058828]\n",
            "   [-0.04313725]\n",
            "   [-0.73333335]]\n",
            "\n",
            "  [[-0.6627451 ]\n",
            "   [-0.6784314 ]\n",
            "   [-0.67058825]\n",
            "   ...\n",
            "   [-0.15294117]\n",
            "   [-0.15294117]\n",
            "   [-0.654902  ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.58431375]\n",
            "   [ 0.30980396]\n",
            "   [ 0.06666672]\n",
            "   ...\n",
            "   [ 0.45098042]\n",
            "   [ 0.6627451 ]\n",
            "   [ 0.8352941 ]]\n",
            "\n",
            "  [[ 0.2941177 ]\n",
            "   [ 0.11372554]\n",
            "   [-0.00392157]\n",
            "   ...\n",
            "   [ 0.35686278]\n",
            "   [ 0.5058824 ]\n",
            "   [ 0.8745098 ]]\n",
            "\n",
            "  [[ 0.16078436]\n",
            "   [ 0.06666672]\n",
            "   [ 0.01176476]\n",
            "   ...\n",
            "   [ 0.3411765 ]\n",
            "   [ 0.37254906]\n",
            "   [ 0.90588236]]]\n",
            "\n",
            "\n",
            " [[[-0.7176471 ]\n",
            "   [-0.5921569 ]\n",
            "   [-0.49019605]\n",
            "   ...\n",
            "   [-0.30196077]\n",
            "   [-0.2235294 ]\n",
            "   [-0.24705881]]\n",
            "\n",
            "  [[-0.6862745 ]\n",
            "   [-0.5764706 ]\n",
            "   [-0.47450978]\n",
            "   ...\n",
            "   [-0.27058822]\n",
            "   [-0.10588235]\n",
            "   [-0.20784312]]\n",
            "\n",
            "  [[-0.6627451 ]\n",
            "   [-0.5921569 ]\n",
            "   [-0.5058824 ]\n",
            "   ...\n",
            "   [-0.19215685]\n",
            "   [-0.02745098]\n",
            "   [-0.18431371]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.92941177]\n",
            "   [ 0.92941177]\n",
            "   [ 0.92941177]\n",
            "   ...\n",
            "   [ 0.17647064]\n",
            "   [ 0.17647064]\n",
            "   [ 0.2313726 ]]\n",
            "\n",
            "  [[ 0.92156863]\n",
            "   [ 0.92941177]\n",
            "   [ 0.92941177]\n",
            "   ...\n",
            "   [ 0.18431377]\n",
            "   [ 0.17647064]\n",
            "   [ 0.22352946]]\n",
            "\n",
            "  [[ 0.92941177]\n",
            "   [ 0.92941177]\n",
            "   [ 0.92941177]\n",
            "   ...\n",
            "   [ 0.18431377]\n",
            "   [ 0.1686275 ]\n",
            "   [ 0.20784318]]]\n",
            "\n",
            "\n",
            " [[[-0.6       ]\n",
            "   [-0.8980392 ]\n",
            "   [-0.9607843 ]\n",
            "   ...\n",
            "   [-0.9843137 ]\n",
            "   [-0.8980392 ]\n",
            "   [-0.9137255 ]]\n",
            "\n",
            "  [[-0.3333333 ]\n",
            "   [-0.8039216 ]\n",
            "   [-0.9843137 ]\n",
            "   ...\n",
            "   [-0.92941177]\n",
            "   [-0.9137255 ]\n",
            "   [-0.9137255 ]]\n",
            "\n",
            "  [[-0.34117645]\n",
            "   [-0.5529412 ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.9137255 ]\n",
            "   [-0.94509804]\n",
            "   [-0.9137255 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.58431375]\n",
            "   [-0.19215685]\n",
            "   [-0.46666664]\n",
            "   ...\n",
            "   [ 0.6862745 ]\n",
            "   [ 0.69411767]\n",
            "   [ 0.69411767]]\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-0.38039213]\n",
            "   [-0.56078434]\n",
            "   ...\n",
            "   [ 0.6862745 ]\n",
            "   [ 0.6862745 ]\n",
            "   [ 0.69411767]]\n",
            "\n",
            "  [[-0.9843137 ]\n",
            "   [-0.8117647 ]\n",
            "   [ 0.0196079 ]\n",
            "   ...\n",
            "   [ 0.6862745 ]\n",
            "   [ 0.69411767]\n",
            "   [ 0.7019608 ]]]] [[[[-0.8509804 ]\n",
            "   [-0.8509804 ]\n",
            "   [-0.8509804 ]\n",
            "   ...\n",
            "   [-0.09803921]\n",
            "   [-0.06666666]\n",
            "   [-0.00392157]]\n",
            "\n",
            "  [[-0.8509804 ]\n",
            "   [-0.84313726]\n",
            "   [-0.84313726]\n",
            "   ...\n",
            "   [-0.19999999]\n",
            "   [-0.30196077]\n",
            "   [-0.2862745 ]]\n",
            "\n",
            "  [[-0.8509804 ]\n",
            "   [-0.8509804 ]\n",
            "   [-0.8509804 ]\n",
            "   ...\n",
            "   [-0.4588235 ]\n",
            "   [-0.40392154]\n",
            "   [-0.38823527]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.8352941 ]\n",
            "   [-0.84313726]\n",
            "   [-0.8352941 ]\n",
            "   ...\n",
            "   [-0.7882353 ]\n",
            "   [-0.7411765 ]\n",
            "   [-0.27058822]]\n",
            "\n",
            "  [[-0.8509804 ]\n",
            "   [-0.84313726]\n",
            "   [-0.8352941 ]\n",
            "   ...\n",
            "   [-0.8039216 ]\n",
            "   [-0.75686276]\n",
            "   [-0.5686275 ]]\n",
            "\n",
            "  [[-0.8509804 ]\n",
            "   [-0.8509804 ]\n",
            "   [-0.84313726]\n",
            "   ...\n",
            "   [-0.78039217]\n",
            "   [-0.77254903]\n",
            "   [-0.73333335]]]\n",
            "\n",
            "\n",
            " [[[-0.81960785]\n",
            "   [-0.8980392 ]\n",
            "   [-0.5137255 ]\n",
            "   ...\n",
            "   [-0.827451  ]\n",
            "   [-0.4588235 ]\n",
            "   [ 0.06666672]]\n",
            "\n",
            "  [[-0.9137255 ]\n",
            "   [-0.85882354]\n",
            "   [-0.84313726]\n",
            "   ...\n",
            "   [-0.92156863]\n",
            "   [-0.7019608 ]\n",
            "   [-0.23137254]]\n",
            "\n",
            "  [[-0.77254903]\n",
            "   [-0.88235295]\n",
            "   [-0.64705884]\n",
            "   ...\n",
            "   [-0.90588236]\n",
            "   [-0.8352941 ]\n",
            "   [-0.47450978]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.5764706 ]\n",
            "   [-0.58431375]\n",
            "   [-0.30196077]\n",
            "   ...\n",
            "   [-0.09803921]\n",
            "   [-0.09019607]\n",
            "   [-0.09019607]]\n",
            "\n",
            "  [[-0.5686275 ]\n",
            "   [-0.60784316]\n",
            "   [-0.29411763]\n",
            "   ...\n",
            "   [-0.14509803]\n",
            "   [-0.17647058]\n",
            "   [-0.20784312]]\n",
            "\n",
            "  [[-0.58431375]\n",
            "   [-0.54509807]\n",
            "   [-0.58431375]\n",
            "   ...\n",
            "   [-0.21568626]\n",
            "   [-0.27058822]\n",
            "   [-0.34117645]]]\n",
            "\n",
            "\n",
            " [[[-0.23137254]\n",
            "   [-0.21568626]\n",
            "   [-0.41960782]\n",
            "   ...\n",
            "   [ 0.4039216 ]\n",
            "   [ 0.1686275 ]\n",
            "   [ 0.03529418]]\n",
            "\n",
            "  [[-0.42745095]\n",
            "   [-0.21568626]\n",
            "   [-0.27843136]\n",
            "   ...\n",
            "   [ 0.2313726 ]\n",
            "   [ 0.18431377]\n",
            "   [ 0.10588241]]\n",
            "\n",
            "  [[-0.6156863 ]\n",
            "   [-0.36470586]\n",
            "   [-0.2235294 ]\n",
            "   ...\n",
            "   [ 0.28627455]\n",
            "   [ 0.05882359]\n",
            "   [ 0.06666672]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.46666664]\n",
            "   [-0.21568626]\n",
            "   [-0.00392157]\n",
            "   ...\n",
            "   [-0.4823529 ]\n",
            "   [-0.42745095]\n",
            "   [-0.75686276]]\n",
            "\n",
            "  [[-0.23137254]\n",
            "   [-0.02745098]\n",
            "   [-0.00392157]\n",
            "   ...\n",
            "   [-0.11372548]\n",
            "   [-0.42745095]\n",
            "   [-0.11372548]]\n",
            "\n",
            "  [[-0.05882353]\n",
            "   [ 0.03529418]\n",
            "   [-0.0745098 ]\n",
            "   ...\n",
            "   [ 0.22352946]\n",
            "   [-0.1372549 ]\n",
            "   [ 0.23921573]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 0.09019613]\n",
            "   [ 0.22352946]\n",
            "   [-0.27058822]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 0.24705887]\n",
            "   [ 0.04313731]\n",
            "   [-0.29411763]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 0.10588241]\n",
            "   [ 0.0196079 ]\n",
            "   [ 0.09803927]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [-0.8901961 ]\n",
            "   [-0.81960785]\n",
            "   [-0.8509804 ]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [-0.94509804]\n",
            "   [-0.85882354]\n",
            "   [-0.8117647 ]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [-0.9843137 ]\n",
            "   [-0.8980392 ]\n",
            "   [-0.88235295]]]\n",
            "\n",
            "\n",
            " [[[-0.88235295]\n",
            "   [-0.06666666]\n",
            "   [ 0.7254902 ]\n",
            "   ...\n",
            "   [-0.1372549 ]\n",
            "   [-0.8352941 ]\n",
            "   [-1.        ]]\n",
            "\n",
            "  [[-0.96862745]\n",
            "   [-0.08235294]\n",
            "   [ 0.73333335]\n",
            "   ...\n",
            "   [-0.04313725]\n",
            "   [-0.47450978]\n",
            "   [-1.        ]]\n",
            "\n",
            "  [[-0.92156863]\n",
            "   [ 0.06666672]\n",
            "   [ 0.70980394]\n",
            "   ...\n",
            "   [-0.02745098]\n",
            "   [-0.23921567]\n",
            "   [-0.8509804 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.81960785]\n",
            "   [ 0.9529412 ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [-0.9607843 ]\n",
            "   [-1.        ]\n",
            "   [-0.3333333 ]]\n",
            "\n",
            "  [[ 0.77254903]\n",
            "   [ 0.8980392 ]\n",
            "   [ 0.99215686]\n",
            "   ...\n",
            "   [-0.88235295]\n",
            "   [-1.        ]\n",
            "   [-0.5529412 ]]\n",
            "\n",
            "  [[ 0.7411765 ]\n",
            "   [ 0.77254903]\n",
            "   [ 0.92156863]\n",
            "   ...\n",
            "   [-0.9372549 ]\n",
            "   [-0.9843137 ]\n",
            "   [-0.827451  ]]]\n",
            "\n",
            "\n",
            " [[[-0.04313725]\n",
            "   [-0.09803921]\n",
            "   [-0.1372549 ]\n",
            "   ...\n",
            "   [ 0.70980394]\n",
            "   [ 0.67058825]\n",
            "   [ 0.64705884]]\n",
            "\n",
            "  [[-0.04313725]\n",
            "   [-0.09803921]\n",
            "   [-0.1372549 ]\n",
            "   ...\n",
            "   [ 0.70980394]\n",
            "   [ 0.6862745 ]\n",
            "   [ 0.654902  ]]\n",
            "\n",
            "  [[-0.04313725]\n",
            "   [-0.09803921]\n",
            "   [-0.1372549 ]\n",
            "   ...\n",
            "   [ 0.7176471 ]\n",
            "   [ 0.69411767]\n",
            "   [ 0.6627451 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.3098039 ]\n",
            "   [-0.3333333 ]\n",
            "   [-0.3490196 ]\n",
            "   ...\n",
            "   [-0.372549  ]\n",
            "   [-0.38823527]\n",
            "   [-0.40392154]]\n",
            "\n",
            "  [[-0.3098039 ]\n",
            "   [-0.3333333 ]\n",
            "   [-0.35686272]\n",
            "   ...\n",
            "   [-0.372549  ]\n",
            "   [-0.38823527]\n",
            "   [-0.40392154]]\n",
            "\n",
            "  [[-0.31764704]\n",
            "   [-0.3333333 ]\n",
            "   [-0.35686272]\n",
            "   ...\n",
            "   [-0.372549  ]\n",
            "   [-0.3960784 ]\n",
            "   [-0.41176468]]]] [[[[-0.47450978]\n",
            "   [-0.35686272]\n",
            "   [-0.3490196 ]\n",
            "   ...\n",
            "   [-0.6       ]\n",
            "   [-0.42745095]\n",
            "   [-0.3333333 ]]\n",
            "\n",
            "  [[-0.3490196 ]\n",
            "   [-0.35686272]\n",
            "   [-0.40392154]\n",
            "   ...\n",
            "   [-0.56078434]\n",
            "   [-0.41960782]\n",
            "   [-0.32549018]]\n",
            "\n",
            "  [[-0.38823527]\n",
            "   [-0.41960782]\n",
            "   [-0.41176468]\n",
            "   ...\n",
            "   [-0.4823529 ]\n",
            "   [-0.44313723]\n",
            "   [-0.3333333 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.02745098]\n",
            "   [ 0.48235297]\n",
            "   [ 0.37254906]\n",
            "   ...\n",
            "   [ 0.94509804]\n",
            "   [ 0.78039217]\n",
            "   [ 0.81960785]]\n",
            "\n",
            "  [[ 0.33333337]\n",
            "   [ 0.38823533]\n",
            "   [ 0.37254906]\n",
            "   ...\n",
            "   [ 0.90588236]\n",
            "   [ 0.78039217]\n",
            "   [ 0.88235295]]\n",
            "\n",
            "  [[ 0.41176474]\n",
            "   [ 0.37254906]\n",
            "   [ 0.37254906]\n",
            "   ...\n",
            "   [ 0.8509804 ]\n",
            "   [ 0.7882353 ]\n",
            "   [ 0.92156863]]]\n",
            "\n",
            "\n",
            " [[[ 1.        ]\n",
            "   [ 0.99215686]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 0.41176474]\n",
            "   [ 0.27058828]\n",
            "   [ 0.64705884]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 0.9137255 ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 0.427451  ]\n",
            "   [ 0.52156866]\n",
            "   [ 0.7490196 ]]\n",
            "\n",
            "  [[ 0.92156863]\n",
            "   [ 0.5058824 ]\n",
            "   [ 0.9607843 ]\n",
            "   ...\n",
            "   [ 0.6784314 ]\n",
            "   [ 0.5372549 ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-0.99215686]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.92156863]]\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-0.9764706 ]\n",
            "   ...\n",
            "   [ 0.99215686]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [ 0.9843137 ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]]\n",
            "\n",
            "\n",
            " [[[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 0.99215686]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 0.99215686]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 0.99215686]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.5294118 ]\n",
            "   [ 0.24705887]\n",
            "   [ 0.05098045]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 0.23921573]\n",
            "   [ 0.10588241]\n",
            "   [ 0.12156868]\n",
            "   ...\n",
            "   [ 0.9843137 ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 0.03529418]\n",
            "   [ 0.09803927]\n",
            "   [ 0.11372554]\n",
            "   ...\n",
            "   [ 0.99215686]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 0.92156863]\n",
            "   [ 0.92156863]\n",
            "   [ 0.92941177]\n",
            "   ...\n",
            "   [-0.6784314 ]\n",
            "   [-0.5764706 ]\n",
            "   [-0.6313726 ]]\n",
            "\n",
            "  [[ 0.92156863]\n",
            "   [ 0.92156863]\n",
            "   [ 0.92941177]\n",
            "   ...\n",
            "   [-0.81960785]\n",
            "   [-0.64705884]\n",
            "   [-0.6156863 ]]\n",
            "\n",
            "  [[ 0.92156863]\n",
            "   [ 0.92156863]\n",
            "   [ 0.92156863]\n",
            "   ...\n",
            "   [-0.84313726]\n",
            "   [-0.77254903]\n",
            "   [-0.6156863 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.9137255 ]\n",
            "   [ 0.9137255 ]\n",
            "   [ 0.90588236]\n",
            "   ...\n",
            "   [ 0.9137255 ]\n",
            "   [ 0.9137255 ]\n",
            "   [ 0.90588236]]\n",
            "\n",
            "  [[ 0.9137255 ]\n",
            "   [ 0.9137255 ]\n",
            "   [ 0.92156863]\n",
            "   ...\n",
            "   [ 0.9137255 ]\n",
            "   [ 0.9137255 ]\n",
            "   [ 0.90588236]]\n",
            "\n",
            "  [[ 0.9137255 ]\n",
            "   [ 0.9137255 ]\n",
            "   [ 0.92941177]\n",
            "   ...\n",
            "   [ 0.9137255 ]\n",
            "   [ 0.9137255 ]\n",
            "   [ 0.90588236]]]\n",
            "\n",
            "\n",
            " [[[-0.8352941 ]\n",
            "   [-0.7411765 ]\n",
            "   [-0.75686276]\n",
            "   ...\n",
            "   [-0.6784314 ]\n",
            "   [-0.5764706 ]\n",
            "   [-0.02745098]]\n",
            "\n",
            "  [[-0.7647059 ]\n",
            "   [-0.8039216 ]\n",
            "   [-0.77254903]\n",
            "   ...\n",
            "   [-0.6784314 ]\n",
            "   [-0.5686275 ]\n",
            "   [-0.04313725]]\n",
            "\n",
            "  [[-0.79607844]\n",
            "   [-0.78039217]\n",
            "   [-0.7254902 ]\n",
            "   ...\n",
            "   [-0.60784316]\n",
            "   [-0.60784316]\n",
            "   [ 0.03529418]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.13725495]\n",
            "   [ 0.02745104]\n",
            "   [ 0.10588241]\n",
            "   ...\n",
            "   [-0.19215685]\n",
            "   [-0.11372548]\n",
            "   [ 0.73333335]]\n",
            "\n",
            "  [[-0.09019607]\n",
            "   [-0.09019607]\n",
            "   [-0.03529412]\n",
            "   ...\n",
            "   [-0.18431371]\n",
            "   [-0.20784312]\n",
            "   [ 0.45882356]]\n",
            "\n",
            "  [[-0.17647058]\n",
            "   [-0.2235294 ]\n",
            "   [-0.19999999]\n",
            "   ...\n",
            "   [-0.19999999]\n",
            "   [-0.23921567]\n",
            "   [ 0.15294123]]]\n",
            "\n",
            "\n",
            " [[[-0.27843136]\n",
            "   [-0.4823529 ]\n",
            "   [ 0.427451  ]\n",
            "   ...\n",
            "   [-0.7490196 ]\n",
            "   [-0.7490196 ]\n",
            "   [-0.7411765 ]]\n",
            "\n",
            "  [[-0.29411763]\n",
            "   [-0.27843136]\n",
            "   [ 0.75686276]\n",
            "   ...\n",
            "   [-0.64705884]\n",
            "   [-0.7019608 ]\n",
            "   [-0.70980394]]\n",
            "\n",
            "  [[-0.38039213]\n",
            "   [ 0.07450986]\n",
            "   [ 0.94509804]\n",
            "   ...\n",
            "   [-0.6862745 ]\n",
            "   [-0.7490196 ]\n",
            "   [-0.75686276]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.2235294 ]\n",
            "   [-0.27058822]\n",
            "   [-0.21568626]\n",
            "   ...\n",
            "   [-0.6313726 ]\n",
            "   [-0.6784314 ]\n",
            "   [-0.7490196 ]]\n",
            "\n",
            "  [[-0.1372549 ]\n",
            "   [-0.19215685]\n",
            "   [-0.19999999]\n",
            "   ...\n",
            "   [-0.6392157 ]\n",
            "   [-0.6862745 ]\n",
            "   [-0.75686276]]\n",
            "\n",
            "  [[-0.20784312]\n",
            "   [-0.2235294 ]\n",
            "   [-0.26274508]\n",
            "   ...\n",
            "   [-0.654902  ]\n",
            "   [-0.69411767]\n",
            "   [-0.73333335]]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\\n\\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKvEv321Stt5",
        "outputId": "a9e3764d-25dc-416f-955b-d58be1e6d7f5"
      },
      "source": [
        "print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validasi (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "test (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "train (28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH9Q-TegBR26"
      },
      "source": [
        "#hyperparameter and callback\n",
        "batch_size = 128\n",
        "num_epochs = 60\n",
        "input_shape = (48, 48, 1)\n",
        "num_classes = 7\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGsscQRJBR-h"
      },
      "source": [
        "#Compile the model.\n",
        "\n",
        "\n",
        "from keras.optimizers import Adam, SGD\n",
        "model = ResNet50(input_shape = (48, 48, 1), classes = 7)\n",
        "optimizer = SGD(learning_rate=0.0005)\n",
        "model.compile(optimizer= optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rodttDWeT2yP"
      },
      "source": [
        "#kita mau save model callbackshuhuhuhuhhg\n",
        "\"\"\"import os\n",
        "try:\n",
        "  os.mkdir('scratchcheckpoint')\n",
        "except:\n",
        "  pass\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV29sTjET28U"
      },
      "source": [
        "\"\"\"file_name = 'Best_Model_resnet50Scracth_sena1.h5'\n",
        "\n",
        "checkpoint_path = os.path.join('checkpoint',file_name)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_S6wUaPT3Jx"
      },
      "source": [
        "\"\"\"call_back = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
        "                                               monitor='val_accuracy',\n",
        "                                               verbose=1,\n",
        "                                               save_freq='epoch',\n",
        "                                               save_best_only=True,\n",
        "                                               save_weights_only=False,\n",
        "                                               mode='max')\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy53DHMGB-Mr",
        "outputId": "1ae2adba-52f8-47e9-9e2c-ee2d88eefa68"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 46, 46, 128)  0           add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_33 (Add)                    (None, 46, 46, 128)  0           activation_101[0][0]             \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 46, 46, 128)  0           add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, 46, 46, 128)  0           activation_104[0][0]             \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 46, 46, 128)  0           add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_35 (Add)                    (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 23, 23, 256)  0           add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_36 (Add)                    (None, 23, 23, 256)  0           activation_110[0][0]             \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 23, 23, 256)  0           add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_37 (Add)                    (None, 23, 23, 256)  0           activation_113[0][0]             \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 23, 23, 256)  0           add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_38 (Add)                    (None, 23, 23, 256)  0           activation_116[0][0]             \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 23, 23, 256)  0           add_38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_39 (Add)                    (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 12, 12, 512)  0           add_39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_40 (Add)                    (None, 12, 12, 512)  0           activation_122[0][0]             \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 12, 12, 512)  0           add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_41 (Add)                    (None, 12, 12, 512)  0           activation_125[0][0]             \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 12, 12, 512)  0           add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_42 (Add)                    (None, 12, 12, 512)  0           activation_128[0][0]             \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 12, 12, 512)  0           add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_43 (Add)                    (None, 12, 12, 512)  0           activation_131[0][0]             \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 12, 12, 512)  0           add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_44 (Add)                    (None, 12, 12, 512)  0           activation_134[0][0]             \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 12, 12, 512)  0           add_44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_45 (Add)                    (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 6, 6, 1024)   0           add_45[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_46 (Add)                    (None, 6, 6, 1024)   0           activation_140[0][0]             \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 6, 6, 1024)   0           add_46[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_47 (Add)                    (None, 6, 6, 1024)   0           activation_143[0][0]             \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 6, 6, 1024)   0           add_47[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgxCecVwCGEr"
      },
      "source": [
        "\"\"\"history = model.fit(data_generator.flow(xtrain, ytrain,),\n",
        "                        steps_per_epoch=len(xtrain) / batch_size,\n",
        "                        epochs=num_epochs, verbose=1,callbacks=call_back,\n",
        "                        validation_data= (xtest,ytest))\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2muXWns0sJSH",
        "outputId": "04dfe190-8777-49a2-b839-48a9dd44d2a1"
      },
      "source": [
        "history = model.fit(\n",
        "    data_generator.flow(xtrain, ytrain,),\n",
        "    steps_per_epoch=len(xtrain) / batch_size,\n",
        "    epochs=num_epochs,\n",
        "    shuffle=False, \n",
        "    verbose=1,\n",
        "    validation_data= (x_val,y_val))\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "224/224 [==============================] - 75s 278ms/step - loss: 2.2340 - accuracy: 0.2028 - val_loss: 1.9367 - val_accuracy: 0.2527\n",
            "Epoch 2/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.9952 - accuracy: 0.2245 - val_loss: 1.9153 - val_accuracy: 0.2483\n",
            "Epoch 3/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.9235 - accuracy: 0.2268 - val_loss: 2.0522 - val_accuracy: 0.1817\n",
            "Epoch 4/60\n",
            "224/224 [==============================] - 57s 256ms/step - loss: 1.8714 - accuracy: 0.2264 - val_loss: 1.8960 - val_accuracy: 0.2112\n",
            "Epoch 5/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.8622 - accuracy: 0.2375 - val_loss: 1.8652 - val_accuracy: 0.2485\n",
            "Epoch 6/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.8381 - accuracy: 0.2418 - val_loss: 2.0157 - val_accuracy: 0.2223\n",
            "Epoch 7/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.8185 - accuracy: 0.2547 - val_loss: 1.9293 - val_accuracy: 0.2441\n",
            "Epoch 8/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.8094 - accuracy: 0.2507 - val_loss: 1.8562 - val_accuracy: 0.2469\n",
            "Epoch 9/60\n",
            "224/224 [==============================] - 61s 271ms/step - loss: 1.7980 - accuracy: 0.2574 - val_loss: 1.8323 - val_accuracy: 0.2474\n",
            "Epoch 10/60\n",
            "224/224 [==============================] - 57s 256ms/step - loss: 1.8009 - accuracy: 0.2663 - val_loss: 1.8200 - val_accuracy: 0.2497\n",
            "Epoch 11/60\n",
            "224/224 [==============================] - 57s 256ms/step - loss: 1.8087 - accuracy: 0.2580 - val_loss: 1.8791 - val_accuracy: 0.2502\n",
            "Epoch 12/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.7809 - accuracy: 0.2583 - val_loss: 1.7864 - val_accuracy: 0.2653\n",
            "Epoch 13/60\n",
            "224/224 [==============================] - 57s 256ms/step - loss: 1.7830 - accuracy: 0.2759 - val_loss: 1.8050 - val_accuracy: 0.2616\n",
            "Epoch 14/60\n",
            "224/224 [==============================] - 57s 256ms/step - loss: 1.7709 - accuracy: 0.2804 - val_loss: 1.7885 - val_accuracy: 0.2583\n",
            "Epoch 15/60\n",
            "224/224 [==============================] - 57s 256ms/step - loss: 1.7617 - accuracy: 0.2838 - val_loss: 1.7771 - val_accuracy: 0.2739\n",
            "Epoch 16/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.7585 - accuracy: 0.2840 - val_loss: 1.7754 - val_accuracy: 0.2686\n",
            "Epoch 17/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.7552 - accuracy: 0.2755 - val_loss: 1.8117 - val_accuracy: 0.2753\n",
            "Epoch 18/60\n",
            "224/224 [==============================] - 58s 256ms/step - loss: 1.7375 - accuracy: 0.2933 - val_loss: 1.7728 - val_accuracy: 0.2834\n",
            "Epoch 19/60\n",
            "224/224 [==============================] - 57s 256ms/step - loss: 1.7315 - accuracy: 0.2962 - val_loss: 1.7587 - val_accuracy: 0.2809\n",
            "Epoch 20/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.7437 - accuracy: 0.2886 - val_loss: 1.7903 - val_accuracy: 0.2756\n",
            "Epoch 21/60\n",
            "224/224 [==============================] - 58s 256ms/step - loss: 1.7108 - accuracy: 0.3078 - val_loss: 1.7468 - val_accuracy: 0.2892\n",
            "Epoch 22/60\n",
            "224/224 [==============================] - 57s 256ms/step - loss: 1.7115 - accuracy: 0.3050 - val_loss: 1.7392 - val_accuracy: 0.2934\n",
            "Epoch 23/60\n",
            "224/224 [==============================] - 58s 256ms/step - loss: 1.7147 - accuracy: 0.3123 - val_loss: 1.7335 - val_accuracy: 0.3018\n",
            "Epoch 24/60\n",
            "224/224 [==============================] - 57s 256ms/step - loss: 1.6992 - accuracy: 0.3195 - val_loss: 1.7229 - val_accuracy: 0.3020\n",
            "Epoch 25/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.7046 - accuracy: 0.3039 - val_loss: 1.7267 - val_accuracy: 0.3026\n",
            "Epoch 26/60\n",
            "224/224 [==============================] - 57s 256ms/step - loss: 1.6820 - accuracy: 0.3203 - val_loss: 1.7260 - val_accuracy: 0.3026\n",
            "Epoch 27/60\n",
            "224/224 [==============================] - 58s 256ms/step - loss: 1.6780 - accuracy: 0.3311 - val_loss: 1.7345 - val_accuracy: 0.3015\n",
            "Epoch 28/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.6762 - accuracy: 0.3266 - val_loss: 1.7090 - val_accuracy: 0.3143\n",
            "Epoch 29/60\n",
            "224/224 [==============================] - 57s 256ms/step - loss: 1.6608 - accuracy: 0.3358 - val_loss: 1.7147 - val_accuracy: 0.3135\n",
            "Epoch 30/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.6788 - accuracy: 0.3275 - val_loss: 1.7231 - val_accuracy: 0.3068\n",
            "Epoch 31/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.6709 - accuracy: 0.3332 - val_loss: 1.7034 - val_accuracy: 0.3123\n",
            "Epoch 32/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.6671 - accuracy: 0.3469 - val_loss: 1.7040 - val_accuracy: 0.3190\n",
            "Epoch 33/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.6476 - accuracy: 0.3415 - val_loss: 1.7065 - val_accuracy: 0.3118\n",
            "Epoch 34/60\n",
            "224/224 [==============================] - 57s 256ms/step - loss: 1.6388 - accuracy: 0.3431 - val_loss: 1.7173 - val_accuracy: 0.3110\n",
            "Epoch 35/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.6503 - accuracy: 0.3412 - val_loss: 1.7246 - val_accuracy: 0.3162\n",
            "Epoch 36/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.6448 - accuracy: 0.3559 - val_loss: 1.7019 - val_accuracy: 0.3157\n",
            "Epoch 37/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.6410 - accuracy: 0.3496 - val_loss: 1.6953 - val_accuracy: 0.3190\n",
            "Epoch 38/60\n",
            "224/224 [==============================] - 57s 256ms/step - loss: 1.6466 - accuracy: 0.3453 - val_loss: 1.6962 - val_accuracy: 0.3271\n",
            "Epoch 39/60\n",
            "224/224 [==============================] - 57s 256ms/step - loss: 1.6188 - accuracy: 0.3531 - val_loss: 1.7004 - val_accuracy: 0.3146\n",
            "Epoch 40/60\n",
            "224/224 [==============================] - 58s 256ms/step - loss: 1.6219 - accuracy: 0.3618 - val_loss: 1.6990 - val_accuracy: 0.3215\n",
            "Epoch 41/60\n",
            "224/224 [==============================] - 57s 256ms/step - loss: 1.6180 - accuracy: 0.3677 - val_loss: 1.7048 - val_accuracy: 0.3296\n",
            "Epoch 42/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.6016 - accuracy: 0.3702 - val_loss: 1.7058 - val_accuracy: 0.3098\n",
            "Epoch 43/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.6026 - accuracy: 0.3613 - val_loss: 1.6915 - val_accuracy: 0.3355\n",
            "Epoch 44/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.5913 - accuracy: 0.3828 - val_loss: 1.6710 - val_accuracy: 0.3424\n",
            "Epoch 45/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.5816 - accuracy: 0.3802 - val_loss: 1.6777 - val_accuracy: 0.3371\n",
            "Epoch 46/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.5779 - accuracy: 0.3883 - val_loss: 1.6826 - val_accuracy: 0.3313\n",
            "Epoch 47/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.5761 - accuracy: 0.3788 - val_loss: 1.6887 - val_accuracy: 0.3324\n",
            "Epoch 48/60\n",
            "224/224 [==============================] - 57s 256ms/step - loss: 1.5762 - accuracy: 0.3975 - val_loss: 1.6933 - val_accuracy: 0.3341\n",
            "Epoch 49/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.5713 - accuracy: 0.3897 - val_loss: 1.6657 - val_accuracy: 0.3452\n",
            "Epoch 50/60\n",
            "224/224 [==============================] - 58s 258ms/step - loss: 1.5477 - accuracy: 0.3999 - val_loss: 1.6629 - val_accuracy: 0.3472\n",
            "Epoch 51/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.5474 - accuracy: 0.3946 - val_loss: 1.6686 - val_accuracy: 0.3410\n",
            "Epoch 52/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.5580 - accuracy: 0.4006 - val_loss: 1.6640 - val_accuracy: 0.3419\n",
            "Epoch 53/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.5386 - accuracy: 0.4042 - val_loss: 1.6521 - val_accuracy: 0.3511\n",
            "Epoch 54/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.5258 - accuracy: 0.4132 - val_loss: 1.6603 - val_accuracy: 0.3533\n",
            "Epoch 55/60\n",
            "224/224 [==============================] - 58s 258ms/step - loss: 1.5371 - accuracy: 0.4120 - val_loss: 1.6589 - val_accuracy: 0.3435\n",
            "Epoch 56/60\n",
            "224/224 [==============================] - 58s 258ms/step - loss: 1.5389 - accuracy: 0.4032 - val_loss: 1.6440 - val_accuracy: 0.3452\n",
            "Epoch 57/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.5102 - accuracy: 0.4179 - val_loss: 1.6496 - val_accuracy: 0.3449\n",
            "Epoch 58/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.5257 - accuracy: 0.4166 - val_loss: 1.6414 - val_accuracy: 0.3530\n",
            "Epoch 59/60\n",
            "224/224 [==============================] - 58s 257ms/step - loss: 1.4830 - accuracy: 0.4340 - val_loss: 1.6514 - val_accuracy: 0.3516\n",
            "Epoch 60/60\n",
            "224/224 [==============================] - 58s 258ms/step - loss: 1.4894 - accuracy: 0.4217 - val_loss: 1.6276 - val_accuracy: 0.3522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaXUP-8fDWRN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "outputId": "a70bbc51-16be-475a-897d-1ed6ff59bd8c"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "model.save('/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_noAug_adam1_shuffalse1.h5')\n",
        "\n",
        "#gffhgffkjkjdskjjkjkjkjhjhnnnhjhhuyghhg\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "num_epochs = range(len(accuracy))\n",
        "plt.plot(num_epochs, accuracy, 'r', label='Training acc')\n",
        "plt.plot(num_epochs, val_accuracy, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(num_epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(num_epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_LxatO5J-pp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a556c6d8-37dc-491b-9ad5-a25d216ae4aa"
      },
      "source": [
        "testloss = model.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "trainloss = model.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(trainloss[0]))\n",
        "print(\"Train Acc: \" + str(trainloss[1]))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 7s 65ms/step - loss: 1.6525 - accuracy: 0.3522\n",
            "Test Loss 1.6524783372879028\n",
            "Test Acc: 0.35218724608421326\n",
            "898/898 [==============================] - 58s 64ms/step - loss: 1.4509 - accuracy: 0.4502\n",
            "Train Loss 1.4508779048919678\n",
            "Train Acc: 0.4502420723438263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swoRERVdKQ1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a0b8d4d-5c23-4320-cd4c-b2c5d4701de9"
      },
      "source": [
        "testlosz = model.evaluate(x_val, y_val) \n",
        "print(\"val Loss \" + str(testlosz[0]))\n",
        "print(\"val Acc: \" + str(testlosz[1]))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 7s 65ms/step - loss: 1.6276 - accuracy: 0.3522\n",
            "val Loss 1.6275686025619507\n",
            "val Acc: 0.35218724608421326\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5iaZIU6pPzk",
        "outputId": "2c977e8e-6c43-4d21-9dea-bd61779a2ae1"
      },
      "source": [
        "from keras.models import load_model\n",
        "model_load = load_model('/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_noAug_adam1_shuffalse1.h5')\n",
        "\n",
        "model_load.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 46, 46, 128)  0           add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_33 (Add)                    (None, 46, 46, 128)  0           activation_101[0][0]             \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 46, 46, 128)  0           add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, 46, 46, 128)  0           activation_104[0][0]             \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 46, 46, 128)  0           add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_35 (Add)                    (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 23, 23, 256)  0           add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_36 (Add)                    (None, 23, 23, 256)  0           activation_110[0][0]             \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 23, 23, 256)  0           add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_37 (Add)                    (None, 23, 23, 256)  0           activation_113[0][0]             \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 23, 23, 256)  0           add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_38 (Add)                    (None, 23, 23, 256)  0           activation_116[0][0]             \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 23, 23, 256)  0           add_38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_39 (Add)                    (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 12, 12, 512)  0           add_39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_40 (Add)                    (None, 12, 12, 512)  0           activation_122[0][0]             \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 12, 12, 512)  0           add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_41 (Add)                    (None, 12, 12, 512)  0           activation_125[0][0]             \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 12, 12, 512)  0           add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_42 (Add)                    (None, 12, 12, 512)  0           activation_128[0][0]             \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 12, 12, 512)  0           add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_43 (Add)                    (None, 12, 12, 512)  0           activation_131[0][0]             \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 12, 12, 512)  0           add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_44 (Add)                    (None, 12, 12, 512)  0           activation_134[0][0]             \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 12, 12, 512)  0           add_44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_45 (Add)                    (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 6, 6, 1024)   0           add_45[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_46 (Add)                    (None, 6, 6, 1024)   0           activation_140[0][0]             \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 6, 6, 1024)   0           add_46[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_47 (Add)                    (None, 6, 6, 1024)   0           activation_143[0][0]             \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 6, 6, 1024)   0           add_47[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypc8clklx2p8",
        "outputId": "8451291f-9b3d-4756-c5b5-4d5168ca43a1"
      },
      "source": [
        "#loss,acc = model_load.evaluate(xtrain,ytrain)\n",
        "\"\"\"print(\"loss:\",loss)\n",
        "print(\"acc:\",acc)kjjkj\"\"\"\n",
        "\n",
        "\n",
        "testdatamodel = model_load.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testdatamodel[0]))\n",
        "print(\"Test Acc: \" + str(testdatamodel[1]))\n",
        "\n",
        "traindata = model_load.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(traindata[0]))\n",
        "print(\"Train Acc: \" + str(traindata[1]))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 13s 65ms/step - loss: 1.6525 - accuracy: 0.3522\n",
            "Test Loss 1.6524783372879028\n",
            "Test Acc: 0.35218724608421326\n",
            "898/898 [==============================] - 58s 65ms/step - loss: 1.4509 - accuracy: 0.4502\n",
            "Train Loss 1.4508779048919678\n",
            "Train Acc: 0.4502420723438263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7mSww_U2O_q",
        "outputId": "7e55686b-a4ca-44ad-9136-c3e48c924f91"
      },
      "source": [
        "valdata = model_load.evaluate(x_val, y_val) \n",
        "print(\"Val Loss \" + str(valdata[0]))\n",
        "print(\"Val Acc: \" + str(valdata[1]))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 7s 65ms/step - loss: 1.6276 - accuracy: 0.3522\n",
            "Val Loss 1.6275686025619507\n",
            "Val Acc: 0.35218724608421326\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdU7uU3PYCnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "399d0450-e84e-4f4c-c179-03ab9be36639"
      },
      "source": [
        "print (x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3589, 48, 48, 1)\n",
            "(3589,)\n",
            "(3589, 48, 48, 1)\n",
            "(3589,)\n",
            "(28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_Tf1qg8TKnx",
        "outputId": "e274d9dc-3f8e-4c4b-edf9-d1ecb0f142b4"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "#y_pred = model_load.predict(xtest)\n",
        "\n",
        "test_prob = model_load.predict(xtest)\n",
        "test_pred = np.argmax(test_prob, axis=1)\n",
        "test_accuracy = np.mean(test_pred == ytest)\n",
        "\n",
        "print(test_accuracy)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.35218723878517694\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpwJv9V54_1M"
      },
      "source": [
        "\n",
        "emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "KMe4WL0T5BcJ",
        "outputId": "41bc192b-98a8-4c67-9a18-1a5b513f446f"
      },
      "source": [
        "conf_mat = confusion_matrix(ytest, test_pred)\n",
        "\n",
        "pd.DataFrame(conf_mat, columns=emotions.values(), index=emotions.values())\n",
        "\n",
        "\n",
        "\n",
        "fig, ax = plot_confusion_matrix(conf_mat=conf_mat,show_normed=True,show_absolute=False,figsize=(8, 8))\n",
        "fig.show()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW3FZjp-5DgF",
        "outputId": "e7097ded-3e97-4409-c3aa-b1e4d101d793"
      },
      "source": [
        "print(classification_report(ytest, test_pred, target_names=emotions.values()))\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry       0.28      0.12      0.16       487\n",
            "     Disgust       0.00      0.00      0.00        60\n",
            "        Fear       0.28      0.15      0.20       543\n",
            "       Happy       0.42      0.59      0.49       914\n",
            "         Sad       0.27      0.26      0.27       607\n",
            "    Surprise       0.47      0.49      0.48       394\n",
            "     Neutral       0.29      0.40      0.34       584\n",
            "\n",
            "    accuracy                           0.35      3589\n",
            "   macro avg       0.29      0.29      0.28      3589\n",
            "weighted avg       0.33      0.35      0.33      3589\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}