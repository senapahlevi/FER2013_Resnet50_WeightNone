{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER2013_Resnet50_weightnone_fixTrainTestVal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-Qn1jsBTIBl0b7myLQxqa8WjCcfbamqM",
      "authorship_tag": "ABX9TyPLnqfuLxueF0sRX76sUK1D",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/senapahlevi/FER2013_Resnet50_WeightNone/blob/master/FER2013_Resnet50_weightnone_fixTrainTestVal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b86nukQOxN7l"
      },
      "source": [
        "Resnet-50 From Scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p8gxtGy0TWP",
        "outputId": "ddceb0de-41cf-4e97-af65-37103c2a941e"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "inputFolder = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth' \n",
        "for root, directories, filenames in os.walk(inputFolder): \n",
        "    for filename in filenames: print(os.path.join(root,filename))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Best_Model_resnet50Scracth1again.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe4.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth1again.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50ScracthSGD1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50AUGScracthadam3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD1try2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD4.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50oriSGD1st.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50SGD5stori.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editSGD5st.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editAdamst120epochBS128.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editAdamst120epochBS128_1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editAdamst120epochBS128+aug:vf_2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50oriScracth_sena2.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsiscWIMBDX2",
        "outputId": "08c7006e-8e42-4126-83c4-13b0cd23449f"
      },
      "source": [
        "%cd /content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "wLMSe510xNCJ",
        "outputId": "3da9f6f5-cb75-4f61-d978-1e7de9a074fc"
      },
      "source": [
        "#Create a directory to save our generated models.dasdas\n",
        "\n",
        "#os.mkdir(\"./modelscracth\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-cf55f19f3613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#os.mkdir(\"./modelscracth\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ls' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_kluusLxM1B",
        "outputId": "869f1524-7221-434b-a78b-d8d9829ea6dc"
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:400: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfUSF_tAxNMP"
      },
      "source": [
        "#Define the identity block helper function.\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "   \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VdYtzhn1F0I"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path \n",
        "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b',padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd-O8ZMx1GAW"
      },
      "source": [
        "\"\"\"def ResNet50(input_shape = (48,48,1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    #X = ZeroPadding2D((1, 1))(X_input)\n",
        "    X = X_input\n",
        "    # Stage 1\n",
        "\n",
        "    X = Conv2D(8, (3, 3), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # removed maxpool\n",
        "    #X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='c')\n",
        "\n",
        "\n",
        "    # Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [64,64,256], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL . \n",
        "    X = AveragePooling2D((2,2), name='avg_pool')(X)\n",
        "    \n",
        "    # output layerds\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(512, activation = 'relu', name='fc1024' , kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GKsSwtp-GuL"
      },
      "source": [
        "def ResNet50ori(input_shape = (48, 48, 1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns: dsdsf\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50ori')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oWTDXlyBHM2"
      },
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        " \n",
        "dataset_path = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv'\n",
        "image_size=(48,48)\n",
        "#batch_size = 64\n",
        "\n",
        "def load_fer2013():\n",
        "    data = pd.read_csv(dataset_path)\n",
        "    data = (data[data['pixels'].notnull()])\n",
        "    pixels = data['pixels'].tolist()\n",
        "    width, height = 48, 48\n",
        "    faces = []\n",
        "    for pixel_sequence in pixels:\n",
        "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "        face = np.asarray(face).reshape(width, height)\n",
        "        face = cv2.resize(face.astype('uint8'),image_size)\n",
        "        faces.append(face.astype('float32'))\n",
        "    faces = np.asarray(faces)\n",
        "    faces = np.expand_dims(faces, -1)\n",
        "    emotions = (data['emotion'])#.values\n",
        "    return faces, emotions\n",
        " \n",
        "def preprocess_input(x, v2=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if v2:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x\n",
        " \n",
        "faces, emotions = load_fer2013()\n",
        "faces = preprocess_input(faces)\n",
        "#xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
        "#Data Augumentation\n",
        "\"\"\"data_generator = ImageDataGenerator(\n",
        "                        rotation_range=10,\n",
        "                        shear_range = 10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True,\n",
        "                        )\"\"\"\n",
        "data_generator = ImageDataGenerator( )\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWLhavr-rSF5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "895f7f85-9930-46ca-c552-cbb571846a4e"
      },
      "source": [
        "\"\"\"\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.1,)\n",
        "x_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1,)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nxtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.1,)\\nx_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1,)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "RGhnYFXgaqL9",
        "outputId": "0e60da2f-3a44-4d06-910b-2e0f2fa4191a"
      },
      "source": [
        "\"\"\"print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (y_train.shape)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'print (\"validasi\",x_val.shape)\\nprint (y_val.shape)\\nprint (\"test\",xtest.shape)\\nprint (ytest.shape)\\nprint (\"train\",xtrain.shape)\\nprint (y_train.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rDS3hqhDSteM",
        "outputId": "af7690c6-3acd-4f49-8feb-e76275732814"
      },
      "source": [
        "train_ratio = 0.80\n",
        "validation_ratio = 0.10\n",
        "test_ratio = 0.10\n",
        "\n",
        "# train is now 75% of the entire data set\n",
        "# the _junk suffix means that we drop that variable completely # the _junk suffix means that we drop that variable completely\n",
        "#x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=1 - train_ratio)\n",
        "\n",
        "# test is now 10% of the initial data set\n",
        "# validation is now 15% of the initial data set\n",
        "#x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "x_val, xtest, y_val, ytest = train_test_split(xtest, ytest, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "\n",
        "print(xtrain, x_val, xtest)\n",
        "\n",
        "\"\"\"X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2\"\"\""
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[-0.77254903]\n",
            "   [-0.6784314 ]\n",
            "   [-0.6156863 ]\n",
            "   ...\n",
            "   [-0.7490196 ]\n",
            "   [-0.8039216 ]\n",
            "   [-0.8039216 ]]\n",
            "\n",
            "  [[-0.6862745 ]\n",
            "   [-0.60784316]\n",
            "   [-0.60784316]\n",
            "   ...\n",
            "   [-0.75686276]\n",
            "   [-0.8117647 ]\n",
            "   [-0.8039216 ]]\n",
            "\n",
            "  [[-0.6784314 ]\n",
            "   [-0.6862745 ]\n",
            "   [-0.6862745 ]\n",
            "   ...\n",
            "   [-0.7490196 ]\n",
            "   [-0.8039216 ]\n",
            "   [-0.8117647 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.8745098 ]\n",
            "   [-0.88235295]\n",
            "   [-0.90588236]\n",
            "   ...\n",
            "   [-0.84313726]\n",
            "   [-0.8509804 ]\n",
            "   [-0.8509804 ]]\n",
            "\n",
            "  [[-0.88235295]\n",
            "   [-0.8901961 ]\n",
            "   [-0.8745098 ]\n",
            "   ...\n",
            "   [-0.8509804 ]\n",
            "   [-0.84313726]\n",
            "   [-0.8509804 ]]\n",
            "\n",
            "  [[-0.8901961 ]\n",
            "   [-0.8901961 ]\n",
            "   [-0.8980392 ]\n",
            "   ...\n",
            "   [-0.8509804 ]\n",
            "   [-0.84313726]\n",
            "   [-0.8509804 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.06666672]\n",
            "   [ 0.06666672]\n",
            "   [ 0.05098045]\n",
            "   ...\n",
            "   [ 0.05882359]\n",
            "   [ 0.05882359]\n",
            "   [ 0.07450986]]\n",
            "\n",
            "  [[ 0.05882359]\n",
            "   [ 0.04313731]\n",
            "   [ 0.06666672]\n",
            "   ...\n",
            "   [ 0.082353  ]\n",
            "   [ 0.05098045]\n",
            "   [ 0.05882359]]\n",
            "\n",
            "  [[ 0.05098045]\n",
            "   [ 0.03529418]\n",
            "   [-0.01176471]\n",
            "   ...\n",
            "   [ 0.02745104]\n",
            "   [ 0.03529418]\n",
            "   [ 0.05098045]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.15294117]\n",
            "   [-0.15294117]\n",
            "   [-0.1607843 ]\n",
            "   ...\n",
            "   [-0.12156862]\n",
            "   [-0.12941176]\n",
            "   [-0.1372549 ]]\n",
            "\n",
            "  [[-0.15294117]\n",
            "   [-0.15294117]\n",
            "   [-0.15294117]\n",
            "   ...\n",
            "   [-0.1607843 ]\n",
            "   [-0.12156862]\n",
            "   [-0.12156862]]\n",
            "\n",
            "  [[-0.15294117]\n",
            "   [-0.15294117]\n",
            "   [-0.1607843 ]\n",
            "   ...\n",
            "   [ 0.17647064]\n",
            "   [-0.15294117]\n",
            "   [-0.11372548]]]\n",
            "\n",
            "\n",
            " [[[-0.7176471 ]\n",
            "   [-0.49019605]\n",
            "   [-0.5686275 ]\n",
            "   ...\n",
            "   [-0.5529412 ]\n",
            "   [-0.64705884]\n",
            "   [-0.67058825]]\n",
            "\n",
            "  [[-0.7019608 ]\n",
            "   [-0.5764706 ]\n",
            "   [-0.64705884]\n",
            "   ...\n",
            "   [-0.6       ]\n",
            "   [-0.6784314 ]\n",
            "   [-0.7019608 ]]\n",
            "\n",
            "  [[-0.70980394]\n",
            "   [-0.6627451 ]\n",
            "   [-0.62352943]\n",
            "   ...\n",
            "   [-0.6156863 ]\n",
            "   [-0.6784314 ]\n",
            "   [-0.7019608 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.05882359]\n",
            "   [ 0.34901965]\n",
            "   [ 0.49803925]\n",
            "   ...\n",
            "   [-0.70980394]\n",
            "   [-0.7019608 ]\n",
            "   [-0.7019608 ]]\n",
            "\n",
            "  [[-0.01960784]\n",
            "   [ 0.21568632]\n",
            "   [ 0.5529412 ]\n",
            "   ...\n",
            "   [-0.6862745 ]\n",
            "   [-0.654902  ]\n",
            "   [-0.7019608 ]]\n",
            "\n",
            "  [[ 0.01176476]\n",
            "   [ 0.02745104]\n",
            "   [ 0.47450984]\n",
            "   ...\n",
            "   [-0.6392157 ]\n",
            "   [-0.654902  ]\n",
            "   [-0.7019608 ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.2235294 ]\n",
            "   [-0.2235294 ]\n",
            "   [-0.10588235]\n",
            "   ...\n",
            "   [-0.5137255 ]\n",
            "   [-0.52156866]\n",
            "   [-0.4980392 ]]\n",
            "\n",
            "  [[-0.26274508]\n",
            "   [-0.08235294]\n",
            "   [ 0.17647064]\n",
            "   ...\n",
            "   [-0.36470586]\n",
            "   [-0.42745095]\n",
            "   [-0.23137254]]\n",
            "\n",
            "  [[ 0.16078436]\n",
            "   [ 0.28627455]\n",
            "   [ 0.2313726 ]\n",
            "   ...\n",
            "   [-0.27843136]\n",
            "   [-0.45098037]\n",
            "   [-0.3333333 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.31764704]\n",
            "   [-0.4588235 ]\n",
            "   [-0.6862745 ]\n",
            "   ...\n",
            "   [-0.5058824 ]\n",
            "   [-0.58431375]\n",
            "   [-0.79607844]]\n",
            "\n",
            "  [[-0.27843136]\n",
            "   [-0.6156863 ]\n",
            "   [-0.8039216 ]\n",
            "   ...\n",
            "   [-0.4980392 ]\n",
            "   [-0.38039213]\n",
            "   [-0.5372549 ]]\n",
            "\n",
            "  [[-0.4980392 ]\n",
            "   [-0.40392154]\n",
            "   [-0.6862745 ]\n",
            "   ...\n",
            "   [-0.6392157 ]\n",
            "   [-0.6       ]\n",
            "   [-0.56078434]]]\n",
            "\n",
            "\n",
            " [[[ 0.2941177 ]\n",
            "   [ 0.30196083]\n",
            "   [ 0.3176471 ]\n",
            "   ...\n",
            "   [ 0.8666667 ]\n",
            "   [ 0.90588236]\n",
            "   [ 0.90588236]]\n",
            "\n",
            "  [[ 0.20000005]\n",
            "   [ 0.24705887]\n",
            "   [ 0.27843142]\n",
            "   ...\n",
            "   [ 0.8117647 ]\n",
            "   [ 0.9137255 ]\n",
            "   [ 0.79607844]]\n",
            "\n",
            "  [[ 0.07450986]\n",
            "   [ 0.09803927]\n",
            "   [ 0.06666672]\n",
            "   ...\n",
            "   [ 0.69411767]\n",
            "   [ 0.8745098 ]\n",
            "   [ 0.7019608 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.08235294]\n",
            "   [-0.04313725]\n",
            "   [-0.01176471]\n",
            "   ...\n",
            "   [ 0.8117647 ]\n",
            "   [ 0.75686276]\n",
            "   [ 0.7882353 ]]\n",
            "\n",
            "  [[-0.12941176]\n",
            "   [-0.09019607]\n",
            "   [-0.05882353]\n",
            "   ...\n",
            "   [ 0.7490196 ]\n",
            "   [ 0.77254903]\n",
            "   [ 0.8039216 ]]\n",
            "\n",
            "  [[-0.20784312]\n",
            "   [-0.1607843 ]\n",
            "   [-0.11372548]\n",
            "   ...\n",
            "   [ 0.7647059 ]\n",
            "   [ 0.7882353 ]\n",
            "   [ 0.79607844]]]\n",
            "\n",
            "\n",
            " [[[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.8117647 ]\n",
            "   [-0.81960785]\n",
            "   [-0.8117647 ]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[-0.81960785]\n",
            "   [-0.81960785]\n",
            "   [-0.827451  ]\n",
            "   ...\n",
            "   [ 0.9843137 ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[-0.8509804 ]\n",
            "   [-0.84313726]\n",
            "   [-0.8509804 ]\n",
            "   ...\n",
            "   [ 0.9764706 ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]]] [[[[ 0.3803922 ]\n",
            "   [ 0.3803922 ]\n",
            "   [ 0.48235297]\n",
            "   ...\n",
            "   [-0.81960785]\n",
            "   [-0.8980392 ]\n",
            "   [-0.92941177]]\n",
            "\n",
            "  [[ 0.38823533]\n",
            "   [ 0.3803922 ]\n",
            "   [ 0.47450984]\n",
            "   ...\n",
            "   [-0.7019608 ]\n",
            "   [-0.79607844]\n",
            "   [-0.9137255 ]]\n",
            "\n",
            "  [[ 0.37254906]\n",
            "   [ 0.37254906]\n",
            "   [ 0.427451  ]\n",
            "   ...\n",
            "   [-0.7490196 ]\n",
            "   [-0.7647059 ]\n",
            "   [-0.8509804 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.3411765 ]\n",
            "   [ 0.33333337]\n",
            "   [ 0.3411765 ]\n",
            "   ...\n",
            "   [-0.5294118 ]\n",
            "   [-0.4823529 ]\n",
            "   [-0.5372549 ]]\n",
            "\n",
            "  [[ 0.3411765 ]\n",
            "   [ 0.35686278]\n",
            "   [ 0.34901965]\n",
            "   ...\n",
            "   [-0.6627451 ]\n",
            "   [-0.62352943]\n",
            "   [-0.6156863 ]]\n",
            "\n",
            "  [[ 0.32549024]\n",
            "   [ 0.3411765 ]\n",
            "   [ 0.34901965]\n",
            "   ...\n",
            "   [-0.7411765 ]\n",
            "   [-0.6862745 ]\n",
            "   [-0.7019608 ]]]\n",
            "\n",
            "\n",
            " [[[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 0.9764706 ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.6313726 ]\n",
            "   [ 0.6392157 ]\n",
            "   [ 0.5686275 ]\n",
            "   ...\n",
            "   [ 0.23921573]\n",
            "   [ 0.24705887]\n",
            "   [ 0.16078436]]\n",
            "\n",
            "  [[ 0.5137255 ]\n",
            "   [ 0.4901961 ]\n",
            "   [ 0.43529415]\n",
            "   ...\n",
            "   [ 0.2313726 ]\n",
            "   [ 0.14509809]\n",
            "   [ 0.00392163]]\n",
            "\n",
            "  [[ 0.38823533]\n",
            "   [ 0.32549024]\n",
            "   [ 0.27058828]\n",
            "   ...\n",
            "   [ 0.17647064]\n",
            "   [ 0.0196079 ]\n",
            "   [-0.09019607]]]\n",
            "\n",
            "\n",
            " [[[ 0.04313731]\n",
            "   [ 0.28627455]\n",
            "   [ 0.24705887]\n",
            "   ...\n",
            "   [ 0.17647064]\n",
            "   [-0.09019607]\n",
            "   [-0.10588235]]\n",
            "\n",
            "  [[ 0.09019613]\n",
            "   [ 0.15294123]\n",
            "   [ 0.16078436]\n",
            "   ...\n",
            "   [ 0.26274514]\n",
            "   [-0.01176471]\n",
            "   [-0.09803921]]\n",
            "\n",
            "  [[ 0.10588241]\n",
            "   [ 0.0196079 ]\n",
            "   [ 0.05882359]\n",
            "   ...\n",
            "   [ 0.32549024]\n",
            "   [ 0.18431377]\n",
            "   [-0.12156862]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.85882354]\n",
            "   [-0.90588236]\n",
            "   [-0.90588236]\n",
            "   ...\n",
            "   [ 0.07450986]\n",
            "   [-0.17647058]\n",
            "   [-0.47450978]]\n",
            "\n",
            "  [[-0.85882354]\n",
            "   [-0.90588236]\n",
            "   [-0.90588236]\n",
            "   ...\n",
            "   [-0.01176471]\n",
            "   [-0.3333333 ]\n",
            "   [-0.6392157 ]]\n",
            "\n",
            "  [[-0.85882354]\n",
            "   [-0.90588236]\n",
            "   [-0.90588236]\n",
            "   ...\n",
            "   [-0.17647058]\n",
            "   [-0.5058824 ]\n",
            "   [-0.64705884]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.27058822]\n",
            "   [-0.27843136]\n",
            "   [-0.29411763]\n",
            "   ...\n",
            "   [-0.41176468]\n",
            "   [-0.35686272]\n",
            "   [-0.41176468]]\n",
            "\n",
            "  [[-0.27058822]\n",
            "   [-0.30196077]\n",
            "   [-0.32549018]\n",
            "   ...\n",
            "   [-0.42745095]\n",
            "   [-0.35686272]\n",
            "   [-0.47450978]]\n",
            "\n",
            "  [[-0.17647058]\n",
            "   [-0.23921567]\n",
            "   [-0.23921567]\n",
            "   ...\n",
            "   [-0.40392154]\n",
            "   [-0.47450978]\n",
            "   [-0.54509807]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.81960785]\n",
            "   [-0.8117647 ]\n",
            "   [-0.81960785]\n",
            "   ...\n",
            "   [-0.94509804]\n",
            "   [-0.9529412 ]\n",
            "   [-0.96862745]]\n",
            "\n",
            "  [[-0.8352941 ]\n",
            "   [-0.8666667 ]\n",
            "   [-0.8666667 ]\n",
            "   ...\n",
            "   [-0.96862745]\n",
            "   [-0.9607843 ]\n",
            "   [-0.99215686]]\n",
            "\n",
            "  [[-0.84313726]\n",
            "   [-0.8745098 ]\n",
            "   [-0.8666667 ]\n",
            "   ...\n",
            "   [-0.9607843 ]\n",
            "   [-0.9764706 ]\n",
            "   [-0.99215686]]]\n",
            "\n",
            "\n",
            " [[[ 0.60784316]\n",
            "   [ 0.6       ]\n",
            "   [ 0.6       ]\n",
            "   ...\n",
            "   [ 0.4666667 ]\n",
            "   [ 0.4901961 ]\n",
            "   [ 0.5137255 ]]\n",
            "\n",
            "  [[ 0.6       ]\n",
            "   [ 0.58431375]\n",
            "   [ 0.5921569 ]\n",
            "   ...\n",
            "   [ 0.4431373 ]\n",
            "   [ 0.48235297]\n",
            "   [ 0.5137255 ]]\n",
            "\n",
            "  [[ 0.5764706 ]\n",
            "   [ 0.5686275 ]\n",
            "   [ 0.5764706 ]\n",
            "   ...\n",
            "   [ 0.43529415]\n",
            "   [ 0.45882356]\n",
            "   [ 0.49803925]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.67058825]\n",
            "   [ 0.64705884]\n",
            "   [ 0.60784316]\n",
            "   ...\n",
            "   [ 0.75686276]\n",
            "   [ 0.78039217]\n",
            "   [ 0.79607844]]\n",
            "\n",
            "  [[ 0.69411767]\n",
            "   [ 0.67058825]\n",
            "   [ 0.6392157 ]\n",
            "   ...\n",
            "   [ 0.7882353 ]\n",
            "   [ 0.7882353 ]\n",
            "   [ 0.7882353 ]]\n",
            "\n",
            "  [[ 0.70980394]\n",
            "   [ 0.6784314 ]\n",
            "   [ 0.654902  ]\n",
            "   ...\n",
            "   [ 0.78039217]\n",
            "   [ 0.78039217]\n",
            "   [ 0.77254903]]]\n",
            "\n",
            "\n",
            " [[[-0.3098039 ]\n",
            "   [-0.29411763]\n",
            "   [-0.30196077]\n",
            "   ...\n",
            "   [-0.70980394]\n",
            "   [-0.7411765 ]\n",
            "   [-0.58431375]]\n",
            "\n",
            "  [[-0.2862745 ]\n",
            "   [-0.31764704]\n",
            "   [-0.3490196 ]\n",
            "   ...\n",
            "   [-0.6784314 ]\n",
            "   [-0.73333335]\n",
            "   [-0.6784314 ]]\n",
            "\n",
            "  [[-0.31764704]\n",
            "   [-0.36470586]\n",
            "   [-0.34117645]\n",
            "   ...\n",
            "   [-0.7647059 ]\n",
            "   [-0.69411767]\n",
            "   [-0.7019608 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.827451  ]\n",
            "   [ 0.7490196 ]\n",
            "   [ 0.81960785]\n",
            "   ...\n",
            "   [-0.92941177]\n",
            "   [-0.85882354]\n",
            "   [-0.69411767]]\n",
            "\n",
            "  [[ 0.8745098 ]\n",
            "   [ 0.8980392 ]\n",
            "   [ 0.88235295]\n",
            "   ...\n",
            "   [-0.92941177]\n",
            "   [-0.88235295]\n",
            "   [-0.7882353 ]]\n",
            "\n",
            "  [[ 0.8980392 ]\n",
            "   [ 0.9372549 ]\n",
            "   [ 0.9372549 ]\n",
            "   ...\n",
            "   [-0.9372549 ]\n",
            "   [-0.9137255 ]\n",
            "   [-0.8039216 ]]]] [[[[ 0.082353  ]\n",
            "   [ 0.082353  ]\n",
            "   [ 0.07450986]\n",
            "   ...\n",
            "   [-0.6       ]\n",
            "   [-0.77254903]\n",
            "   [-0.827451  ]]\n",
            "\n",
            "  [[ 0.05098045]\n",
            "   [ 0.05098045]\n",
            "   [ 0.06666672]\n",
            "   ...\n",
            "   [-0.5529412 ]\n",
            "   [-0.7254902 ]\n",
            "   [-0.73333335]]\n",
            "\n",
            "  [[ 0.082353  ]\n",
            "   [ 0.07450986]\n",
            "   [ 0.082353  ]\n",
            "   ...\n",
            "   [-0.6156863 ]\n",
            "   [-0.7176471 ]\n",
            "   [-0.56078434]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.02745098]\n",
            "   [-0.04313725]\n",
            "   [-0.02745098]\n",
            "   ...\n",
            "   [-0.2235294 ]\n",
            "   [-0.38039213]\n",
            "   [-0.67058825]]\n",
            "\n",
            "  [[-0.09019607]\n",
            "   [-0.05882353]\n",
            "   [-0.02745098]\n",
            "   ...\n",
            "   [-0.15294117]\n",
            "   [-0.38039213]\n",
            "   [-0.73333335]]\n",
            "\n",
            "  [[-0.02745098]\n",
            "   [-0.08235294]\n",
            "   [-0.0745098 ]\n",
            "   ...\n",
            "   [-0.09019607]\n",
            "   [-0.41176468]\n",
            "   [-0.6862745 ]]]\n",
            "\n",
            "\n",
            " [[[-0.62352943]\n",
            "   [-0.6       ]\n",
            "   [-0.8039216 ]\n",
            "   ...\n",
            "   [-0.9137255 ]\n",
            "   [-0.96862745]\n",
            "   [-0.9607843 ]]\n",
            "\n",
            "  [[-0.5372549 ]\n",
            "   [-0.5137255 ]\n",
            "   [-0.8901961 ]\n",
            "   ...\n",
            "   [-0.8980392 ]\n",
            "   [-0.9529412 ]\n",
            "   [-0.96862745]]\n",
            "\n",
            "  [[-0.79607844]\n",
            "   [-0.67058825]\n",
            "   [-0.827451  ]\n",
            "   ...\n",
            "   [-0.88235295]\n",
            "   [-0.92156863]\n",
            "   [-0.96862745]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.67058825]\n",
            "   [-0.6627451 ]\n",
            "   [-0.67058825]\n",
            "   ...\n",
            "   [-0.9607843 ]\n",
            "   [-0.96862745]\n",
            "   [-0.9764706 ]]\n",
            "\n",
            "  [[-0.6862745 ]\n",
            "   [-0.6784314 ]\n",
            "   [-0.6784314 ]\n",
            "   ...\n",
            "   [-1.        ]\n",
            "   [-0.9607843 ]\n",
            "   [-0.96862745]]\n",
            "\n",
            "  [[-0.69411767]\n",
            "   [-0.6862745 ]\n",
            "   [-0.7019608 ]\n",
            "   ...\n",
            "   [-0.8745098 ]\n",
            "   [-0.92941177]\n",
            "   [-0.96862745]]]\n",
            "\n",
            "\n",
            " [[[ 0.92941177]\n",
            "   [ 0.92156863]\n",
            "   [ 0.92156863]\n",
            "   ...\n",
            "   [-0.6       ]\n",
            "   [-0.58431375]\n",
            "   [-0.5764706 ]]\n",
            "\n",
            "  [[ 0.8980392 ]\n",
            "   [ 0.90588236]\n",
            "   [ 0.92941177]\n",
            "   ...\n",
            "   [-0.5529412 ]\n",
            "   [-0.58431375]\n",
            "   [-0.5764706 ]]\n",
            "\n",
            "  [[ 0.8980392 ]\n",
            "   [ 0.90588236]\n",
            "   [ 0.92156863]\n",
            "   ...\n",
            "   [-0.56078434]\n",
            "   [-0.5921569 ]\n",
            "   [-0.58431375]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.60784316]\n",
            "   [ 0.5764706 ]\n",
            "   [ 0.5764706 ]\n",
            "   ...\n",
            "   [ 0.3803922 ]\n",
            "   [ 0.48235297]\n",
            "   [ 0.45098042]]\n",
            "\n",
            "  [[ 0.5764706 ]\n",
            "   [ 0.5921569 ]\n",
            "   [ 0.58431375]\n",
            "   ...\n",
            "   [ 0.47450984]\n",
            "   [ 0.427451  ]\n",
            "   [ 0.41176474]]\n",
            "\n",
            "  [[ 0.5686275 ]\n",
            "   [ 0.5921569 ]\n",
            "   [ 0.5764706 ]\n",
            "   ...\n",
            "   [ 0.45098042]\n",
            "   [ 0.41960788]\n",
            "   [ 0.36470592]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.5686275 ]\n",
            "   [-0.6       ]\n",
            "   [-0.654902  ]\n",
            "   ...\n",
            "   [-0.827451  ]\n",
            "   [-0.4588235 ]\n",
            "   [-0.29411763]]\n",
            "\n",
            "  [[-0.5686275 ]\n",
            "   [-0.6156863 ]\n",
            "   [-0.654902  ]\n",
            "   ...\n",
            "   [-0.7882353 ]\n",
            "   [-0.6862745 ]\n",
            "   [-0.35686272]]\n",
            "\n",
            "  [[-0.4588235 ]\n",
            "   [-0.5137255 ]\n",
            "   [-0.54509807]\n",
            "   ...\n",
            "   [-0.73333335]\n",
            "   [-0.7647059 ]\n",
            "   [-0.56078434]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.7882353 ]\n",
            "   [ 0.8509804 ]\n",
            "   [ 0.8666667 ]\n",
            "   ...\n",
            "   [ 0.67058825]\n",
            "   [ 0.70980394]\n",
            "   [ 0.7019608 ]]\n",
            "\n",
            "  [[ 0.3411765 ]\n",
            "   [ 0.4431373 ]\n",
            "   [ 0.5137255 ]\n",
            "   ...\n",
            "   [ 0.7019608 ]\n",
            "   [ 0.70980394]\n",
            "   [ 0.70980394]]\n",
            "\n",
            "  [[ 0.5529412 ]\n",
            "   [ 0.45098042]\n",
            "   [ 0.2941177 ]\n",
            "   ...\n",
            "   [ 0.69411767]\n",
            "   [ 0.69411767]\n",
            "   [ 0.69411767]]]\n",
            "\n",
            "\n",
            " [[[ 0.8980392 ]\n",
            "   [ 0.9764706 ]\n",
            "   [ 0.6156863 ]\n",
            "   ...\n",
            "   [-0.21568626]\n",
            "   [-0.05098039]\n",
            "   [ 0.5764706 ]]\n",
            "\n",
            "  [[ 0.9137255 ]\n",
            "   [ 0.9764706 ]\n",
            "   [-0.40392154]\n",
            "   ...\n",
            "   [-0.34117645]\n",
            "   [ 0.2313726 ]\n",
            "   [ 0.5686275 ]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 0.77254903]\n",
            "   [-0.8117647 ]\n",
            "   ...\n",
            "   [-0.36470586]\n",
            "   [ 0.7019608 ]\n",
            "   [ 0.8117647 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.9843137 ]\n",
            "   [-0.9843137 ]\n",
            "   [-0.99215686]\n",
            "   ...\n",
            "   [-0.94509804]\n",
            "   [-0.9607843 ]\n",
            "   [-0.99215686]]\n",
            "\n",
            "  [[-0.9843137 ]\n",
            "   [-0.9764706 ]\n",
            "   [-0.9843137 ]\n",
            "   ...\n",
            "   [-0.94509804]\n",
            "   [-0.9607843 ]\n",
            "   [-0.99215686]]\n",
            "\n",
            "  [[-0.9843137 ]\n",
            "   [-0.9843137 ]\n",
            "   [-0.99215686]\n",
            "   ...\n",
            "   [-0.9529412 ]\n",
            "   [-0.9607843 ]\n",
            "   [-0.9843137 ]]]\n",
            "\n",
            "\n",
            " [[[-0.78039217]\n",
            "   [-0.73333335]\n",
            "   [-0.6392157 ]\n",
            "   ...\n",
            "   [-0.36470586]\n",
            "   [ 0.41960788]\n",
            "   [ 0.5058824 ]]\n",
            "\n",
            "  [[-0.75686276]\n",
            "   [-0.7176471 ]\n",
            "   [-0.6392157 ]\n",
            "   ...\n",
            "   [-0.6784314 ]\n",
            "   [-0.3960784 ]\n",
            "   [ 0.30196083]]\n",
            "\n",
            "  [[-0.7411765 ]\n",
            "   [-0.7019608 ]\n",
            "   [-0.6627451 ]\n",
            "   ...\n",
            "   [-0.6392157 ]\n",
            "   [-0.6784314 ]\n",
            "   [-0.54509807]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.7490196 ]\n",
            "   [-0.7411765 ]\n",
            "   [-0.7254902 ]\n",
            "   ...\n",
            "   [-0.23921567]\n",
            "   [-0.27843136]\n",
            "   [-0.09803921]]\n",
            "\n",
            "  [[-0.77254903]\n",
            "   [-0.75686276]\n",
            "   [-0.7411765 ]\n",
            "   ...\n",
            "   [-0.23921567]\n",
            "   [-0.27058822]\n",
            "   [ 0.11372554]]\n",
            "\n",
            "  [[-0.78039217]\n",
            "   [-0.7647059 ]\n",
            "   [-0.7647059 ]\n",
            "   ...\n",
            "   [-0.26274508]\n",
            "   [-0.1607843 ]\n",
            "   [ 0.28627455]]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\\n\\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKvEv321Stt5",
        "outputId": "09ab42fb-6978-471c-abdf-77ba2e58d662"
      },
      "source": [
        "print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validasi (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "test (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "train (28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH9Q-TegBR26"
      },
      "source": [
        "#hyperparameter and callback\n",
        "batch_size = 128\n",
        "num_epochs = 120\n",
        "input_shape = (48, 48, 1)\n",
        "num_classes = 7\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGsscQRJBR-h"
      },
      "source": [
        "#Compile the model.\n",
        "\n",
        "\n",
        "from keras.optimizers import Adam, SGD\n",
        "model = ResNet50ori(input_shape = (48, 48, 1), classes = 7)\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "model.compile(optimizer= optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rodttDWeT2yP"
      },
      "source": [
        "#kita mau save model callbackshuhuhuhuhhg\n",
        "\"\"\"import os\n",
        "try:\n",
        "  os.mkdir('scratchcheckpoint')\n",
        "except:\n",
        "  pass\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV29sTjET28U"
      },
      "source": [
        "\"\"\"file_name = 'Best_Model_resnet50Scracth_sena1.h5'\n",
        "\n",
        "checkpoint_path = os.path.join('checkpoint',file_name)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_S6wUaPT3Jx"
      },
      "source": [
        "\"\"\"call_back = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
        "                                               monitor='val_accuracy',\n",
        "                                               verbose=1,\n",
        "                                               save_freq='epoch',\n",
        "                                               save_best_only=True,\n",
        "                                               save_weights_only=False,\n",
        "                                               mode='max')\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy53DHMGB-Mr",
        "outputId": "2b52cca8-9102-4748-cf2c-3ce91b8256aa"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50ori\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 54, 54, 1)    0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 24, 24, 64)   3200        zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 24, 24, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 24, 24, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 11, 11, 64)   0           activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 11, 11, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 11, 11, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 11, 11, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 11, 11, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 11, 11, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 11, 11, 256)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 11, 11, 256)  0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 11, 11, 64)   16448       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 11, 11, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 11, 11, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 11, 11, 256)  0           activation_52[0][0]              \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 11, 11, 256)  0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 11, 11, 64)   16448       activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 11, 11, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 11, 11, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 11, 11, 256)  0           activation_55[0][0]              \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 11, 11, 256)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 6, 6, 128)    32896       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 6, 6, 128)    0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 6, 6, 128)    0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 6, 6, 512)    131584      activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 6, 6, 512)    2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 6, 6, 512)    0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 6, 6, 512)    0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 6, 6, 128)    0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 6, 6, 128)    0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 6, 6, 512)    0           activation_61[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 6, 6, 512)    0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 6, 6, 128)    0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 6, 6, 128)    0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 6, 6, 512)    0           activation_64[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 6, 6, 512)    0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 6, 6, 128)    0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 6, 6, 128)    0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 6, 6, 512)    0           activation_67[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 6, 6, 512)    0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 3, 3, 256)    131328      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 256)    0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 3, 3, 256)    0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 3, 3, 1024)   525312      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 3, 3, 1024)   4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 3, 3, 1024)   0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 3, 3, 1024)   0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 3, 3, 256)    0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 256)    0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 3, 3, 1024)   0           activation_73[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 1024)   0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 256)    0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 256)    0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 3, 3, 1024)   0           activation_76[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 1024)   0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 256)    0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 256)    0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 3, 3, 1024)   0           activation_79[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 1024)   0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 256)    0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 256)    0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 3, 3, 1024)   0           activation_82[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 1024)   0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 256)    0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 256)    0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 3, 3, 1024)   0           activation_85[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 1024)   0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 2, 2, 512)    524800      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 2, 2, 2048)   2099200     activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 2, 2, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 2, 2, 2048)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 2, 2, 2048)   0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 2, 2, 2048)   0           activation_91[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 2, 2, 2048)   0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 2, 2, 2048)   0           activation_94[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 2, 2, 2048)   0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 2048)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            14343       flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 23,595,783\n",
            "Trainable params: 23,542,663\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgxCecVwCGEr"
      },
      "source": [
        "\"\"\"history = model.fit(data_generator.flow(xtrain, ytrain,),\n",
        "                        steps_per_epoch=len(xtrain) / batch_size,\n",
        "                        epochs=num_epochs, verbose=1,callbacks=call_back,\n",
        "                        validation_data= (xtest,ytest))\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2muXWns0sJSH",
        "outputId": "5709a374-d886-42eb-978c-63ef013c850a"
      },
      "source": [
        "history = model.fit(\n",
        "    data_generator.flow(xtrain, ytrain,),\n",
        "    steps_per_epoch=len(xtrain) / batch_size,\n",
        "    epochs=num_epochs, \n",
        "    verbose=1,\n",
        "    validation_data= (x_val,y_val))\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/120\n",
            "224/224 [==============================] - 48s 150ms/step - loss: 6.0282 - accuracy: 0.1978 - val_loss: 1.9184 - val_accuracy: 0.2416\n",
            "Epoch 2/120\n",
            "224/224 [==============================] - 29s 129ms/step - loss: 1.8508 - accuracy: 0.2474 - val_loss: 2.2961 - val_accuracy: 0.2006\n",
            "Epoch 3/120\n",
            "224/224 [==============================] - 29s 129ms/step - loss: 1.8132 - accuracy: 0.2413 - val_loss: 2.3191 - val_accuracy: 0.2458\n",
            "Epoch 4/120\n",
            "224/224 [==============================] - 29s 129ms/step - loss: 1.8014 - accuracy: 0.2474 - val_loss: 6.3273 - val_accuracy: 0.2134\n",
            "Epoch 5/120\n",
            "224/224 [==============================] - 31s 138ms/step - loss: 1.7970 - accuracy: 0.2542 - val_loss: 1.7934 - val_accuracy: 0.2575\n",
            "Epoch 6/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.7828 - accuracy: 0.2706 - val_loss: 1.8011 - val_accuracy: 0.2959\n",
            "Epoch 7/120\n",
            "224/224 [==============================] - 29s 129ms/step - loss: 1.7434 - accuracy: 0.2889 - val_loss: 1.7402 - val_accuracy: 0.3179\n",
            "Epoch 8/120\n",
            "224/224 [==============================] - 31s 138ms/step - loss: 1.7085 - accuracy: 0.3016 - val_loss: 1.6451 - val_accuracy: 0.3500\n",
            "Epoch 9/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.6676 - accuracy: 0.3209 - val_loss: 1.6474 - val_accuracy: 0.3380\n",
            "Epoch 10/120\n",
            "224/224 [==============================] - 29s 129ms/step - loss: 1.6302 - accuracy: 0.3506 - val_loss: 1.6151 - val_accuracy: 0.3519\n",
            "Epoch 11/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.6281 - accuracy: 0.3432 - val_loss: 1.6452 - val_accuracy: 0.3756\n",
            "Epoch 12/120\n",
            "224/224 [==============================] - 29s 129ms/step - loss: 1.5908 - accuracy: 0.3705 - val_loss: 1.5756 - val_accuracy: 0.3661\n",
            "Epoch 13/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.5636 - accuracy: 0.3823 - val_loss: 1.6656 - val_accuracy: 0.3817\n",
            "Epoch 14/120\n",
            "224/224 [==============================] - 29s 129ms/step - loss: 1.5251 - accuracy: 0.3931 - val_loss: 1.6119 - val_accuracy: 0.3909\n",
            "Epoch 15/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.4931 - accuracy: 0.4188 - val_loss: 1.4795 - val_accuracy: 0.4291\n",
            "Epoch 16/120\n",
            "224/224 [==============================] - 31s 138ms/step - loss: 1.4967 - accuracy: 0.4111 - val_loss: 1.5027 - val_accuracy: 0.4046\n",
            "Epoch 17/120\n",
            "224/224 [==============================] - 31s 138ms/step - loss: 1.4585 - accuracy: 0.4247 - val_loss: 3.9590 - val_accuracy: 0.4244\n",
            "Epoch 18/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.4407 - accuracy: 0.4430 - val_loss: 1.7418 - val_accuracy: 0.3795\n",
            "Epoch 19/120\n",
            "224/224 [==============================] - 31s 138ms/step - loss: 1.4482 - accuracy: 0.4364 - val_loss: 1.7239 - val_accuracy: 0.3486\n",
            "Epoch 20/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.3976 - accuracy: 0.4560 - val_loss: 141.2221 - val_accuracy: 0.2210\n",
            "Epoch 21/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.4433 - accuracy: 0.4368 - val_loss: 1.6422 - val_accuracy: 0.3982\n",
            "Epoch 22/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.4636 - accuracy: 0.4266 - val_loss: 2.1618 - val_accuracy: 0.3318\n",
            "Epoch 23/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.5446 - accuracy: 0.3934 - val_loss: 1.6543 - val_accuracy: 0.4202\n",
            "Epoch 24/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.4147 - accuracy: 0.4585 - val_loss: 2.7733 - val_accuracy: 0.2683\n",
            "Epoch 25/120\n",
            "224/224 [==============================] - 31s 139ms/step - loss: 1.4887 - accuracy: 0.4203 - val_loss: 6.5172 - val_accuracy: 0.2413\n",
            "Epoch 26/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.4298 - accuracy: 0.4442 - val_loss: 1.3953 - val_accuracy: 0.4592\n",
            "Epoch 27/120\n",
            "224/224 [==============================] - 31s 139ms/step - loss: 1.3906 - accuracy: 0.4542 - val_loss: 11.2868 - val_accuracy: 0.2800\n",
            "Epoch 28/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.3729 - accuracy: 0.4622 - val_loss: 1.3410 - val_accuracy: 0.4703\n",
            "Epoch 29/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.3540 - accuracy: 0.4731 - val_loss: 4.7310 - val_accuracy: 0.3736\n",
            "Epoch 30/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.3249 - accuracy: 0.4894 - val_loss: 1.8797 - val_accuracy: 0.3987\n",
            "Epoch 31/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.4406 - accuracy: 0.4360 - val_loss: 1.4318 - val_accuracy: 0.4455\n",
            "Epoch 32/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.3176 - accuracy: 0.4789 - val_loss: 1.3228 - val_accuracy: 0.4890\n",
            "Epoch 33/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.3118 - accuracy: 0.4885 - val_loss: 1.3575 - val_accuracy: 0.4854\n",
            "Epoch 34/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.3106 - accuracy: 0.4915 - val_loss: 1.4019 - val_accuracy: 0.4695\n",
            "Epoch 35/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.2747 - accuracy: 0.5087 - val_loss: 1.3308 - val_accuracy: 0.4781\n",
            "Epoch 36/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.2406 - accuracy: 0.5306 - val_loss: 1.5416 - val_accuracy: 0.4567\n",
            "Epoch 37/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.2439 - accuracy: 0.5222 - val_loss: 1.6785 - val_accuracy: 0.4581\n",
            "Epoch 38/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.2219 - accuracy: 0.5382 - val_loss: 1.3319 - val_accuracy: 0.4901\n",
            "Epoch 39/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.2243 - accuracy: 0.5181 - val_loss: 1.2564 - val_accuracy: 0.5160\n",
            "Epoch 40/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.1834 - accuracy: 0.5441 - val_loss: 1.3000 - val_accuracy: 0.5110\n",
            "Epoch 41/120\n",
            "224/224 [==============================] - 31s 140ms/step - loss: 1.2290 - accuracy: 0.5411 - val_loss: 2.5387 - val_accuracy: 0.3697\n",
            "Epoch 42/120\n",
            "224/224 [==============================] - 31s 139ms/step - loss: 1.1480 - accuracy: 0.5660 - val_loss: 1.5918 - val_accuracy: 0.4313\n",
            "Epoch 43/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.1451 - accuracy: 0.5756 - val_loss: 1.2494 - val_accuracy: 0.5263\n",
            "Epoch 44/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 1.1237 - accuracy: 0.5826 - val_loss: 1.2945 - val_accuracy: 0.5216\n",
            "Epoch 45/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.1013 - accuracy: 0.5885 - val_loss: 1.2379 - val_accuracy: 0.5355\n",
            "Epoch 46/120\n",
            "224/224 [==============================] - 31s 139ms/step - loss: 1.0984 - accuracy: 0.5816 - val_loss: 1.3424 - val_accuracy: 0.4951\n",
            "Epoch 47/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.0963 - accuracy: 0.5888 - val_loss: 1.2850 - val_accuracy: 0.5241\n",
            "Epoch 48/120\n",
            "224/224 [==============================] - 31s 139ms/step - loss: 1.0479 - accuracy: 0.6104 - val_loss: 1.3025 - val_accuracy: 0.5205\n",
            "Epoch 49/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.0387 - accuracy: 0.6110 - val_loss: 1.4897 - val_accuracy: 0.4837\n",
            "Epoch 50/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.0399 - accuracy: 0.6128 - val_loss: 1.3532 - val_accuracy: 0.4962\n",
            "Epoch 51/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 1.0392 - accuracy: 0.6154 - val_loss: 1.2834 - val_accuracy: 0.5339\n",
            "Epoch 52/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 1.0025 - accuracy: 0.6290 - val_loss: 1.2780 - val_accuracy: 0.5249\n",
            "Epoch 53/120\n",
            "224/224 [==============================] - 32s 141ms/step - loss: 0.9747 - accuracy: 0.6490 - val_loss: 1.3034 - val_accuracy: 0.5291\n",
            "Epoch 54/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 0.9526 - accuracy: 0.6449 - val_loss: 1.2999 - val_accuracy: 0.5294\n",
            "Epoch 55/120\n",
            "224/224 [==============================] - 30s 131ms/step - loss: 0.9242 - accuracy: 0.6606 - val_loss: 1.2642 - val_accuracy: 0.5358\n",
            "Epoch 56/120\n",
            "224/224 [==============================] - 29s 130ms/step - loss: 0.8936 - accuracy: 0.6756 - val_loss: 1.2788 - val_accuracy: 0.5481\n",
            "Epoch 57/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 0.9039 - accuracy: 0.6721 - val_loss: 1.3257 - val_accuracy: 0.5361\n",
            "Epoch 58/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 0.8749 - accuracy: 0.6855 - val_loss: 1.6382 - val_accuracy: 0.5063\n",
            "Epoch 59/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 0.8432 - accuracy: 0.6939 - val_loss: 1.2764 - val_accuracy: 0.5536\n",
            "Epoch 60/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 0.8692 - accuracy: 0.6846 - val_loss: 1.2377 - val_accuracy: 0.5536\n",
            "Epoch 61/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 0.8394 - accuracy: 0.6962 - val_loss: 1.3271 - val_accuracy: 0.5333\n",
            "Epoch 62/120\n",
            "224/224 [==============================] - 31s 140ms/step - loss: 0.8031 - accuracy: 0.6996 - val_loss: 1.3076 - val_accuracy: 0.5609\n",
            "Epoch 63/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 0.7707 - accuracy: 0.7293 - val_loss: 1.3009 - val_accuracy: 0.5612\n",
            "Epoch 64/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 0.7444 - accuracy: 0.7387 - val_loss: 1.3661 - val_accuracy: 0.5495\n",
            "Epoch 65/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 0.7624 - accuracy: 0.7272 - val_loss: 1.4292 - val_accuracy: 0.5319\n",
            "Epoch 66/120\n",
            "224/224 [==============================] - 31s 140ms/step - loss: 0.7068 - accuracy: 0.7433 - val_loss: 1.4575 - val_accuracy: 0.5300\n",
            "Epoch 67/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 0.7120 - accuracy: 0.7412 - val_loss: 1.4331 - val_accuracy: 0.5419\n",
            "Epoch 68/120\n",
            "224/224 [==============================] - 31s 140ms/step - loss: 0.6942 - accuracy: 0.7571 - val_loss: 1.3892 - val_accuracy: 0.5606\n",
            "Epoch 69/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 0.6456 - accuracy: 0.7714 - val_loss: 1.3816 - val_accuracy: 0.5598\n",
            "Epoch 70/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 0.6472 - accuracy: 0.7619 - val_loss: 1.4207 - val_accuracy: 0.5620\n",
            "Epoch 71/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 0.6290 - accuracy: 0.7845 - val_loss: 1.4313 - val_accuracy: 0.5528\n",
            "Epoch 72/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 0.5880 - accuracy: 0.7945 - val_loss: 1.4575 - val_accuracy: 0.5600\n",
            "Epoch 73/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 0.5679 - accuracy: 0.7997 - val_loss: 1.4412 - val_accuracy: 0.5687\n",
            "Epoch 74/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 0.5445 - accuracy: 0.8114 - val_loss: 1.4604 - val_accuracy: 0.5678\n",
            "Epoch 75/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 0.5091 - accuracy: 0.8291 - val_loss: 1.4308 - val_accuracy: 0.5637\n",
            "Epoch 76/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 0.5081 - accuracy: 0.8160 - val_loss: 1.5609 - val_accuracy: 0.5500\n",
            "Epoch 77/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 0.5018 - accuracy: 0.8245 - val_loss: 1.5144 - val_accuracy: 0.5430\n",
            "Epoch 78/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 0.4697 - accuracy: 0.8424 - val_loss: 1.5613 - val_accuracy: 0.5508\n",
            "Epoch 79/120\n",
            "224/224 [==============================] - 29s 132ms/step - loss: 0.4703 - accuracy: 0.8388 - val_loss: 1.5874 - val_accuracy: 0.5553\n",
            "Epoch 80/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 0.4603 - accuracy: 0.8443 - val_loss: 1.6350 - val_accuracy: 0.5430\n",
            "Epoch 81/120\n",
            "224/224 [==============================] - 31s 140ms/step - loss: 0.4164 - accuracy: 0.8567 - val_loss: 1.5570 - val_accuracy: 0.5678\n",
            "Epoch 82/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 0.4306 - accuracy: 0.8551 - val_loss: 1.5754 - val_accuracy: 0.5536\n",
            "Epoch 83/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 0.3891 - accuracy: 0.8764 - val_loss: 1.6250 - val_accuracy: 0.5575\n",
            "Epoch 84/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 0.3910 - accuracy: 0.8682 - val_loss: 1.6791 - val_accuracy: 0.5506\n",
            "Epoch 85/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 0.3799 - accuracy: 0.8726 - val_loss: 1.6918 - val_accuracy: 0.5684\n",
            "Epoch 86/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 0.3607 - accuracy: 0.8744 - val_loss: 1.8464 - val_accuracy: 0.5408\n",
            "Epoch 87/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 0.3629 - accuracy: 0.8778 - val_loss: 1.8606 - val_accuracy: 0.5394\n",
            "Epoch 88/120\n",
            "224/224 [==============================] - 29s 132ms/step - loss: 0.3488 - accuracy: 0.8793 - val_loss: 1.7417 - val_accuracy: 0.5570\n",
            "Epoch 89/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 0.3494 - accuracy: 0.8783 - val_loss: 1.7769 - val_accuracy: 0.5483\n",
            "Epoch 90/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 0.3066 - accuracy: 0.8980 - val_loss: 1.8005 - val_accuracy: 0.5592\n",
            "Epoch 91/120\n",
            "224/224 [==============================] - 29s 132ms/step - loss: 0.3383 - accuracy: 0.8862 - val_loss: 1.6980 - val_accuracy: 0.5626\n",
            "Epoch 92/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 0.2962 - accuracy: 0.8936 - val_loss: 1.9088 - val_accuracy: 0.5495\n",
            "Epoch 93/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 0.3293 - accuracy: 0.8892 - val_loss: 1.8231 - val_accuracy: 0.5525\n",
            "Epoch 94/120\n",
            "224/224 [==============================] - 31s 140ms/step - loss: 0.3113 - accuracy: 0.8938 - val_loss: 1.7862 - val_accuracy: 0.5553\n",
            "Epoch 95/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 0.3027 - accuracy: 0.9008 - val_loss: 1.8951 - val_accuracy: 0.5617\n",
            "Epoch 96/120\n",
            "224/224 [==============================] - 31s 140ms/step - loss: 0.2873 - accuracy: 0.9009 - val_loss: 2.0007 - val_accuracy: 0.5419\n",
            "Epoch 97/120\n",
            "224/224 [==============================] - 30s 131ms/step - loss: 0.2599 - accuracy: 0.9119 - val_loss: 1.8149 - val_accuracy: 0.5659\n",
            "Epoch 98/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 0.2654 - accuracy: 0.9108 - val_loss: 1.8230 - val_accuracy: 0.5595\n",
            "Epoch 99/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 0.2516 - accuracy: 0.9190 - val_loss: 1.9349 - val_accuracy: 0.5525\n",
            "Epoch 100/120\n",
            "224/224 [==============================] - 29s 132ms/step - loss: 0.2342 - accuracy: 0.9208 - val_loss: 1.9233 - val_accuracy: 0.5500\n",
            "Epoch 101/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 0.2681 - accuracy: 0.9064 - val_loss: 1.9132 - val_accuracy: 0.5570\n",
            "Epoch 102/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 0.2218 - accuracy: 0.9253 - val_loss: 1.9206 - val_accuracy: 0.5626\n",
            "Epoch 103/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 0.2092 - accuracy: 0.9270 - val_loss: 2.0726 - val_accuracy: 0.5433\n",
            "Epoch 104/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 0.2376 - accuracy: 0.9151 - val_loss: 2.0221 - val_accuracy: 0.5433\n",
            "Epoch 105/120\n",
            "224/224 [==============================] - 29s 132ms/step - loss: 0.2332 - accuracy: 0.9181 - val_loss: 2.0449 - val_accuracy: 0.5648\n",
            "Epoch 106/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 0.2187 - accuracy: 0.9252 - val_loss: 1.9933 - val_accuracy: 0.5653\n",
            "Epoch 107/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 0.2028 - accuracy: 0.9303 - val_loss: 1.9923 - val_accuracy: 0.5623\n",
            "Epoch 108/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 0.2252 - accuracy: 0.9209 - val_loss: 1.9907 - val_accuracy: 0.5595\n",
            "Epoch 109/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 0.2197 - accuracy: 0.9305 - val_loss: 2.1790 - val_accuracy: 0.5665\n",
            "Epoch 110/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 0.1894 - accuracy: 0.9389 - val_loss: 2.1174 - val_accuracy: 0.5603\n",
            "Epoch 111/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 0.1900 - accuracy: 0.9322 - val_loss: 2.0269 - val_accuracy: 0.5662\n",
            "Epoch 112/120\n",
            "224/224 [==============================] - 29s 132ms/step - loss: 0.1924 - accuracy: 0.9342 - val_loss: 2.0590 - val_accuracy: 0.5734\n",
            "Epoch 113/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 0.1992 - accuracy: 0.9299 - val_loss: 2.1518 - val_accuracy: 0.5386\n",
            "Epoch 114/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 0.1807 - accuracy: 0.9407 - val_loss: 2.1672 - val_accuracy: 0.5678\n",
            "Epoch 115/120\n",
            "224/224 [==============================] - 31s 140ms/step - loss: 0.2014 - accuracy: 0.9297 - val_loss: 2.0904 - val_accuracy: 0.5712\n",
            "Epoch 116/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 0.1709 - accuracy: 0.9482 - val_loss: 2.1559 - val_accuracy: 0.5517\n",
            "Epoch 117/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 0.1651 - accuracy: 0.9459 - val_loss: 2.1408 - val_accuracy: 0.5678\n",
            "Epoch 118/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 0.1587 - accuracy: 0.9450 - val_loss: 2.2103 - val_accuracy: 0.5561\n",
            "Epoch 119/120\n",
            "224/224 [==============================] - 29s 131ms/step - loss: 0.1576 - accuracy: 0.9497 - val_loss: 2.1329 - val_accuracy: 0.5639\n",
            "Epoch 120/120\n",
            "224/224 [==============================] - 30s 132ms/step - loss: 0.1777 - accuracy: 0.9384 - val_loss: 2.2288 - val_accuracy: 0.5712\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "GaXUP-8fDWRN",
        "outputId": "367d1688-fde9-4f3e-85a4-b9d0ead389ac"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "model.save('/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50oriAdamst120epochBS128_noaug1.h5')\n",
        "\n",
        "#gffhgffkjkjdskjjkjkjkjhjhnnnhjhhu\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "num_epochs = range(len(accuracy))\n",
        "plt.plot(num_epochs, accuracy, 'r', label='Training acc')\n",
        "plt.plot(num_epochs, val_accuracy, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(num_epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(num_epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_LxatO5J-pp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e56add5-b8e7-4ba3-ba59-7fb70ea79aed"
      },
      "source": [
        "testloss = model.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "trainloss = model.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(trainloss[0]))\n",
        "print(\"Train Acc: \" + str(trainloss[1]))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 4s 31ms/step - loss: 2.3319 - accuracy: 0.5467\n",
            "Test Loss 2.331927537918091\n",
            "Test Acc: 0.5466703772544861\n",
            "898/898 [==============================] - 28s 31ms/step - loss: 0.1939 - accuracy: 0.9344\n",
            "Train Loss 0.19394201040267944\n",
            "Train Acc: 0.9343760013580322\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swoRERVdKQ1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c453f03-b8bf-4a17-dd7a-079d1d7b15ef"
      },
      "source": [
        "testlosz = model.evaluate(x_val, y_val) \n",
        "print(\"val Loss \" + str(testlosz[0]))\n",
        "print(\"val Acc: \" + str(testlosz[1]))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 4s 32ms/step - loss: 2.2288 - accuracy: 0.5712\n",
            "val Loss 2.228792667388916\n",
            "val Acc: 0.5711897611618042\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5iaZIU6pPzk",
        "outputId": "c24c7047-653e-4f51-e8b4-9cba1b6226ba"
      },
      "source": [
        "from keras.models import load_model\n",
        "model_load = load_model('/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50oriAdamst120epochBS128_noaug1.h5')\n",
        "\n",
        "model_load.summary()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50ori\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 54, 54, 1)    0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 24, 24, 64)   3200        zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 24, 24, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 24, 24, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 11, 11, 64)   0           activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 11, 11, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 11, 11, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 11, 11, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 11, 11, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 11, 11, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 11, 11, 256)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 11, 11, 256)  0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 11, 11, 64)   16448       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 11, 11, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 11, 11, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 11, 11, 256)  0           activation_52[0][0]              \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 11, 11, 256)  0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 11, 11, 64)   16448       activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 11, 11, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 11, 11, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 11, 11, 256)  0           activation_55[0][0]              \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 11, 11, 256)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 6, 6, 128)    32896       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 6, 6, 128)    0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 6, 6, 128)    0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 6, 6, 512)    131584      activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 6, 6, 512)    2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 6, 6, 512)    0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 6, 6, 512)    0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 6, 6, 128)    0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 6, 6, 128)    0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 6, 6, 512)    0           activation_61[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 6, 6, 512)    0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 6, 6, 128)    0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 6, 6, 128)    0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 6, 6, 512)    0           activation_64[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 6, 6, 512)    0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 6, 6, 128)    0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 6, 6, 128)    0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 6, 6, 512)    0           activation_67[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 6, 6, 512)    0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 3, 3, 256)    131328      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 256)    0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 3, 3, 256)    0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 3, 3, 1024)   525312      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 3, 3, 1024)   4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 3, 3, 1024)   0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 3, 3, 1024)   0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 3, 3, 256)    0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 256)    0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 3, 3, 1024)   0           activation_73[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 1024)   0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 256)    0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 256)    0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 3, 3, 1024)   0           activation_76[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 1024)   0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 256)    0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 256)    0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 3, 3, 1024)   0           activation_79[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 1024)   0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 256)    0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 256)    0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 3, 3, 1024)   0           activation_82[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 1024)   0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 256)    0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 256)    0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 3, 3, 1024)   0           activation_85[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 1024)   0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 2, 2, 512)    524800      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 2, 2, 2048)   2099200     activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 2, 2, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 2, 2, 2048)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 2, 2, 2048)   0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 2, 2, 2048)   0           activation_91[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 2, 2, 2048)   0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 2, 2, 2048)   0           activation_94[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 2, 2, 2048)   0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 2048)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            14343       flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 23,595,783\n",
            "Trainable params: 23,542,663\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypc8clklx2p8",
        "outputId": "9b4ff73e-fe2f-4ed1-bb45-e825e1f8e820"
      },
      "source": [
        "#loss,acc = model_load.evaluate(xtrain,ytrain)\n",
        "\"\"\"print(\"loss:\",loss)\n",
        "print(\"acc:\",acc)kjjkj\"\"\"\n",
        "\n",
        "\n",
        "testloss = model_load.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "\n",
        "testloss = model_load.evaluate(xtrain, ytrain) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 9s 31ms/step - loss: 2.3319 - accuracy: 0.5467\n",
            "Test Loss 2.331927537918091\n",
            "Test Acc: 0.5466703772544861\n",
            "898/898 [==============================] - 27s 30ms/step - loss: 0.1939 - accuracy: 0.9344\n",
            "Test Loss 0.19394201040267944\n",
            "Test Acc: 0.9343760013580322\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7mSww_U2O_q",
        "outputId": "beccc8fe-1b2d-40a8-e759-550c52d02b84"
      },
      "source": [
        "testlosz = model_load.evaluate(x_val, y_val) \n",
        "print(\"Test Loss \" + str(testlosz[0]))\n",
        "print(\"Test Acc: \" + str(testlosz[1]))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 3s 30ms/step - loss: 2.2288 - accuracy: 0.5712\n",
            "Test Loss 2.228792667388916\n",
            "Test Acc: 0.5711897611618042\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdU7uU3PYCnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d9db371-526a-480e-d0b3-3f1a02ff0049"
      },
      "source": [
        "print (x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3589, 48, 48, 1)\n",
            "(3589,)\n",
            "(3589, 48, 48, 1)\n",
            "(3589,)\n",
            "(28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_Tf1qg8TKnx",
        "outputId": "eaccc2f1-6f68-4c74-9929-a61afc4ba7ee"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "#y_pred = model_load.predict(xtest)\n",
        "\n",
        "test_prob = model_load.predict(xtest)\n",
        "test_pred = np.argmax(test_prob, axis=1)\n",
        "test_accuracy = np.mean(test_pred == ytest)\n",
        "\n",
        "print(test_accuracy)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5466703817219282\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpwJv9V54_1M"
      },
      "source": [
        "\n",
        "emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "KMe4WL0T5BcJ",
        "outputId": "19c900e3-67d2-4868-fbc0-ecb1a9cf3a84"
      },
      "source": [
        "conf_mat = confusion_matrix(ytest, test_pred)\n",
        "\n",
        "pd.DataFrame(conf_mat, columns=emotions.values(), index=emotions.values())\n",
        "\n",
        "\n",
        "\n",
        "fig, ax = plot_confusion_matrix(conf_mat=conf_mat,show_normed=True,show_absolute=False,figsize=(8, 8))\n",
        "fig.show()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW3FZjp-5DgF",
        "outputId": "acc0c107-c213-45e0-e411-7c1390669362"
      },
      "source": [
        "print(classification_report(ytest, test_pred, target_names=emotions.values()))\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry       0.48      0.30      0.37       501\n",
            "     Disgust       0.78      0.40      0.53        52\n",
            "        Fear       0.47      0.30      0.37       495\n",
            "       Happy       0.71      0.80      0.75       916\n",
            "         Sad       0.39      0.47      0.43       591\n",
            "    Surprise       0.62      0.73      0.67       366\n",
            "     Neutral       0.48      0.55      0.51       668\n",
            "\n",
            "    accuracy                           0.55      3589\n",
            "   macro avg       0.56      0.51      0.52      3589\n",
            "weighted avg       0.54      0.55      0.54      3589\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}