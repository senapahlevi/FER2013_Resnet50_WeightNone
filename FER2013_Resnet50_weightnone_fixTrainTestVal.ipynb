{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER2013_Resnet50_weightnone_fixTrainTestVal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-Qn1jsBTIBl0b7myLQxqa8WjCcfbamqM",
      "authorship_tag": "ABX9TyODaTOIostPHtKNNgts+GC0"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b86nukQOxN7l"
      },
      "source": [
        "Resnet-50 From Scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p8gxtGy0TWP",
        "outputId": "4e0beae2-cc9c-4611-f040-8fb657db20f6"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "inputFolder = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth' \n",
        "for root, directories, filenames in os.walk(inputFolder): \n",
        "    for filename in filenames: print(os.path.join(root,filename))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Best_Model_resnet50Scracth1again.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe4.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth1again.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50ScracthSGD1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50AUGScracthadam3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD1try2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD4.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50oriSGD1st.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50SGD5stori.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editSGD5st.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editAdamst120epochBS128.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50oriScracth_sena2.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsiscWIMBDX2",
        "outputId": "abff8cc9-0a07-4108-e993-f8ba9201beb4"
      },
      "source": [
        "%cd /content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "wLMSe510xNCJ",
        "outputId": "3da9f6f5-cb75-4f61-d978-1e7de9a074fc"
      },
      "source": [
        "#Create a directory to save our generated models.dasdas\n",
        "\n",
        "#os.mkdir(\"./modelscracth\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-cf55f19f3613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#os.mkdir(\"./modelscracth\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ls' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_kluusLxM1B",
        "outputId": "99532e1b-1620-4f9f-9920-f4a6d96cea5e"
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:400: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfUSF_tAxNMP"
      },
      "source": [
        "#Define the identity block helper function.\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "   \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VdYtzhn1F0I"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path \n",
        "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b',padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd-O8ZMx1GAW"
      },
      "source": [
        "def ResNet50(input_shape = (48,48,1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    #X = ZeroPadding2D((1, 1))(X_input)\n",
        "    X = X_input\n",
        "    # Stage 1\n",
        "\n",
        "    X = Conv2D(8, (3, 3), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # removed maxpool\n",
        "    #X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='c')\n",
        "\n",
        "\n",
        "    # Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [64,64,256], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL . \n",
        "    X = AveragePooling2D((2,2), name='avg_pool')(X)\n",
        "    \n",
        "    # output layerds\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(512, activation = 'relu', name='fc1024' , kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GKsSwtp-GuL"
      },
      "source": [
        "\"\"\"def ResNet50ori(input_shape = (48, 48, 1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns: dsdsf\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50ori')\n",
        "\n",
        "    return model\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3oWTDXlyBHM2",
        "outputId": "16da671e-6bae-48c0-b953-9f600422b13a"
      },
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        " \n",
        "dataset_path = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv'\n",
        "image_size=(48,48)\n",
        "#batch_size = 64\n",
        "\n",
        "def load_fer2013():\n",
        "    data = pd.read_csv(dataset_path)\n",
        "    data = (data[data['pixels'].notnull()])\n",
        "    pixels = data['pixels'].tolist()\n",
        "    width, height = 48, 48\n",
        "    faces = []\n",
        "    for pixel_sequence in pixels:\n",
        "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "        face = np.asarray(face).reshape(width, height)\n",
        "        face = cv2.resize(face.astype('uint8'),image_size)\n",
        "        faces.append(face.astype('float32'))\n",
        "    faces = np.asarray(faces)\n",
        "    faces = np.expand_dims(faces, -1)\n",
        "    emotions = (data['emotion'])#.values\n",
        "    return faces, emotions\n",
        " \n",
        "def preprocess_input(x, v2=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if v2:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x\n",
        " \n",
        "faces, emotions = load_fer2013()\n",
        "faces = preprocess_input(faces)\n",
        "#xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
        "#Data Augumentation\n",
        "data_generator = ImageDataGenerator(\n",
        "                        rotation_range=10,\n",
        "                        shear_range = 10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True)\n",
        "\"\"\"data_generator = ImageDataGenerator( )\n",
        "\"\"\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'data_generator = ImageDataGenerator( )\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWLhavr-rSF5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "895f7f85-9930-46ca-c552-cbb571846a4e"
      },
      "source": [
        "\"\"\"\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.1,)\n",
        "x_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1,)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nxtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.1,)\\nx_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1,)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "RGhnYFXgaqL9",
        "outputId": "0e60da2f-3a44-4d06-910b-2e0f2fa4191a"
      },
      "source": [
        "\"\"\"print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (y_train.shape)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'print (\"validasi\",x_val.shape)\\nprint (y_val.shape)\\nprint (\"test\",xtest.shape)\\nprint (ytest.shape)\\nprint (\"train\",xtrain.shape)\\nprint (y_train.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rDS3hqhDSteM",
        "outputId": "477d522a-77fb-47f5-f9d8-adad767214d4"
      },
      "source": [
        "train_ratio = 0.80\n",
        "validation_ratio = 0.10\n",
        "test_ratio = 0.10\n",
        "\n",
        "# train is now 75% of the entire data set\n",
        "# the _junk suffix means that we drop that variable completely # the _junk suffix means that we drop that variable completely\n",
        "#x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=1 - train_ratio)\n",
        "\n",
        "# test is now 10% of the initial data set\n",
        "# validation is now 15% of the initial data set\n",
        "#x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "x_val, xtest, y_val, ytest = train_test_split(xtest, ytest, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "\n",
        "print(xtrain, x_val, xtest)\n",
        "\n",
        "\"\"\"X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2\"\"\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[-0.5058824 ]\n",
            "   [-0.6       ]\n",
            "   [-0.73333335]\n",
            "   ...\n",
            "   [-0.54509807]\n",
            "   [-0.5058824 ]\n",
            "   [-0.6313726 ]]\n",
            "\n",
            "  [[-0.58431375]\n",
            "   [-0.654902  ]\n",
            "   [-0.77254903]\n",
            "   ...\n",
            "   [-0.4588235 ]\n",
            "   [-0.6313726 ]\n",
            "   [-0.64705884]]\n",
            "\n",
            "  [[-0.6156863 ]\n",
            "   [-0.7490196 ]\n",
            "   [-0.79607844]\n",
            "   ...\n",
            "   [-0.5764706 ]\n",
            "   [-0.7411765 ]\n",
            "   [-0.5921569 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.30980396]\n",
            "   [-0.06666666]\n",
            "   [-0.5294118 ]\n",
            "   ...\n",
            "   [-0.12941176]\n",
            "   [-0.16862744]\n",
            "   [-0.17647058]]\n",
            "\n",
            "  [[-0.21568626]\n",
            "   [-0.5529412 ]\n",
            "   [-0.6       ]\n",
            "   ...\n",
            "   [-0.16862744]\n",
            "   [-0.19999999]\n",
            "   [ 0.16078436]]\n",
            "\n",
            "  [[-0.5764706 ]\n",
            "   [-0.56078434]\n",
            "   [-0.67058825]\n",
            "   ...\n",
            "   [-0.23137254]\n",
            "   [ 0.04313731]\n",
            "   [ 0.5294118 ]]]\n",
            "\n",
            "\n",
            " [[[-0.5529412 ]\n",
            "   [-0.38039213]\n",
            "   [-0.1372549 ]\n",
            "   ...\n",
            "   [ 0.5372549 ]\n",
            "   [ 0.35686278]\n",
            "   [ 0.13725495]]\n",
            "\n",
            "  [[ 0.10588241]\n",
            "   [ 0.41176474]\n",
            "   [ 0.62352943]\n",
            "   ...\n",
            "   [-0.19215685]\n",
            "   [-0.2862745 ]\n",
            "   [-0.38039213]]\n",
            "\n",
            "  [[ 0.7647059 ]\n",
            "   [ 0.827451  ]\n",
            "   [ 0.7882353 ]\n",
            "   ...\n",
            "   [-0.30196077]\n",
            "   [-0.12156862]\n",
            "   [ 0.082353  ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.15294117]\n",
            "   [-0.29411763]\n",
            "   [-0.34117645]\n",
            "   ...\n",
            "   [-0.88235295]\n",
            "   [-0.372549  ]\n",
            "   [ 0.5921569 ]]\n",
            "\n",
            "  [[-0.25490195]\n",
            "   [-0.18431371]\n",
            "   [-0.05098039]\n",
            "   ...\n",
            "   [-0.81960785]\n",
            "   [-0.73333335]\n",
            "   [-0.24705881]]\n",
            "\n",
            "  [[ 0.427451  ]\n",
            "   [ 0.6       ]\n",
            "   [ 0.7176471 ]\n",
            "   ...\n",
            "   [-0.8352941 ]\n",
            "   [-0.8509804 ]\n",
            "   [-0.7254902 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.52156866]\n",
            "   [ 0.48235297]\n",
            "   [ 0.4666667 ]\n",
            "   ...\n",
            "   [ 0.654902  ]\n",
            "   [ 0.64705884]\n",
            "   [ 0.654902  ]]\n",
            "\n",
            "  [[ 0.52156866]\n",
            "   [ 0.48235297]\n",
            "   [ 0.4039216 ]\n",
            "   ...\n",
            "   [ 0.64705884]\n",
            "   [ 0.654902  ]\n",
            "   [ 0.654902  ]]\n",
            "\n",
            "  [[ 0.5058824 ]\n",
            "   [ 0.4431373 ]\n",
            "   [ 0.35686278]\n",
            "   ...\n",
            "   [ 0.654902  ]\n",
            "   [ 0.654902  ]\n",
            "   [ 0.654902  ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.8509804 ]\n",
            "   [-0.8980392 ]\n",
            "   [-0.9372549 ]\n",
            "   ...\n",
            "   [-0.8901961 ]\n",
            "   [-0.8352941 ]\n",
            "   [-0.79607844]]\n",
            "\n",
            "  [[-0.8509804 ]\n",
            "   [-0.90588236]\n",
            "   [-0.9529412 ]\n",
            "   ...\n",
            "   [-0.88235295]\n",
            "   [-0.8509804 ]\n",
            "   [-0.81960785]]\n",
            "\n",
            "  [[-0.8901961 ]\n",
            "   [-0.92156863]\n",
            "   [-0.94509804]\n",
            "   ...\n",
            "   [-0.88235295]\n",
            "   [-0.84313726]\n",
            "   [-0.8352941 ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.827451  ]\n",
            "   [-0.8117647 ]\n",
            "   [-0.8039216 ]\n",
            "   ...\n",
            "   [-0.6313726 ]\n",
            "   [-0.6313726 ]\n",
            "   [-0.70980394]]\n",
            "\n",
            "  [[-0.84313726]\n",
            "   [-0.8666667 ]\n",
            "   [-0.84313726]\n",
            "   ...\n",
            "   [-0.70980394]\n",
            "   [-0.6627451 ]\n",
            "   [-0.5921569 ]]\n",
            "\n",
            "  [[-0.8509804 ]\n",
            "   [-0.85882354]\n",
            "   [-0.827451  ]\n",
            "   ...\n",
            "   [-0.5921569 ]\n",
            "   [-0.79607844]\n",
            "   [-0.7019608 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.35686272]\n",
            "   [-0.1607843 ]\n",
            "   [-0.10588235]\n",
            "   ...\n",
            "   [-0.31764704]\n",
            "   [-0.4823529 ]\n",
            "   [-0.34117645]]\n",
            "\n",
            "  [[-0.2862745 ]\n",
            "   [-0.27058822]\n",
            "   [-0.06666666]\n",
            "   ...\n",
            "   [-0.25490195]\n",
            "   [-0.49019605]\n",
            "   [-0.35686272]]\n",
            "\n",
            "  [[-0.11372548]\n",
            "   [-0.2862745 ]\n",
            "   [-0.1607843 ]\n",
            "   ...\n",
            "   [-0.2862745 ]\n",
            "   [-0.47450978]\n",
            "   [-0.35686272]]]\n",
            "\n",
            "\n",
            " [[[-0.69411767]\n",
            "   [-0.6313726 ]\n",
            "   [-0.6784314 ]\n",
            "   ...\n",
            "   [-0.5921569 ]\n",
            "   [-0.47450978]\n",
            "   [-0.44313723]]\n",
            "\n",
            "  [[-0.7019608 ]\n",
            "   [-0.6392157 ]\n",
            "   [-0.67058825]\n",
            "   ...\n",
            "   [-0.5921569 ]\n",
            "   [-0.49019605]\n",
            "   [-0.4588235 ]]\n",
            "\n",
            "  [[-0.6784314 ]\n",
            "   [-0.64705884]\n",
            "   [-0.6784314 ]\n",
            "   ...\n",
            "   [-0.60784316]\n",
            "   [-0.5137255 ]\n",
            "   [-0.4823529 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.38039213]\n",
            "   [-0.35686272]\n",
            "   [-0.34117645]\n",
            "   ...\n",
            "   [-0.58431375]\n",
            "   [-0.6627451 ]\n",
            "   [-0.60784316]]\n",
            "\n",
            "  [[-0.38039213]\n",
            "   [-0.372549  ]\n",
            "   [-0.38823527]\n",
            "   ...\n",
            "   [-0.64705884]\n",
            "   [-0.56078434]\n",
            "   [-0.5921569 ]]\n",
            "\n",
            "  [[-0.3490196 ]\n",
            "   [-0.372549  ]\n",
            "   [-0.40392154]\n",
            "   ...\n",
            "   [-0.6862745 ]\n",
            "   [-0.5686275 ]\n",
            "   [-0.5294118 ]]]\n",
            "\n",
            "\n",
            " [[[-0.26274508]\n",
            "   [-0.25490195]\n",
            "   [-0.24705881]\n",
            "   ...\n",
            "   [-0.52156866]\n",
            "   [-0.3490196 ]\n",
            "   [-0.31764704]]\n",
            "\n",
            "  [[-0.25490195]\n",
            "   [-0.25490195]\n",
            "   [-0.25490195]\n",
            "   ...\n",
            "   [-0.58431375]\n",
            "   [-0.3960784 ]\n",
            "   [-0.47450978]]\n",
            "\n",
            "  [[-0.24705881]\n",
            "   [-0.24705881]\n",
            "   [-0.24705881]\n",
            "   ...\n",
            "   [-0.94509804]\n",
            "   [-0.7176471 ]\n",
            "   [-0.5921569 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.17647058]\n",
            "   [-0.18431371]\n",
            "   [-0.09803921]\n",
            "   ...\n",
            "   [-0.7647059 ]\n",
            "   [-0.85882354]\n",
            "   [-0.8745098 ]]\n",
            "\n",
            "  [[-0.17647058]\n",
            "   [-0.17647058]\n",
            "   [-0.12156862]\n",
            "   ...\n",
            "   [-0.7882353 ]\n",
            "   [-0.8352941 ]\n",
            "   [-0.85882354]]\n",
            "\n",
            "  [[-0.16862744]\n",
            "   [-0.16862744]\n",
            "   [-0.12941176]\n",
            "   ...\n",
            "   [-0.79607844]\n",
            "   [-0.79607844]\n",
            "   [-0.85882354]]]] [[[[-0.6862745 ]\n",
            "   [-0.60784316]\n",
            "   [-0.5058824 ]\n",
            "   ...\n",
            "   [-0.7254902 ]\n",
            "   [-0.75686276]\n",
            "   [-0.75686276]]\n",
            "\n",
            "  [[-0.6784314 ]\n",
            "   [-0.5921569 ]\n",
            "   [-0.4823529 ]\n",
            "   ...\n",
            "   [-0.75686276]\n",
            "   [-0.7882353 ]\n",
            "   [-0.7254902 ]]\n",
            "\n",
            "  [[-0.67058825]\n",
            "   [-0.6       ]\n",
            "   [-0.49019605]\n",
            "   ...\n",
            "   [-0.7411765 ]\n",
            "   [-0.8352941 ]\n",
            "   [-0.79607844]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.70980394]\n",
            "   [-0.6313726 ]\n",
            "   [-0.5372549 ]\n",
            "   ...\n",
            "   [-0.23137254]\n",
            "   [-0.2235294 ]\n",
            "   [-0.17647058]]\n",
            "\n",
            "  [[-0.7019608 ]\n",
            "   [-0.6313726 ]\n",
            "   [-0.5372549 ]\n",
            "   ...\n",
            "   [-0.10588235]\n",
            "   [-0.04313725]\n",
            "   [ 0.03529418]]\n",
            "\n",
            "  [[-0.7019608 ]\n",
            "   [-0.6392157 ]\n",
            "   [-0.5529412 ]\n",
            "   ...\n",
            "   [ 0.0196079 ]\n",
            "   [ 0.03529418]\n",
            "   [ 0.03529418]]]\n",
            "\n",
            "\n",
            " [[[ 0.7411765 ]\n",
            "   [ 0.7254902 ]\n",
            "   [ 0.7176471 ]\n",
            "   ...\n",
            "   [ 0.18431377]\n",
            "   [ 0.33333337]\n",
            "   [ 0.30196083]]\n",
            "\n",
            "  [[ 0.78039217]\n",
            "   [ 0.77254903]\n",
            "   [ 0.77254903]\n",
            "   ...\n",
            "   [ 0.03529418]\n",
            "   [ 0.2941177 ]\n",
            "   [ 0.24705887]]\n",
            "\n",
            "  [[ 0.77254903]\n",
            "   [ 0.77254903]\n",
            "   [ 0.77254903]\n",
            "   ...\n",
            "   [-0.08235294]\n",
            "   [ 0.11372554]\n",
            "   [ 0.21568632]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.5686275 ]\n",
            "   [ 0.5686275 ]\n",
            "   [ 0.54509807]\n",
            "   ...\n",
            "   [-0.88235295]\n",
            "   [-0.7882353 ]\n",
            "   [-0.64705884]]\n",
            "\n",
            "  [[ 0.54509807]\n",
            "   [ 0.5372549 ]\n",
            "   [ 0.56078434]\n",
            "   ...\n",
            "   [-0.92156863]\n",
            "   [-0.7176471 ]\n",
            "   [-0.5921569 ]]\n",
            "\n",
            "  [[ 0.5372549 ]\n",
            "   [ 0.56078434]\n",
            "   [ 0.5294118 ]\n",
            "   ...\n",
            "   [-0.88235295]\n",
            "   [-0.7019608 ]\n",
            "   [-0.49019605]]]\n",
            "\n",
            "\n",
            " [[[-0.56078434]\n",
            "   [-0.85882354]\n",
            "   [-0.8352941 ]\n",
            "   ...\n",
            "   [-0.09019607]\n",
            "   [ 0.05882359]\n",
            "   [ 0.05098045]]\n",
            "\n",
            "  [[-0.75686276]\n",
            "   [-0.8509804 ]\n",
            "   [-0.84313726]\n",
            "   ...\n",
            "   [-0.35686272]\n",
            "   [ 0.01176476]\n",
            "   [ 0.05098045]]\n",
            "\n",
            "  [[-0.8039216 ]\n",
            "   [-0.81960785]\n",
            "   [-0.8509804 ]\n",
            "   ...\n",
            "   [-0.6313726 ]\n",
            "   [-0.09019607]\n",
            "   [ 0.06666672]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.04313731]\n",
            "   [ 0.03529418]\n",
            "   [ 0.03529418]\n",
            "   ...\n",
            "   [ 0.02745104]\n",
            "   [ 0.02745104]\n",
            "   [ 0.03529418]]\n",
            "\n",
            "  [[ 0.04313731]\n",
            "   [ 0.04313731]\n",
            "   [ 0.03529418]\n",
            "   ...\n",
            "   [ 0.02745104]\n",
            "   [ 0.02745104]\n",
            "   [ 0.02745104]]\n",
            "\n",
            "  [[ 0.05098045]\n",
            "   [ 0.05098045]\n",
            "   [ 0.03529418]\n",
            "   ...\n",
            "   [ 0.03529418]\n",
            "   [ 0.02745104]\n",
            "   [ 0.03529418]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 0.81960785]\n",
            "   [ 0.7254902 ]\n",
            "   [ 0.5058824 ]\n",
            "   ...\n",
            "   [ 0.1686275 ]\n",
            "   [ 0.09019613]\n",
            "   [-0.12156862]]\n",
            "\n",
            "  [[ 0.827451  ]\n",
            "   [ 0.7490196 ]\n",
            "   [ 0.41960788]\n",
            "   ...\n",
            "   [ 0.2313726 ]\n",
            "   [ 0.06666672]\n",
            "   [-0.06666666]]\n",
            "\n",
            "  [[ 0.827451  ]\n",
            "   [ 0.7882353 ]\n",
            "   [ 0.3803922 ]\n",
            "   ...\n",
            "   [ 0.23921573]\n",
            "   [ 0.16078436]\n",
            "   [ 0.00392163]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.6784314 ]\n",
            "   [ 0.6862745 ]\n",
            "   [ 0.6862745 ]\n",
            "   ...\n",
            "   [-0.19999999]\n",
            "   [-0.25490195]\n",
            "   [-0.20784312]]\n",
            "\n",
            "  [[ 0.7254902 ]\n",
            "   [ 0.7411765 ]\n",
            "   [ 0.7254902 ]\n",
            "   ...\n",
            "   [-0.21568626]\n",
            "   [-0.20784312]\n",
            "   [-0.23137254]]\n",
            "\n",
            "  [[ 0.33333337]\n",
            "   [ 0.13725495]\n",
            "   [-0.1372549 ]\n",
            "   ...\n",
            "   [-0.18431371]\n",
            "   [-0.17647058]\n",
            "   [-0.24705881]]]\n",
            "\n",
            "\n",
            " [[[-0.8745098 ]\n",
            "   [-0.88235295]\n",
            "   [-0.81960785]\n",
            "   ...\n",
            "   [ 0.41176474]\n",
            "   [ 0.32549024]\n",
            "   [ 0.13725495]]\n",
            "\n",
            "  [[-0.827451  ]\n",
            "   [-0.827451  ]\n",
            "   [-0.75686276]\n",
            "   ...\n",
            "   [ 0.5058824 ]\n",
            "   [ 0.41176474]\n",
            "   [ 0.18431377]]\n",
            "\n",
            "  [[-0.75686276]\n",
            "   [-0.7019608 ]\n",
            "   [-0.654902  ]\n",
            "   ...\n",
            "   [ 0.6       ]\n",
            "   [ 0.4666667 ]\n",
            "   [ 0.3411765 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]]\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-0.99215686]\n",
            "   ...\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]]\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-0.99215686]\n",
            "   ...\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   [-0.99215686]]]\n",
            "\n",
            "\n",
            " [[[-0.20784312]\n",
            "   [-0.21568626]\n",
            "   [-0.20784312]\n",
            "   ...\n",
            "   [-0.372549  ]\n",
            "   [-0.5921569 ]\n",
            "   [-0.78039217]]\n",
            "\n",
            "  [[-0.2235294 ]\n",
            "   [-0.2235294 ]\n",
            "   [-0.2235294 ]\n",
            "   ...\n",
            "   [-0.34117645]\n",
            "   [-0.54509807]\n",
            "   [-0.7176471 ]]\n",
            "\n",
            "  [[-0.23137254]\n",
            "   [-0.25490195]\n",
            "   [-0.23921567]\n",
            "   ...\n",
            "   [-0.25490195]\n",
            "   [-0.45098037]\n",
            "   [-0.64705884]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.654902  ]\n",
            "   [-0.5529412 ]\n",
            "   [-0.47450978]\n",
            "   ...\n",
            "   [-0.5921569 ]\n",
            "   [-0.70980394]\n",
            "   [-0.81960785]]\n",
            "\n",
            "  [[-0.69411767]\n",
            "   [-0.5921569 ]\n",
            "   [-0.47450978]\n",
            "   ...\n",
            "   [-0.67058825]\n",
            "   [-0.81960785]\n",
            "   [-0.88235295]]\n",
            "\n",
            "  [[-0.69411767]\n",
            "   [-0.6156863 ]\n",
            "   [-0.4980392 ]\n",
            "   ...\n",
            "   [-0.79607844]\n",
            "   [-0.8666667 ]\n",
            "   [-0.88235295]]]] [[[[ 0.45098042]\n",
            "   [-0.12156862]\n",
            "   [-0.04313725]\n",
            "   ...\n",
            "   [ 0.2313726 ]\n",
            "   [ 0.11372554]\n",
            "   [ 0.20784318]]\n",
            "\n",
            "  [[ 0.654902  ]\n",
            "   [ 0.30980396]\n",
            "   [ 0.01176476]\n",
            "   ...\n",
            "   [ 0.24705887]\n",
            "   [ 0.13725495]\n",
            "   [ 0.07450986]]\n",
            "\n",
            "  [[ 0.5921569 ]\n",
            "   [ 0.23921573]\n",
            "   [ 0.26274514]\n",
            "   ...\n",
            "   [ 0.21568632]\n",
            "   [ 0.10588241]\n",
            "   [ 0.082353  ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.09019613]\n",
            "   [ 0.38823533]\n",
            "   [ 0.52156866]\n",
            "   ...\n",
            "   [-0.2235294 ]\n",
            "   [-0.18431371]\n",
            "   [-0.17647058]]\n",
            "\n",
            "  [[-0.08235294]\n",
            "   [ 0.24705887]\n",
            "   [ 0.45098042]\n",
            "   ...\n",
            "   [-0.3098039 ]\n",
            "   [-0.24705881]\n",
            "   [-0.23921567]]\n",
            "\n",
            "  [[-0.12941176]\n",
            "   [ 0.1686275 ]\n",
            "   [ 0.34901965]\n",
            "   ...\n",
            "   [-0.41176468]\n",
            "   [-0.3960784 ]\n",
            "   [-0.31764704]]]\n",
            "\n",
            "\n",
            " [[[-0.827451  ]\n",
            "   [-0.8352941 ]\n",
            "   [-0.90588236]\n",
            "   ...\n",
            "   [-0.84313726]\n",
            "   [-0.84313726]\n",
            "   [-0.8509804 ]]\n",
            "\n",
            "  [[-0.81960785]\n",
            "   [-0.84313726]\n",
            "   [-0.92156863]\n",
            "   ...\n",
            "   [-0.84313726]\n",
            "   [-0.8352941 ]\n",
            "   [-0.84313726]]\n",
            "\n",
            "  [[-0.81960785]\n",
            "   [-0.84313726]\n",
            "   [-0.9372549 ]\n",
            "   ...\n",
            "   [-0.84313726]\n",
            "   [-0.84313726]\n",
            "   [-0.8352941 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.9764706 ]\n",
            "   [-0.9843137 ]\n",
            "   [-0.9764706 ]\n",
            "   ...\n",
            "   [-0.27843136]\n",
            "   [-0.05882353]\n",
            "   [-0.27843136]]\n",
            "\n",
            "  [[-0.94509804]\n",
            "   [-0.94509804]\n",
            "   [-0.94509804]\n",
            "   ...\n",
            "   [-0.09803921]\n",
            "   [-0.32549018]\n",
            "   [-0.5294118 ]]\n",
            "\n",
            "  [[-0.90588236]\n",
            "   [-0.90588236]\n",
            "   [-0.92156863]\n",
            "   ...\n",
            "   [-0.16862744]\n",
            "   [-0.6313726 ]\n",
            "   [-0.44313723]]]\n",
            "\n",
            "\n",
            " [[[-0.85882354]\n",
            "   [-0.8509804 ]\n",
            "   [-0.8666667 ]\n",
            "   ...\n",
            "   [-0.79607844]\n",
            "   [-0.73333335]\n",
            "   [-0.6627451 ]]\n",
            "\n",
            "  [[-0.827451  ]\n",
            "   [-0.84313726]\n",
            "   [-0.88235295]\n",
            "   ...\n",
            "   [-0.7882353 ]\n",
            "   [-0.81960785]\n",
            "   [-0.7490196 ]]\n",
            "\n",
            "  [[-0.7882353 ]\n",
            "   [-0.8509804 ]\n",
            "   [-0.85882354]\n",
            "   ...\n",
            "   [-0.7176471 ]\n",
            "   [-0.827451  ]\n",
            "   [-0.81960785]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.9137255 ]\n",
            "   [ 0.92156863]\n",
            "   [ 0.92156863]\n",
            "   ...\n",
            "   [ 0.7882353 ]\n",
            "   [ 0.78039217]\n",
            "   [ 0.7176471 ]]\n",
            "\n",
            "  [[ 0.90588236]\n",
            "   [ 0.90588236]\n",
            "   [ 0.8980392 ]\n",
            "   ...\n",
            "   [ 0.8117647 ]\n",
            "   [ 0.8117647 ]\n",
            "   [ 0.7647059 ]]\n",
            "\n",
            "  [[ 0.8901961 ]\n",
            "   [ 0.8901961 ]\n",
            "   [ 0.8745098 ]\n",
            "   ...\n",
            "   [ 0.8117647 ]\n",
            "   [ 0.8352941 ]\n",
            "   [ 0.8117647 ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.4352941 ]\n",
            "   [-0.5137255 ]\n",
            "   [-0.5686275 ]\n",
            "   ...\n",
            "   [-0.4352941 ]\n",
            "   [-0.31764704]\n",
            "   [-0.36470586]]\n",
            "\n",
            "  [[-0.49019605]\n",
            "   [-0.58431375]\n",
            "   [-0.5764706 ]\n",
            "   ...\n",
            "   [-0.46666664]\n",
            "   [-0.38039213]\n",
            "   [-0.34117645]]\n",
            "\n",
            "  [[-0.58431375]\n",
            "   [-0.6       ]\n",
            "   [-0.5686275 ]\n",
            "   ...\n",
            "   [-0.4980392 ]\n",
            "   [-0.40392154]\n",
            "   [-0.372549  ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.27843136]\n",
            "   [-0.26274508]\n",
            "   [-0.27058822]\n",
            "   ...\n",
            "   [-0.30196077]\n",
            "   [-0.27843136]\n",
            "   [-0.2862745 ]]\n",
            "\n",
            "  [[-0.23921567]\n",
            "   [-0.23921567]\n",
            "   [-0.27843136]\n",
            "   ...\n",
            "   [-0.23137254]\n",
            "   [-0.27843136]\n",
            "   [-0.29411763]]\n",
            "\n",
            "  [[-0.2235294 ]\n",
            "   [-0.24705881]\n",
            "   [-0.23921567]\n",
            "   ...\n",
            "   [-0.25490195]\n",
            "   [-0.30196077]\n",
            "   [-0.2862745 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.5294118 ]\n",
            "   [ 0.4666667 ]\n",
            "   [ 0.54509807]\n",
            "   ...\n",
            "   [-0.3960784 ]\n",
            "   [-0.5294118 ]\n",
            "   [-0.5294118 ]]\n",
            "\n",
            "  [[ 0.69411767]\n",
            "   [ 0.5764706 ]\n",
            "   [ 0.62352943]\n",
            "   ...\n",
            "   [-0.49019605]\n",
            "   [-0.4588235 ]\n",
            "   [-0.372549  ]]\n",
            "\n",
            "  [[ 0.6       ]\n",
            "   [ 0.60784316]\n",
            "   [ 0.5686275 ]\n",
            "   ...\n",
            "   [-0.21568626]\n",
            "   [-0.14509803]\n",
            "   [-0.27843136]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.88235295]\n",
            "   [ 0.8745098 ]\n",
            "   [ 0.88235295]\n",
            "   ...\n",
            "   [-0.2862745 ]\n",
            "   [-0.30196077]\n",
            "   [-0.30196077]]\n",
            "\n",
            "  [[ 0.88235295]\n",
            "   [ 0.8980392 ]\n",
            "   [ 0.90588236]\n",
            "   ...\n",
            "   [-0.38823527]\n",
            "   [-0.40392154]\n",
            "   [-0.35686272]]\n",
            "\n",
            "  [[ 0.8901961 ]\n",
            "   [ 0.8980392 ]\n",
            "   [ 0.8980392 ]\n",
            "   ...\n",
            "   [-0.46666664]\n",
            "   [-0.45098037]\n",
            "   [-0.41960782]]]\n",
            "\n",
            "\n",
            " [[[-0.6       ]\n",
            "   [-0.654902  ]\n",
            "   [-0.5686275 ]\n",
            "   ...\n",
            "   [ 0.654902  ]\n",
            "   [ 0.5137255 ]\n",
            "   [ 0.427451  ]]\n",
            "\n",
            "  [[-0.58431375]\n",
            "   [-0.5921569 ]\n",
            "   [-0.5686275 ]\n",
            "   ...\n",
            "   [ 0.7490196 ]\n",
            "   [ 0.62352943]\n",
            "   [ 0.56078434]]\n",
            "\n",
            "  [[-0.5764706 ]\n",
            "   [-0.6156863 ]\n",
            "   [-0.5529412 ]\n",
            "   ...\n",
            "   [ 0.8039216 ]\n",
            "   [ 0.70980394]\n",
            "   [ 0.64705884]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.6       ]\n",
            "   [ 0.5686275 ]\n",
            "   [ 0.58431375]\n",
            "   ...\n",
            "   [ 0.5294118 ]\n",
            "   [ 0.4901961 ]\n",
            "   [ 0.4901961 ]]\n",
            "\n",
            "  [[ 0.64705884]\n",
            "   [ 0.6156863 ]\n",
            "   [ 0.654902  ]\n",
            "   ...\n",
            "   [ 0.5686275 ]\n",
            "   [ 0.5294118 ]\n",
            "   [ 0.5294118 ]]\n",
            "\n",
            "  [[ 0.6313726 ]\n",
            "   [ 0.64705884]\n",
            "   [ 0.69411767]\n",
            "   ...\n",
            "   [ 0.52156866]\n",
            "   [ 0.5372549 ]\n",
            "   [ 0.54509807]]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\\n\\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKvEv321Stt5",
        "outputId": "65a6bbe7-d7d3-43a3-d20e-04b11c0ae69e"
      },
      "source": [
        "print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validasi (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "test (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "train (28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH9Q-TegBR26"
      },
      "source": [
        "#hyperparameter and callback\n",
        "batch_size = 128\n",
        "num_epochs = 120\n",
        "input_shape = (48, 48, 1)\n",
        "num_classes = 7\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGsscQRJBR-h"
      },
      "source": [
        "#Compile the model.\n",
        "\n",
        "\n",
        "from keras.optimizers import Adam, SGD\n",
        "model = ResNet50(input_shape = (48, 48, 1), classes = 7)\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer= optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rodttDWeT2yP"
      },
      "source": [
        "#kita mau save model callbacks\n",
        "\"\"\"import os\n",
        "try:\n",
        "  os.mkdir('scratchcheckpoint')\n",
        "except:\n",
        "  pass\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV29sTjET28U"
      },
      "source": [
        "\"\"\"file_name = 'Best_Model_resnet50Scracth_sena1.h5'\n",
        "\n",
        "checkpoint_path = os.path.join('checkpoint',file_name)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_S6wUaPT3Jx"
      },
      "source": [
        "\"\"\"call_back = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
        "                                               monitor='val_accuracy',\n",
        "                                               verbose=1,\n",
        "                                               save_freq='epoch',\n",
        "                                               save_best_only=True,\n",
        "                                               save_weights_only=False,\n",
        "                                               mode='max')\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy53DHMGB-Mr",
        "outputId": "029c9ec8-1e4a-4fe5-e84a-dd63fc4b77f5"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 46, 46, 128)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 46, 46, 128)  0           activation_3[0][0]               \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 46, 46, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 46, 46, 128)  0           activation_6[0][0]               \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 46, 46, 128)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 23, 23, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 23, 23, 256)  0           activation_12[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 23, 23, 256)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 23, 23, 256)  0           activation_15[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 23, 23, 256)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 23, 23, 256)  0           activation_18[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 23, 23, 256)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 12, 12, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 12, 12, 512)  0           activation_24[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 12, 12, 512)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 12, 12, 512)  0           activation_27[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 12, 12, 512)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 12, 12, 512)  0           activation_30[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 12, 12, 512)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 12, 12, 512)  0           activation_33[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 12, 12, 512)  0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 12, 12, 512)  0           activation_36[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 12, 12, 512)  0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 6, 6, 1024)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 6, 6, 1024)   0           activation_42[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 6, 6, 1024)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 6, 6, 1024)   0           activation_45[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 6, 6, 1024)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgxCecVwCGEr"
      },
      "source": [
        "\"\"\"history = model.fit(data_generator.flow(xtrain, ytrain,),\n",
        "                        steps_per_epoch=len(xtrain) / batch_size,\n",
        "                        epochs=num_epochs, verbose=1,callbacks=call_back,\n",
        "                        validation_data= (xtest,ytest))\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2muXWns0sJSH",
        "outputId": "4eba997e-e3d3-47ea-f74e-4cc308c16a2e"
      },
      "source": [
        "history = model.fit(\n",
        "    data_generator.flow(xtrain, ytrain,),\n",
        "    steps_per_epoch=len(xtrain) / batch_size,\n",
        "    epochs=num_epochs, \n",
        "    verbose=1,\n",
        "    validation_data= (x_val,y_val))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/120\n",
            "224/224 [==============================] - 84s 126ms/step - loss: 4.5183 - accuracy: 0.2286 - val_loss: 1.8246 - val_accuracy: 0.2541\n",
            "Epoch 2/120\n",
            "224/224 [==============================] - 24s 109ms/step - loss: 1.8136 - accuracy: 0.2526 - val_loss: 1.8022 - val_accuracy: 0.2602\n",
            "Epoch 3/120\n",
            "224/224 [==============================] - 24s 109ms/step - loss: 1.7810 - accuracy: 0.2663 - val_loss: 1.7149 - val_accuracy: 0.3174\n",
            "Epoch 4/120\n",
            "224/224 [==============================] - 25s 111ms/step - loss: 1.7095 - accuracy: 0.3219 - val_loss: 1.6851 - val_accuracy: 0.3324\n",
            "Epoch 5/120\n",
            "224/224 [==============================] - 25s 110ms/step - loss: 1.6676 - accuracy: 0.3379 - val_loss: 1.5744 - val_accuracy: 0.3728\n",
            "Epoch 6/120\n",
            "224/224 [==============================] - 27s 120ms/step - loss: 1.5536 - accuracy: 0.3923 - val_loss: 1.6951 - val_accuracy: 0.3734\n",
            "Epoch 7/120\n",
            "224/224 [==============================] - 27s 121ms/step - loss: 1.5094 - accuracy: 0.4046 - val_loss: 1.5060 - val_accuracy: 0.4154\n",
            "Epoch 8/120\n",
            "224/224 [==============================] - 27s 121ms/step - loss: 1.4513 - accuracy: 0.4273 - val_loss: 1.4774 - val_accuracy: 0.4146\n",
            "Epoch 9/120\n",
            "224/224 [==============================] - 25s 110ms/step - loss: 1.4194 - accuracy: 0.4479 - val_loss: 1.6296 - val_accuracy: 0.4174\n",
            "Epoch 10/120\n",
            "224/224 [==============================] - 25s 111ms/step - loss: 1.3931 - accuracy: 0.4657 - val_loss: 1.4292 - val_accuracy: 0.4402\n",
            "Epoch 11/120\n",
            "224/224 [==============================] - 25s 110ms/step - loss: 1.3744 - accuracy: 0.4670 - val_loss: 1.6671 - val_accuracy: 0.3812\n",
            "Epoch 12/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 1.3542 - accuracy: 0.4756 - val_loss: 1.6353 - val_accuracy: 0.3653\n",
            "Epoch 13/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 1.4064 - accuracy: 0.4454 - val_loss: 1.7111 - val_accuracy: 0.4166\n",
            "Epoch 14/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.3381 - accuracy: 0.4892 - val_loss: 1.3861 - val_accuracy: 0.4815\n",
            "Epoch 15/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.2764 - accuracy: 0.5121 - val_loss: 1.3618 - val_accuracy: 0.4823\n",
            "Epoch 16/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.2780 - accuracy: 0.5217 - val_loss: 1.2681 - val_accuracy: 0.5088\n",
            "Epoch 17/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.2418 - accuracy: 0.5272 - val_loss: 1.2933 - val_accuracy: 0.4862\n",
            "Epoch 18/120\n",
            "224/224 [==============================] - 28s 124ms/step - loss: 1.2732 - accuracy: 0.5121 - val_loss: 1.3329 - val_accuracy: 0.4879\n",
            "Epoch 19/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.2404 - accuracy: 0.5265 - val_loss: 1.4425 - val_accuracy: 0.4804\n",
            "Epoch 20/120\n",
            "224/224 [==============================] - 28s 123ms/step - loss: 1.1785 - accuracy: 0.5551 - val_loss: 1.2951 - val_accuracy: 0.5013\n",
            "Epoch 21/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.2019 - accuracy: 0.5468 - val_loss: 1.2968 - val_accuracy: 0.5118\n",
            "Epoch 22/120\n",
            "224/224 [==============================] - 27s 122ms/step - loss: 1.2026 - accuracy: 0.5421 - val_loss: 1.2427 - val_accuracy: 0.5319\n",
            "Epoch 23/120\n",
            "224/224 [==============================] - 28s 123ms/step - loss: 1.1720 - accuracy: 0.5491 - val_loss: 1.3365 - val_accuracy: 0.4890\n",
            "Epoch 24/120\n",
            "224/224 [==============================] - 28s 123ms/step - loss: 1.1615 - accuracy: 0.5617 - val_loss: 1.2564 - val_accuracy: 0.5313\n",
            "Epoch 25/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.1456 - accuracy: 0.5633 - val_loss: 1.3134 - val_accuracy: 0.4990\n",
            "Epoch 26/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.1597 - accuracy: 0.5717 - val_loss: 1.1537 - val_accuracy: 0.5589\n",
            "Epoch 27/120\n",
            "224/224 [==============================] - 28s 123ms/step - loss: 1.1216 - accuracy: 0.5686 - val_loss: 1.1682 - val_accuracy: 0.5542\n",
            "Epoch 28/120\n",
            "224/224 [==============================] - 28s 123ms/step - loss: 1.1384 - accuracy: 0.5731 - val_loss: 1.1182 - val_accuracy: 0.5678\n",
            "Epoch 29/120\n",
            "224/224 [==============================] - 28s 123ms/step - loss: 1.1153 - accuracy: 0.5807 - val_loss: 1.2249 - val_accuracy: 0.5316\n",
            "Epoch 30/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 1.1127 - accuracy: 0.5772 - val_loss: 1.2100 - val_accuracy: 0.5450\n",
            "Epoch 31/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 1.1035 - accuracy: 0.5819 - val_loss: 1.2317 - val_accuracy: 0.5430\n",
            "Epoch 32/120\n",
            "224/224 [==============================] - 27s 123ms/step - loss: 1.1025 - accuracy: 0.5803 - val_loss: 1.1864 - val_accuracy: 0.5364\n",
            "Epoch 33/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.0917 - accuracy: 0.5888 - val_loss: 1.1401 - val_accuracy: 0.5634\n",
            "Epoch 34/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 1.0844 - accuracy: 0.5884 - val_loss: 1.2469 - val_accuracy: 0.5419\n",
            "Epoch 35/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 1.0542 - accuracy: 0.6076 - val_loss: 1.1676 - val_accuracy: 0.5467\n",
            "Epoch 36/120\n",
            "224/224 [==============================] - 28s 123ms/step - loss: 1.0834 - accuracy: 0.5931 - val_loss: 1.1677 - val_accuracy: 0.5628\n",
            "Epoch 37/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 1.0899 - accuracy: 0.5791 - val_loss: 1.1394 - val_accuracy: 0.5720\n",
            "Epoch 38/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 1.0563 - accuracy: 0.6055 - val_loss: 1.1037 - val_accuracy: 0.5871\n",
            "Epoch 39/120\n",
            "224/224 [==============================] - 28s 124ms/step - loss: 1.0636 - accuracy: 0.5975 - val_loss: 1.1838 - val_accuracy: 0.5651\n",
            "Epoch 40/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 1.0562 - accuracy: 0.6009 - val_loss: 1.1598 - val_accuracy: 0.5575\n",
            "Epoch 41/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 1.0563 - accuracy: 0.6010 - val_loss: 1.2006 - val_accuracy: 0.5481\n",
            "Epoch 42/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 1.0586 - accuracy: 0.6053 - val_loss: 1.1161 - val_accuracy: 0.5815\n",
            "Epoch 43/120\n",
            "224/224 [==============================] - 28s 123ms/step - loss: 1.0342 - accuracy: 0.6069 - val_loss: 1.0880 - val_accuracy: 0.5832\n",
            "Epoch 44/120\n",
            "224/224 [==============================] - 28s 125ms/step - loss: 1.0146 - accuracy: 0.6146 - val_loss: 1.1405 - val_accuracy: 0.5639\n",
            "Epoch 45/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.9980 - accuracy: 0.6314 - val_loss: 1.1207 - val_accuracy: 0.5676\n",
            "Epoch 46/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 1.0372 - accuracy: 0.6131 - val_loss: 1.1242 - val_accuracy: 0.5832\n",
            "Epoch 47/120\n",
            "224/224 [==============================] - 26s 114ms/step - loss: 0.9958 - accuracy: 0.6147 - val_loss: 1.2701 - val_accuracy: 0.5171\n",
            "Epoch 48/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 1.0395 - accuracy: 0.6096 - val_loss: 1.2543 - val_accuracy: 0.5341\n",
            "Epoch 49/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 1.0194 - accuracy: 0.6070 - val_loss: 1.0882 - val_accuracy: 0.5876\n",
            "Epoch 50/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 1.0103 - accuracy: 0.6234 - val_loss: 1.0864 - val_accuracy: 0.5862\n",
            "Epoch 51/120\n",
            "224/224 [==============================] - 26s 114ms/step - loss: 0.9859 - accuracy: 0.6321 - val_loss: 1.1801 - val_accuracy: 0.5614\n",
            "Epoch 52/120\n",
            "224/224 [==============================] - 28s 123ms/step - loss: 1.0186 - accuracy: 0.6156 - val_loss: 1.1344 - val_accuracy: 0.5723\n",
            "Epoch 53/120\n",
            "224/224 [==============================] - 28s 123ms/step - loss: 1.0041 - accuracy: 0.6209 - val_loss: 1.0874 - val_accuracy: 0.5957\n",
            "Epoch 54/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.9890 - accuracy: 0.6224 - val_loss: 1.1060 - val_accuracy: 0.5949\n",
            "Epoch 55/120\n",
            "224/224 [==============================] - 26s 114ms/step - loss: 0.9947 - accuracy: 0.6215 - val_loss: 1.0409 - val_accuracy: 0.6032\n",
            "Epoch 56/120\n",
            "224/224 [==============================] - 26s 114ms/step - loss: 0.9756 - accuracy: 0.6328 - val_loss: 1.1276 - val_accuracy: 0.5815\n",
            "Epoch 57/120\n",
            "224/224 [==============================] - 26s 114ms/step - loss: 0.9907 - accuracy: 0.6229 - val_loss: 1.0352 - val_accuracy: 0.6091\n",
            "Epoch 58/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.9602 - accuracy: 0.6488 - val_loss: 1.0809 - val_accuracy: 0.5954\n",
            "Epoch 59/120\n",
            "224/224 [==============================] - 26s 114ms/step - loss: 0.9423 - accuracy: 0.6495 - val_loss: 1.0814 - val_accuracy: 0.5876\n",
            "Epoch 60/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.9858 - accuracy: 0.6330 - val_loss: 1.1196 - val_accuracy: 0.5821\n",
            "Epoch 61/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.9561 - accuracy: 0.6478 - val_loss: 1.0162 - val_accuracy: 0.6163\n",
            "Epoch 62/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.9558 - accuracy: 0.6373 - val_loss: 1.2945 - val_accuracy: 0.5386\n",
            "Epoch 63/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.9592 - accuracy: 0.6460 - val_loss: 1.1122 - val_accuracy: 0.5890\n",
            "Epoch 64/120\n",
            "224/224 [==============================] - 28s 124ms/step - loss: 0.9524 - accuracy: 0.6313 - val_loss: 1.0958 - val_accuracy: 0.5874\n",
            "Epoch 65/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.9395 - accuracy: 0.6488 - val_loss: 1.0609 - val_accuracy: 0.6027\n",
            "Epoch 66/120\n",
            "224/224 [==============================] - 26s 114ms/step - loss: 0.9441 - accuracy: 0.6524 - val_loss: 1.0640 - val_accuracy: 0.6080\n",
            "Epoch 67/120\n",
            "224/224 [==============================] - 25s 114ms/step - loss: 0.9594 - accuracy: 0.6434 - val_loss: 1.1065 - val_accuracy: 0.5821\n",
            "Epoch 68/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 0.9271 - accuracy: 0.6483 - val_loss: 1.0516 - val_accuracy: 0.6147\n",
            "Epoch 69/120\n",
            "224/224 [==============================] - 28s 123ms/step - loss: 0.9184 - accuracy: 0.6591 - val_loss: 1.1290 - val_accuracy: 0.5848\n",
            "Epoch 70/120\n",
            "224/224 [==============================] - 26s 114ms/step - loss: 0.9342 - accuracy: 0.6537 - val_loss: 1.0327 - val_accuracy: 0.6088\n",
            "Epoch 71/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 0.9164 - accuracy: 0.6520 - val_loss: 1.1417 - val_accuracy: 0.5743\n",
            "Epoch 72/120\n",
            "224/224 [==============================] - 26s 114ms/step - loss: 0.9088 - accuracy: 0.6641 - val_loss: 1.2149 - val_accuracy: 0.5698\n",
            "Epoch 73/120\n",
            "224/224 [==============================] - 26s 114ms/step - loss: 0.9160 - accuracy: 0.6595 - val_loss: 1.0513 - val_accuracy: 0.6135\n",
            "Epoch 74/120\n",
            "224/224 [==============================] - 26s 114ms/step - loss: 0.9109 - accuracy: 0.6694 - val_loss: 1.0700 - val_accuracy: 0.6060\n",
            "Epoch 75/120\n",
            "224/224 [==============================] - 28s 123ms/step - loss: 0.8978 - accuracy: 0.6588 - val_loss: 1.0275 - val_accuracy: 0.6191\n",
            "Epoch 76/120\n",
            "224/224 [==============================] - 26s 114ms/step - loss: 0.9364 - accuracy: 0.6485 - val_loss: 1.1062 - val_accuracy: 0.5904\n",
            "Epoch 77/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.9077 - accuracy: 0.6628 - val_loss: 1.0540 - val_accuracy: 0.6085\n",
            "Epoch 78/120\n",
            "224/224 [==============================] - 26s 114ms/step - loss: 0.9538 - accuracy: 0.6477 - val_loss: 1.0205 - val_accuracy: 0.6283\n",
            "Epoch 79/120\n",
            "224/224 [==============================] - 28s 123ms/step - loss: 0.8992 - accuracy: 0.6568 - val_loss: 1.1267 - val_accuracy: 0.5745\n",
            "Epoch 80/120\n",
            "224/224 [==============================] - 26s 114ms/step - loss: 0.8856 - accuracy: 0.6599 - val_loss: 1.0600 - val_accuracy: 0.5954\n",
            "Epoch 81/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.8982 - accuracy: 0.6563 - val_loss: 1.1414 - val_accuracy: 0.5977\n",
            "Epoch 82/120\n",
            "224/224 [==============================] - 28s 124ms/step - loss: 0.8907 - accuracy: 0.6631 - val_loss: 1.0768 - val_accuracy: 0.6074\n",
            "Epoch 83/120\n",
            "224/224 [==============================] - 26s 114ms/step - loss: 0.9020 - accuracy: 0.6655 - val_loss: 1.0858 - val_accuracy: 0.5957\n",
            "Epoch 84/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.8758 - accuracy: 0.6702 - val_loss: 1.0096 - val_accuracy: 0.6344\n",
            "Epoch 85/120\n",
            "224/224 [==============================] - 28s 124ms/step - loss: 0.8631 - accuracy: 0.6783 - val_loss: 0.9759 - val_accuracy: 0.6325\n",
            "Epoch 86/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.9022 - accuracy: 0.6611 - val_loss: 1.0384 - val_accuracy: 0.6252\n",
            "Epoch 87/120\n",
            "224/224 [==============================] - 26s 114ms/step - loss: 0.8918 - accuracy: 0.6707 - val_loss: 1.1095 - val_accuracy: 0.5868\n",
            "Epoch 88/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.8619 - accuracy: 0.6759 - val_loss: 1.0672 - val_accuracy: 0.6113\n",
            "Epoch 89/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.8893 - accuracy: 0.6757 - val_loss: 1.0538 - val_accuracy: 0.6060\n",
            "Epoch 90/120\n",
            "224/224 [==============================] - 28s 125ms/step - loss: 0.8853 - accuracy: 0.6694 - val_loss: 0.9931 - val_accuracy: 0.6283\n",
            "Epoch 91/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.8461 - accuracy: 0.6801 - val_loss: 1.0412 - val_accuracy: 0.6147\n",
            "Epoch 92/120\n",
            "224/224 [==============================] - 26s 114ms/step - loss: 0.8538 - accuracy: 0.6907 - val_loss: 1.0073 - val_accuracy: 0.6194\n",
            "Epoch 93/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.8575 - accuracy: 0.6899 - val_loss: 1.0575 - val_accuracy: 0.6133\n",
            "Epoch 94/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.8646 - accuracy: 0.6809 - val_loss: 0.9770 - val_accuracy: 0.6459\n",
            "Epoch 95/120\n",
            "224/224 [==============================] - 26s 114ms/step - loss: 0.8643 - accuracy: 0.6760 - val_loss: 1.0560 - val_accuracy: 0.6225\n",
            "Epoch 96/120\n",
            "224/224 [==============================] - 25s 114ms/step - loss: 0.8419 - accuracy: 0.6829 - val_loss: 1.0681 - val_accuracy: 0.6021\n",
            "Epoch 97/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.8759 - accuracy: 0.6768 - val_loss: 1.0431 - val_accuracy: 0.6149\n",
            "Epoch 98/120\n",
            "224/224 [==============================] - 28s 124ms/step - loss: 0.8444 - accuracy: 0.6847 - val_loss: 1.0456 - val_accuracy: 0.6116\n",
            "Epoch 99/120\n",
            "224/224 [==============================] - 28s 124ms/step - loss: 0.8561 - accuracy: 0.6858 - val_loss: 0.9683 - val_accuracy: 0.6403\n",
            "Epoch 100/120\n",
            "224/224 [==============================] - 26s 114ms/step - loss: 0.8390 - accuracy: 0.6910 - val_loss: 1.0210 - val_accuracy: 0.6369\n",
            "Epoch 101/120\n",
            "224/224 [==============================] - 26s 114ms/step - loss: 0.8264 - accuracy: 0.6852 - val_loss: 1.0235 - val_accuracy: 0.6133\n",
            "Epoch 102/120\n",
            "224/224 [==============================] - 25s 114ms/step - loss: 0.8267 - accuracy: 0.6991 - val_loss: 0.9618 - val_accuracy: 0.6417\n",
            "Epoch 103/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.8306 - accuracy: 0.6922 - val_loss: 0.9762 - val_accuracy: 0.6319\n",
            "Epoch 104/120\n",
            "224/224 [==============================] - 26s 114ms/step - loss: 0.8159 - accuracy: 0.6919 - val_loss: 1.0550 - val_accuracy: 0.5848\n",
            "Epoch 105/120\n",
            "224/224 [==============================] - 28s 124ms/step - loss: 0.8043 - accuracy: 0.7013 - val_loss: 1.0014 - val_accuracy: 0.6247\n",
            "Epoch 106/120\n",
            "224/224 [==============================] - 26s 114ms/step - loss: 0.8264 - accuracy: 0.6923 - val_loss: 0.9680 - val_accuracy: 0.6417\n",
            "Epoch 107/120\n",
            "224/224 [==============================] - 26s 115ms/step - loss: 0.8368 - accuracy: 0.6912 - val_loss: 0.9484 - val_accuracy: 0.6442\n",
            "Epoch 108/120\n",
            "224/224 [==============================] - 26s 114ms/step - loss: 0.8025 - accuracy: 0.7011 - val_loss: 0.9732 - val_accuracy: 0.6467\n",
            "Epoch 109/120\n",
            "224/224 [==============================] - 28s 124ms/step - loss: 0.8249 - accuracy: 0.6899 - val_loss: 1.0240 - val_accuracy: 0.6300\n",
            "Epoch 110/120\n",
            "224/224 [==============================] - 26s 114ms/step - loss: 0.8120 - accuracy: 0.6900 - val_loss: 1.1179 - val_accuracy: 0.6113\n",
            "Epoch 111/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.7958 - accuracy: 0.6930 - val_loss: 1.0611 - val_accuracy: 0.6135\n",
            "Epoch 112/120\n",
            "224/224 [==============================] - 28s 123ms/step - loss: 0.7991 - accuracy: 0.7001 - val_loss: 0.9871 - val_accuracy: 0.6383\n",
            "Epoch 113/120\n",
            "224/224 [==============================] - 26s 114ms/step - loss: 0.7973 - accuracy: 0.6982 - val_loss: 1.0486 - val_accuracy: 0.6314\n",
            "Epoch 114/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.8269 - accuracy: 0.6881 - val_loss: 1.1139 - val_accuracy: 0.5993\n",
            "Epoch 115/120\n",
            "224/224 [==============================] - 25s 112ms/step - loss: 0.7665 - accuracy: 0.7073 - val_loss: 0.9630 - val_accuracy: 0.6484\n",
            "Epoch 116/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.7683 - accuracy: 0.7105 - val_loss: 1.0205 - val_accuracy: 0.6305\n",
            "Epoch 117/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.7979 - accuracy: 0.7132 - val_loss: 1.0433 - val_accuracy: 0.6197\n",
            "Epoch 118/120\n",
            "224/224 [==============================] - 28s 124ms/step - loss: 0.7853 - accuracy: 0.7004 - val_loss: 1.0563 - val_accuracy: 0.6082\n",
            "Epoch 119/120\n",
            "224/224 [==============================] - 25s 113ms/step - loss: 0.7592 - accuracy: 0.7141 - val_loss: 1.0746 - val_accuracy: 0.6113\n",
            "Epoch 120/120\n",
            "224/224 [==============================] - 26s 114ms/step - loss: 0.7967 - accuracy: 0.7056 - val_loss: 1.0637 - val_accuracy: 0.6250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "GaXUP-8fDWRN",
        "outputId": "c0178a08-3536-4a44-9aaa-3113b977b6f1"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "model.save('/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editAdamst120epochBS128_1.h5')\n",
        "\n",
        "#gffhgffkjkjdskjjkjkjkjhjhnnnhjhhu\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "num_epochs = range(len(accuracy))\n",
        "plt.plot(num_epochs, accuracy, 'r', label='Training acc')\n",
        "plt.plot(num_epochs, val_accuracy, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(num_epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(num_epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3hUVfPHv0NCEYL0moD0XkIIIChFAQVBugIqglQBe0FUEF5sr4rl5af4vigCIhoEBelSBBtSQpWSkEgNEAg9EAIp8/tj7s1uNrubTchmd7PzeZ59bjv33Ln3JmfumTMzh5gZiqIoiv9SyNMCKIqiKJ5FFYGiKIqfo4pAURTFz1FFoCiK4ueoIlAURfFzVBEoiqL4OaoIlCwQ0WoiGprXZT0JER0loi5uqJeJqI6x/l8imuxK2Vxc51EiWptbORXFGaRxBAUDIrpqtVkcwA0Aacb2GGZekP9SeQ9EdBTASGZen8f1MoC6zBybV2WJqAaAIwAKM3NqXsipKM4I9LQASt7AzEHmurNGj4gCtXFRvAX9e/QO1DRUwCGiTkQUR0SvEFE8gDlEVIaIVhBRAhFdNNZDrM7ZREQjjfVhRPQHEU03yh4hou65LFuTiH4jokQiWk9EnxHRNw7kdkXGN4noT6O+tURU3ur4ECI6RkTnieh1J8+nDRHFE1GA1b6+RLTXWG9NRH8R0SUiOk1EnxJREQd1zSWit6y2XzbOOUVEw23K9iCiXUR0hYhOENFUq8O/GctLRHSViNqaz9bq/HZEtJ2ILhvLdq4+mxw+57JENMe4h4tEtNTqWG8i2m3cwz9E1M3Yn8kMR0RTzfdMRDUME9kIIjoO4Bdj/yLjPVw2/kYaW51/GxF9aLzPy8bf2G1EtJKInra5n71E1NfevSqOUUXgH1QGUBbAHQBGQ977HGO7OoDrAD51cn4bANEAygN4H8BsIqJclP0WwDYA5QBMBTDEyTVdkfERAE8AqAigCICXAICIGgH43Ki/qnG9ENiBmbcCuAbgXpt6vzXW0wA8b9xPWwCdAYxzIjcMGboZ8nQFUBeA7fjENQCPAygNoAeAsUTUxzjWwViWZuYgZv7Lpu6yAFYCmGHc20cAVhJROZt7yPJs7JDdc54PMTU2Nur62JChNYCvAbxs3EMHAEcdPQ87dATQEMD9xvZqyHOqCGAnAGtT5nQALQG0g/wdTwCQDmAegMfMQkTUHEAw5NkoOYGZ9VfAfpB/yC7GeicANwEUc1I+FMBFq+1NENMSAAwDEGt1rDgABlA5J2UhjUwqgOJWx78B8I2L92RPxklW2+MArDHW3wAQYXWshPEMujio+y0AXxnrJSGN9B0Oyj4HYInVNgOoY6zPBfCWsf4VgH9blatnXdZOvZ8A+NhYr2GUDbQ6PgzAH8b6EADbbM7/C8Cw7J5NTp4zgCqQBreMnXL/M+V19vdnbE8137PVvdVyIkNpo0wpiKK6DqC5nXLFAFyEjLsAojBm5vf/W0H4aY/AP0hg5mRzg4iKE9H/jK72FYgporS1ecSGeHOFmZOM1aAclq0K4ILVPgA44UhgF2WMt1pPspKpqnXdzHwNwHlH14J8/fcjoqIA+gHYyczHDDnqGeaSeEOOdyC9g+zIJAOAYzb314aINhommcsAnnSxXrPuYzb7jkG+hk0cPZtMZPOcq0He2UU7p1YD8I+L8toj49kQUQAR/dswL12BpWdR3vgVs3ct4296IYDHiKgQgMGQHoySQ1QR+Ae2rmEvAqgPoA0z3w6LKcKRuScvOA2gLBEVt9pXzUn5W5HxtHXdxjXLOSrMzAcgDWl3ZDYLAWJiioJ8dd4O4LXcyADpEVnzLYBlAKoxcykA/7WqNztXvlMQU4411QGcdEEuW5w95xOQd1baznknANR2UOc1SG/QpLKdMtb3+AiA3hDzWSlIr8GU4RyAZCfXmgfgUYjJLoltzGiKa6gi8E9KQrrblwx78xR3X9D4wo4EMJWIihBRWwAPuknGxQB6EtHdxsDuNGT/t/4tgGchDeEiGzmuALhKRA0AjHVRhu8BDCOiRoYispW/JORrO9mwtz9idSwBYpKp5aDuVQDqEdEjRBRIRAMBNAKwwkXZbOWw+5yZ+TTEdj/TGFQuTESmopgN4Aki6kxEhYgo2Hg+ALAbwCCjfDiAAS7IcAPSaysO6XWZMqRDzGwfEVFVo/fQ1ui9wWj40wF8CO0N5BpVBP7JJwBug3xtbQGwJp+u+yhkwPU8xC6/ENIA2CPXMjLzfgDjIY37aYgdOS6b076DDGD+wsznrPa/BGmkEwF8YcjsigyrjXv4BUCssbRmHIBpRJQIGdP43urcJABvA/iTxFvpTpu6zwPoCfmaPw8ZPO1pI7erZPechwBIgfSKzkLGSMDM2yCD0R8DuAzgV1h6KZMhX/AXAfwLmXtY9vga0iM7CeCAIYc1LwH4G8B2ABcAvIfMbdfXAJpCxpyUXKABZYrHIKKFAKKY2e09EqXgQkSPAxjNzHd7WhZfRXsESr5BRK2IqLZhSugGsQsvze48RXGEYXYbB2CWp2XxZVQRKPlJZYhr41WID/xYZt7lUYkUn4WI7oeMp5xB9uYnxQlqGlIURfFztEegKIri5/hc0rny5ctzjRo1PC2GoiiKT7Fjx45zzFzB3jGfUwQ1atRAZGSkp8VQFEXxKYjINho9AzUNKYqi+DmqCBRFUfwcVQSKoih+js+NEdgjJSUFcXFxSE5Ozr6w4hGKFSuGkJAQFC5c2NOiKIpiQ4FQBHFxcShZsiRq1KgBx/OlKJ6CmXH+/HnExcWhZs2anhZHURQbCoRpKDk5GeXKlVMl4KUQEcqVK6c9NkXxUgqEIgCgSsDL0fejKN5LgVEEiqIoBZaUFODll4ETDif1uyVUEeQB58+fR2hoKEJDQ1G5cmUEBwdnbN+8edPpuZGRkXjmmWeyvUa7du3ySlxFUXyJK1eAnj2B6dOBlSvdcokCMVjsacqVK4fdu3cDAKZOnYqgoCC89NJLGcdTU1MRGGj/UYeHhyM8PDzba2zevDlvhFUUxXu4eRPYuhVo2xYw2whm4OBB4PJlICkJePFFYN8+YPZsYPhwt4jh1h4BEXUjomgiiiWiiXaOf0xEu43fISK65E558pNhw4bhySefRJs2bTBhwgRs27YNbdu2RYsWLdCuXTtER0cDADZt2oSePXsCECUyfPhwdOrUCbVq1cKMGTMy6gsKCsoo36lTJwwYMAANGjTAo48+CjOD7KpVq9CgQQO0bNkSzzzzTEa91hw9ehTt27dHWFgYwsLCMimY9957D02bNkXz5s0xcaK8rtjYWHTp0gXNmzdHWFgY/vnnVuYrVxQ/5NIlID096/5z54CuXYEOHYAmTYDvvweWLgXatAEaNwbatQO6dAH++Ud6Am5SAoAbewREFADgMwBdIdMEbieiZcZE4QAAZn7eqvzTAFrc8oWfew4wvs7zjNBQ4JNPcnxaXFwcNm/ejICAAFy5cgW///47AgMDsX79erz22mv44YcfspwTFRWFjRs3IjExEfXr18fYsWOz+N7v2rUL+/fvR9WqVXHXXXfhzz//RHh4OMaMGYPffvsNNWvWxODBg+3KVLFiRaxbtw7FihVDTEwMBg8ejMjISKxevRo//fQTtm7diuLFi+PChQsAgEcffRQTJ05E3759kZycjHR7f9CKothn7VqgTx+gVStg8WKggpHz7cAB4MEHgZMngcmTgR9+AAYOlGO1agGffgrUqQMUKQLUrw9UrepWMd1pGmoNIJaZDwMAEUVAZqQ64KD8YOTDJOr5yUMPPYSAgAAAwOXLlzF06FDExMSAiJCSkmL3nB49eqBo0aIoWrQoKlasiDNnziAkJCRTmdatW2fsCw0NxdGjRxEUFIRatWpl+OkPHjwYs2ZlnbQpJSUFTz31FHbv3o2AgAAcOnQIALB+/Xo88cQTKF68OACgbNmySExMxMmTJ9G3b18AEhSmKIqLrFgB9O8P3HEHsG2bKIN//xtYskQa/vLlgV9/lR7AlCmyHxDF4cCU7C7cebVgANZD3HEA2tgrSER3AKiJrBN8m8dHAxgNANWrV3d+1Vx8ubuLEiVKZKxPnjwZ99xzD5YsWYKjR4+iU6dOds8pWrRoxnpAQABSU1NzVcYRH3/8MSpVqoQ9e/YgPT1dG3dFyS1xcdLAR0YC5coB48cDxYqJjf/LL4Fx48Sa8PPPwOHD0sAPHgyULg08/zzwwgtAlSpSV0AAMGCAx27FW7yGBgFYzMxp9g4y8yxmDmfm8AoV7KbT9nouX76M4OBgAMDcuXPzvP769evj8OHDOHr0KABg4cKFDuWoUqUKChUqhPnz5yMtTR55165dMWfOHCQlJQEALly4gJIlSyIkJARLl8q0wjdu3Mg4rig+SVwcUKOGNM72SEwE9u93XkdiojT61arJF//77wMvvSR2/vnzgXvvBUaPBtq3B9avB8qWBcLDgR07gO++Exk++MCiBLwAdyqCkwCqWW2HGPvsMQjAd26UxeNMmDABr776Klq0aJGjL3hXue222zBz5kx069YNLVu2RMmSJVGqVKks5caNG4d58+ahefPmiIqKyui1dOvWDb169UJ4eDhCQ0Mxffp0AMD8+fMxY8YMNGvWDO3atUN8fHyey64obiE1VTxyrKfjnTEDOHYMeOedzGWZgQULxB7ftKk02vZYu1Ya/M8/B559Vuq/ehVYt06+6h9/HNi1C5g1S5SA9f9gpUrAoEGAlaXAa2Bmt/wgZqfDEJNPEQB7ADS2U64BgKMw5k/O7teyZUu25cCBA1n2+SOJiYnMzJyens5jx47ljz76yMMSZUbfk5JvnDjB3KEDM8D8ySey78oV5lKlmG+/Xfbv2iX7r19n7tJF9rVqxVyhAnO7dszp6Zb6rlxhHjVKyjRowLx5c9ZrJiczf/st8+nT7r+/XAAgkh20q27rETBzKoCnAPwM4CCA75l5PxFNI6JeVkUHAYgwBFVugS+++AKhoaFo3LgxLl++jDFjxnhaJEXJf5YuBZo3l6/65s2B118Hjh8HvvpKfPO//x4oXlx6B4B47axfL546W7YA774LbN4MfPutHP/1V+klfPmlRPfu2iV+/7YULSpjAJUr59+95hWONIS3/rRH4Lvoe/Jzduxgvv9+5osX3VN/fDzzww/LV3uLFszR0cxHjjAXL878wAPMNWsy33WXlB07lrloUebFi5mJmJ980lJPWhpzeDhz1arML74ox+vUYf7zT/fInU/ASY/A4w17Tn+qCHwXfU8FlPT0zGYUR4wYIU3O5MmZ95844dr5zq7/1VfMZcsyFynC/OabzDduWI5/+KFcF2D+8UfZd+CAbBMx167NbJhVM9i82XLO6NFZj/sgzhSBt3gNKYriqzz3nPjCOyM1FfjpJ1n/5BPg/HlZ//xz8b5p2FBy6ezaBezZIykWsrMWJybKYG2nThJ126iRBJNOmiSBWCbPPCM+/A0bAr0Mq3TDhsB99wFE4uljRO5n0LYtMGcOsHo18L//ZT1ewNBcQ4qi5J59+8S2np4OxMQAdevaL/fHH5JS4V//AqZOlUa/f39RIu3aSYP88suZz+nWTez6VarIdT75BIiNBc6eBeLjgYsXpVyZMmK/f+IJoJCdb9vAQOD334HkZPHsMZk/X2S2Z+8HgGHDcvo0fBZVBIqi5J6JEyWIKikJWLPGsSL44Qcp9+KLQFSUDNRGRIhL5bJlEpAVFSU9AUAa6KlTZZD27rulTIkSQFiYfPnfc49E7FavLvl4ypd3LmfRovKzpmJF+Sk6RpAXdOrUidesWZNp38cff8xPWg9A2dCxY0fevn07MzN3796dL9oZQJsyZQp/8MEHTq+9ZMkS3r9/f8b25MmTed26dTkRP9/w9HtS8phffhEb+nvvMderx9y9u/1yaWnMwcHMffrIdlQUc6FCzIGBzH/95bj+gwdl0DYoiPm115jPncv7e/AjoGME7mXw4MGIiIjItC8iIsJh4jdbVq1ahdKlS+fq2kuXLsWBA5b0TdOmTUOXLl1yVZeiuExaGjBhgtj3n35azDibNgHXr8vxuDhg3jyZUGX7dkmu1r+/HKtfX8YGFi4E7rzT8TUaNJBzL18G3n5beg2KW1BFkAcMGDAAK1euzJiE5ujRozh16hTat2+PsWPHIjw8HI0bN8aUKfZz6tWoUQPnzp0DALz99tuoV68e7r777oxU1YDECLRq1QrNmzdH//79kZSUhM2bN2PZsmV4+eWXERoain/++QfDhg3D4sWLAQAbNmxAixYt0LRpUwwfPhw3btzIuN6UKVMQFhaGpk2bIioqKotMmq5acci1a5IXJzJSInRvuw3o3l2UwG+/ySDvo4+KjT0sTBKtBQbK5Como0cD/fq5dj17dn8lTylwYwSeyEJdtmxZtG7dGqtXr0bv3r0RERGBhx9+GESEt99+G2XLlkVaWho6d+6MvXv3olmzZnbr2bFjByIiIrB7926kpqYiLCwMLVu2BAD069cPo0aNAgBMmjQJs2fPxtNPP41evXqhZ8+eGGCTsCo5ORnDhg3Dhg0bUK9ePTz++OP4/PPP8dxzzwEAypcvj507d2LmzJmYPn06vvzyy0zna7pqBYAMAkdHy2Bt8eJip3/pJWDnTuA//wEee0zKdewoYwCrV4s3z2+/ASNHyrjB0qXA/fdLsjXFKylwisBTmOYhUxHMnj0bAPD9999j1qxZSE1NxenTp3HgwAGHiuD3339H3759M1JB9+plCcDet28fJk2ahEuXLuHq1au4//77ncoTHR2NmjVrol69egCAoUOH4rPPPstQBP2Mr7GWLVvixx9/zHK+pqv2c27eFLfL77+3eOeYlCghrqAPPmjZd9tt4sa5YoUca9pUzD/XrwP/93+iCBSvpcApAk9loe7duzeef/557Ny5E0lJSWjZsiWOHDmC6dOnY/v27ShTpgyGDRuG5OTkXNU/bNgwLF26FM2bN8fcuXOxadOmW5LXTGXtKI21pqv2UVJTgTfflC/5N94ArCc1SkkRH/2tW+UL/+BB4MwZ+VIvW1ZMNyNGiP1/wABg1SpgyBDx0GnRArhxA7hwQXzwa9TIeu1u3aQHAAAbNog5qGRJ4LXX8uXWldyjxrc8IigoCPfccw+GDx+eMUh85coVlChRAqVKlcKZM2ewevVqp3V06NABS5cuxfXr15GYmIjly5dnHEtMTESVKlWQkpKCBQsWZOwvWbIkEhMTs9RVv359HD16FLGxsQAki2jHjh1dvh9NV+2DnD0rUx9Omwa89ZY04KdOiZmmf3/g9tslsOqpp8R18+ZNmRIxKEjy5Y8bJwO0995rCaT6+mvxzw8NlaCx7t3tKwFAjgGSd//ee/PttpVbp8D1CDzJ4MGD0bdv3wwPoubNm6NFixZo0KABqlWrhrvuusvp+WFhYRg4cCCaN2+OihUrolWrVhnH3nzzTbRp0wYVKlRAmzZtMhr/QYMGYdSoUZgxY0bGIDEg5pk5c+bgoYceQmpqKlq1aoUnn3zS5XsZN24c+vfvj6+//hrdunXLlK569+7dCA8PR5EiRfDAAw/gnXfewfz58zFmzBi88cYbKFy4MBYtWoRatWq5fD3FAUeOyMxVZcuKr/zZs2Kzv3pVUhrffbcESn37rcxydf68NN6FC4uNvkYN6QmULQuMGiXl77xTvH2ILNdhlq/5118XT53582XANyfUqyfTMXbokKePQHE/xNmFcXsZ4eHhHBkZmWnfwYMH0bBhQw9JpLiKvic7HDsmbpgPPAA88khmUw4gtvW1azPvK1xYfklJ4oqZkCAmm2bNgLlzxYwDyLy4H3wgkbuPPiqDvdmRni5jAuqqWeAgoh3MHG7vmJqGFMVTnDsnDf2iReJqWaeOJfUxIJ45a9dKhG1srKRIjo0VBXD2rOTCqVJFTECbNom7nKkEAInAnTNHegKuKAFAXDVVCfgdahpSlLwkNlbMLrbpDGy5dg3o0QM4elQa8cREafCHDAGCg8Ud8/33xa7/3HMy01Xt2pbzAwNFefhRPpyCxI8/itUuLMzTkggFpkfgayYuf6PAvZ+UFEm2lpBg2XfunLhNPvaY88yZKSnAww9LQFZEhNjUe/QAfvlFGvvHHpNJ0RctAsaOzTzdoZ8RFQVY+Ux4jJs3xZP2/vslyPlWGTlSArK9Bke5J7z1Zy/X0OHDhzkhIYHTbyWnueI20tPTOSEhgQ8fPuxpUfKOqVMlz87YsZZ9//mPJYf9ggX2z0tPZx4+XMr8739Zj0dGMhcuLJOpFC3KfOqUe+T3EQYOlCkGrl3zzPUPH2Z+9VXmSpXklRUuLKmPrl7NfZ2XLln+TI4ezTtZswNOcg0ViMHilJQUxMXF5dpHX3E/xYoVQ0hICArbDob6Itu3S+riIkUkrfHJk2LCMfv5xYqJj/7+/UDVqpnPnTpVUjFPnixunvb46CPJ0jlmDPDf/7r1Vryd+vWBQ4dkqKRrV9fOuXxZhjpKlsx6LClJ5pd/7bXszTJPPilz0BNJiMXYsfJq77lHnKrMoOqcsnevzKAJAO+9J74C+YGzwWKPf+Hn9GevR6Ao+ca1a5JpMySEed06+az7v/9j3r3bsn7oEPNttzG3b8/89dfMv//OPGOGTJMIMD/xhPMZudLSmCMi3Delo4+QmCgTiAHMr7zi+nlt28r89O+8k7UnYb6yJk0yT2JmS3S0lHvsMebjxy3709KYa9Rg7trVuQynTzP/+qv9Yz/9JHWXKiUzauYXKOhTVSpKvvHss/Jvs2GDbLdqxdywIfNzz4ndwEyVPHs2c0CAxQYAMDdtyvzuu8w3b3pOfh/izz/lsRUpItmoXSExUTJcV60q51arxhwXZzn+5puW1/H2247rmTxZ6jl5MuuxN94QBXXihOPzzVk5Fy7Mesy0IL72miyjoly7t1tFFYGi5AU7dkjrMG6cZd/cuZbWqn//zOWvX5ec+qtWyRy5BYjEROZ+/ZgnTmTeuvXWphx2xGefyaMdMUIa3vPnsz9n0yY5Z8UK5p9/lvUZMyzHe/YUvT1ggAzBxMRkrSM9Xea5d/TVHxMj9f77347lqFXL8mdh2zN4/nkZAoqLk/uaOjX7+8oLVBEoSny8fGLmlrQ05jZtmCtWzGyyuX6duVw5+VdavvzW5fQRTBOL+WvZUgZB85KRI+XR/v67XOOHH7I/5733pOzZs7JdsyZz796ynp7OXL4887Bh8qV/++3M99+ftQ7zevPmOb5Ou3bMjRrZV4DHj8v5b7zB3KABc+nS8j1g0qcPc+PGst6pE3P9+u5RpLY4UwQFxn1UURySliaZMu+6S6ZIBCzZNWvXFh/F7Jg9W5K1TZ+eOZ1ysWLA88/LqGa3bu6R303cvCmpiHKDOaPk/v0ynr1nj3jE2slfaJeEBODKFedldu+WFEetW0vC0w0bsq9361agVi2gQgXZ7txZwjTS0iRbx7lzkmGjalUZi1+/PqvM8+dL/J2z6RKGDpXA7Z07sx779VdZ9usnKZtu3JBErCZHj1rSNQ0eLBlDfvst+3tzK440hLf+tEeg5BjTxtC0qSxffdUycBsUJAO/x45lPW/aNOa772bu1k1G9jp0yJ9Pt3zitdfkazU1Nefnjh0rj8R8HF9+KY9z3DjXHlGTJs4HXG/eFNPNSy/J9gMPyBh9dgQHMw8ebNn+9luRa9s28egFZFyfmfmLL2Tb2qs5OVmeyaOPOr/O+fMy0+aECVmPjRjBXKaMdCKZZfC6fXvL8dKlmcePl/Vr1+TPr2VLS3lH5OY9WQPtESh+S3y8+Ap27gzs2CGRu+++K5+bERHA77/Lp+l992UODps/X9I4X70qidyaNpVsnNaJ2nwYZpkp8tIlyUSdU6KiJBu1+ThGjBA3yJkzJWrWGUeOSBbsdeuAXbvsl4mOli/p0FDZ7txZ3Ejj4hzXe/Kk/Nq0sewzk6Bu2CC9heLFJeEqID0HUx6TVavkmQwZ4vweypYVmRYvzho7uGmTxAiaE6u1aCF/bunpUvelS5YeQfHiMoHbjh3yJ+eIxETpvFpnIMlLVBEoBZsXX5TJUWbOlERtc+eKc/i2bcDAgdLSLF8uyd/uvFNiBKKjxWm8QwfZ3rZNFEaDBp6+mzxj/37AnE30+PGcn3/woCgCa959VzJam6YRR5g59IoUAT780H4Zc5ZBa0UAiCnHEVu3ytJaEVSqBDRpIkHbW7ZIFu5AI7FOzZqyPHzYUn7zZskOYl7PGQ89JOdaK7O4OHmu1hnfw8KkIT98WP7MgMyZvAcPFvPXa69J5hF7zJ4t59apk71cuUEVgeLdpKYCy5bJZ9Pw4RKBc/q0a+f+8Yd8Qr3yiqRIBuQzbdQoSchm0qGDfDKmpMg4wn33ie3/228trYYPkp4uk4WlpGQ99tNPlvUTJ3JW76VL0tGy1YuFCsk+c/zAET//LOmYxo+XTpl5/Z9/tqST2LVLXkH9+rLdtClQubJ8sTti61bR9abyMLn3XvlT2L07s5KoVk3iAa17BFFRQN26rr323r3lfKvs7xlKsFMnyz4zD+DOnTI+AGRWBIUKAR9/LOM177+f9TqpqTLhVvv2ojDcgiObkbf+dIzAz5gwweKaUqGCLAMCmLt0YR4zRlwz5s8XtwxrI2t6uhhnq1RxPT/B+fPMvXqJi+iKFbkS9/hxcSTyBkz7+DffZD0WHi4eLQDzhx/mrN6//pLzli3LemzIELHTO+LmTfHWGTlS0isEBEhoxksvWV7zrFnM994rIRrWjBrFXLKk40Cwjh2znsNsCeACmH/8MfOxmjWZBw2ybNetK66lrtK1K3OdOpZxkVGjZOzE2p6fnCzjCRMnMn/yichhhptY8/DD4lZ6+nTm/RERcs7Spa7LZQ+o+6jikyQmyn9Vnz7Mly/LvuhoGext1kwUgxl6CsgInenC+eOPllYlJ6SnW3wPc8j169JQffBBrk7PJMKnnzKfOZOz85KTM9fRrJk8AnNg0uTECdn/7rvMJUpILFxO+OorOd+eD/4778gx83XZ8scfcnzRItkeNMjy+saNk0FhM6fPqFGZz122TI6tXWvZ9+674guQlCT38tRTWa958aLodiBrgONUJ20AACAASURBVFjnzuIVzCwKJiCAedIk154Ds6SLsh6ArluX+cEHs5Zr3lxcVZ99VvwT7A2ox8SIwrBOX5WeLsqtbt3sB5OzQxWB4pt8/rn8iTrz/09JYd63TwK7wsLkP+mbb8Q5u0EDOZ5P7NxpadBuhX37pJ5p01w/588/JXjJ/EpfuVLqKFYsa1Su6UR18KAEV/XrlzP5Xn5ZrmXPi2XJEql761bLvitXLI2YGbF74YJs//23eBCZOfqSky3KYObMzHVfuyaZO8zGfssWixKpUkWW8+fbl7l1a4kytmXUKPmeYJaYP2d12OPsWbmfBx6QXgzA/NFHWcsNGybX6dVL7tcR48eLMoqOlu3ffpM6P//cdZkcoYpA8T3S0yViJyzMdZfNy5fFxdNsHZYsyTNxDh3KvowZZPzQQ7d2rW++kXp69cq8PynJ8VehaXIIChJF0r69NHwvvCBf19bmqq5dRU8yM993n31zijMefNBxYxYVJXLMnSvbqaniHtm6tcT0tW4tFjtnJCeLsrKXaqlXL+Y77pA/iQcflE7g4sUiT2Ag85Ej9uuMjGTeuDHrfrMHk5ho6URu3+5cPlu6dpXzateWKGHrnpnJjBlSpmJFiW52RHy89Gx69xbZypWTILi8yL6qikDxPdavz9yiuMq1a5LqoVevPPP5N23i9vLGWPPCC1Lunntcr3v3blEc1vlwTHt5lSqWfTduyPb06fbreeopaUAqV5bGBpCcNmbjtnmzlLtwIbP/+4gRco4zLl2Sr3NTmdSp41jZpaSI4jGTxEVGWvRy9eq3nlLB9P03laVZV2pq7jJ2m/b3vXuzN2s54vRpuU9nf25mtDJg33xlzZQplrLdu1vMTreKM0XgVq8hIupGRNFEFEtEEx2UeZiIDhDRfiJyk5es4lPcuCGpmMuXFxfPnFC8uLhx/PRTnvn8b9oky/ffdz7fzN69sjx3zrV6V62SueQXLZJJT0xMd8TTp8UvHhAv1tOnHUegxsaKh82PP4pXT7ly4ttvesls2ybLpUvFC2XAANmuVk08gG7ccCzn888D48aJZ0tysrhBOpp6OjBQvG5MzyHz2S1bJpHMzDK5S27p2VOWo0aJq6o5uUtAgMzamVNMF9IjR8RruGpVySieEypXBlq2dP7n1ry55bi1x5A9Xn4ZmDJFvKBWrbKkrHYnblMERBQA4DMA3QE0AjCYiBrZlKkL4FUAdzFzYwDPuUsexYNERkpqh3fflcnUHeUWWLlS/tPLlZP/gPHjxYcwH9m6FejeXXLam2zeLMsdO5ynAsiJIpg7V7Je1K0rM1P+/rvsZxY3RzPoaft2Wf7yS+Zr2BIbKz7mbduKr/3SpZKWoWpVICTE4mO/cKEEUoUbWemrV5elqXBs2bhRpj0uWVIU4bZt4pbqSBEAcsxaEdSrJ/e6bRswb15mF86cUrmyuFBevy7KqWzZ3NcFZA4qi4qyuKvmNSVLWmIAslMEJUrItBVucxW1h6Ouwq3+ALQF8LPV9qsAXrUp8z6AkTmpV01DXsjevZLf197oYUqKZXon8xcamtlH7tQp8dkz7QfjxonP3626SeSQ8+fl8oC4XjJbEpUNGiSDfY7su/Hxcl7JkmIacWYmSEoS23b79mKbfvxxqTs93ZKwbPp0MeG89pqc06mT5fHZmi5u3sxc1pb+/SUb5tmzMhA5caLlmJk8btOmrOddvy7eKrVry8AskSRLA5h37XJ8f5MmyQDqtWviKjp6tOOyueGjj6Te+Phbrys9XcZVnnlGUj9Ye+zkNQ8/LM9uxw73XcMZ8JBpKBiAdahKnLHPmnoA6hHRn0S0hYjsZu0iotFEFElEkQnWaQAUz5OeLhm4HM249euvksPgm2/ErrB6NRATA7RrJ5m4BgyQz+Lly2Uy2JgY4LPPgF69LDH6+QCzmFJOnZKvtzVrZP8//8gX/j33SAdlxQr7OerML/WOHSWAy1lCtcWLgYsX5asvKEgChRISJIWCGVHbtq1ExG7fLl+/mzdbArj27ctc3/HjYu5xFHXapo2Yc2bNkuRr1ta2atUsdVhz/ryYhGJiJKlcmzYSAbt/v5g4nH05N2wofxaLFslzuOcex2Vzw7PPSgRvpUq3XheR9Aq2bBGTmjuDx9u2lYA30xzlVTjSELf6AzAAwJdW20MAfGpTZgWAJQAKA6gJURylndWrPQIvY+FC+cxp1Eg+GdesyXx85Ej5TE5KsuzbulU+swGZQWTUKNfccvKYXbskQdlLL0knxPwSf+QRGXBNS5MJxszBxLNnxR1zxIisdU2fzhnBWQBzbKzj6951l3xpm70G09Pmiy/EZZRIegqjRknPwfxqnzmT7boSrlkj+3/7zf71fv2VMzyK6tXL3Fu5dk2OmZO0xMcz9+0rvRpAYvZMTD/3mjWdP1fTjbZNG1l6+7TLvXtbwlFs/3zzkhs3mPfvd1/92QFPeA3BNdPQfwE8YbW9AUArZ/WqIvAiUlKkZWncWFqupk3F382c2+/GDWnJhgzJem5CgjiRezCb58iRYiopWlT+E3r3ztz4R0aKqaBkSYvVy5ygzDaq9vHHRaeZ/vtbtti/phkjYB10lp4upqHHH5dG2MyyOWuWlB00SOS8fFlMIrZxCp9+6rzBvXrVMlna5MlZj5crx/zkk7I+YYI09i+8IIrS9vV88AHz++/bv47JtWuWhtV0U/Vmnn/eYnbLz8nk8xtPKYJAAIeNL/0iAPYAaGxTphuAecZ6eaNHUM5ZvaoIvAjTl8+MfY+OllazbVtRAitWyPGVKz0rpwPMSUvS0mTIwmz0zpwRsd96SyJCu3SxnJOUJCmDb789cycmNFSyVW/bJuc6mqPm6aclGCshIfP+vn1Fnpo1xZbMLA0xIPb2O++UfXfdJZmxrXnuOUlN4EynNm8ude3bl/VYaKgERDGLTr/3Xsf1uEqNGll7FN6K6eN/2235PiyVrzhTBG4zwjJzKoCnAPwM4CCA75l5PxFNI6JeRrGfAZwnogMANgJ4mZnPu0smJQ9YtQro0UOM4S+9JBk7exmvs149SZP411+SkzgiAihTBjc7dEFaWv6JeOqUeKskJjouc/iweIp06SJDEZUrW9z7KlYUd8DFi4G//xbbrslttwE//CCZM/v2lWukpMgkJc2aiccrkNlzaMgQqWPKFEk1PGCApZxJ+/Yiz5EjlqRpjRuL01R6uiWdcrNmIhNbubGaHkPO3Bf79we6drV4I1lTvbokfjt6VMYAevRwXI+rmF5FeT0+4A5Mz6F69fJ1WMq7cKQhvPWnPQIPkpYmxu0KFSTDV58+Yt6x5Zln5BOrcGFOHzGSW7dmHj48/8Ts29fyJR0WZv8r2DS7OJpKeNIki7lg1aqsx9evl/rbtLHY4L/5RtIpWJt+0tLE9FS2rCXfze+/Z61v+3bL9Vavtuxv21b2rV8v22bWDet5dBo0yHmaCGvGjxePGdPEZKY3uBVefFHqsk2g5o3s3y+ymj2xggp0YholT/jlF3Ej+egj+eReskRcW2z54ANxM0lJwR9NnsS2bRLo5Mo0hunp4jkzc6bjbNOJifJlbf1VbE1srOSdnzRJplC0N5nHhg0SgOTIS8R61sk778x6vHNn6Rns3i1xB4B8rQcFSW/BdG47e1aCtaZNk17Czp0SRGZLaKica66b3HWX+JW3ayfbTZvK0vRSSkuT3s2t5KmvVk08ZhYulHrMjN23wnPPSY+qcuVbr8vd1KwpPa/8CNzyWhxpCG/9aY/Ag/TrJyOLruRZjo9nnjOHBw9Kz/jSNdMcOGLhQkt6BCBr1kyT11+X49YTgltTqpQljL9NG7GrW5OWJp0ae2PYJikp8pXcsKFzmX/9Va5XpIglPXJwsKUHZCZGc2Ve+/vuy5xWgll6GNb3eemS1PfOO7J99Khs5zTJqjVmumog55lICwr79+dNPh9vBtojUFzi6lWJby9fHvjXv8Tv3+TkSUnbMGKEa9G+lSrh7APDsPgHwpAhYns1ffMdMW+epCiYO1fSECxZIj0Ea1JTJdIVsD/x+pUrEhVs+sd36iQRrdYzP/39t3yxO5uFKjBQOjZvvOFc5g4dJHB6zRrpCQDy+MwxAnNGqjvucF4PAPznP5lTTQAS02DdaylVSiJTzR5BbKwsb7VHYJIX4wO+SKNGkp3EX1FFoAgrV8oI3/Tp0qpMnSpmn8WLZTT0iy+kVR4zxuUq58yRU199VcLlf/7Zefk9e2RQdOhQ4LHHpKE3c+SYrFplUQDx8VnrMGe7MlMnmAFef/1lKbNhgyyzm45w5Ehg0CDnZQB5XNaDotaKwJyRyhVF0KCBfbORLU2bijID8lYRBAWJYlP8D1UEiiSU6dMHKFNGQli3bJGENYGBMjFrSIh8rt5/v8XFIhvS02Wu944dRb906yaN+nkHPmHnzkmnw7SP9+wpl7edCP2LL0RMwLkiMBu3u+6ShGTW8+hu2CCRsSEhLt1KjqlQwTJGcOyYyJvTRGbOaNZMopsPHhRFULSo5CvKLVWrSo/tvvssvRrFv1BF4O/ExIhvYb16kvnM9JXs3FlyGSxfLq1pcrJMBO8iy5aJK+TYsbLdrZtYodets19+zx5ZmgN2pUuLCD/+aBkUjouTHsGYMdJgnTmTtR4zVYLZI7j9dnEFNbNgXr4sSsGVyclzi61pyJXeQE4YPFiUi+niWrv2rbk9Fi4s6Sf+9a+8k1HxLVQR+DMXLiCpx0PSiixfLgZoawID5dP8xx8l4U2XLi5Ve+kS8NRT0hPo21f2hYdLpkhH5iFbRQAA/fpJrh/TDDJnjvQ0Ro4UbxRHPYJChTKnJO7YUXojSUnAW2/JcuRIl24lV5QvL7mEUlPFNJTXiqBxY3le7dpJ/bdiFjIZMcK+A5jiH6gi8Bdu3LAYlAHg8GF81fhDVIj5E+fnLHPZ5OMKL7wgjfS8eRZTQ0CABDStWWPf7XPPHmm8K1Sw7OvdW4KkfvgB+O474JNPRBfVru1YERw/LqaOwEDLvk6dJBf+ggVi4Ro2DGjRIs9uNwtmsNj58+7pEQByj2vXysD61Kl5X7/iX6giKIgkJwMXLmTe7t5dsnzeeSfwwQdIa9MO75wdgSSUwJ4S7Vyu+soVMdE4YtUq+XKfMEF8+a3p1k0ab3vmoT17svpxV6okg6dvvw088oh4y8yYIcec9QhMs5DJ3XdLL+Hpp0Uxvf12trd5S5jK7NAhccTKLv98bilUSAbW3anUFP9AFUFBIy1NWtxq1SQqKyVFjMobN0oe5StXgAkT8FNgf/yTLr0A27TGznj+efEAsnXrBMQU8uSTYrqYMiXr8f79xTPm0Uct3jSAfK0fOJA5kMrkySdlIHTWLDHvmKkLnPUIrN0hARknCAuTTtHEibmbySonmD2CyEhZuqNHoCh5iSqCgsa//y2joXXqSMNfsyawdCkuvPs/bOj7KXjffmD7dnx4x39Qs6bY7ffvd736jRsl4tds5KxZs0a+yN96SzxZbClZUkIRUlLE7HP1quw/eFD22YvsfOQRMa+MGiXmJZPKlcUzxzpamVl6K7Y9AkDy+zRsmKPx7lxjKoIdO2SpikDxdlQRFCS2bpVP8UGDJPfB//4nkVTTpuHDxNHo0gV4bAhh/aVwbN4aiOeflwFCV3sEp0+LJxAgJiBb5syRhG3OgpLq1ZNUBvv2SeMO2B8ozo7KlaXht56nKCFBvvptewQA8MorovBuu831a+QWW0XgLtOQouQVqggKCteuic0lJERm/iICRo+WsYLJk3HsmHylR0RIOECZMsATT4gZZ/9+55Oym5hBWaVLy0Rj1iQkiMvokCHijuiM+++X3DsRETIQvGePBCvXrev67ZqzU1m7kNq6jtqSR3PZZ4upCKKjJU/Qrc6rqyjuRhVBQWHhQvG1/PJLaalNjNbv5Elx4Vy7VmzkEyZIJGmTJuJb72jycmv+/FOUyfjxMoWi9df4ggVipnniCdfEnTBBBjnHj5cJ4Zs0yezpkx1mMjPrcQLbYDJPUaSIjEswi1kovxSQouQWVQQFha++knBZB5FSp07JoGvnztJgTpwo+8389K6YhzZvFk+gPn2kkTNjApjl8q1b2893b4/CheWcc+dkvCGnmR/tKYLsegT5idkr0PEBxRdQReCLREbKp/fZs7J96JB8rg8f7vDz89Qp8T0HMhcxG+7sBoyTk8Xm3a6deOBUrGgZJ9i5U4K+XO0NmISGiu0eyLkiME1Dtj2CYsWAcuVyVpc7MBWBjg8ovkAOOuOKV7BkiYwFXL8ubjeLFskobUCAGOjtcOWKFDUVgTXly0ujavYIzp0Tr582bWTQ18yRExkpnj3t2on/erduwIoVkpZo4EAxM7mSoM2WyZMl62NOzy1RQryQbHsE1at7hynGjCXQHoHiC2iPwFe4cEE8gvr3l/STL70kiWa++w74+mtpmR04yJvZOh0lJmvSxNIjeP99ib595BFREuPHS8zA5s1y3Jwg5YEHRKR27aTh/eWXzEMTrlKsGPD665kjil3FNpbgxAnPjw+YqGlI8SW0R+DtnDsnzu8LF4pv5MCBYlwvUkTiBYYOlU91M+TWDqYisNcjAMQ89OWXkh/nv/8FHn4YeOYZ6WjMnCk9gOPHxavHbLDvu08a/rZtZbYwT5hjbBXB8ePikeQNqCJQfAlVBN7O1Kny1T9qlKTdbNbMcmzuXHG9KV8eePBBh1VkpwiaNJFEbK+9JtNAvvKKjAO0ayd56D76SJTB449bzilTRuotVsxzpphKlSwJ6VJSJM7BW3oE5hiGjhEovoAqAm8mKQn45hv5RP/ss6zHGzUSZ/yAAKeJ5E3XUGc9AkB6A126iBIApIH/4ANJnjZvnsUsZJIfwVnOqFxZpk0A5B6ZvUcRDB0qz9vd6SwUJS9QReDNLFokTv5mCK4drnaVPM9BTqo5dUoGfYMcFLJ2+Xz55czHChUSs1HXrpaU0t5C5cqS8jo5WRynAO8xxVSsKGP6iuIL6GCxN/PFF5KTwcn8gX37ZvW4+fBD6USYWLuO2qNUKWlAmzeXBt+WwEBp1LxtTlczluDMGRlCCQqSOXQURckZ2iPwVg4ckNiA9993aIQ/e1amXbQ1P6xYIZONXb8u5puTJ7OfyvCHH2Tw1xtcL13FVARHjogDVf/+3qesFMUX0B6Bp0lJEa+gRYsyJ/z54gsJvx061OGpK1fKKadOSaohk5gYyUZtDqRm1yMAZNrD2rVv4T48gKkIvvhCYiUchFEoipIN2iPwNKtWiVsOIDkaBg4Up/x16ySXQ8WKDk/96SfLemysmHaSkiyDw7t3S0oIVxSBL2IqgoULpcfTqZNHxVEUn0V7BJ5m7lzxNZw9W1rwF1+UBP1jxkhklwOSkiSBnGkTj4mRpfVslLt2icdPSkr2piFfxNSRaWkyhmE9X4GiKK7jkiIgoh+JqAcRqeLISxISxKD/2GOSJyg2Vqbuio2VADEnvocbNsgYwAsvyLapCEzvmXLlRBFk5zrqyxQubAlke+wxz8qiKL6Mqw37TACPAIghon8TUX03yuQ/fPed5G42xwGKFXM5b/FPP4lLaM+eYiIxewKmQujbF9i715KauSAqAkCmX2jeXLJuKIqSO1xSBMy8npkfBRAG4CiA9US0mYieIKJspiFRHDJ3rozS5rAVS0sDli+X+eiLFJHUD6YCiImRjkT79tJj2LhR9hdE0xAgaTAWLvS0FIri27hs6iGicgCGARgJYBeA/0AUwzq3SFbQ2bNHbDdOvIIc8fvv4jrau7ds16mTWRHUrSuZJwDxLAIsA6sFjRYtZBoGRVFyj6tjBEsA/A6gOIAHmbkXMy9k5qfhPKhVccRXXwGFCyN94GBMn27JB5Qd6ekyqUylSpb0QnXrSvK1xEQZI6hbF2jQQGYTi46WRHFOMlAoiuLnuOo+OoOZN9o7wMzheSiPf5CQIHkbBg7EnpPl8fLL4t3z7rvZn7pggcxRP2eOJWWEOdfvrl3SU6hbVwZSmzSRyWQKqllIUZS8wVXTUCMiysg2T0RliGhcdicRUTciiiaiWCKaaOf4MCJKIKLdxm9kDmT3XT7+WAz4r7+OP/6QXWvXZn+amRm0devMmUBNRWBOKG9um+ahgjpQrChK3uCqIhjFzJfMDWa+CMBxJjQARBQA4DMA3QE0AjCYiBrZKbqQmUON35cuyuO7XLgAfPop8NBDQIMG+PNP2b1zZ+bJ4O3x7ruSannGDEkGZ2JGBJvjAfXqyVIVgaIoruCqIgggsvg0Go18dlbn1gBimfkwM98EEAGgd+7ELEDMmCGf9pMmgVkGfs2G20ypbI+bNyUT9cCBMo2kNUFB4ilkppQwFYOpCNQ0pCiKM1xVBGsALCSizkTUGcB3xj5nBAM4YbUdZ+yzpT8R7SWixURkN5s8EY0mokgiikzI7rPZm7lyRaKF+/QBmjbFsWMySDx+vEz04sw89McfcrqjuX1Nc1C1apZ5AkJDxTu1ffu8vQ1FUQoWriqCVwBsBDDW+G0AMCEPrr8cQA1mbgZxQ51nrxAzz2LmcGYOr5CbyW29ha1bJYH+OBleMc1CHTvKhDDr1mXOO2fNypXi+dOli/3jpiIwl4AohMhIoHPnPJJfUZQCiasBZenM/DkzDzB+/2PmtGxOOwnA+gs/xNhnXe95Zr5hbH4JoKWrgvskprN/Ixkq+eMPiQ5u0kTmAD55UtIM2WPFCkmq5mhymTp1ZGmtCBRFUVzB1TiCuobp5gARHTZ/2Zy2HUBdIqpJREUADAKwzKZe62Q6vQA4aAYLCLGx8plujN7++adM/h4QYJkQxp55KDZW4gN69nRctakAzPEGRVEUV3HVNDQHwOcAUgHcA+BrAN84O4GZUwE8BeBnSAP/PTPvJ6JpRNTLKPYMEe0noj0AnoFELhdcYmPl050IFy8C+/ZZsofecYc04vPnS+LRBg2ATz6RY6Y3UI8ejqsOCxPTke1AsqIoSna4GlB2GzNvICJi5mMAphLRDgBvODuJmVcBWGWz7w2r9VcBvJpDmX2XmBigYUMAwF9/yXjA3XdbDvfoISEGsbHSaXjhBdEbK1bIabVqOa66Zk2Z3rhYMTffg6IoBQ5XFcENIwV1DBE9BbH1a2qJnJCWBv7nMLaGP4W/v5AJyQICJDjMZNo0yavfrJnMIdC+PfDIIzI5+7PPZn8JVQKKouQGVxXBs5A8Q88AeBNiHsp5tjR/5sQJ/J1SH22/GQ98IykgBg8GSpSwFAkKEndPQI4vXQqEh0vYgbPxAUVRlFshW0VgBI8NZOaXAFwF8ITbpSqIxMbiCGoCkNkp77sv+xm1qlUTs9CcOZaxBEVRlLwmW0XAzGlEdHd25fye1FQg0MnjjIlBPCQXdLNmrk+r2KqV/BRFUdyFq15Du4hoGRENIaJ+5s+tkvkS8+cDpUuLLccRsbGID6wGInY2H72iKEq+46oiKAbgPIB7ATxo/NRqbTJ/PnDtGtC/PzBzpv0ysbE4XbIeypcnFNY53RRF8SJcGixmZh0XcERiIrBpk6SNiIuTxEGffCLzDt9+uxj5K1US01DRO1DZhzNkKIpSMHFJERDRHABZsuAw8/A8l8jXWLdOfD0HDgTatZNc0fv2SZDAokXAF18Ar74K/PMP4stVLrBTRiqK4ru46j66wmq9GIC+AFycXLGAs3y5jA+0ayeDxZMnW47ddx8wa5YEA9y8idM3yqKeKgJFUbwMV01DP1hvE9F3AP5wi0S+RHq65H/o3t2+x9DYsUC/fsAnn4ABxCeWQJUqWYspiqJ4ElcHi22pC0B9X7Zvl2nFHEV7PfigzArz+ee4hNK4mVJITUOKongdrmYfTSSiK+YPMo/AK+4VzQdYsULmjOzWzf7xwEBg9GggNRXxRe4AAFUEiqJ4Ha7OR1CSmW+3+tWzNRf5JcuXS8hv2bKOy4wcCQQE4HSVMABQ05CiKF6Hqz2CvkRUymq7NBH1cZ9YPsA//wB79gC9ejkvV7UqMHEi4tvK49IegaIo3oarYwRTmPmyucHMlwBMcY9IPkJEhCwffjj7sm+9hfhWojBUESiK4m24qgjslXPV9bRgEhEhZqHq1V0qfvq0pIkuVSr7soqiKPmJq4ogkog+IqLaxu8jADvcKZhXs2+f/AYPdvmU+HjpDRC5US5FUZRc4KoieBrATQALAUQASAYw3l1CeT0REeItNGAAAAkivn7d+SmmIlAURfE2XPUausbME5k5nJlbMfNrzHzN3cJ5JczAd98BnTtLDiEA8+aJN9A1J0/k9GlVBIqieCeueg2tI6LSVttliOhn94nlxWzfDhw+nMkstHixzBd84oTj0+Lj1XVUURTvxFXTUHnDUwgAwMwX4a+RxYsWAUWKAH37AgBu3pTkowBw8qT9U27eBM6f1x6BoijeiauKIJ2IMtxjiKgG7GQj9QvWrgXuvlsSzQHYssViEnKkCM6elaUqAkVRvBFXXUBfB/AHEf0KgAC0BzDabVJ5K2fOAHv3Sqppg3XrZNw4PR045SAf6+nTslTTkKIo3oirg8VrAIQDiAbwHYAXAWTjJ1MAWb9ell27Zuxatw5o00biAxz1COLjZak9AkVRvBFXJ6YZCeBZACEAdgO4E8BfkKkr/Yf16yWvUIsWAICLF2XseNIkGSxWRaAoii/i6hjBswBaATjGzPcAaAHgkvNTChjM8vnfubPYggD88ouYhLp2lZRC2ZmGDG9TRVEUr8JVRZDMzMkAQERFmTkKQH33ieWFREXJJ7+NWSgoSExDwcHOewTlyomzkaIoirfh6mBxnBFHsBTAOiK6COCY+8TyQtatk6WhCKKjZXKyTp2AwoVFEZw+DaSlAQEBmU/VqGJFUbwZV6eq7GusTiWijQBKAVjjNqm8jORkoPdbd4OK/4pa79fAiRMyJ03RosCYMVImOFiUQEJC1kb/1ClVBIqieC85ziDKzL+6QxBvJh9G8AAAD6pJREFU5u9dqVibEIZatydgW4RMPPbGG8D48UBFI6yualVZnjyZtdE/flymNVYURfFG/DuVtIvE/LAXQBiWv7sfjcZ1AnPWLKLBwbI8eRJo2dKy/8YNMRm5mK1aURQl38nt5PV+RcyqGBDSUWvIXQDsp5K2VgTWmPmH7rjDjQIqiqLcAm5VBETUjYiiiSiWiCY6KdefiJiIwt0pT644dw6HotJxx+0XUaxkYYfFKlYUr1JbF9Ljx2WpikBRFG/FbYqAiAIAfAagO4BGAAYTUSM75UpC4hS2ukuWW+K77xDDtVG3kXPfz8BAGRuw7REcM3yrVBEoiuKtuLNH0BpALDMfZuabkAltetsp9yaA9yCT3XgdPGcuDgU0RL2WJbMtay+W4NgxMSWFhLhJQEVRlFvEnYogGIB1hv44Y18GRBQGoBozr3RWERGNJqJIIopMSEjIe0kdsXcvzu06jstpJVG3bvbFg4OzmoaOHZNkcxpMpiiKt+KxwWIiKgTgI0gCO6cw8yxjdrTwChUquF84k6+/xqEAsWa5ogiqVs3aIzh+XM1CiqJ4N+5UBCcBVLPaDjH2mZQE0ATAJiI6Cklkt8yrBoy3bEFM7fsBAPXqZV88OFgS0VnPX3zsmCoCRVG8G3cqgu0A6hJRTSIqAmAQgGXmQWa+zMzlmbkGM9cAsAVAL2aOdKNMOSMqCoeKt0BgIFCjRvbFTRdS0zyUni7uoxpDoCiKN+M2RcDMqQCeAvAzgIMAvmfm/UQ0jYh6ueu6eca5c8D584jh2qhVS7yCssM6uhiQeWxu3tQegaIo3o1bI4uZeRWAVTb73nBQtpM7ZckxUVEAgENXKqNuFqdX+9gGlanrqKIovoBGFjsiKgrpIMTGB7k0PgBkNQ2pIlAUxRdQReCIqCicKloLSdcLueQxBAC33w6UKJG1R6BjBIqieDOqCBwRFYWY4E4AXPMYAiRwrHFjYONG2T5+HChdWhSEoiiKt6KKwBFRUThUpg0A12IITIYOBXbvBnbuVNdRRVF8A1UEdjh99Aa2HK6IX663RbFiOUsP8cgjQLFiwJdfqiJQFMU30PkIbNi3D2jWrAiYNwMHgDvvzJir3iVKlwb69we+/VZmLOvY0X2yKoqi5AXaI7Bhxw6AmTAHw7B9flTGVMU5YcQI4PJl4OpV7REoiuL9qCKwIToaCCyUhkexAOF9QhAUlPM6OnYEatWSdVUEiqJ4O6oIbIiOBmoHnUHhalWQKy0AMSUNHy7rrqSmUBRF8SQ6RmBDdDRQv1AM0KDBLdXz3HMyUU2496TQUxRFsYv2CKxISwNiYxn1r+26ZUVQooSMFdib31hRFMWbUEVgxbFjwI0bhPopf9+yIlAURfEVVBFYER0ty/qIBho29KwwiqIo+YQqAisyKYLQUM8KoyiKkk/oYLEV0dFAmSJXUb5KEFCmjKfFURRFyRe0R2CF6TFELcM8LYqiKEq+oYrAiqiD6aifvAcIU0WgKIr/oIrA4MoV4HR8IRkfaNHC0+IoiqLkG6oIDA4dkmV9RGuPQFEUv0IVgUGGx1C58xISrCiK4ieoIjCIjgYKIQ11wkt7WhRFUZR8Rd1HDaIPpKIGjqFoeFNPi6IoipKvaI8AkmPorz/S0AT7dHxAURS/QxUBgNWrgRNnimII5qsiUBTF71DTEID//heoXPwyehf5TWeSURTF7/D7HsHRo8CqVcDIMj+icGhjzRutKIrf4feKYNYsaftHX/8PULeup8VRFEXJd/xaEdy8CcyeDfTslopqF/YANWt6WiRFUZR8x68Vwdq1wNmzwJgecbJDFYGiKH6IXyuC2FhZ3lk6SlZUESiK4of4tSKIiwOKFQPKJBiJhlQRKIrih/i9IggJAejoEaB4caBCBU+LpCiKku/4tSI4eRIIDgZw5Ij0BtR1VFEUP8StioCIuhFRNBHFEtFEO8efJKK/iWg3Ef1BRI3cKY8tZo8gQxEoiqL4IW5TBEQUAOAzAN0BNAIw2E5D/y0zN2XmUADvA/jIXfLYkp4OnDoFhASzKgJFUfwad/YIWgOIZebDzHwTQASA3tYFmPmK1WYJAOxGeTJx7pzEEQSXSQISE1URKIrit7gz11AwgBNW23EA2tgWIqLxAF4AUATAvfYqIqLRAEYDQPXq1fNEuDgjdCAk4LSsqCJQFMVP8fhgMTN/xsy1AbwCYJKDMrOYOZyZwyvkkWfPyZOyDE49Jis1auRJvYqiKL6GOxXBSQDVrLZDjH2OiADQx43yZCKjR3DNmKNSewSKovgp7lQE2wHUJaKaRFQEwCAAy6wLEJF1lrceAGLcKE8m4uKAgACg0rn9QJkyQKlS+XVpRVEUr8JtYwTMnEpETwH4GUAAgK+YeT8RTQMQyczLADxFRF0ApAC4CGCou+Sx5eRJoEoVIODYYe0NKIri17h1YhpmXgVglc2+N6zWn3Xn9Z2RKYagSRNPiaEoiuJxPD5Y7ClOngSCq7LMTKM9AkVR/Bi/VATMwIkTQEiZa8CNG6oIFEXxa/xSEVy5Aly7BoQUTZAdqggURfFj/FIRZMQQ3DgsK3XqeE4YRVEUD+OXiiAjhiB6A1C9uioCRVH8Gr9WBME7lwMPPKDppxVF8Wv8UhGYpqGqSTGiCBRFUfwYt8YReCtxcUCF2xJRLI2Be+3muVMURfEb/LZHEJx+AujUCShRwtPiKIqieBS/VARxh28g5MY/QI8enhZFURTF4/idIliwAPg7qjAa4YCODyiKosDPFME33wCPPw50LPs3ptReoG6jiqIo8CNFsGCBKIFO7dOw4uo9KN5TB4kVRVEAP1IE1asDDz4ILH/qZxS/cRHo2dPTIimKongFfuM+2r69/PDkMiAoCOjQwdMiKYqieAV+0yMAIGlHV64E7rsPKFLE09IoiqJ4Bf6lCPbulWgyNQspiqJk4F+KYMUKWXbv7lk5FEVRvAj/UgQrVwKtWgGVK3taEkVRFK/BfxRBQgKwZYuahRRFUWzwH0WwerUMFmtaCUVRlEz4jyIoXRro3Rto0cLTkiiKongVfhNHgF695KcoiqJkwn96BIqiKIpdVBEoiqL4OaoIFEVR/BxVBIqiKH6OKgJFURQ/RxWBoiiKn6OKQFEUxc9RRaAoiuLnEDN7WoYcQUQJAI7l8vTyAM7loTiepCDdC1Cw7kfvxTvx93u5g5kr2Dvgc4rgViCiSGYO97QceUFBuhegYN2P3ot3ovfiGDUNKYqi+DmqCBRFUfwcf1MEszwtQB5SkO4FKFj3o/finei9OMCvxggURVGUrPhbj0BRFEWxQRWBoiiKn+M3ioCIuhFRNBHFEtFET8uTE4ioGhFtJKIDRLSfiJ419pclonVEFGMsy3haVlchogAi2kVEK4ztmkS01Xg/C4moiKdldAUiKk1Ei4koiogOElFbX30vRPS88fe1j4i+I6JivvReiOgrIjpLRPus9tl9FyTMMO5rLxGFeU7yrDi4lw+Mv7O9RLSEiEpbHXvVuJdoIro/p9fzC0VARAEAPgPQHUAjAIOJqJFnpcoRqQBeZOZGAO4EMN6QfyKADcxcF8AGY9tXeBbAQavt9wB8zMx1AFwEMMIjUuWc/wBYw8wNADSH3JPPvRciCgbwDIBwZm4CIADAIPjWe5kLoJvNPkfvojuAusZvNIDP80lGV5mLrPeyDkATZm4G4BCAVwHAaAsGAWhsnDPTaPNcxi8UAYDWAGKZ+TAz3wQQAaC3h2VyGWY+zcw7jfVESGMTDLmHeUaxeQD6eEbCnEFEIQB6APjS2CYA9wJYbBTxiXsholIAOgCYDQDMfJOZL8FH3wtk6trbiCgQQHEAp+FD74WZfwNwwWa3o3fRG8DXLGwBUJqIquSPpNlj716YeS0zpxqbWwCEGOu9AUQw8w1mPgIgFtLmuYy/KIJgACestuOMfT4HEdUA0ALAVgCVmPm0cSgeQCUPiZVTPgEwAUC6sV0OwCWrP3JfeT81ASQAmGOYub4kohLwwffCzCcBTAdwHKIALgPYAd98L9Y4ehe+3iYMB7DaWL/le/EXRVAgIKIgAD8AeI6Zr1gfY/ED9npfYCLqCeAsM+/wtCx5QCCAMACfM3MLANdgYwbyofdSBvJlWRNAVQAlkNU04dP4yrvIDiJ6HWIuXpBXdfqLIjgJoJrVdoixz2cgosIQJbCAmX80dp8xu7PG8qyn5MsBdwHoRURHISa6eyF29tKGSQLwnfcTByCOmbca24shisEX30sXAEeYOYGZUwD8CHlXvvherHH0LnyyTSCiYQB6AniULUFgt3wv/qIItgOoa3hAFIEMrCzzsEwuY9jQZwM4yMwfWR1aBmCosT4UwE/5LVtOYeZXmTmEmWtA3sMvzPwogI0ABhjFfOVe4gGcIKL6xq7OAA7AB98LxCR0JxEVN/7ezHvxufdig6N3sQzA44b30J0ALluZkLwSIuoGMan2YuYkq0PLAAwioqJEVBMyAL4tR5Uzs1/8ADwAGWn/B8DrnpYnh7LfDenS7gWw2/g9ALGtbwAQA2A9gLKeljWH99UJwApjvZbxxxsLYBGAop6Wz8V7CAUQabybpQDK+Op7AfAvAFEA9gGYD6CoL70XAN9BxjdSIL21EY7eBQCCeBL+A+BviLeUx+8hm3uJhYwFmG3Af63Kv27cSzSA7jm9nqaYUBRF8XP8xTSkKIqiOEAVgaIoip+jikBRFMXPUUWgKIri56giUBRF8XNUESj/3979s0YRRWEYf14RRIlgo42FojZiYUCwUATBL2ChCGoKaxs7ERTBL2AlmDJiChG0F1MEUkgUiQiWVqlsREihRTwWc1fWTcBFNCvM86t279697BSzZ/4w79EWSnJ2kLgq/S8sBJLUcxYCaRNJriZZTrKSZLb1T1hLcr9l9i8k2dvmTid5NZQTP8i8P5LkZZJ3Sd4mOdyWnxrqYTDfnuSVJsZCII1IchS4BJyuqmlgHbhCF8T2pqqOAYvA3faVR8DN6nLi3w+NzwMPquo4cIruSVHo0mNv0PXGOESX6SNNzPbfT5F65xxwAnjdDtZ30oWVfQeetDmPgWetJ8Geqlps43PA0yS7gf1V9Rygqr4CtPWWq2q1vV8BDgJL/36zpM1ZCKSNAsxV1a1fBpM7I/P+NJ/l29DrddwPNWFeGpI2WgAuJNkHP/veHqDbXwZJnJeBpar6AnxOcqaNzwCL1XWSW01yvq2xI8muLd0KaUweiUgjqupDktvAiyTb6BIgr9M1njnZPvtEdx8Bunjjh+2P/iNwrY3PALNJ7rU1Lm7hZkhjM31UGlOStaqamvTvkP42Lw1JUs95RiBJPecZgST1nIVAknrOQiBJPWchkKSesxBIUs/9AABVYhFnln3pAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_LxatO5J-pp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba14e3ec-3430-4598-da9f-c74a8110c61e"
      },
      "source": [
        "testloss = model.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "trainloss = model.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(trainloss[0]))\n",
        "print(\"Train Acc: \" + str(trainloss[1]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 3s 28ms/step - loss: 1.0423 - accuracy: 0.6322\n",
            "Test Loss 1.0423483848571777\n",
            "Test Acc: 0.6322095394134521\n",
            "898/898 [==============================] - 24s 26ms/step - loss: 0.8253 - accuracy: 0.6946\n",
            "Train Loss 0.825255274772644\n",
            "Train Acc: 0.6945556998252869\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swoRERVdKQ1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a37c8270-16ce-4129-a414-b57f10b9d28a"
      },
      "source": [
        "testlosz = model.evaluate(x_val, y_val) \n",
        "print(\"val Loss \" + str(testlosz[0]))\n",
        "print(\"val Acc: \" + str(testlosz[1]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 3s 26ms/step - loss: 1.0637 - accuracy: 0.6250\n",
            "val Loss 1.0637133121490479\n",
            "val Acc: 0.6249651908874512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5iaZIU6pPzk",
        "outputId": "ea1d6ec7-029c-4e83-dc7c-76d91015585c"
      },
      "source": [
        "from keras.models import load_model\n",
        "model_load = load_model('/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editAdamst120epochBS128_1.h5')\n",
        "\n",
        "model_load.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 46, 46, 128)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 46, 46, 128)  0           activation_3[0][0]               \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 46, 46, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 46, 46, 128)  0           activation_6[0][0]               \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 46, 46, 128)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 23, 23, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 23, 23, 256)  0           activation_12[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 23, 23, 256)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 23, 23, 256)  0           activation_15[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 23, 23, 256)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 23, 23, 256)  0           activation_18[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 23, 23, 256)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 12, 12, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 12, 12, 512)  0           activation_24[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 12, 12, 512)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 12, 12, 512)  0           activation_27[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 12, 12, 512)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 12, 12, 512)  0           activation_30[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 12, 12, 512)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 12, 12, 512)  0           activation_33[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 12, 12, 512)  0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 12, 12, 512)  0           activation_36[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 12, 12, 512)  0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 6, 6, 1024)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 6, 6, 1024)   0           activation_42[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 6, 6, 1024)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 6, 6, 1024)   0           activation_45[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 6, 6, 1024)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypc8clklx2p8",
        "outputId": "7da812f8-c1bf-416b-a08f-a1d7333fed8a"
      },
      "source": [
        "#loss,acc = model_load.evaluate(xtrain,ytrain)\n",
        "\"\"\"print(\"loss:\",loss)\n",
        "print(\"acc:\",acc)kjjkj\"\"\"\n",
        "\n",
        "\n",
        "testloss = model_load.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "\n",
        "testloss = model_load.evaluate(xtrain, ytrain) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 7s 27ms/step - loss: 1.0423 - accuracy: 0.6322\n",
            "Test Loss 1.0423483848571777\n",
            "Test Acc: 0.6322095394134521\n",
            "898/898 [==============================] - 24s 26ms/step - loss: 0.8253 - accuracy: 0.6946\n",
            "Test Loss 0.825255274772644\n",
            "Test Acc: 0.6945556998252869\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7mSww_U2O_q",
        "outputId": "e55beba5-4971-48bf-edaa-461cf90a75f8"
      },
      "source": [
        "testlosz = model_load.evaluate(x_val, y_val) \n",
        "print(\"Test Loss \" + str(testlosz[0]))\n",
        "print(\"Test Acc: \" + str(testlosz[1]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 3s 27ms/step - loss: 1.0637 - accuracy: 0.6250\n",
            "Test Loss 1.0637133121490479\n",
            "Test Acc: 0.6249651908874512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdU7uU3PYCnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08ba9d9b-5976-4a6e-949e-9ba2a0e619cf"
      },
      "source": [
        "print (x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3589, 48, 48, 1)\n",
            "(3589,)\n",
            "(3589, 48, 48, 1)\n",
            "(3589,)\n",
            "(28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_Tf1qg8TKnx",
        "outputId": "00005e13-5359-4274-d2f4-408f36f2ab74"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "#y_pred = model_load.predict(xtest)\n",
        "\n",
        "test_prob = model_load.predict(xtest)\n",
        "test_pred = np.argmax(test_prob, axis=1)\n",
        "test_accuracy = np.mean(test_pred == ytest)\n",
        "\n",
        "print(test_accuracy)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6322095291167457\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpwJv9V54_1M"
      },
      "source": [
        "\n",
        "emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "KMe4WL0T5BcJ",
        "outputId": "1730ffe6-3a30-40e7-c6f7-7f84c9d53823"
      },
      "source": [
        "conf_mat = confusion_matrix(ytest, test_pred)\n",
        "\n",
        "pd.DataFrame(conf_mat, columns=emotions.values(), index=emotions.values())\n",
        "\n",
        "\n",
        "\n",
        "fig, ax = plot_confusion_matrix(conf_mat=conf_mat,show_normed=True,show_absolute=False,figsize=(8, 8))\n",
        "fig.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdwAAAHgCAYAAAAPG9wjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3gUVd/G8e/AEpqQQkt2Qw0tCQQITXpHIAlIRzpYHn0EsTy+dkREqlLsoiiKKB1DAOlFAaWLCqj0sklAKUFBE7KZ949gYAlKhOysCffnurzM7JzZ/Z09e+bemZ1dDNM0EREREc/K4+0CREREbgUKXBEREQsocEVERCygwBUREbGAAldERMQCClwREREL2LxdwJUKFvU3fUs5vF2G5exFC3i7BK9wpd2aX0lLu4W/imdgeLsEr7DlvTX7/cdFl7dLsFz88aOcPX3qmgP+rwpc31IO+k6c5+0yLPdiuyreLsErTv+W4u0SvCI5Nc3bJXhNHuPWDJ4SRfN7uwSv+CH+V2+XYLl+HZv95TqdUhYREbGAAldERMQCClwRERELKHBFREQsoMAVERGxgAJXRETEAgpcERERCyhwRURELKDAFRERsYACV0RExAIKXBEREQsocEVERCygwBUREbGAAldERMQCClwRERELKHBFREQsoMAVERGxgAJXRETEAgpcERERCyhwRURELKDAFRERsYACV0RExAIKXBEREQsocEVERCyQ6wP30PYvef+B9ky77w42z3v3L9v9tGkFr3QMJXHf9wAknXAypVtNPhrWmY+GdWblmyMsqjh7rFi+jBrhVakWWomXx4/NtD45OZl+vXtRLbQSTRvdzpHDhwE4deoU7dq0pIR/ER4ZNsTiqm/e2lUraFqvOo1qh/H65AmZ1icnJ/PA4L40qh1GdOsmHDt6GICUlBQeffBeWjWqTZsmddm0Yb3Fld+89WtW0LpBDVrUq8bbr76caf2WrzbQsVUDKgcV4fO4hRm37/luF93aN6ddk9p0aFaPxZ/Ns7Lsm7Z+9Qpa3h5B87rhvDUl85hv3rSB6JYNqBh4G0sXLXBbN6BHRyJCArm7dxerys02K5cvo1a1qkSEVuKVCdee4/379CIitBLNG7vP8fZtW1IqoAiP5sA5vmn9Krq0rM2dzWsy/a2JmdZ//N7rdG9Tj17tGvJAnxgSjh/NWLd4/id0blGLzi1qsXj+J1aWDXg4cA3DaGcYxo+GYew3DONJTz7WtaS5XKx+50W6PD+VgW/E8eMXSzh1dH+mdikXzrNj0UcEVY5wu903sDT9pyyk/5SFtPnvCIuqvnkul4tHhg3hs7il7Ni1m7mzZ7F3zx63NtM/mIafvx/f793H0Ice5tmn04enQIECDB8xktHjMu+4/u1cLhfP/t8wZsyJZe1X3xA7fw4//bDXrc2sj6fj6+fHxu17uPeBoYwe8SwAn3z0PgCrN27n0wVLePG5J0lLS7O8DzfK5XIx4olHeP/Tz1i+YQdxC+ay70f3vtsdpRn/6lRiuvR0u71goUJMeOM9ln25nQ9mf8aoZx/nXNJZK8u/YS6Xi+FPPsz0WbGs2LiTRQsz99sRXJoJr02lY9eemba/b8gjTHxzmlXlZhuXy8Wjw4awYNFStv05x/e6z/EPP5iGn58f3+7dx4MPPcxzz1ye4889P5KXxubMOT5u+GO8On0ec1dsYfmi+Rzc94Nbm6rhEcxYtI5ZyzbRqn0nXh07HICks6d5d8pYpi9czYefreHdKWM5l3TG0vo9FriGYeQF3gDaA2HAXYZhhHnq8a4lcd+3+AWVwS+wNHnz+VClSQf2b16Tqd3GmVOo1/Ue8vrkt7I8j9m2dQshIRUpX6ECPj4+dOvRk8VxsW5tlsQtom+/AQB07tqNdWtXY5omhQsXpmGjxhQoUMAbpd+Ub7ZvpVz5EMqWS+93py7dWfF5nFubFUvj6N6rLwBRnbqw4Yu1mKbJvh/30rBpcwCKlyhJUV9fdu3cbnUXbtiuHdsoWz6EMuXK4+PjQ3TnbqxattitTXCZslQNr06ePO7TvnxIJcpXqAhAqUA7xYqX5NSpXyyr/Wbs2rGVsuUu9zvmzu6s/Dxzv0PDq5PHyLy7a9S0BbfdVsSqcrPNtq1bqHDVHF9yjTne58853iV3zPHdu7ZTumwFgsuUJ5+PD21jurB+5RK3NnUaNKVAwUIAVKtVlxOJ8QB89cUa6jVuga9fAEV9/anXuAWb1q+2tH5PHuHWA/abpnnQNM0UYBbQyYOPl8lvp05SpHhgxnKR4qX47dQJtzYnDuzm118SqVC3eabtk044+WhYF2Y/1Y/ju7d5utxsE+904ggOzlh2OIKJj3deo01pAGw2G0V9fTl16pSldWa3hIR4ghyX+x1od5CQEO/WJvGKNjabjaJFi3Lm9ClCw6uz8vMlpKamcvTIIb77ZifxzuOW1n8zTiTGE+RwZCwHBjk4cVXfs2LXjq1cvJhC2XIVsrM8j0m8xpgnJjj/ZovcIT7eSXDpq+a405m5zRVz3Ldozp/jJxPjKRV0+XVeMtDBycSEv2wfO3sGDZu1AeDnxHhKBV1+zkoFOvg58Z/PkZth8+B9O4BjVywfB+p78PH+MTMtjXXTxtFu2JhM6woHlOC+aaspWNSfE/t389noIQx8PY78hW7zQqXiab36DmT/Tz/SoWVDgkuXoXa928mbN6+3y7LUyRMJPPbgPUx47d1MR8EiOc3ShbPZ+91Ops5a6u1SMnh9VhmGcZ9hGNsMw9h2IZvPp99WrCS//pKYsfzrLye4rVipjOWU38/zy5F9zHmmP+/e04qEH3fx2Uv/JXHf99jy+VCwqD8ApSqG4xdYmjPOw9lan6fYHQ6cxy8fnTmdx7HbHddok/5+KDU1lXNJSRQrVszSOrNbUJCdhCuOShPjnQQF2d3aBF7RJjU1lXPnzuEfUAybzcaI0RNY8cUW3p85j3NJSVQIqWRp/TejVKCdhCuOcBITnJS6qu9/59dfz3FP7y489vQIatWp54kSPSLwGmMeGOT4my1yB7vdwfFjV81xhyNzmyvmeNK5nD/HSwbaOXHFGYyTiU5KBgZlard5w1ref+NlJr47C5/86R8Vlgi0cyLh8nN2ItFJicCsz5Hs4MnAdQKlr1gOvnSbG9M0p5qmWcc0zTqFfP2ztYDAStU5G3+EpMTjuC6m8OOXSwmp3yJjff7CRXhw5lfc+95q7n1vNUFVanDnM28SWKkaF5JOk+ZyAXA28Rhn44/gGxj8Vw/1r1K7Tl3279/H4UOHSElJYd6c2URFd3Rr0yE6ho9nfAjAwvnzaNa8JYZheKPcbFMjsg6HDu7n6JH0fscumEubdtFubdq0j2burI8BWBK7gEZNmmMYBr9fuMCF8+cB+GLtKmy2vFSuGmp5H25URK3aHD64n2NHDpOSksLihfNodUdUlrZNSUnhgYG96NyjD+1jOnu40uwVUasOhw9d7nfcZ3Np3S5r/c7Jatepy4Gr5niHa8zxmX/O8QW5Y46HRURy7PABnMcOczElhRVxC2jauoNbmx9272L0Mw8z8d1ZBBQvkXF7g6Yt2fzlGs4lneFc0hk2f7mGBk1bWlq/J08pbwUqGYZRnvSg7QX09uDjZZInr42W/3mW+SPuIS0tjWqtu1C8TCU2znyVUhWrUbH+Xz/Zx3dvY9PMV8ljy4dhGLT+7wgKFvGzsPobZ7PZmDj5NTpGtcOV5qL/gEGEhYczcsRwImvXITqmIwMH3c3dA/tTLbQS/v4BfPTxpxnbV61Unl/PnUvfgS2KJW7JckLDLL3e7YbYbDZeHD+ZPt1iSHO56NlnAFVCw5gw+gVq1KpN2/bR9Oo7kGH3D6ZR7TD8/AN4872PAPjll5P06RZDHiMPgXY7U95+38u9+WdsNhvPj53IwJ4dSXO56Na7P5WrhjFp7Eiq14ykdbtovt25jQcG9iIp6SxrVixlyvhRLPtyO0tj57P1qw2cPX2K+bNmADD+1amEVa/h5V5dn81m44Uxk+jfI4a0NBfd7xpA5aphTLzU7zbtotm1cxv3D+hJUtJZVq9YyuTxo1ixYQcA3aNbcXD/T5w//xsNIkIYO/ltmrVs4+VeXZ/NZuOVya9xZ3Q7XC4X/QYOIiwsnBdfGE5kZB2iYjoyYNDd3DOoPxGhlfAPCGD6jMtzPKzy5Tm+OC6W2CXLCQ3NGXP88RdeZmj/LrjSXHTs3peQyqG8PfElQqvXolmbDrw65jl+P3+eJx9Mv2CslD2YSe/NwtcvgLuH/h/9O6UfdN3z0BP4+gVYWr9hmqbn7twwOgCTgbzA+6ZpvvR37QMrVTP7TsxZ3wHMDi+2q+LtErzi9G8p3i7BK5JTc87XjbJbnhx+hHWjShTNHd+A+Kd+iP/V2yVYrl/HZuz5duc1X+iePMLFNM2lwL/nE2sREREv8fpFUyIiIrcCBa6IiIgFFLgiIiIWUOCKiIhYQIErIiJiAQWuiIiIBRS4IiIiFlDgioiIWECBKyIiYgEFroiIiAUUuCIiIhZQ4IqIiFhAgSsiImIBBa6IiIgFFLgiIiIWUOCKiIhYQIErIiJiAQWuiIiIBRS4IiIiFlDgioiIWECBKyIiYgEFroiIiAUUuCIiIhZQ4IqIiFhAgSsiImIBBa6IiIgFbN4u4ErFCvrQr4bD22VYbtY3x7xdgld0jwj2dglecfq3FG+X4DXxZ/7wdgle4WO7NY9tqgTd5u0SLFcgX96/XHdrvgpEREQspsAVERGxgAJXRETEAgpcERERCyhwRURELKDAFRERsYACV0RExAIKXBEREQsocEVERCygwBUREbGAAldERMQCClwRERELKHBFREQsoMAVERGxgAJXRETEAgpcERERCyhwRURELKDAFRERsYACV0RExAIKXBEREQsocEVERCygwBUREbGAAldERMQCClwRERELKHBFREQskOsDd+O6lXRqEUlM0xq8/+bETOu3b95Irw5NqF3Bn5VLPnNbN3nMcLq2qU/XNvVZHjffqpKzxXdfreOpbi14sktTlnz4Zqb1a+d/zHN3teX5Pu0ZfW9XnAd/AuCX+GP8p0llnu/Tnuf7tOejMU9bXfpNWbliGbWqh1IjrDKvTBiXaX1ycjID+vaiRlhlWjRpwJHDhwFYs2olTRrUpX7tGjRpUJf1a9dYXPnNW7d6BS3qR9C0bjhvTpmQaf3mTRvo0KIBFUrdxpJFC9zWzZv1Mc3qVqNZ3WrMm/WxVSVni6++WEXPtnXp1iqSj96ZlGn9p++/wV3tbqdvdCOG9O9EgvMoAAnOowzo1Iz+MU3o3b4BCz553+rSb8raVctpUrcajSJDeX1S5vFOTk7m/sF9aBQZSnTrxhw7ehiAixcvMuyBu2nVMJJm9SN4beJ4iyu/OTl5jts8dceGYbwPRAMnTdOs5qnH+Tsul4sxzz3G2zNjKRXooE/H5jRr3YGQylUz2gTagxn5ylt8NPVVt22/WL2Mvd/vYvbnG7mYkszdPTvQqHkbbitS1Opu/GNpLhcfj3+Ox16fSUDJQEYO6EjNJq1xVKic0eb2OzrRomtfAHZ+sZLZk0fx6KsfAVDSUZYXZn7uldpvhsvl4rFhQ4ldshxHcDDNGtUnKjqGqqFhGW0+mv4+fn7+7NrzE/PmzGL4s0/y4cezKFa8OHPmxxJkt7Nn9/fcGdOenw4e82Jv/hmXy8VzTzzMzHlLCLQ76NimMa3bRVO5SmhGG3twaV55fSpT35jstu3ZM6eZPOElFq/aiGEYRLVqSJt2Ufj6+VvdjX/M5XLxyojHmTJ9ISUD7Qzu2pImLdtTvtLlOV45LIIPFq6hQMFCLJg5jTfGj2DUlPcpXiKQd+eswCd/fi6c/40+UQ1p0qo9JUoFebFHWeNyuXjm8WF8unApQfZgOrRsSNv20VSuenm8P53xAb6+fmzcsZfY+XN4acQzvP3+TBZ/Np+U5GRWb9rB7xcu0Pz2mtzZrQely5TzXoeyKKfPcU8e4U4H2nnw/q/r+2+2UbpcBYLLlCefjw93xHRl3colbm0cpctSObQaRh73p+Lgvh+pXa8hNpuNgoUKU7lqNTauX2Vl+Tfs4O5vKBlcjpKOMtjy+VC/bQzffLHSrU3B24pk/J38+wUwrK4y+23buoUKISGUr1ABHx8funbvyeK4RW5tlsTF0rtvfwDu7NKNdWvXYJomNWrWIshuByA0LJw/fv+d5ORky/two77ZsZVy5UMoU648Pj4+xHTuzsrPF7u1KV2mLKHh1clz1Wt9/ZqVNGnWCj//AHz9/GnSrBXrVq+wsvwbtufb7QSXrYCjTDny+fjQOqoLX6xe6tam9u1NKFCwEADhNetyMtEJQD4fH3zy5wfgYkoKZlqatcXfhJ3bt1KuQghly6W/1jt16cHypXFubVZ8Hkf3u/oBENWpCxvWr8U0TQzD4MKF86SmpvL7H7+TzydfjjiQgJw/xz0WuKZpfgGc9tT9Z8XJxAQCg4IzlksF2TmZGJ+lbSuHpQfs779f4MzpU2z96ktOxDs9VWq2OvtzIgFXvEv3LxnEmZ8TM7VbPfdDnujchLmvjaHPYy9k3P5z/DFG9G3P2P/04KedWyypOTskxDtxBJfOWHY4HCRcNWbx8fEEX2pjs9nwLerLqVOn3NrELpxPjZqR5L+0M84JEhPiCbJffq0H2R0kJmTt9ZqYEE+Q4/K2gXYHiQlZmyfe9nNiAiWDHBnLJQPt/Hwi4S/bx82bQYOmbTKWTyQcp290Izo1rUbf+4bliKNbSB8zu+Pya/1a450YH4/90rjabDaKFi3KmdOniOrUhUKFClOralnqVa/I/UMewd8/wNL6b1ROn+MeO6Wc0zVs2ordu3YwoEsb/AOKExFZlzx5c9dH3q26D6BV9wF8vewz4t5/jXtGTMS3eEleXvQVt/n5c3jvd7z2+L2MmrXS7Yg4N9u7ZzfDn3mKzxYv83Ypks2Wxc7mh+++4c2Zl4/8SwUF8/Hijfx8IoEn/tuXlu06EVC8pBer9Lxvtm8lb9687Nh7mKSzZ+jcoSVNmrekbLkK3i7NEt6c415PEMMw7jMMY5thGNvOnP4lW++7ZGAQiQnHM5ZPJMRTMtCe5e3vHfo4cz7fyDszYzFNk7LlK2ZrfZ7iVyKQ01e8yz9zMgH/EoF/2b5e247sXJ9+CjGfT35uu/TZXbnQ6pQMLkvi0UOeLTibBNkdOI9f/kzG6XQSZHe4tbHb7Ry/1CY1NZWkc0kUK1Ysvf3x49zVoyvvTJtOhZAQ6wrPBoFBdhLiL7/WE+KdBAY5/maLq7Z1Xt42Md5JYFDW54k3lQgM4uQVR3YnE+OveZS6ZeM6pr85kfHvfJJxGtntfkoFUaFSKN9s/cqj9WaXwCA78c7Lr/VrjXeg3U78pXFNTU3l3Llz+AcUY+G8WTRv1ZZ8+fJRvERJ6tZvyK6dOyyt/0bl9Dnu9cA1TXOqaZp1TNOs4x9QPFvvO7xGbY4eOojz6GEupqSwPG4+zdp0yNK2LpeLs2fST0P8tPd79v2wmwZNW2VrfZ5SPqwGJ44d4mfnUVIvprB5RRw1m7Rxa3PiihD9duMaSpYuB8C5M6dIc7kAOOk8yoljhyjhKGNZ7Tejdp26HNi/n8OHDpGSksL8ubOJio5xa9MhuiOffJx+cdhnC+bRrHkLDMPg7NmzdOscwwujRtOgYSNvlH9TatSqw6GD+zl65DApKSnELZxLm3ZRWdq2Wcs2fLFuFUlnz5B09gxfrFtFs5Ztrr/hv0Bo9UiOHT5A/LEjXExJYdWSBTRp1d6tzY+7v2X8c48w4Z1PCChWIuP2kwlO/vjjdwDOJZ3l2+1fU6ZCznhTXTOyDocO7OfokfTXeuyCObRtH+3Wpm27aOZ+OgOAJbELaNS0OYZh4Aguw8Yv1wFw4fx5dmzbTMVKVazuwg3J6XM8V59SttlsPDlyAg/070yay0WnHv2oWDmUN18ZRVhEJM3bdOD7Xdt59L4+nEs6yxerPuetSaNZsGoLqRcvMrhb+jVfhYsU4aXJ72Kz5YynK6/NRt/HRzLxof6kpbloHNMDR0hlFr7zCuVCI6jVtA2r537Ini0byGvLR+GiRbnn+fSvTP20czOfvTORvLZ8GHkM+j85mtt8/bzco6yx2Wy8PPlV7oxpT5rLRb8BgwgNC2fUC89Tq3ZtoqI70n/gYO4d3J8aYZXxDwjgg48+AWDqW29w8MB+xo0exbjRowCIXbyMEiVzxulFm83GyLGT6N89Bleaix69B1C5ahivjBlJRM1I2rSPZteObdw3oCdJSWdZtXwpk8aNYtXGHfj5B/DQY08R06YxAMP+9zR+OeQzPZvNxmPPj+fhwV1Jc7mI7taHCpVCmTp5NKHVa9KkVQdeHz+cCxfO88zQgQCUsgcz4Z1POXzgJ14d+yyGYWCaJr3vHkLFKuHe7VAW2Ww2Ro2fTO+u0aS5XPTsM5AqoWFMGP0CNWpG0rZDDL36DeKh+wfRKDIUP/8A3pyWHr4D77mfR4bcS4sGNTFNk569+xNWrbqXe5Q1OX2OG6ZpeuaODeNToDlQHDgBPG+a5rS/2yY8ItL8ZPF6j9Tzb7bjxBlvl+AV3SOCr98oFzr9W4q3S/Ca+DN/eLsEryhTvJC3S/CKogVzxkFKdmrasB47tm+75vc+PPZsmKZ5l6fuW0REJKfx+me4IiIitwIFroiIiAUUuCIiIhZQ4IqIiFhAgSsiImIBBa6IiIgFFLgiIiIWUOCKiIhYQIErIiJiAQWuiIiIBRS4IiIiFlDgioiIWECBKyIiYgEFroiIiAUUuCIiIhZQ4IqIiFhAgSsiImIBBa6IiIgFFLgiIiIWUOCKiIhYQIErIiJiAQWuiIiIBRS4IiIiFlDgioiIWECBKyIiYgEFroiIiAVs3i7gSnnzGPgVzuftMix3V60y3i7BK+btOu7tEryiRUhJb5fgNfnz3Zrv8ZNT07xdglccP/27t0uwXMrfjPWt+eoXERGxmAJXRETEAgpcERERCyhwRURELKDAFRERsYACV0RExAIKXBEREQsocEVERCygwBUREbGAAldERMQCClwRERELKHBFREQsoMAVERGxgAJXRETEAgpcERERCyhwRURELKDAFRERsYACV0RExAIKXBEREQsocEVERCygwBUREbGAAldERMQCClwRERELKHBFREQsoMAVERGxgAJXRETEArk+cNetXkHL+hE0qxvOm1MmZFq/edMGolo0IKTUbSxdtMBtXf8eHaleIZDBd3Wxqtxss2L5MiLCqxBetSITxo/NtD45OZm+vXsSXrUiTRrW58jhwxnrJowbQ3jVikSEV2HliuUWVp09vt20lse7NOOxOxsTN/2NTOtXz5vBUz1b80zvO3jx7i44D/7ktv6XRCf3NKnCkhlvW1Vytli7ajlN61ajUWQor0/K/FpPTk7mgcF9aBQZSnTrxhw7ehiAlJQUHn3wXlo1jKRN4zps2rDe4spvzsZ1q+jcsjYdm9XkgzcnZlr/8Xuv07V1PXq0a8h/escQf/xoxrq4eZ/QqXktOjWvRdy8T6ws+6atX72CVrdH0KJuOG9dY9+2ZdMGYlo2oFJg5n3bwB4dqRESyN29c96+7cu1K2nfuBZ3NIzg3ddeybR+69cb6NK2EdVK+7J88UK3deHBRencugGdWzfgvwN6WFVyBo8FrmEYpQ3DWGsYxh7DMHYbhjHMU4/1V1wuF8OfeJjps2NZuXEnixbMZd+Pe93a2INL8/LrU+nUtWem7f8z5BEmvTnNqnKzjcvl4uGHHiQ27nN2fruHubM+Ze+ePW5tpr8/DX8/f3b/sJ+hwx7hmaefAGDvnj3MnT2LHbt2s2jxMoYN/S8ul8sb3bghaS4XH457lsdf/Yhxc9fw1fLYTIHasN2djJm9ipc+WU5U//uZOWmk2/pPJo4komELK8u+aS6Xi2cfH8aMuYtY+/UuYufP5qcf3F/rs2Z8gK+vHxt37OXeBx5i9IhnAPjkw/TX+OpNO/h04VJefPYJ0tLSLO/DjXC5XIwb/hivTZ/H/JVbWLZoPgf3/eDWpkpYBB/HrWPOsk20bt+JKWOGA5B09jRTp4zlo89WMyN2DVOnjOVc0hlvdOMfc7lcPP/kw3wwK5blG3cSt/Da+7bxr02l4zX2bfcOeYSJOXTf9uLTjzJ15gLi1m1jSexc9v90Vb8dpRkz+R2iOmcO1AIFCrJw1VcsXPUVb344x6qyM3jyCDcVeMw0zTDgduBBwzDCPPh4mXyzYytly4dQplx5fHx8iOncnRWfL3ZrU7pMWULDq2PkyfxUNGragsK3FbGq3GyzdcsWQkIqUr5CBXx8fOjesxeL42Ld2iyOi6VPvwEAdOnajXVrVmOaJovjYunesxf58+enXPnyhIRUZOuWLd7oxg05sPsbSpUuR8ngstjy+XB7245sX7/CrU3BK8Y0+fcLGIaRsbxt3TJKOEoTXKGyZTVnh2+2b6VchRDKlksf805derBiaZxbmxWfx9H9rn4ARHXqwob1azFNk30/7qVhk+YAFC9RkqK+vuzaud3qLtyQ77/ZTnDZCgSXKU8+Hx/uiOnCuhVL3NrUbdiUggULAVC9Vl1OJsYD8NX6NdRv3AJfvwCK+vpTv3ELNq1bbXkfbsSuHVspW+7yvi36zu6svGrfFnxp35bHyD37tm93bqNMuQqULpve7w6durFmuft4O0qXpUpYNfJcY5/ubR6ryDTNBNM0d1z6+1dgL+Dw1ONdy4mEeOz24IzlILuDEwlOK0vwivh4J8HBpTOWHY5gnE5n5jal09vYbDaK+vpy6tQpnM7M28bH55zn7MzJRAJK2TOWA0oGceZkYqZ2K+dM57FOjZj12mj6/S/9CPePC+dZ8uFbdL73EcvqzS4JCfEEOS6PW6DdQcJVr/XE+HiCHOnzwWazUbRoUc6cPkVotQhWLltMamoqR48c4rtvdhLvPG5p/Tfq5xPxBNov71ZKBjk4eSLhL9t/NmcGjZq3AeDkiXgCr9g/lApycPJEvOeKzUaJCZfHEm6dfdvJxMxjdiIh62OWnPwH3do1oWd0C1Z9Hnf9DbKZzYoHMQyjHFAL2HyNdfcB9wE4rgpr6fcAACAASURBVNjRi3hSmx4DadNjIJuWLSR22qv854VJLJg6kXa976FAocLeLs9SvfoOZP9PP9ChRQOCS5ehdr3byZv333d0cLOWLJzNnm938t7spd4uRbxk9Za9lAqyc+zIIQZ2j6JyaDhlylWw7PE9HriGYdwGzAceNk3z3NXrTdOcCkwFiKhZ28zOxy4VZCc+/vI79YR4J6WCLD3I9gq73cHx48cylp3O4zgcjsxtjh0jODiY1NRUziUlUaxYMRyOzNva7TnnOfMvGcjpK45STp9MwL9k4F+2v71tJ6aPSf8s88D3O9m6eimzXh3NhV/PYeQx8PEpQJueAz1d9k0LCrKT4Lw8bonxToKueq0H2u0kOI9jd1wa83Pn8A8ohmEYjBj9cka7Tm2bUSEkZ5xSL1HKTuIVZ2BOJjgpWSooU7vNG9Yy7fWXeW/2Unzy5wegZCk7277+MqPNiQQndW5v4vmis0FgUPpY/ulW2beVDLSTeMU+/USCk1JB9r/Zwt2fbUuXLU+9hk3Y+/0uSwPXo29jDcPIR3rYzjRNc8H12me3GrXqcPjgfo4dOUxKSgpxC+fSpl2U1WVYrk7duuzfv4/Dhw6RkpLC3NmziIru6NYmKrojM2d8CMCC+fNo1qIlhmEQFd2RubNnkZyczOFDh9i/fx9169XzRjduSIWwGiQeO8xJ51FSL6bw9YpFRDZt49Ym8eihjL+/2bCawDLlAHjuvQVMivuKSXFfccdddxMzaEiOCFuAGpF1OHRgP0ePpI957II5tGkf7damTbto5n46A4AlsQto1LQ5hmHw+4ULXDh/HoAv1q7CZrNRuWqo5X24EeE1Ijl2+ADOY4e5mJLC8rgFNGvTwa3ND9/v4qWnH2bye7MIKF4i4/YGzVry9ZdrOJd0hnNJZ/j6yzU0aNbS6i7ckIhadTh86PK+bfFnc2l9C+zbqteszZFDBzh+NL3fS2Pn0aJth+tvCCSdPUNKcjIAZ079wo6tXxNSuaony83EY0e4RvqVKNOAvaZpZr5W3wI2m42RYyfRv3sMrjQXPXoPoHLVMCaOGUn1mpG0aR/Nrh3b+M+AniQlnWX18qVMGjeKlRt3ANA9uhUH9v3E+fO/cXv1EMZNeZtmLdtc51G9z2azMWnK68RE3YHL5WLAwMGEhYczcsRwImvXITqmIwMH383ggf0Ir1oRf/8AZsycBUBYeDhdu/egVkQYNpuNya++Qd68eb3co6zLa7PR//EXmTC0L2kuF0079iQ4pArz336Z8qERRDZry8o509m9ZQN5bTYKF/HlvhGTvF32TbPZbLw4fjJ9ukaT5nLRs89AqoSGMWH0C9SoGUnbDjH06jeIYfcPolFkKH7+Abw5LT18f/nlJH26RpMnTx4Cg+xMeft9L/cm62w2G0+MfJkH+3chzeWiY4++hFQO5a2JLxFWvRbN2nRg8pjnuHDhPP/33/SLBAMdwUx+bxa+fgHc89D/0bdj+hXp9z70BL5+Ad7sTpbZbDZGjJnEgB4xpKW56H5X+r5t0tj0fVvrdtHs2rmNB/7ct61YypTxo1i+IX3f1iO6FQf3p+/bGkaEMHby2zTNIfu2Z196hXt630may0WXXv2oVCWMV8e/SLUakbS8I4rvvtnO0Lvv4tzZs6xd+TmvvfwSi9dt4+C+H3n+iYfIkycPaWlp3Pvgo1SsbO0bS8M0s/Us7uU7NozGwJfAd8Cf3zF42jTNv/wAJaJmbTNu9UaP1PNvVsq3gLdL8Ip5u3LGhTnZrUVISW+X4DUnk/7wdgle4VfYx9sleEXyxZzzlcLs0q1dE77ftcO41jqPHeGaprkBuOaDioiI3Gpy36WIIiIi/0IKXBEREQsocEVERCygwBUREbGAAldERMQCClwRERELKHBFREQsoMAVERGxgAJXRETEAgpcERERCyhwRURELKDAFRERsYACV0RExAIKXBEREQsocEVERCygwBUREbGAAldERMQCClwRERELKHBFREQsoMAVERGxgAJXRETEAgpcERERCyhwRURELKDAFRERsYACV0RExAI2bxdwJVteg5JF83u7DLFIl+oOb5fgFcXqD/V2CV5zavNr3i5BLJRmmt4uwXI+tr8+jtURroiIiAUUuCIiIhZQ4IqIiFhAgSsiImIBBa6IiIgFFLgiIiIWUOCKiIhYQIErIiJiAQWuiIiIBf7yl6YMw/gV+PNnQoxL/zcv/W2aplnUw7WJiIjkGn8ZuKZpFrGyEBERkdwsS6eUDcNobBjGoEt/FzcMo7xnyxIREcldrhu4hmE8DzwBPHXpJh/gY08WJSIikttk5Qi3M9AROA9gmmY8oNPNIiIi/0BWAjfFNE2TSxdQGYZR2LMliYiI5D5ZCdw5hmG8A/gZhnEvsAp417NliYiI5C7X/QfoTdN82TCMNsA5oDIw3DTNlR6vTEREJBe5buBe8h1QkPTTyt95rhwREZHcKStXKd8DbAG6AN2Arw3DGOzpwkRERHKTrBzhPg7UMk3zFIBhGMWATcD7nixMREQkN8nKRVOngF+vWP710m0iIiKSRX/3W8qPXvpzP7DZMIxY0j/D7QR8a0FtIiIiucbfnVL+88ctDlz670+xnitHREQkd/q7f7zgBSsLERERyc2ue9GUYRglgP8DwoECf95ummZLD9YlIiKSq2TloqmZwA9AeeAF4DCw1YM1iYiI5DpZCdxipmlOAy6aprneNM3BQI45ul2xfBk1wqtSLbQSL48fm2l9cnIy/Xr3olpoJZo2up0jhw8DcOrUKdq1aUkJ/yI8MmyIxVXfvBXLlxERXoXwqhWZ8Bf97tu7J+FVK9KkYf2MfgNMGDeG8KoViQivwsoVyy2s+uatWL6MmtWqUj20Ei9PuHa/+/fpRfXQSjRr7D7e7du2pGRAER7NgeMN0KZhKLsWPsf3sc/zv0FtMq0vE+TP0reHsmX2Uyx/dxiOkn5u64sULsD+ZS8y6YnuVpWcLW7VMb9V+71yxTJqVQ+lRlhlXpkwLtP65ORkBvTtRY2wyrRo0iCj32tWraRJg7rUr12DJg3qsn7tGosrz1rgXrz0/wTDMKIMw6gFBFxvI8MwChiGscUwjF2GYew2DMPyz4RdLhePDBvCZ3FL2bFrN3Nnz2Lvnj1ubaZ/MA0/fz++37uPoQ89zLNPPwlAgQIFGD5iJKPHTbC67Jvmcrl4+KEHiY37nJ3f7mHurE8z9/v9afj7+bP7h/0MHfYIzzz9BAB79+xh7uxZ7Ni1m0WLlzFs6H9xuVze6MY/5nK5eHTYEBYuWsr2P8d7r3u/P/xgGn5+fny3dx9DHnqY5565PN7PPT+S0WNz3ngD5MljMPnJHnQa8ia1uo6ie7vaVK0Q6NZmzCOdmblkC/V6jmH01M8ZObSj2/rn/xvFhh0HyElu1TG/lfv92LChLIhdwtZvvmfenFn8cFW/P5r+Pn5+/uza8xMPDh3G8GfT+12seHHmzI9l8/ZdvPPeB9x79wDL689K4I4yDMMXeAz4H/Ae8EgWtksGWpqmWQOoCbQzDOP2G670BmzbuoWQkIqUr1ABHx8fuvXoyeI494usl8Qtom+/9Ce+c9durFu7GtM0KVy4MA0bNaZAgQLXuut/ta1b3PvdvWevTP1eHBdLn0v97tK1G+vWpPd7cVws3Xv2In/+/JQrX56QkIps3bLFG934x7Zt3UKF64z34rhFGf3u3CXzeOfPgeMNULdaOQ4c+4XDzlNcTHUxd/kOoptHuLWpWiGI9Vt+BGD91p+Ibl49Y12t0NKULFaUVV/ttbTum3Wrjvmt3e+QjH537d6TxXGL3NosiYuld9/+ANzZpRvr1q7BNE1q1KxFkN0OQGhYOH/8/jvJycmW1n/dwDVNc7FpmkmmaX5vmmYL0zRrm6a5KAvbmaZp/nZpMd+l/8ybrPcfiXc6cQQHZyw7HMHExzuv0aY0ADabjaK+vpw6lbN/1yM+3knwpT5Ber+dTmfmNqUz99vpzLzt1c/Zv1V6n9zHO+Fa/b5yvIvm/PEGsJf05fiJMxnLzhNncJTwdWvz3U9OOrWsCUCnljUoeltBAnwLYxgGYx/twlMTF1pac3a4Vcf8Vu13Qvzl/TWAw+Eg4ep9eny8W799r9Hv2IXzqVEzkvz583u+6Cv83Q9fvMbfBKRpmg9d784Nw8gLbAcqAm+Yprn5Gm3uA+4DKF2mTBZKFpEb8dSkhUx6ojt9O9Zn4479OE+cweVK4z89mrB8w26cJ896u0QRj9u7ZzfDn3mKzxYvs/yx/+5rQdtu9s5N03QBNQ3D8AMWGoZRzTTN769qMxWYChBZu062HgHbHQ6cx49nLDudx7HbHddoc4zg4GBSU1M5l5REsWLFsrMMy9ntDo4fP5ax7HQex+FwZG5zLHO/HY7M2179nP1bpffJfbyDrtXv48dw/Nnvczl/vAHiTyYRXMo/Y9lRyh/nz0lubRJ+TqLX/94DoHBBH+5sVZOk336nfkR5GtUK4b4eTShcMD8++fLy2+/JPPfqdU9ked2tOua3ar+D7On76z85nU6Crt6n2+1u/U66ot/O48e5q0dX3pk2nQohIZbWDn9zStk0zQ//7r9/8iCmaZ4F1gLtbrbgf6J2nbrs37+Pw4cOkZKSwrw5s4mKdr9QpEN0DB/PSO/OwvnzaNa8JYZhWFlmtqtT173fc2fPytTvqOiOzLzU7wXz59GsRXq/o6I7Mnf2LJKTkzl86BD79++jbr163ujGP1a7Tl0OXGe8o6JjMvq9cEHuGG+AbbuPULFMCcrai5HPlpfud0SyZJ37L7AW8yuc0dfHB9/Bh7FfAzDomQ+p3GE4VaOe56lJC/lk8ZYcEbZw6475rd3v/Rn9nj93NlHRMW5tOkR35JOPPwLgswXzaNa8BYZhcPbsWbp1juGFUaNp0LCRN8rP8r+H+49d+sGMi6ZpnjUMoyDQBsh8DbcH2Ww2Jk5+jY5R7XClueg/YBBh4eGMHDGcyNp1iI7pyMBBd3P3wP5UC62Ev38AH338acb2VSuV59dz50hJSSFuUSxxS5YTGhZmZRduiM1mY9KU14mJugOXy8WAgYMz93vw3Qwe2I/wqhXx9w9gxsxZAISFh9O1ew9qRYRhs9mY/Oob5M2b18s9yhqbzcYrk1+jU3Q7XC4X/QcOIiwsnBdfGE5kZB2iYjoyYNDd3DOoP9VDK+EfEMCHMy6Pd2jlK8Y7LpZFS5YTGvrvH28AlyuNR8bNIe7NB8mbx+DD2K/ZezCR5x6IYseeoyxZ/x1N61Ri5NCOmCZs2LGfh8fM8XbZN+1WHfNbud8vT36VO2Pak+Zy0W/AIELDwhn1wvPUql2bqOiO9B84mHsH96dGWGX8AwL44KNPAJj61hscPLCfcaNHMW70KABiFy+jRMmSltVvmKZnrmMyDCMC+BDIS/qR9BzTNEf+3TaRteuYG7++9X5TI6e/67xRaWmWXkP3r1Gs/lBvl+A1pza/5u0SxEJpHsqXf7OmDeuxY/u2a+7UPXaEa5rmt0AtT92/iIhITnLdrwUZhlHZMIzVhmF8f2k5wjCMZz1fmoiISO6RlR++eBd4iku/OHXpyLWXJ4sSERHJbbISuIVM07z6p4ZSPVGMiIhIbpWVwP3FMIwQLv0IhmEY3YAEj1YlIiKSy2TloqkHSf9hiqqGYTiBQ0Bfj1YlIiKSy1w3cE3TPAi0NgyjMJDHNM1fPV+WiIhI7nLdwDUMY/hVywBc7zu1IiIicllWTimfv+LvAkA0kLP+DS8REREvy8op5VeuXDYM42VguccqEhERyYWycpXy1QoBwddtJSIiIhmy8hnud1z+d3HzAiUAfX4rIiLyD2TlM9zoK/5OBU6YpqkfvhAREfkH/jZwDcPICyw3TbOqRfWIiIjkSn/7Ga5pmi7gR8MwylhUj4iISK6UlVPK/sBuwzC2cMVXhEzT7OixqkRERHKZrATucx6vQkREJJfLSuB2ME3ziStvMAxjHLDeMyWJiIjkPln5Hm6ba9zWPrsLERERyc3+8gjXMIwHgP8CFQzD+PaKVUWAjZ4uTEREJDf5u1PKnwCfA2OAJ6+4/VfTNE97tCoREZFc5i8D1zTNJCAJuMu6ckRERHKnG/ktZREREfmHFLgiIiIWUOCKiIhYQIErIiJigaz88IVlTBP+uJjm7TIsV9Anr7dL8Irfkm/Nf3Tqx1Uve7sEr7l/7rfXb5QLvdU9wtsleMXWQ2e8XYLlzv/Nfk1HuCIiIhZQ4IqIiFhAgSsiImIBBa6IiIgFFLgiIiIWUOCKiIhYQIErIiJiAQWuiIiIBRS4IiIiFlDgioiIWECBKyIiYgEFroiIiAUUuCIiIhZQ4IqIiFhAgSsiImIBBa6IiIgFFLgiIiIWUOCKiIhYQIErIiJiAQWuiIiIBRS4IiIiFlDgioiIWECBKyIiYgEFroiIiAUUuCIiIhZQ4IqIiFgg1wfuqhXLqFczjNrVqzD55XGZ1icnJzO4/13Url6F1s0acPTIYbf1x48dpXRJX16b/IpFFWePFcuXERFehfCqFZkwfmym9cnJyfTt3ZPwqhVp0rA+Rw4fzlg3YdwYwqtWJCK8CitXLLew6pu3ZuVyGkaGU79GKK9OHJ9pfXJyMvcO7E39GqG0a9HIbbx3f/8tHVo1oWm9GjS7vRZ//PGHhZXfvHWrV9CifgRN64bz5pQJmdZv3rSBDi0aUKHUbSxZtMBtXf8eHaleIZBBd3WxqtxsUz2oCONiqjChY1Wiw0pmWt+4gj+vdw3nxfaVebF9ZZqFBGSs+1+L8rzVvRqPNi9vZcnZYuXyZdSqVpWI0Eq8MuHac7x/n15EhFaieePbM+b4qVOnaN+2JaUCivDosCEWV33ztny5mv7t69P3jrp88u6UTOvnTn+TQdENuadTUx4b1JlE57GMdSfij/P43d0YGNWAQdENSXQetbJ0zweuYRh5DcPYaRjGYk8/1tVcLhf/9+hDzFm4mK+2f8f8ubP5Ye8etzYff/g+fn7+bP/uRx4Y8jAjnnvKbf0zT/6PVm3bWVn2TXO5XDz80IPExn3Ozm/3MHfWp+zd497v6e9Pw9/Pn90/7GfosEd45uknANi7Zw9zZ89ix67dLFq8jGFD/4vL5fJGN/4xl8vFk48N45P5cXy5dRcL583mxx/c+/3JRx/g5+fP5l17+c+DD/Hi808DkJqayoP3DmTC5Nf5YssuFi5ZRb58+bzRjRvicrl47omH+XB2LKs27mTRgrn89ONetzb24NK88vpUOnXtmWn7+4Y8wqQ3p1lVbrYxDOhf18HLaw/x5OIfub2cH/ai+TO123zkLM99/hPPff4T6w+czrh96Z6feWeTtTvd7OByuXh02BAWLFrKtl27mTt7Fnuv2rd9+ME0/Pz8+HbvPh586GGee+ZJAAoUKMBzz4/kpbGZ35T927lcLqa8+ARjp87mg7iNrFmygMP7f3RrUzG0Om/NXcV7sV/QtG0MU18ekbFu7JP/pefgIUxf8hVvzl6BX0BxS+u34gh3GLD3uq08YPu2LZSvEEK58hXw8fGhS7cefL54kVubpYsX0atPPwA6de7KF+vWYJomAEviYilbthxVQ8Msr/1mbN2yhZCQipSvkN7v7j17sTgu1q3N4rhY+vQbAECXrt1Yt2Y1pmmyOC6W7j17kT9/fsqVL09ISEW2btnijW78Yzu2bXUb7zu79mDZkji3NsuWxNHjrvTxjrmzKxvWrcU0TdatXklYeHXCq9cAIKBYMfLmzWt5H27UNzu2Uq58CGXKlcfHx4eYzt1Z+bn7e9zSZcoSGl6dPHkyT/vGTVtQ+LYiVpWbbUKKFeLkryn8/FsKrjSTr4+cJbK0b5a333PiN/64mDPeUF5p29YtVLhijnfr0ZMlV83xJXGLMuZ45y7dWLc2fY4XLlyYho0aU6BAAW+UflN++HYHjjLlsZcuRz4fH1p26MymNZ+7talVvwkFChYCIKxGHX4+kQDA4f0/4nK5qNOoOQAFC9+W0c4qHg1cwzCCgSjgPU8+zl9JiI/HEVw6Y9nuCCYhIf4v29hsNooW9eX0qVP89ttvTJk4nv97erilNWeH+HgnwVf02+EIxul0Zm5T+op++/py6tQpnM7M28bHu2/7b5WY4MQeHJyxbLc7SIy/arwTnDgutbHZbBQp6svp06c4sH8fhmHQ884oWjepx+uTX7a09puVmBBPkP1y34PsDhITcsa43Qz/gvk4dSElY/n0hYv4F8x8ZqJuGV9GdajMkCZlCSiUc85c/JX0+Xt5vB2OYOKvNcev2Lf5Fk2f4znZLycTKBloz1guXsqeEajXsnT+TOo1aQXA8cMHuK1IUYYPHcB9XVrw9oTnLT97Z/Pw/U8G/g/4y7fOhmHcB9wHEFy6jIfLybpxL73AA0Me5rbbbvN2KWIBlyuVzV9vYvm6TRQsWIhuMXcQUTOSps1bers0uUnfHD/H14fPkppm0qJiAPc1KM3Y1Qe9XZZ42MpFc/jp+2+YNCP9rKbLlcp327/mnQVrKRUUzMhH72H5wk/p0K2vZTV57AjXMIxo4KRpmtv/rp1pmlNN06xjmmad4sVLZGsNQXY7zuOXPzCPdx4nKMj+l21SU1M5dy6JgGLF2L5tCyOefZIaoSG8/carTHp5LO++/Ua21ucpdruD41f02+k8jsPhyNzm2BX9TkqiWLFiOByZt7Xb3bf9twoMchB//HjGcny8k0D7VeMd5MB5qU1qaiq/nksiIKAYQXYHDRo2plix4hQqVIjWbdvx3a6dltZ/MwKD7CTEX+57QryTwKCcMW4348zvFylWyCdjOaBQPs78ftGtzW8pLlLT0j8mWnfgNOUCrD2N6Anp8/fyeDudx7Ffa45fsW9LOpc+x3Oy4iWDOJl4+azVLyfiKVEqKFO77ZvWM/OdSYx682N8fNI/0y9Ryk5I1WrYS5cjr81Go1Yd2LfnW8tqB8+eUm4EdDQM4zAwC2hpGMbHHny8TCJr1+Xggf0cOXyIlJQUFsybQ7uoGLc27aNimDVzBgCxC+fTpFkLDMNg6cr17Np7gF17D3D/gw/xyP+e5N77H7Sy/BtWp25d9u/fx+FD6f2eO3sWUdEd3dpERXdk5owPAVgwfx7NWrTEMAyiojsyd/YskpOTOXzoEPv376NuvXre6MY/Vqt2HQ4evDzen82fwx0dot3a3NEhmjmfpo933GfzadysOYZh0KJVW/bu+Z4LFy6QmprKpo1fUrlKqDe6cUNq1KrDoYP7OXrkMCkpKcQtnEubdlHeLsvjDp66QKkiPhQv7EPePAa3l/Vj5/Ektza+BS6fyIt0FCX+XM66+vxaatepy4Er5vi8ObPpcNUc7xAdkzHHFy6YR7Pm6XM8J6tavRbOIwdJOH6EiykprFm6kAYt3C9q3bfnWyaOeIxRb3yMf7HLB3FVqtfit1/Pcfb0LwDs3PwlZUOqWFq/x04pm6b5FPAUgGEYzYH/maZp3bE76Z9bjH9lCt06dcDlctGn/0BCw8IZ/eLz1IqsQ/uoGPoOGMz99wygdvUq+Pv7896Hn1hZokfYbDYmTXmdmKg7cLlcDBg4mLDwcEaOGE5k7TpEx3Rk4OC7GTywH+FVK+LvH8CMmbMACAsPp2v3HtSKCMNmszH51TdyzMVDNpuNMRMm06tzFC5XGnf1G0DV0HDGjRpBjcjatOsQQ+/+gxhy30Dq1wjFz9+fdz5Ifw/o5+/P/Q8Oo13zBmAYtG7bjjbtOni3Q/+AzWZj5NhJ9O8egyvNRY/eA6hcNYxXxowkomYkbdpHs2vHNu4b0JOkpLOsWr6USeNGsWrjDgC6RbfiwL6fOH/+N+pXD2H8lLdp1rKNl3t1fWkmfLTNyf+1rIBhwBcHTuNMSqZLRCkOnfqdnc5ztK1anFoOX9JMk9+SXbz71eUzOM+0CSGoaAEK2PIwuXMo074+zncJv3qxR1ljs9l4ZfJr3BndDpfLRb+BgwgLC+fFF4YTGVmHqJiODBh0N/cM6k9EaCX8AwKYPuPTjO3DKpfn13PnSElJYXFcLLFLlhOaAy4OzWuzMfTZsTxxT3dcaWm079Kb8pWq8sGrY6hcrSaNWrbnnQkj+OPCeV545G4ASgY5eOnNmeTNm5f7H3+B/w3qgmmaVA6vQVT3fpbWb/x5Ra5HH+Ry4Eb/XbtakXXMNRs2e7yef5uCPjkj0LLbuatO/d0q/kjJeVfFZpdnl/14/Ua50FvdI7xdgldsOXj6+o1ymfu7teLH77+55qkET180BYBpmuuAdVY8loiIyL9Rrv+lKRERkX8DBa6IiIgFFLgiIiIWUOCKiIhYQIErIiJiAQWuiIiIBRS4IiIiFlDgioiIWECBKyIiYgEFroiIiAUUuCIiIhZQ4IqIiFhAgSsiImIBBa6IiIgFFLgiIiIWUOCKiIhYQIErIiJiAQWuiIiIBRS4IiIiFlDgioiIWECBKyIiYgEFroiIiAUUuCIiIhZQ4IqIiFhAgSsiImIBBa6IiIgFbN4u4GqG4e0KxCppaaa3S/CK5NQ0b5fgNW93j/B2CV4R+vhib5fgFd+O7eDtEixXyOevY1VHuCIiIhZQ4IqIiFhAgSsiImIBBa6IiIgFFLgiIiIWUOCKiIhYQIErIiJiAQWuiIiIBRS4IiIiFlDgioiIWECBKyIiYgEFroiIiAUUuCIiIhZQ4IqIiFhAgSsiImIBBa6IiIgFFLgiIiIWUOCKiIhYQIErIiJiAQWuiIiIBRS4IiIiFlDgioiIWECBKyIiYgEFroiIiAUUuCIiIhbI9YG7asUy6tYII7JaFSa9PC7T+uTkZAb3u4vIalVo3bQBR48cBmD71i00qV+bJvVr07h+5P+3d9/xUZXZ48c/B4aAgJAQhCQThFBTaAkJvaMIpIgUwVWqq7uuBXX1u8W14VpREVfd1Z+oyKJ0DAGkKegKQkhoUgUkQAqCUYiieS2rcAAAHm1JREFUJGR4fn/MEDIkSsvcm5Dzfr3yytzc5849J/eZ58wtM5dFyR9ZHPnlWb5sKW2jWhEV3pxJLzxXYn5+fj63/W4EUeHN6dG1EwcyMormTXr+WaLCm9M2qhUrli+zMOqy8enKZXSPbU2X6Aj+NXlSifn5+fn8YdytdImOYFC/7hzybPNTp05x3x9vp0/XGHp0bMurL79gceSX5/NPl3NDt/Zc17kNb/7rxRLzN3z5BYOv70qEsw5LUxYU/T3r0EEGX9+VpH6dGdQzlg+nvW1l2Jdt+bKltG8dTpuIFrw4qfS+PvrWkbSJaEGv7p2L+npubi4D+/elQb2reXDCPRZHffl6hV/Dp3/vw2f/6Mtd1zUvMf/Rm6JY8nBPljzck1WP9GHrswMAiHTWYcH93Vjx194s/UsvEqJDrA79sqxcvpTYdpFE/8aYPm7ULUS3bkW/nl04UGxM796pA907daBbpxhSbBjTHb58chHJAH4EXEChMSbWl+s7l8vl4uEH7mPBoqWEOEPp26MzA+MTCY+ILGoz/b13qOsfwMZtu5k3ZxZP/ONvvDP9QyKiWrNqzXocDgeHc3Lo0TmGAfEJOBw+/ZeVCZfLxf333c3ij1fgDA2le+c4EhKSiIg8m/d770wlwD+A7bv2MnvWTB75+1/47wez2LljB3NmzWTjlu3kZGczaMB1fLXja6pWrWpjRhfO5XLx94cmMOujJQSHhDKwT1f6D0ygVXhEUZsPp79LXX9/vty0k4/mzeafTzzCm+/OIOWjeRQU5LNq7UZ+/vlnenVqz01Db6ZR4yb2JXSBXC4XT/7tQd6dnUJQsJOhA3rQr388zVudzTvY2YjnprzJ1DemeC17TcMgZi9ahV/16pw48RMJveLoe0M8DYOCrU7jorlcLh6ccA8pS5bjDA2lR9eOxCckEVHsNT7t3an4+/vz1c49zJk9k0cf+Svvz5hJjRo1ePTxiezYvo0d27fZmMXFqyLw1PA23PrGOg4f+4WFf+7Byq8Os+fbn4raPLVge9HjsT2aEBVaF4BfClw8MGMzGUdP0KBOdRY/1JPPdx0h75dCy/O4WC6Xi4ceuI+PPGN6n18Z0/39A9hUbEx/1zOmry42pnfvHMNAi8d0K/Zw+xhj2ltdbAHS01Jp2qwZTcKa4ufnx5BhN7Nk0UKvNh8vXsgtt40C4MabhvLZ6k8xxlCzZs2iDZGffxIRsTr8S7YhNZVmzZoT1tSd9/ARI1mUkuzVZlFKMreOGgPAkKHDWP3pJxhjWJSSzPARI6levTpNwsJo1qw5G1JT7UjjkmxK30CTps1o3MSd+41Db2bZkhSvNkuXpHDzLe5tnnDjEP732SqMMYgIP584QWFhISdP/oKfXzVq16ljRxoXbeumNBqHNeXaxmH4+fkRP3gYK5ct8moTem1jwiPbUKWK98vez88Pv+rVASjIz+e0OW1Z3JcrbUMqTYv19WE3jyilry8s6us3DRnG6lXuvl6rVi26dutO9Ro17Aj9srRvHEDG0RMcyv2ZUy5DysZsrm8T9Kvtkzo4Sd6YBcD+oyfIOHoCgCN5+Xz3Uz71ale3JO7Lde6YPrSUMX3JBYzpJ20a06/oQ8o52dk4nY2KpkOcoeRkZ3u1yS7WxuFwUKdOXb7PzQUgLXU9XTq0pVtce16e8kaF2LsFyM7OIjT0bN5OZyhZWVkl2zQqlnfduuTm5pKVVXLZ7GzvZcuzwzne2zw4xMnhnKwSbUKcocCZbV6H77/PJeHGIdSsVYt2rRoT27o5f7z3AQIC6lka/6X6NieboJDQoumgYCff5uRc8PI5WZkk9ulIrw6tuOPuByvE3i2c6cdn83Y6Q8kpra+Her/Gcz2v8YoqqG4Nco79UjSdc+wkQXVLf+PgDLiKRvVqsvbr70rMa3etP35Vq3DguxM+i7UsXciYnnOeMb2zjWO6rwuuAZaLSLqI3OnjdZW52I6d+DJ9K5/8bx2TX3yOkydP2h2S8qFN6RuoUrUqm3dlkLplN2++9goHMr6xOyxLBDtDSVmVyoovv2LB7Bl8d/Rbu0NSZSQxJoQlW3I4bbz/3qBOdSbfFs1DH2zGmNKXvdLEduzEuvStfGrTmO7rgtvdGBMDDATuFpGe5zYQkTtFJE1E0r777miZrjw4JISsrENF09lZmQSHeF8gEFKsTWFhIXl5x6kXGOjVplV4BLVq12ZnBTnPExLiJDPzbN5ZWZk4nc6SbQ4Vy/v4cQIDA3E6Sy4bEuK9bHkWFOy9zXOyswgKdpZok52VCZzZ5nnUqxfIgrkz6dOvP9WqVaP+NQ2I69SVLZs2Whr/pWoYHMLh7Myi6cM5WTQMvvi91IZBwbQMjyRt3dqyDM9n3P34bN5ZWZkEl9bXM71f44HnvMYrmsPHTxLsf1XRdLB/DQ4fL714JMU4WZjuvddfu7qDd+/sxIuLd7HpwDGfxlqWLmRMDy7HY7pPC64xJsvz+wiwAOhYSpu3jDGxxpjY+vWvKdP1x3SIY9/evRzI2E9BQQHz585mYHyiV5sBgxL58L/TAUheMI+evfogIhzI2E9hofsigoMHD7Bn926urQAXzwDExsWxd+8eMva7854zaybxCUlebeITkpgxfRoA8+fNpVefvogI8QlJzJk1k/z8fDL272fv3j3EdSyx2cqt9jGx7N+3l4OebZ48bzY3DEzwanPDwARmf+je5ouS59O9Z29EBGfotaz5fDUAP584QXraepq3aGV1CpekTfsOZHyzj0MHMigoKGDxR3Pp1z/+gpY9nJ3FyV/chyePH/uB9NQvCWvewpfhlpkOsXHsK9bX586eVUpfTyzq6wvmz6VX774V6pqM0mw5eIywa2rRqN5VVKsqJMaEsGLb4RLtmjWoTZ2rqpGe8UPR36pVFd76fSzzNhxiyZYLP+1QHpwZ0zM8r+95pYzpA39lTM8oB2O6zw5gi0gtoIox5kfP4/7ARF+trzQOh4MXXp7C0KRBuFwubh09lojIKJ6Z+DjtY2IZlJDIqLHj+ePtY4hp3YqAgACmvv8BAF+uXcOUl17A4ahGlSpVePGV1wisX9/K8C+Zw+Fg8pTXSIy/AZfLxZix44mMimLiE48R0yGWhMQkxo6/nfFjRxEV3pyAgHpMnzETgMioKIYOv5notpE4HA5eefX1CnOFMrhzf2bSK9wyNAGXy8XI28bSKiKSF55+knbRMdwwKJFbRo3j3j+Mo0t0BP4B9fjPO+4X57jf/5H7776DXp3bY4xh5K2jiWzdxuaMLozD4eCxZ17i9ltuxOVyMeyW0bQIj2TK80/Run0M/W6IZ+umdO4eP5K8Y8dYteJjXp30NEs+T2Pfnl0898TfQASMYfxdE2gV0drulC6Iw+HgpVf+xY0JA3C5XIweO47IyCieevIxYmJiiU9MYsy42/n9uNG0iWhBQL16TJv+YdHyES3D+DEvj4KCAlJSklm4eJnXFc7lleu04bF523j/rs5UrSLMXneIPYd/4sGBrdh66Bgrt7lPCSTGhJCyyXvvNiE6hI7NAvGv6cewju5znQ99sJkdWXmW53GxHA4Hk4qN6bd5xvSnJz5OdLEx/Q+3jyHaM6a/4xnT161dwys2j+lifHTwXkSa4t6rBXdh/8AY8/RvLRMdE2tWrVnvk3jKsxrVKk5BK0vHThTYHYItfjxZ/j9+4SvOgKvO3+gKFPHwovM3ugJtfW6Q3SFYrne3TmzamFbqIRSf7eEaY74B2vnq+ZVSSqmK5Ir+WJBSSilVXmjBVUoppSygBVcppZSygBZcpZRSygJacJVSSikLaMFVSimlLKAFVymllLKAFlyllFLKAlpwlVJKKQtowVVKKaUsoAVXKaWUsoAWXKWUUsoCWnCVUkopC2jBVUoppSygBVcppZSygBZcpZRSygJacJVSSikLaMFVSimlLKAFVymllLKAFlyllFLKAlpwlVJKKQtowVVKKaUsoAVXKaWUsoAWXKWUUsoCWnCVUkopC2jBVUoppSzgsDsALwJVROyOQlmkzlXV7A7BFkfy8u0OwTbf/Vg5c98xKcHuEGzRaeJKu0Ow3L6cvF+dp3u4SimllAW04CqllFIW0IKrlFJKWUALrlJKKWUBLbhKKaWUBbTgKqWUUhbQgquUUkpZQAuuUkopZQEtuEoppZQFtOAqpZRSFtCCq5RSSllAC65SSillAS24SimllAW04CqllFIW0IKrlFJKWUALrlJKKWUBLbhKKaWUBbTgKqWUUhbQgquUUkpZQAuuUkopZQEtuEoppZQFtOAqpZRSFtCCq5RSSllAC65SSillAS24SimllAWu+IK7cvlSOrSNoH1US16e9HyJ+fn5+Yy9bSTto1rSt0cXDhzIACB9QyrdO8XQvVMM3TpGk5K8wOLIL8/yZUtpG9WKqPDmTHrhuRLz8/Pzue13I4gKb06Prp04kJFRNG/S888SFd6ctlGtWLF8mYVRX77ly5bSvnU4bSJa8OKk0vMefetI2kS0oFf3zkV55+bmMrB/XxrUu5oHJ9xjcdRlY83qFST1jiGhRzumvv5yifnp69cwYlAPYsICWLH4I695k59+lJv6dWRw31iee+xhjDFWhX3ZVn+ynD6d2tIzLoo3pkwqMX/92i8Y1KcLTRvWZvHC+V7zRt+cRJumQYy7ZYhV4ZaZFcuWEt06nLYRLXjpN/p624gW9C6lrzesoH29W4tAUiZ0ZckD3bi9Z5NS29zQuiHJ93Xho3u78Pzw1gDEhQUw9+7ORT/pj/elb8Q1Fkbu44IrIv4iMldEdonIThHp4sv1ncvlcvHn++9lbvJiUjdtY96cmezaucOrzfvvvYN/QACbt3/Nn+6dwOOP/BWAiKjWrF6TyhfrNzIveQn333sXhYWFVoZ/yVwuF/ffdzfJKR+zaesO5sz8kJ07vPN+752pBPgHsH3XXu6d8ACP/P0vAOzcsYM5s2aycct2Fi5ayoR7/4TL5bIjjYvmcrl4cMI9LFi4hPQt25kzayY7z9ne096dir+/P1/t3MM9993Po57tXaNGDR59fCLPPFdywK4IXC4Xz/zjz7wxbR4LPtnA0oVz2ff1Lq82QSGhPPXSvxl443Cvv29OW8/mtHXMXf4l81asZ/vWjaSt+8LK8C+Zy+Xi0b/cz7RZyaxcs4mF8+fw9e6dXm1CQhvx0mtvcePQESWWv/OeB5j8xlSrwi0zZ/r6/IVLSDtPX9+6cw93l9LXn66Afb2KwD8Sw7nr/U0kvbqWQW2CaHpNLa821wbW5Pc9mzDqrQ0M/teXPL9kNwAb9v/AsNfXMez1dYx/J42Tp06zdm+utfH7+PmnAEuNMeFAO2DnedqXqfQNqTRt1oywsKb4+fkxZPgIFi9a6NVmyaJkfnfraAAGDxnGZ6s/xRhDzZo1cTgcAJzMP4mIWBn6ZdmQmkqzZs0Ja+rOe/iIkSxKSfZqsyglmVtHjQFgyNBhrP70E4wxLEpJZviIkVSvXp0mYWE0a9acDampdqRx0dI2pNK0WN7Dbh5RSt4Li/K+acgwVq9y512rVi26dutO9Ro17Aj9sm3bnEajJk0JbRxGNT8/BiQOZfXyxV5tnI0a0zKiNVWqeL/sRdx7Q6dOFVBQkE/hqUIC6zewMvxLtnnjBpqENePaJmH4+fmReNNwVny8yKtNo2sbExHVpkTeAN179qFW7autCrfMlNbXF5/T1xefp6/XqIB9vU1oXQ7m/kzmD79Q6DJ8/NXhEnupw2KdzFyfSd5J9w7S9ydOlXie/lEN+d+e7zh56rQlcZ/hs4IrInWBnsBUAGNMgTHmmK/WV5rs7CycoY2Kpp1OJzlZWV5tcrKzi9o4HA7q1KnL97nudz1pqevpFNOGrrHtmPzqG0UFuLzLzs4i1CvvULLOyTs7O4vQRsXyrluX3NxcsrJKLpud7b1seeXOKbRo2ukMLbG9i/9vzmzv3Fxr3+X6wpHDOQSFnM29QXAI336bfUHLtuvQibiuPbgutiXXxbaka69+NG3RylehlqnDOdkEF8s7OMTJ4ZyK0V8vR2l9Pfs8fb3uFdDXG9SpzuHj+UXT3+bl06BOda82jQNr0rh+TabfEceMP8TRrUVgiecZ2DaIj7ce9nm85/LlHm4YcBR4V0Q2icjbIlLrfAuVJ7EdO7F+41es+mI9L096npMnT9odklJl7mDGPvbv3c3y9TtZkbqL1LWfsXH9WrvDUuqSOKoIjQNrMm5qGv83+yueHBzJ1TXO7izVr+1Hi4a1WbPH+jcfviy4DiAG+LcxJho4Afz13EYicqeIpIlIWu7Ro2UaQEiIk6zMQ0XTWVlZBDudXm2CQ0KK2hQWFpKXd5x6gd7viFqFR1Crdm12bN9WpvH5SkiIk0yvvDNxnpN3SIiTzEPF8j5+nMDAQJzOksuGhHgvW165c8osms7KyiyxvYv/b85s78DAku+AK5oGQcEczj6b+5GcbBo2DLmgZT9duog20XHUrFWbmrVq06339WzZWDFOIwQFh5BTLO+c7CyCgitGf70cpfX1kPP09eNXQF8/kpdPUN2ze7QN61TnSF6+V5tv8/JZtesohacNWT+cJOO7EzQOrFk0f0Cbhnyy4wiFp62/MNCXBTcTyDTGrPdMz8VdgL0YY94yxsQaY2IDrynbK8ZiYuPYt3cvGRn7KSgoYP6cWQyKT/RqMyg+iQ9mvA/AR/Pn0rNXH0SEjIz9RRdJHTxwgD27d9G4cZMyjc9XYuPi2Lt3Dxn73XnPmTWT+IQkrzbxCUnMmD4NgPnz5tKrT19EhPiEJObMmkl+fj4Z+/ezd+8e4jp2tCONi9YhNo59xfKeO3tWKXknFuW9YP5cevXuW6HOz/+aqHYdOLj/GzIPZnCqoIClKfPodf2gC1o2KCSU9HVrKCws5NSpU6SvW0NY84pxSLlddCz7v9nLwQMZFBQUkLJgDtcPiLc7LJ8rra8POqevD7oC+/q2rDyuDayJM6AGjqrCwDZBrNrlvaP2yc4jxIUFAOBfsxpN6tfi0Pe/FM0f2DaIJTYcTgb3XqhPGGMOi8ghEWlljNkN9AN2nG+5suRwOHhx8qsMSRyIy+XitjHjiIiM4umJjxMd04FBCUmMGjueO8ePpn1USwIC6vHO9A8AWLf2Cya/+ALVqlVDqlThpSmvEVi/vpXhXzKHw8HkKa+RGH8DLpeLMWPHExkVxcQnHiOmQywJiUmMHX8748eOIiq8OQEB9Zg+YyYAkVFRDB1+M9FtI3E4HLzy6utUrVrV5owujMPh4KVX/sWNCQNwuVyMHjuOyMgonnryMWJiYolPTGLMuNv5/bjRtIloQUC9ekyb/mHR8hEtw/gxL889cKcks3DxMiIiIm3M6MI5HA7+9tQk7hp1E6ddLgaPGEXzVhG8/tI/iWoTQ+/+g9i2JZ0H7riVvOPH+Gzlx7zx8jMs+CSV6+MHk7r2c4b174wgdO19Hb2vH2h3ShfE4XAw8bnJjB6eiOu0i5t/N4aW4ZG89OxE2raP4fqBCWzZmMadY0Zw/PgxVi5bwuTn/8nKNRsBGJbQj317vubEiZ/o1KYZL0z5D736Xm9zVud3pq8P9vT1Ub/R19t6+vp7xfp6ZLG+viglmeQK0tddpw3PLNrNm2NiqFpFWJCezb4jJ7i7XzO2Z+WxetdR1uzJpWvzQJLv64LrtOGlpV9z/Bf3hVMh/jUIqluDtIwfbIlffPl5OxFpD7wN+AHfAOOMMb+aaXSHWPPZmopxKKss+Tmu+I9Dl+q0DYd0yoO93/5kdwi28a9Zze4QbBF4dfXzN7oCdZq40u4QLLdv6t38kvN1qYcSfHrZrTFmMxDry3UopZRSFUHl3LVSSimlLKYFVymllLKAFlyllFLKAlpwlVJKKQtowVVKKaUsoAVXKaWUsoAWXKWUUsoCWnCVUkopC2jBVUoppSygBVcppZSygBZcpZRSygJacJVSSikLaMFVSimlLKAFVymllLKAFlyllFLKAlpwlVJKKQtowVVKKaUsoAVXKaWUsoAWXKWUUsoCWnCVUkopC2jBVUoppSygBVcppZSygBZcpZRSygJacJVSSikLaMFVSimlLKAFVymllLKAGGPsjqGIiBwFDti0+vrAdzat206ad+WieVcumrf1GhtjriltRrkquHYSkTRjTKzdcVhN865cNO/KRfMuX/SQslJKKWUBLbhKKaWUBbTgnvWW3QHYRPOuXDTvykXzLkf0HK5SSillAd3DVUoppSxQ6QuuiAwQkd0isldE/mp3PFYRkXdE5IiIbLM7FquISCMRWSUiO0Rku4hMsDsmq4hIDRFJFZEtntyftDsmq4hIVRHZJCKL7I7FSiKSISJfichmEUmzOx6riIi/iMwVkV0islNEutgd0xmV+pCyiFQFvgauBzKBDcAtxpgdtgZmARHpCfwEvG+MaW13PFYQkWAg2BizUUSuBtKBwZVkewtQyxjzk4hUA74AJhhj1tkcms+JyINALFDHGJNgdzxWEZEMINYYU6k+hysi04D/GWPeFhE/oKYx5pjdcYHu4XYE9hpjvjHGFAAzgRttjskSxpjPge/tjsNKxpgcY8xGz+MfgZ2A096orGHcfvJMVvP8XPHvtkUkFIgH3rY7FuV7IlIX6AlMBTDGFJSXYgtacJ3AoWLTmVSSAbiyE5EmQDSw3t5IrOM5tLoZOAKsMMZUhtxfAf4POG13IDYwwHIRSReRO+0OxiJhwFHgXc9phLdFpJbdQZ1R2QuuqoREpDYwD7jfGJNndzxWMca4jDHtgVCgo4hc0acSRCQBOGKMSbc7Fpt0N8bEAAOBuz2nka50DiAG+LcxJho4AZSba3Mqe8HNAhoVmw71/E1doTznL+cBM4wx8+2Oxw6eQ2yrgAF2x+Jj3YAkz7nMmUBfEfmvvSFZxxiT5fl9BFiA+xTalS4TyCx29GYu7gJcLlT2grsBaCEiYZ6T6yOBhTbHpHzEc+HQVGCnMeZlu+OxkohcIyL+nsdX4b5QcJe9UfmWMeZvxphQY0wT3K/tT40xt9kcliVEpJbnwkA8h1T7A1f8JxKMMYeBQyLSyvOnfkC5uSjSYXcAdjLGFIrIPcAyoCrwjjFmu81hWUJEPgR6A/VFJBN43Bgz1d6ofK4bMAr4ynMuE+DvxpglNsZklWBgmufK/CrAbGNMpfqYTCXTEFjgfo+JA/jAGLPU3pAscy8ww7MT9Q0wzuZ4ilTqjwUppZRSVqnsh5SVUkopS2jBVUoppSygBVcppZSygBZcpZRSygJacJVSSikLaMFVqoIQkd5n7ngjIkm/dXcrzx1T/nQJ63hCRB660L+f0+Y9ERl2EetqUpnuVqWUFlylbOb5bOxFMcYsNMY89xtN/IGLLrhKKd/RgquUj3j24HaJyAzPfTnnikhNz7wMEXleRDYCw0Wkv4h8KSIbRWSO5/uez9yveZen3ZBizz1WRF7zPG4oIgs897rdIiJdgeeAZp57oU7ytHtYRDaIyNbi98MVkUdE5GsR+QJoxXmIyB2e59kiIvPO5ORxnYikeZ4vwdO+qohMKrbuP1zu/1apikgLrlK+1Qp4wxgTAeThvdeZ6/ly+ZXAP4DrPNNpwIMiUgP4f0Ai0AEI+pV1vAp8Zoxph/t7Y7fj/sL2fcaY9saYh0WkP9AC9/fptgc6iEhPEemA+2sP2wODgLgLyGm+MSbOs76dwO3F5jXxrCMe+I8nh9uB48aYOM/z3yEiYRewHqWuKJX6qx2VssAhY8waz+P/AvcBL3qmZ3l+dwYigTWer+LzA74EwoH9xpg9AJ4v3i/tNmt9gdHgviMQcFxEAs5p09/zs8kzXRt3Ab4aWGCM+dmzjgv5LvHWIvJP3Ieta+P+atQzZhtjTgN7ROQbTw79gbbFzu/W9az76wtYl1JXDC24SvnWud+dWnz6hOe34L4/7S3FG4pI+zKMQ4BnjTFvnrOO+y/hud4DBhtjtojIWNzfyX1GafkKcK8xpnhhPnNPYqUqDT2krJRvXSsiXTyPfwd8UUqbdUA3EWkORXd6aYn7bj5NRKSZp90tpSwL8Alwl2fZqiJSF/gR997rGcuA8cXODTtFpAHwOTBYRK7y3F0m8QJyuhrI8dzq8NZz5g0XkSqemJsCuz3rvsvTHhFpWZ5uCq6UVbTgKuVbu3Hf/HsnEAD8+9wGxpijwFjgQxHZiudwsjHmJO5DyIs9F00d+ZV1TAD6iMhXQDoQaYzJxX2IepuITDLGLAc+AL70tJsLXG2M2Yj70PYW4GPct6w8n0eB9cAaSt7i7yCQ6nmuP3pyeBv3LdI2ej4G9CZ6dE1VQnq3IKV8xHPIdJExprXNoSilygHdw1VKKaUsoHu4SimllAV0D1cppZSygBZcpZRSygJacJVSSikLaMFVSimlLKAFVymllLKAFlyllFLKAv8fO3LQaN+Cgo0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW3FZjp-5DgF",
        "outputId": "9f85bd6c-bff1-4809-e280-54800563279a"
      },
      "source": [
        "print(classification_report(ytest, test_pred, target_names=emotions.values()))\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry       0.66      0.45      0.54       535\n",
            "     Disgust       0.77      0.35      0.49        48\n",
            "        Fear       0.57      0.34      0.42       506\n",
            "       Happy       0.71      0.94      0.81       888\n",
            "         Sad       0.55      0.51      0.53       598\n",
            "    Surprise       0.73      0.72      0.73       357\n",
            "     Neutral       0.54      0.67      0.60       657\n",
            "\n",
            "    accuracy                           0.63      3589\n",
            "   macro avg       0.65      0.57      0.59      3589\n",
            "weighted avg       0.63      0.63      0.62      3589\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}