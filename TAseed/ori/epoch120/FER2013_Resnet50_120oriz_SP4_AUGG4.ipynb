{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER2013_Resnet50_120oriz_SP4_AUGG4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "18Zj-Yp1YlH0QWcuD4e7ugx8zCCcRS0jg",
      "authorship_tag": "ABX9TyMIi1hoCF9d8NKPYnTLEXnO"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eWeoD7MRFlN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "111d95f8-4f59-4445-c019-cba04e0038ac"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "inputFolder = '/content/drive/MyDrive/Fer2013_backup/' \n",
        "for root, directories, filenames in os.walk(inputFolder): \n",
        "    for filename in filenames: print(os.path.join(root,filename))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Fer2013_backup/backUpfer2013.csv\n",
            "/content/drive/MyDrive/Fer2013_backup/icml_face_data.csv\n",
            "/content/drive/MyDrive/Fer2013_backup/test.csv\n",
            "/content/drive/MyDrive/Fer2013_backup/train.csv\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/best_model_resnet50_modelB2_170false.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/best_model_resnet50_modelD2_170false.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50Scracth_tipe7.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50Scracth_tipe8.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50oriAUGScracthSGD2.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50oriAUGScracthSGD3.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50AUGScracthadam2.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50AUGScracthAdam1sp.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50AUGScracthSGD4sp.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50AUGScracthSGD5sp.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50AUGScracthSGD6sp.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP1_30_noAug1.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP2_30_noAug2.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP3_30_noAug3.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP4_30_noAug4.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP5_30_noAug5.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP6_30_noAug6.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP1_90_noAug1.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP2_90_noAug2.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP3_90_noAug3.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP4_90_noAug4.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP4_60_noAug1.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP5_90_noAug5.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP1_60_noAug1.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP2_60_noAug2.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP3_60_noAug3.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP4_60_noAug4.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP5_60_noAug5.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP6_60_noAug6.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50oriz_SEED_SP6_60_Augg6.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50oriz_SEED_SP5_120_Augg5.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/fixcheckpoint/Best_Model_resnet50oriAUGScracthSGD2.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH8iEUJiRQS7",
        "outputId": "609cb9dc-9701-40e5-80e4-c2d2a369254c"
      },
      "source": [
        "%cd /content/drive/MyDrive/Fer2013_backup/\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Fer2013_backup\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqZOFwxxRQaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51efe1c8-c224-474e-e672-3a17a6d152a2"
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:400: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUX-dSAgRQh4"
      },
      "source": [
        "#Define the identity block helper function.\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "   \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbdQH3mkRQra"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block4\n",
        "    \n",
        "    Arguments:\n",
        "    _X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path \n",
        "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b',padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33XH76oKRQvh"
      },
      "source": [
        "\"\"\"def ResNet50(input_shape = (48,48,1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    #X = ZeroPadding2D((1, 1))(X_input)\n",
        "    X = X_input\n",
        "    # Stage 1\n",
        "\n",
        "    X = Conv2D(8, (3, 3), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # removed maxpool\n",
        "    #X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='c')\n",
        "\n",
        "\n",
        "    # Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [64,64,256], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL . \n",
        "    X = AveragePooling2D((2,2), name='avg_pool')(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(512, activation = 'relu', name='fc1024' , kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWuYK_f2zGJF"
      },
      "source": [
        "def ResNet50ori(input_shape = (48, 48, 1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50ori')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QQOxN2cRQy3"
      },
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        " \n",
        "dataset_path = '/content/drive/MyDrive/Fer2013_backup/backUpfer2013.csv'\n",
        "image_size=(48,48)\n",
        "\n",
        "def load_fer2013():\n",
        "    data = pd.read_csv(dataset_path)\n",
        "    data = (data[data['pixels'].notnull()])\n",
        "    pixels = data['pixels'].tolist()\n",
        "    width, height = 48, 48\n",
        "    faces = []\n",
        "    for pixel_sequence in pixels:\n",
        "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "        face = np.asarray(face).reshape(width, height)\n",
        "        face = cv2.resize(face.astype('uint8'),image_size)\n",
        "        faces.append(face.astype('float32'))\n",
        "    faces = np.asarray(faces)\n",
        "    faces = np.expand_dims(faces, -1)\n",
        "    emotions = (data['emotion'])#.values\n",
        "    return faces, emotions\n",
        " \n",
        "def preprocess_input(x, v2=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if v2:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x\n",
        " \n",
        "faces, emotions = load_fer2013()\n",
        "faces = preprocess_input(faces)\n",
        "#xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
        "#Data Augumentationfgf\n",
        "data_generator = ImageDataGenerator(\n",
        "                        rotation_range=10,\n",
        "                        shear_range = 10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True,\n",
        "                        )\n",
        "#data_generator = ImageDataGenerator ()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "8zCkwVdnKTm5",
        "outputId": "423f3c04-e65c-4e5d-994b-9d021630097e"
      },
      "source": [
        "train_ratio = 0.80\n",
        "validation_ratio = 0.10\n",
        "test_ratio = 0.10\n",
        "\n",
        "# train is now 75% of the entire data set\n",
        "# the _junk suffix means that we drop that variable completely # the _junk suffix means that we drop that variable completely\n",
        "#x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=1 - train_ratio,random_state=42)\n",
        "\n",
        "# test is now 10% of the initial data set\n",
        "# validation is now 15% of the initial data set\n",
        "#x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "x_val, xtest, y_val, ytest = train_test_split(xtest, ytest, test_size=test_ratio/(test_ratio + validation_ratio), random_state=42) \n",
        "\n",
        "#print(xtrain, x_val, xtest)\n",
        "\n",
        "\"\"\"X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2\"\"\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\\n\\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t--o7TREKTu2",
        "outputId": "087935b7-1e37-417a-cd7f-08595400142d"
      },
      "source": [
        "print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validasi (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "test (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "train (28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ofOj3-fRREN"
      },
      "source": [
        "#hyperparameter and callback\n",
        "batch_size = 64\n",
        "num_epochs = 120\n",
        "input_shape = (48, 48, 1)\n",
        "num_classes = 7\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXikieAnRbYs"
      },
      "source": [
        "#Compile the model.\n",
        "\n",
        "\n",
        "from keras.optimizers import Adam, SGD\n",
        "model = ResNet50ori(input_shape = (48, 48, 1), classes = 7)\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "model.compile(optimizer= optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nefC0ZE8RgX5",
        "outputId": "34a24459-aa9c-49d0-966e-436ad1901ffb"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50ori\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2D)  (None, 54, 54, 1)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 24, 24, 64)   3200        zero_padding2d[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 24, 24, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 24, 24, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 11, 11, 64)   0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 11, 11, 64)   4160        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 11, 11, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 11, 11, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 11, 11, 256)  16640       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 11, 11, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 11, 11, 256)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 11, 11, 256)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 11, 11, 64)   16448       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 11, 11, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 11, 11, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 11, 11, 256)  0           activation_3[0][0]               \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 11, 11, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 11, 11, 64)   16448       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 11, 11, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 11, 11, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 11, 11, 256)  0           activation_6[0][0]               \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 11, 11, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 6, 6, 128)    32896       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 6, 6, 128)    0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 6, 6, 128)    0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 6, 6, 512)    131584      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 6, 6, 512)    2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 6, 6, 512)    0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 6, 6, 512)    0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 6, 6, 128)    0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 6, 6, 128)    0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 6, 6, 512)    0           activation_12[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 6, 6, 512)    0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 6, 6, 128)    0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 6, 6, 128)    0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 6, 6, 512)    0           activation_15[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 6, 6, 512)    0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 6, 6, 128)    0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 6, 6, 128)    0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 6, 6, 512)    0           activation_18[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 6, 6, 512)    0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 3, 3, 256)    131328      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 3, 3, 256)    0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 3, 3, 256)    0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 3, 3, 1024)   525312      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 3, 3, 1024)   4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 3, 3, 1024)   0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 3, 3, 1024)   0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 3, 3, 256)    0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 3, 3, 256)    0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 3, 3, 1024)   0           activation_24[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 3, 3, 1024)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 3, 3, 256)    0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 3, 3, 256)    0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 3, 3, 1024)   0           activation_27[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 3, 3, 1024)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 3, 3, 256)    0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 3, 3, 256)    0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 3, 3, 1024)   0           activation_30[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 3, 3, 1024)   0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 3, 3, 256)    0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 3, 3, 256)    0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 3, 3, 1024)   0           activation_33[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 3, 3, 1024)   0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 3, 3, 256)    0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 3, 3, 256)    0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 3, 3, 1024)   0           activation_36[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 3, 3, 1024)   0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 2, 2, 512)    524800      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 2, 2, 2048)   2099200     activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 2, 2, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 2, 2, 2048)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 2, 2, 2048)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 2, 2, 2048)   0           activation_42[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 2, 2, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 2, 2, 2048)   0           activation_45[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 2, 2, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 2048)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            14343       flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,595,783\n",
            "Trainable params: 23,542,663\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_tXyjuSz_IP",
        "outputId": "1b1b4332-a50f-4f49-8e12-1e7171e89a7a"
      },
      "source": [
        "history = model.fit(\n",
        "    data_generator.flow(xtrain, ytrain,),\n",
        "    steps_per_epoch=len(xtrain) / batch_size,\n",
        "    epochs=num_epochs,\n",
        "    shuffle=False,\n",
        "    verbose=1,\n",
        "    validation_data= (x_val,y_val))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/120\n",
            "448/448 [==============================] - 122s 134ms/step - loss: 4.3833 - accuracy: 0.2136 - val_loss: 1.9619 - val_accuracy: 0.2513\n",
            "Epoch 2/120\n",
            "448/448 [==============================] - 55s 122ms/step - loss: 1.8015 - accuracy: 0.2472 - val_loss: 1.7821 - val_accuracy: 0.2499\n",
            "Epoch 3/120\n",
            "448/448 [==============================] - 55s 122ms/step - loss: 1.7902 - accuracy: 0.2460 - val_loss: 1.7965 - val_accuracy: 0.2583\n",
            "Epoch 4/120\n",
            "448/448 [==============================] - 57s 126ms/step - loss: 1.7800 - accuracy: 0.2529 - val_loss: 1.7843 - val_accuracy: 0.2561\n",
            "Epoch 5/120\n",
            "448/448 [==============================] - 55s 122ms/step - loss: 1.7717 - accuracy: 0.2687 - val_loss: 1.7249 - val_accuracy: 0.2953\n",
            "Epoch 6/120\n",
            "448/448 [==============================] - 57s 126ms/step - loss: 1.7512 - accuracy: 0.2826 - val_loss: 1.6882 - val_accuracy: 0.3112\n",
            "Epoch 7/120\n",
            "448/448 [==============================] - 57s 126ms/step - loss: 1.7259 - accuracy: 0.2952 - val_loss: 1.6811 - val_accuracy: 0.3277\n",
            "Epoch 8/120\n",
            "448/448 [==============================] - 57s 126ms/step - loss: 1.6879 - accuracy: 0.3236 - val_loss: 1.7202 - val_accuracy: 0.3383\n",
            "Epoch 9/120\n",
            "448/448 [==============================] - 55s 122ms/step - loss: 1.6479 - accuracy: 0.3510 - val_loss: 1.7841 - val_accuracy: 0.3079\n",
            "Epoch 10/120\n",
            "448/448 [==============================] - 55s 123ms/step - loss: 1.6068 - accuracy: 0.3674 - val_loss: 2.9344 - val_accuracy: 0.2906\n",
            "Epoch 11/120\n",
            "448/448 [==============================] - 55s 123ms/step - loss: 1.5888 - accuracy: 0.3797 - val_loss: 1.7454 - val_accuracy: 0.2892\n",
            "Epoch 12/120\n",
            "448/448 [==============================] - 55s 122ms/step - loss: 1.5268 - accuracy: 0.4023 - val_loss: 1.6667 - val_accuracy: 0.4065\n",
            "Epoch 13/120\n",
            "448/448 [==============================] - 55s 123ms/step - loss: 1.4977 - accuracy: 0.4221 - val_loss: 1.4759 - val_accuracy: 0.4260\n",
            "Epoch 14/120\n",
            "448/448 [==============================] - 55s 123ms/step - loss: 1.4531 - accuracy: 0.4417 - val_loss: 1.7322 - val_accuracy: 0.3873\n",
            "Epoch 15/120\n",
            "448/448 [==============================] - 55s 123ms/step - loss: 1.4788 - accuracy: 0.4283 - val_loss: 1.6046 - val_accuracy: 0.4227\n",
            "Epoch 16/120\n",
            "448/448 [==============================] - 55s 123ms/step - loss: 1.4284 - accuracy: 0.4529 - val_loss: 1.5297 - val_accuracy: 0.4291\n",
            "Epoch 17/120\n",
            "448/448 [==============================] - 57s 127ms/step - loss: 1.3985 - accuracy: 0.4574 - val_loss: 1.4014 - val_accuracy: 0.4751\n",
            "Epoch 18/120\n",
            "448/448 [==============================] - 57s 127ms/step - loss: 1.3875 - accuracy: 0.4611 - val_loss: 1.4251 - val_accuracy: 0.4433\n",
            "Epoch 19/120\n",
            "448/448 [==============================] - 55s 123ms/step - loss: 1.3945 - accuracy: 0.4660 - val_loss: 1.6159 - val_accuracy: 0.4193\n",
            "Epoch 20/120\n",
            "448/448 [==============================] - 55s 123ms/step - loss: 1.3700 - accuracy: 0.4765 - val_loss: 1.4209 - val_accuracy: 0.4664\n",
            "Epoch 21/120\n",
            "448/448 [==============================] - 57s 127ms/step - loss: 1.3372 - accuracy: 0.4948 - val_loss: 1.3853 - val_accuracy: 0.4522\n",
            "Epoch 22/120\n",
            "448/448 [==============================] - 55s 123ms/step - loss: 1.3232 - accuracy: 0.4942 - val_loss: 2.2186 - val_accuracy: 0.4171\n",
            "Epoch 23/120\n",
            "448/448 [==============================] - 55s 123ms/step - loss: 1.3353 - accuracy: 0.4907 - val_loss: 2.3423 - val_accuracy: 0.3993\n",
            "Epoch 24/120\n",
            "448/448 [==============================] - 55s 123ms/step - loss: 1.3010 - accuracy: 0.5020 - val_loss: 1.5865 - val_accuracy: 0.4458\n",
            "Epoch 25/120\n",
            "448/448 [==============================] - 55s 123ms/step - loss: 1.3284 - accuracy: 0.4956 - val_loss: 1.3087 - val_accuracy: 0.4962\n",
            "Epoch 26/120\n",
            "448/448 [==============================] - 57s 127ms/step - loss: 1.3325 - accuracy: 0.4875 - val_loss: 1.2963 - val_accuracy: 0.5230\n",
            "Epoch 27/120\n",
            "448/448 [==============================] - 55s 123ms/step - loss: 1.3193 - accuracy: 0.4954 - val_loss: 1.3016 - val_accuracy: 0.5174\n",
            "Epoch 28/120\n",
            "448/448 [==============================] - 57s 127ms/step - loss: 1.2681 - accuracy: 0.5086 - val_loss: 1.4379 - val_accuracy: 0.4857\n",
            "Epoch 29/120\n",
            "448/448 [==============================] - 57s 127ms/step - loss: 1.2429 - accuracy: 0.5242 - val_loss: 1.3481 - val_accuracy: 0.5021\n",
            "Epoch 30/120\n",
            "448/448 [==============================] - 55s 122ms/step - loss: 1.2695 - accuracy: 0.5135 - val_loss: 1.3237 - val_accuracy: 0.5169\n",
            "Epoch 31/120\n",
            "448/448 [==============================] - 55s 123ms/step - loss: 1.2328 - accuracy: 0.5286 - val_loss: 1.2844 - val_accuracy: 0.5155\n",
            "Epoch 32/120\n",
            "448/448 [==============================] - 55s 123ms/step - loss: 1.2372 - accuracy: 0.5235 - val_loss: 1.2678 - val_accuracy: 0.5272\n",
            "Epoch 33/120\n",
            "448/448 [==============================] - 55s 123ms/step - loss: 1.2369 - accuracy: 0.5290 - val_loss: 1.4736 - val_accuracy: 0.5121\n",
            "Epoch 34/120\n",
            "448/448 [==============================] - 57s 127ms/step - loss: 1.2406 - accuracy: 0.5283 - val_loss: 1.3696 - val_accuracy: 0.5065\n",
            "Epoch 35/120\n",
            "448/448 [==============================] - 55s 123ms/step - loss: 1.2333 - accuracy: 0.5262 - val_loss: 1.1868 - val_accuracy: 0.5545\n",
            "Epoch 36/120\n",
            "448/448 [==============================] - 57s 127ms/step - loss: 1.2181 - accuracy: 0.5448 - val_loss: 1.1916 - val_accuracy: 0.5620\n",
            "Epoch 37/120\n",
            "448/448 [==============================] - 57s 127ms/step - loss: 1.2181 - accuracy: 0.5421 - val_loss: 1.1896 - val_accuracy: 0.5425\n",
            "Epoch 38/120\n",
            "448/448 [==============================] - 55s 123ms/step - loss: 1.2300 - accuracy: 0.5312 - val_loss: 1.1997 - val_accuracy: 0.5464\n",
            "Epoch 39/120\n",
            "448/448 [==============================] - 55s 123ms/step - loss: 1.1557 - accuracy: 0.5631 - val_loss: 1.2003 - val_accuracy: 0.5397\n",
            "Epoch 40/120\n",
            "448/448 [==============================] - 57s 127ms/step - loss: 1.2164 - accuracy: 0.5452 - val_loss: 1.2183 - val_accuracy: 0.5403\n",
            "Epoch 41/120\n",
            "448/448 [==============================] - 55s 123ms/step - loss: 1.1901 - accuracy: 0.5450 - val_loss: 1.2803 - val_accuracy: 0.5339\n",
            "Epoch 42/120\n",
            "448/448 [==============================] - 55s 123ms/step - loss: 1.1837 - accuracy: 0.5506 - val_loss: 1.1642 - val_accuracy: 0.5639\n",
            "Epoch 43/120\n",
            "448/448 [==============================] - 57s 127ms/step - loss: 1.1620 - accuracy: 0.5520 - val_loss: 1.1567 - val_accuracy: 0.5578\n",
            "Epoch 44/120\n",
            "448/448 [==============================] - 55s 123ms/step - loss: 1.1560 - accuracy: 0.5588 - val_loss: 1.1663 - val_accuracy: 0.5578\n",
            "Epoch 45/120\n",
            "448/448 [==============================] - 55s 123ms/step - loss: 1.1430 - accuracy: 0.5637 - val_loss: 1.1175 - val_accuracy: 0.5748\n",
            "Epoch 46/120\n",
            "448/448 [==============================] - 57s 127ms/step - loss: 1.1157 - accuracy: 0.5742 - val_loss: 1.2817 - val_accuracy: 0.5336\n",
            "Epoch 47/120\n",
            "448/448 [==============================] - 55s 124ms/step - loss: 1.1465 - accuracy: 0.5677 - val_loss: 1.1695 - val_accuracy: 0.5589\n",
            "Epoch 48/120\n",
            "448/448 [==============================] - 55s 123ms/step - loss: 1.1542 - accuracy: 0.5632 - val_loss: 1.1574 - val_accuracy: 0.5659\n",
            "Epoch 49/120\n",
            "448/448 [==============================] - 55s 123ms/step - loss: 1.2015 - accuracy: 0.5493 - val_loss: 1.2983 - val_accuracy: 0.5325\n",
            "Epoch 50/120\n",
            "448/448 [==============================] - 57s 127ms/step - loss: 1.1615 - accuracy: 0.5614 - val_loss: 1.2321 - val_accuracy: 0.5369\n",
            "Epoch 51/120\n",
            "448/448 [==============================] - 55s 123ms/step - loss: 1.1549 - accuracy: 0.5641 - val_loss: 1.1197 - val_accuracy: 0.5770\n",
            "Epoch 52/120\n",
            "448/448 [==============================] - 57s 128ms/step - loss: 1.2271 - accuracy: 0.5388 - val_loss: 1.2017 - val_accuracy: 0.5375\n",
            "Epoch 53/120\n",
            "448/448 [==============================] - 57s 128ms/step - loss: 1.1613 - accuracy: 0.5594 - val_loss: 1.1091 - val_accuracy: 0.5804\n",
            "Epoch 54/120\n",
            "448/448 [==============================] - 58s 129ms/step - loss: 1.1242 - accuracy: 0.5761 - val_loss: 1.1163 - val_accuracy: 0.5751\n",
            "Epoch 55/120\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 1.0979 - accuracy: 0.5835 - val_loss: 1.0961 - val_accuracy: 0.5840\n",
            "Epoch 56/120\n",
            "448/448 [==============================] - 56s 124ms/step - loss: 1.0876 - accuracy: 0.5862 - val_loss: 1.0980 - val_accuracy: 0.5840\n",
            "Epoch 57/120\n",
            "448/448 [==============================] - 56s 124ms/step - loss: 1.0904 - accuracy: 0.5893 - val_loss: 1.1263 - val_accuracy: 0.5756\n",
            "Epoch 58/120\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 1.0786 - accuracy: 0.5890 - val_loss: 1.3589 - val_accuracy: 0.5467\n",
            "Epoch 59/120\n",
            "448/448 [==============================] - 57s 128ms/step - loss: 1.0879 - accuracy: 0.5884 - val_loss: 1.1293 - val_accuracy: 0.5712\n",
            "Epoch 60/120\n",
            "448/448 [==============================] - 56s 124ms/step - loss: 1.0788 - accuracy: 0.5881 - val_loss: 1.0777 - val_accuracy: 0.5949\n",
            "Epoch 61/120\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 1.0784 - accuracy: 0.5883 - val_loss: 1.1168 - val_accuracy: 0.5701\n",
            "Epoch 62/120\n",
            "448/448 [==============================] - 58s 129ms/step - loss: 1.1583 - accuracy: 0.5668 - val_loss: 1.0969 - val_accuracy: 0.5929\n",
            "Epoch 63/120\n",
            "448/448 [==============================] - 56s 124ms/step - loss: 1.0910 - accuracy: 0.5883 - val_loss: 1.1325 - val_accuracy: 0.5751\n",
            "Epoch 64/120\n",
            "448/448 [==============================] - 56s 124ms/step - loss: 1.0900 - accuracy: 0.5921 - val_loss: 1.1199 - val_accuracy: 0.5731\n",
            "Epoch 65/120\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 1.0597 - accuracy: 0.5984 - val_loss: 1.2340 - val_accuracy: 0.5436\n",
            "Epoch 66/120\n",
            "448/448 [==============================] - 56s 124ms/step - loss: 1.0685 - accuracy: 0.5940 - val_loss: 1.0785 - val_accuracy: 0.5893\n",
            "Epoch 67/120\n",
            "448/448 [==============================] - 58s 128ms/step - loss: 1.0325 - accuracy: 0.6099 - val_loss: 1.1047 - val_accuracy: 0.5854\n",
            "Epoch 68/120\n",
            "448/448 [==============================] - 56s 124ms/step - loss: 1.0681 - accuracy: 0.5981 - val_loss: 1.1052 - val_accuracy: 0.5768\n",
            "Epoch 69/120\n",
            "448/448 [==============================] - 57s 128ms/step - loss: 1.0621 - accuracy: 0.6003 - val_loss: 1.1389 - val_accuracy: 0.5871\n",
            "Epoch 70/120\n",
            "448/448 [==============================] - 56s 124ms/step - loss: 1.0950 - accuracy: 0.5887 - val_loss: 1.4402 - val_accuracy: 0.4575\n",
            "Epoch 71/120\n",
            "448/448 [==============================] - 56s 124ms/step - loss: 1.2054 - accuracy: 0.5429 - val_loss: 1.2157 - val_accuracy: 0.5740\n",
            "Epoch 72/120\n",
            "448/448 [==============================] - 56s 124ms/step - loss: 1.0660 - accuracy: 0.5976 - val_loss: 1.0717 - val_accuracy: 0.5857\n",
            "Epoch 73/120\n",
            "448/448 [==============================] - 56s 124ms/step - loss: 1.0483 - accuracy: 0.6013 - val_loss: 1.1068 - val_accuracy: 0.5890\n",
            "Epoch 74/120\n",
            "448/448 [==============================] - 56s 124ms/step - loss: 1.0222 - accuracy: 0.6124 - val_loss: 1.0786 - val_accuracy: 0.5971\n",
            "Epoch 75/120\n",
            "448/448 [==============================] - 58s 129ms/step - loss: 1.0155 - accuracy: 0.6206 - val_loss: 1.1256 - val_accuracy: 0.5709\n",
            "Epoch 76/120\n",
            "448/448 [==============================] - 58s 128ms/step - loss: 1.0351 - accuracy: 0.6133 - val_loss: 1.0484 - val_accuracy: 0.5988\n",
            "Epoch 77/120\n",
            "448/448 [==============================] - 56s 124ms/step - loss: 1.0258 - accuracy: 0.6123 - val_loss: 1.0886 - val_accuracy: 0.5974\n",
            "Epoch 78/120\n",
            "448/448 [==============================] - 56s 124ms/step - loss: 1.0155 - accuracy: 0.6106 - val_loss: 1.0575 - val_accuracy: 0.5968\n",
            "Epoch 79/120\n",
            "448/448 [==============================] - 56s 124ms/step - loss: 1.0170 - accuracy: 0.6190 - val_loss: 1.0541 - val_accuracy: 0.6080\n",
            "Epoch 80/120\n",
            "448/448 [==============================] - 56s 124ms/step - loss: 1.0400 - accuracy: 0.6105 - val_loss: 1.0729 - val_accuracy: 0.6004\n",
            "Epoch 81/120\n",
            "448/448 [==============================] - 58s 128ms/step - loss: 1.0117 - accuracy: 0.6178 - val_loss: 1.0331 - val_accuracy: 0.6147\n",
            "Epoch 82/120\n",
            "448/448 [==============================] - 56s 124ms/step - loss: 1.0002 - accuracy: 0.6305 - val_loss: 1.0457 - val_accuracy: 0.6024\n",
            "Epoch 83/120\n",
            "448/448 [==============================] - 58s 129ms/step - loss: 1.0069 - accuracy: 0.6180 - val_loss: 1.0750 - val_accuracy: 0.5991\n",
            "Epoch 84/120\n",
            "448/448 [==============================] - 56s 124ms/step - loss: 1.0105 - accuracy: 0.6197 - val_loss: 1.1355 - val_accuracy: 0.5759\n",
            "Epoch 85/120\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 1.0172 - accuracy: 0.6233 - val_loss: 1.0561 - val_accuracy: 0.6021\n",
            "Epoch 86/120\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 1.0170 - accuracy: 0.6166 - val_loss: 1.0809 - val_accuracy: 0.5918\n",
            "Epoch 87/120\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 1.0015 - accuracy: 0.6289 - val_loss: 1.0591 - val_accuracy: 0.6016\n",
            "Epoch 88/120\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 0.9989 - accuracy: 0.6283 - val_loss: 1.0860 - val_accuracy: 0.6060\n",
            "Epoch 89/120\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 1.0149 - accuracy: 0.6191 - val_loss: 1.0520 - val_accuracy: 0.5988\n",
            "Epoch 90/120\n",
            "448/448 [==============================] - 58s 129ms/step - loss: 0.9690 - accuracy: 0.6412 - val_loss: 1.0294 - val_accuracy: 0.6160\n",
            "Epoch 91/120\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 0.9757 - accuracy: 0.6359 - val_loss: 1.1019 - val_accuracy: 0.5982\n",
            "Epoch 92/120\n",
            "448/448 [==============================] - 58s 129ms/step - loss: 0.9757 - accuracy: 0.6376 - val_loss: 1.0732 - val_accuracy: 0.5926\n",
            "Epoch 93/120\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 0.9719 - accuracy: 0.6373 - val_loss: 1.0435 - val_accuracy: 0.6099\n",
            "Epoch 94/120\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 0.9609 - accuracy: 0.6418 - val_loss: 1.1039 - val_accuracy: 0.5860\n",
            "Epoch 95/120\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 0.9517 - accuracy: 0.6383 - val_loss: 1.0454 - val_accuracy: 0.6055\n",
            "Epoch 96/120\n",
            "448/448 [==============================] - 57s 128ms/step - loss: 0.9629 - accuracy: 0.6396 - val_loss: 1.0843 - val_accuracy: 0.5952\n",
            "Epoch 97/120\n",
            "448/448 [==============================] - 58s 129ms/step - loss: 0.9761 - accuracy: 0.6292 - val_loss: 1.0416 - val_accuracy: 0.6077\n",
            "Epoch 98/120\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 0.9630 - accuracy: 0.6418 - val_loss: 1.0283 - val_accuracy: 0.6121\n",
            "Epoch 99/120\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 0.9521 - accuracy: 0.6414 - val_loss: 1.0500 - val_accuracy: 0.6046\n",
            "Epoch 100/120\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 0.9524 - accuracy: 0.6407 - val_loss: 1.0716 - val_accuracy: 0.6013\n",
            "Epoch 101/120\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 0.9421 - accuracy: 0.6538 - val_loss: 1.0464 - val_accuracy: 0.6041\n",
            "Epoch 102/120\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 0.9527 - accuracy: 0.6461 - val_loss: 1.0725 - val_accuracy: 0.6063\n",
            "Epoch 103/120\n",
            "448/448 [==============================] - 58s 129ms/step - loss: 0.9544 - accuracy: 0.6405 - val_loss: 1.0853 - val_accuracy: 0.5921\n",
            "Epoch 104/120\n",
            "448/448 [==============================] - 58s 129ms/step - loss: 0.9458 - accuracy: 0.6410 - val_loss: 1.0370 - val_accuracy: 0.6155\n",
            "Epoch 105/120\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 0.9443 - accuracy: 0.6502 - val_loss: 1.0403 - val_accuracy: 0.6085\n",
            "Epoch 106/120\n",
            "448/448 [==============================] - 58s 129ms/step - loss: 0.9396 - accuracy: 0.6517 - val_loss: 1.1070 - val_accuracy: 0.5899\n",
            "Epoch 107/120\n",
            "448/448 [==============================] - 58s 129ms/step - loss: 0.9146 - accuracy: 0.6549 - val_loss: 1.0426 - val_accuracy: 0.6099\n",
            "Epoch 108/120\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 0.9114 - accuracy: 0.6602 - val_loss: 1.0332 - val_accuracy: 0.6041\n",
            "Epoch 109/120\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 0.9282 - accuracy: 0.6502 - val_loss: 1.0124 - val_accuracy: 0.6202\n",
            "Epoch 110/120\n",
            "448/448 [==============================] - 58s 129ms/step - loss: 0.9356 - accuracy: 0.6568 - val_loss: 0.9977 - val_accuracy: 0.6227\n",
            "Epoch 111/120\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 0.9214 - accuracy: 0.6539 - val_loss: 1.0201 - val_accuracy: 0.6227\n",
            "Epoch 112/120\n",
            "448/448 [==============================] - 58s 129ms/step - loss: 0.8945 - accuracy: 0.6640 - val_loss: 1.0186 - val_accuracy: 0.6149\n",
            "Epoch 113/120\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 0.9329 - accuracy: 0.6455 - val_loss: 1.0415 - val_accuracy: 0.6010\n",
            "Epoch 114/120\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 0.9119 - accuracy: 0.6604 - val_loss: 1.0019 - val_accuracy: 0.6241\n",
            "Epoch 115/120\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 0.9018 - accuracy: 0.6697 - val_loss: 1.0219 - val_accuracy: 0.6211\n",
            "Epoch 116/120\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 0.9397 - accuracy: 0.6422 - val_loss: 1.0143 - val_accuracy: 0.6216\n",
            "Epoch 117/120\n",
            "448/448 [==============================] - 58s 129ms/step - loss: 0.9427 - accuracy: 0.6505 - val_loss: 1.0399 - val_accuracy: 0.6202\n",
            "Epoch 118/120\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 0.9271 - accuracy: 0.6591 - val_loss: 1.0450 - val_accuracy: 0.6186\n",
            "Epoch 119/120\n",
            "448/448 [==============================] - 58s 129ms/step - loss: 0.9010 - accuracy: 0.6601 - val_loss: 1.0502 - val_accuracy: 0.6216\n",
            "Epoch 120/120\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 0.8924 - accuracy: 0.6664 - val_loss: 1.0864 - val_accuracy: 0.6213\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "cZvluWhSRkq4",
        "outputId": "3dae9a2b-1f4d-44f4-c103-cf910eee84a1"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "model.save('/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50oriz_SEED_SP4_120_Augg4.h5')\n",
        "\n",
        "#ffddfsgyghuuihtftfdd\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "num_epochs = range(len(accuracy))\n",
        "plt.plot(num_epochs, accuracy, 'r', label='Training acc')\n",
        "plt.plot(num_epochs, val_accuracy, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(num_epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(num_epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Pzozx-30LSe",
        "outputId": "b9236c91-0cf5-4e42-9766-cbdbddd61a22"
      },
      "source": [
        "testloss = model.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "trainloss = model.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(trainloss[0]))\n",
        "print(\"Train Acc: \" + str(trainloss[1]))\n",
        "vallosz = model.evaluate(x_val, y_val) \n",
        "print(\"val Loss \" + str(vallosz[0]))\n",
        "print(\"val Acc: \" + str(vallosz[1]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 4s 32ms/step - loss: 1.1916 - accuracy: 0.6336\n",
            "Test Loss 1.1916258335113525\n",
            "Test Acc: 0.6336026787757874\n",
            "898/898 [==============================] - 28s 31ms/step - loss: 0.8572 - accuracy: 0.6838\n",
            "Train Loss 0.8572058081626892\n",
            "Train Acc: 0.6837925314903259\n",
            "113/113 [==============================] - 4s 32ms/step - loss: 1.0864 - accuracy: 0.6213\n",
            "val Loss 1.086403250694275\n",
            "val Acc: 0.6213430166244507\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ6YCHax59vt",
        "outputId": "2a96b876-82bf-4d80-fbd5-7b7fe0397a14"
      },
      "source": [
        "from keras.models import load_model\n",
        "model_load = load_model('/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50oriz_SEED_SP4_120_Augg4.h5')\n",
        "\n",
        "model_load.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50ori\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2D)  (None, 54, 54, 1)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 24, 24, 64)   3200        zero_padding2d[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 24, 24, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 24, 24, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 11, 11, 64)   0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 11, 11, 64)   4160        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 11, 11, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 11, 11, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 11, 11, 256)  16640       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 11, 11, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 11, 11, 256)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 11, 11, 256)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 11, 11, 64)   16448       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 11, 11, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 11, 11, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 11, 11, 256)  0           activation_3[0][0]               \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 11, 11, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 11, 11, 64)   16448       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 11, 11, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 11, 11, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 11, 11, 256)  0           activation_6[0][0]               \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 11, 11, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 6, 6, 128)    32896       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 6, 6, 128)    0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 6, 6, 128)    0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 6, 6, 512)    131584      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 6, 6, 512)    2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 6, 6, 512)    0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 6, 6, 512)    0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 6, 6, 128)    0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 6, 6, 128)    0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 6, 6, 512)    0           activation_12[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 6, 6, 512)    0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 6, 6, 128)    0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 6, 6, 128)    0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 6, 6, 512)    0           activation_15[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 6, 6, 512)    0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 6, 6, 128)    0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 6, 6, 128)    0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 6, 6, 512)    0           activation_18[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 6, 6, 512)    0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 3, 3, 256)    131328      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 3, 3, 256)    0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 3, 3, 256)    0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 3, 3, 1024)   525312      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 3, 3, 1024)   4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 3, 3, 1024)   0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 3, 3, 1024)   0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 3, 3, 256)    0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 3, 3, 256)    0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 3, 3, 1024)   0           activation_24[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 3, 3, 1024)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 3, 3, 256)    0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 3, 3, 256)    0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 3, 3, 1024)   0           activation_27[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 3, 3, 1024)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 3, 3, 256)    0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 3, 3, 256)    0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 3, 3, 1024)   0           activation_30[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 3, 3, 1024)   0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 3, 3, 256)    0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 3, 3, 256)    0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 3, 3, 1024)   0           activation_33[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 3, 3, 1024)   0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 3, 3, 256)    0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 3, 3, 256)    0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 3, 3, 1024)   0           activation_36[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 3, 3, 1024)   0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 2, 2, 512)    524800      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 2, 2, 2048)   2099200     activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 2, 2, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 2, 2, 2048)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 2, 2, 2048)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 2, 2, 2048)   0           activation_42[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 2, 2, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 2, 2, 2048)   0           activation_45[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 2, 2, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 2048)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            14343       flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,595,783\n",
            "Trainable params: 23,542,663\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fpz7ehkO6Cat",
        "outputId": "3e0636bc-e424-4675-c33e-cfe55d3b3235"
      },
      "source": [
        "testloss = model_load.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "\n",
        "trainloss = model_load.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(trainloss[0]))\n",
        "print(\"Train Acc: \" + str(trainloss[1]))\n",
        "\n",
        "vallosz = model_load.evaluate(x_val, y_val) \n",
        "print(\"val Loss \" + str(vallosz[0]))\n",
        "print(\"val Acc: \" + str(vallosz[1]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 9s 32ms/step - loss: 1.1916 - accuracy: 0.6336\n",
            "Test Loss 1.1916258335113525\n",
            "Test Acc: 0.6336026787757874\n",
            "898/898 [==============================] - 28s 31ms/step - loss: 0.8572 - accuracy: 0.6838\n",
            "Train Loss 0.8572058081626892\n",
            "Train Acc: 0.6837925314903259\n",
            "113/113 [==============================] - 4s 31ms/step - loss: 1.0864 - accuracy: 0.6213\n",
            "val Loss 1.086403250694275\n",
            "val Acc: 0.6213430166244507\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDwmru9p0gyj",
        "outputId": "88918784-376e-4965-8be4-cc22ed0ec8b0"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "#y_pred = model_load.predict(xtest)g\n",
        "\n",
        "test_prob = model_load.predict(xtest)\n",
        "test_pred = np.argmax(test_prob, axis=1)\n",
        "test_accuracy = np.mean(test_pred == ytest)\n",
        "\n",
        "print(test_accuracy)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6336026748397883\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpHHR7Q6y9uU"
      },
      "source": [
        "emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "-0ha8DW80028",
        "outputId": "e3953cb9-212a-437f-cdb5-c5a506e9a467"
      },
      "source": [
        "conf_mat = confusion_matrix(ytest, test_pred)\n",
        "##\n",
        "pd.DataFrame(conf_mat, columns=emotions.values(), index=emotions.values())\n",
        "\n",
        "fig, ax = plot_confusion_matrix(conf_mat=conf_mat,show_normed=True,show_absolute=False,figsize=(9, 9))\n",
        "fig.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDC2YQsIywNO",
        "outputId": "a309ff3e-b358-4ec2-911c-89a6c0059fcc"
      },
      "source": [
        "print(classification_report(ytest, test_pred, target_names=emotions.values()))\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry       0.54      0.59      0.56       480\n",
            "     Disgust       0.83      0.42      0.56        60\n",
            "        Fear       0.53      0.37      0.43       515\n",
            "       Happy       0.81      0.86      0.84       883\n",
            "         Sad       0.59      0.42      0.49       597\n",
            "    Surprise       0.68      0.80      0.74       397\n",
            "     Neutral       0.52      0.69      0.60       657\n",
            "\n",
            "    accuracy                           0.63      3589\n",
            "   macro avg       0.65      0.59      0.60      3589\n",
            "weighted avg       0.63      0.63      0.62      3589\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xfSSuZCuutf",
        "outputId": "a135ff76-f577-4614-f706-230ba80f73c0"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "dataread =pd.read_csv('/content/drive/MyDrive/Fer2013_backup/backUpfer2013.csv')\n",
        "\n",
        "#print(dataread.duplicated().value_counts)\n",
        "#(df[df.duplicated()])s\n",
        "\"\"\"dataread['Usage'].value_counts()\n",
        "dataread['emotion'].value_counts()\n",
        "\"\"\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    8989\n",
              "6    6198\n",
              "4    6077\n",
              "2    5121\n",
              "0    4953\n",
              "5    4002\n",
              "1     547\n",
              "Name: emotion, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncIVy0SZ_WgH"
      },
      "source": [
        "from numpy import expand_dims\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from matplotlib import pyplot\n",
        "#meload gambar\n",
        "img = load_img('')\n",
        "\n",
        "data = img_to_array(img)\n",
        "#meningkatkan dimension ke satu sampel\n",
        "sampels = \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2bP0roK-WpE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
