{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER2013_Resnet50_120oriz_SP5_AUGG5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "18Zj-Yp1YlH0QWcuD4e7ugx8zCCcRS0jg",
      "authorship_tag": "ABX9TyM251On+hmEJDYlAaC0ZlM/"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eWeoD7MRFlN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cc395a9-581f-4bfe-ba06-0db459ea75f5"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "inputFolder = '/content/drive/MyDrive/Fer2013_backup/' \n",
        "for root, directories, filenames in os.walk(inputFolder): \n",
        "    for filename in filenames: print(os.path.join(root,filename))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Fer2013_backup/backUpfer2013.csv\n",
            "/content/drive/MyDrive/Fer2013_backup/icml_face_data.csv\n",
            "/content/drive/MyDrive/Fer2013_backup/test.csv\n",
            "/content/drive/MyDrive/Fer2013_backup/train.csv\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/best_model_resnet50_modelB2_170false.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/best_model_resnet50_modelD2_170false.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50Scracth_tipe7.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50Scracth_tipe8.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50oriAUGScracthSGD2.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50oriAUGScracthSGD3.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50AUGScracthadam2.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50AUGScracthAdam1sp.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50AUGScracthSGD4sp.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50AUGScracthSGD5sp.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50AUGScracthSGD6sp.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP1_30_noAug1.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP2_30_noAug2.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP3_30_noAug3.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP4_30_noAug4.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP5_30_noAug5.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP6_30_noAug6.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP1_90_noAug1.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP2_90_noAug2.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP3_90_noAug3.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP4_90_noAug4.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP4_60_noAug1.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP5_90_noAug5.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP1_60_noAug1.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP2_60_noAug2.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP3_60_noAug3.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP4_60_noAug4.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP5_60_noAug5.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50edit_SEED_SP6_60_noAug6.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50oriz_SEED_SP6_60_Augg6.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/fixcheckpoint/Best_Model_resnet50oriAUGScracthSGD2.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH8iEUJiRQS7",
        "outputId": "3a5d812f-c34d-4571-c622-382301d131ce"
      },
      "source": [
        "%cd /content/drive/MyDrive/Fer2013_backup/\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Fer2013_backup\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqZOFwxxRQaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4055a38-c1da-4117-d38a-71e70d2257e7"
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:400: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUX-dSAgRQh4"
      },
      "source": [
        "#Define the identity block helper function.\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "   \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbdQH3mkRQra"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path \n",
        "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b',padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33XH76oKRQvh"
      },
      "source": [
        "\"\"\"def ResNet50(input_shape = (48,48,1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    #X = ZeroPadding2D((1, 1))(X_input)\n",
        "    X = X_input\n",
        "    # Stage 1\n",
        "\n",
        "    X = Conv2D(8, (3, 3), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # removed maxpool\n",
        "    #X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='c')\n",
        "\n",
        "\n",
        "    # Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [64,64,256], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL . \n",
        "    X = AveragePooling2D((2,2), name='avg_pool')(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(512, activation = 'relu', name='fc1024' , kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWuYK_f2zGJF"
      },
      "source": [
        "def ResNet50ori(input_shape = (48, 48, 1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50ori')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QQOxN2cRQy3"
      },
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        " \n",
        "dataset_path = '/content/drive/MyDrive/Fer2013_backup/backUpfer2013.csv'\n",
        "image_size=(48,48)\n",
        "\n",
        "def load_fer2013():\n",
        "    data = pd.read_csv(dataset_path)\n",
        "    data = (data[data['pixels'].notnull()])\n",
        "    pixels = data['pixels'].tolist()\n",
        "    width, height = 48, 48\n",
        "    faces = []\n",
        "    for pixel_sequence in pixels:\n",
        "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "        face = np.asarray(face).reshape(width, height)\n",
        "        face = cv2.resize(face.astype('uint8'),image_size)\n",
        "        faces.append(face.astype('float32'))\n",
        "    faces = np.asarray(faces)\n",
        "    faces = np.expand_dims(faces, -1)\n",
        "    emotions = (data['emotion'])#.values\n",
        "    return faces, emotions\n",
        " \n",
        "def preprocess_input(x, v2=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if v2:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x\n",
        " \n",
        "faces, emotions = load_fer2013()\n",
        "faces = preprocess_input(faces)\n",
        "#xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
        "#Data Augumentationfgf\n",
        "data_generator = ImageDataGenerator(\n",
        "                        rotation_range=10,\n",
        "                        shear_range = 10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True,\n",
        "                        )\n",
        "#data_generator = ImageDataGenerator ()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "8zCkwVdnKTm5",
        "outputId": "ccf1dea4-dda3-4dfb-9952-ac859f70205c"
      },
      "source": [
        "train_ratio = 0.80\n",
        "validation_ratio = 0.10\n",
        "test_ratio = 0.10\n",
        "\n",
        "# train is now 75% of the entire data set\n",
        "# the _junk suffix means that we drop that variable completely # the _junk suffix means that we drop that variable completely\n",
        "#x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=1 - train_ratio,random_state=42)\n",
        "\n",
        "# test is now 10% of the initial data set\n",
        "# validation is now 15% of the initial data set\n",
        "#x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "x_val, xtest, y_val, ytest = train_test_split(xtest, ytest, test_size=test_ratio/(test_ratio + validation_ratio), random_state=42) \n",
        "\n",
        "#print(xtrain, x_val, xtest)\n",
        "\n",
        "\"\"\"X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2\"\"\""
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\\n\\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t--o7TREKTu2",
        "outputId": "d4533c27-c01b-435a-f614-651aef827265"
      },
      "source": [
        "print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validasi (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "test (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "train (28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ofOj3-fRREN"
      },
      "source": [
        "#hyperparameter and callback\n",
        "batch_size = 64\n",
        "num_epochs = 120\n",
        "input_shape = (48, 48, 1)\n",
        "num_classes = 7\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXikieAnRbYs"
      },
      "source": [
        "#Compile the model.\n",
        "\n",
        "\n",
        "from keras.optimizers import Adam, SGD\n",
        "model = ResNet50ori(input_shape = (48, 48, 1), classes = 7)\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer= optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nefC0ZE8RgX5",
        "outputId": "4b1b8895-7dcb-4bbb-bfa1-e8c4674c631d"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50ori\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 54, 54, 1)    0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 24, 24, 64)   3200        zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 24, 24, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 24, 24, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 11, 11, 64)   0           activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 11, 11, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 11, 11, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 11, 11, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 11, 11, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 11, 11, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 11, 11, 256)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 11, 11, 256)  0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 11, 11, 64)   16448       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 11, 11, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 11, 11, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 11, 11, 256)  0           activation_52[0][0]              \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 11, 11, 256)  0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 11, 11, 64)   16448       activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 11, 11, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 11, 11, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 11, 11, 256)  0           activation_55[0][0]              \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 11, 11, 256)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 6, 6, 128)    32896       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 6, 6, 128)    0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 6, 6, 128)    0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 6, 6, 512)    131584      activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 6, 6, 512)    2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 6, 6, 512)    0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 6, 6, 512)    0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 6, 6, 128)    0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 6, 6, 128)    0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 6, 6, 512)    0           activation_61[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 6, 6, 512)    0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 6, 6, 128)    0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 6, 6, 128)    0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 6, 6, 512)    0           activation_64[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 6, 6, 512)    0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 6, 6, 128)    0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 6, 6, 128)    0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 6, 6, 512)    0           activation_67[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 6, 6, 512)    0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 3, 3, 256)    131328      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 256)    0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 3, 3, 256)    0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 3, 3, 1024)   525312      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 3, 3, 1024)   4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 3, 3, 1024)   0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 3, 3, 1024)   0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 3, 3, 256)    0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 256)    0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 3, 3, 1024)   0           activation_73[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 1024)   0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 256)    0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 256)    0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 3, 3, 1024)   0           activation_76[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 1024)   0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 256)    0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 256)    0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 3, 3, 1024)   0           activation_79[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 1024)   0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 256)    0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 256)    0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 3, 3, 1024)   0           activation_82[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 1024)   0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 256)    0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 256)    0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 3, 3, 1024)   0           activation_85[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 1024)   0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 2, 2, 512)    524800      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 2, 2, 2048)   2099200     activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 2, 2, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 2, 2, 2048)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 2, 2, 2048)   0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 2, 2, 2048)   0           activation_91[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 2, 2, 2048)   0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 2, 2, 2048)   0           activation_94[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 2, 2, 2048)   0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 2048)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            14343       flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 23,595,783\n",
            "Trainable params: 23,542,663\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_tXyjuSz_IP",
        "outputId": "91de3fa8-0880-4e67-c300-9b1725bcddbe"
      },
      "source": [
        "history = model.fit(\n",
        "    data_generator.flow(xtrain, ytrain,),\n",
        "    steps_per_epoch=len(xtrain) / batch_size,\n",
        "    epochs=num_epochs,\n",
        "    shuffle=False,\n",
        "    verbose=1,\n",
        "    validation_data= (x_val,y_val))\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/120\n",
            "448/448 [==============================] - 40s 64ms/step - loss: 2.1910 - accuracy: 0.2133 - val_loss: 1.8353 - val_accuracy: 0.1970\n",
            "Epoch 2/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 1.9320 - accuracy: 0.2507 - val_loss: 2.0087 - val_accuracy: 0.2853\n",
            "Epoch 3/120\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 1.8411 - accuracy: 0.2896 - val_loss: 2.2545 - val_accuracy: 0.3190\n",
            "Epoch 4/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 1.7660 - accuracy: 0.3214 - val_loss: 1.9929 - val_accuracy: 0.3530\n",
            "Epoch 5/120\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.7388 - accuracy: 0.3374 - val_loss: 1.8625 - val_accuracy: 0.3614\n",
            "Epoch 6/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 1.6921 - accuracy: 0.3566 - val_loss: 1.9847 - val_accuracy: 0.3642\n",
            "Epoch 7/120\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.6630 - accuracy: 0.3642 - val_loss: 1.7811 - val_accuracy: 0.4021\n",
            "Epoch 8/120\n",
            "448/448 [==============================] - 27s 59ms/step - loss: 1.6284 - accuracy: 0.3828 - val_loss: 1.6155 - val_accuracy: 0.3859\n",
            "Epoch 9/120\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.6047 - accuracy: 0.3909 - val_loss: 1.7411 - val_accuracy: 0.4135\n",
            "Epoch 10/120\n",
            "448/448 [==============================] - 25s 57ms/step - loss: 1.5681 - accuracy: 0.3982 - val_loss: 1.6016 - val_accuracy: 0.4366\n",
            "Epoch 11/120\n",
            "448/448 [==============================] - 25s 57ms/step - loss: 1.5562 - accuracy: 0.4173 - val_loss: 1.4805 - val_accuracy: 0.4280\n",
            "Epoch 12/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 1.5264 - accuracy: 0.4196 - val_loss: 1.7866 - val_accuracy: 0.4405\n",
            "Epoch 13/120\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 1.4999 - accuracy: 0.4382 - val_loss: 1.5698 - val_accuracy: 0.4051\n",
            "Epoch 14/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 1.4833 - accuracy: 0.4442 - val_loss: 1.5816 - val_accuracy: 0.4483\n",
            "Epoch 15/120\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.4600 - accuracy: 0.4489 - val_loss: 1.3830 - val_accuracy: 0.4581\n",
            "Epoch 16/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 1.4286 - accuracy: 0.4586 - val_loss: 1.3353 - val_accuracy: 0.4948\n",
            "Epoch 17/120\n",
            "448/448 [==============================] - 27s 60ms/step - loss: 1.3728 - accuracy: 0.4666 - val_loss: 1.3333 - val_accuracy: 0.4815\n",
            "Epoch 18/120\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.3812 - accuracy: 0.4670 - val_loss: 1.3080 - val_accuracy: 0.4904\n",
            "Epoch 19/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 1.3308 - accuracy: 0.4961 - val_loss: 1.8427 - val_accuracy: 0.4152\n",
            "Epoch 20/120\n",
            "448/448 [==============================] - 25s 57ms/step - loss: 1.3547 - accuracy: 0.4807 - val_loss: 1.3831 - val_accuracy: 0.4681\n",
            "Epoch 21/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 1.3211 - accuracy: 0.5015 - val_loss: 1.2528 - val_accuracy: 0.5104\n",
            "Epoch 22/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 1.3897 - accuracy: 0.4726 - val_loss: 1.3047 - val_accuracy: 0.4999\n",
            "Epoch 23/120\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.3015 - accuracy: 0.5095 - val_loss: 1.8006 - val_accuracy: 0.4227\n",
            "Epoch 24/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 1.3406 - accuracy: 0.4948 - val_loss: 1.2773 - val_accuracy: 0.5057\n",
            "Epoch 25/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 1.2778 - accuracy: 0.5138 - val_loss: 1.2691 - val_accuracy: 0.5116\n",
            "Epoch 26/120\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.3143 - accuracy: 0.5039 - val_loss: 1.4934 - val_accuracy: 0.4464\n",
            "Epoch 27/120\n",
            "448/448 [==============================] - 26s 59ms/step - loss: 1.3812 - accuracy: 0.4759 - val_loss: 1.2836 - val_accuracy: 0.5230\n",
            "Epoch 28/120\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.2574 - accuracy: 0.5135 - val_loss: 1.2464 - val_accuracy: 0.5258\n",
            "Epoch 29/120\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 1.2136 - accuracy: 0.5370 - val_loss: 1.2269 - val_accuracy: 0.5252\n",
            "Epoch 30/120\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 1.2230 - accuracy: 0.5363 - val_loss: 1.2575 - val_accuracy: 0.5305\n",
            "Epoch 31/120\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.2012 - accuracy: 0.5503 - val_loss: 1.9429 - val_accuracy: 0.4531\n",
            "Epoch 32/120\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.2291 - accuracy: 0.5226 - val_loss: 1.2325 - val_accuracy: 0.5288\n",
            "Epoch 33/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 1.1825 - accuracy: 0.5468 - val_loss: 1.2129 - val_accuracy: 0.5269\n",
            "Epoch 34/120\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.1842 - accuracy: 0.5434 - val_loss: 1.2221 - val_accuracy: 0.5210\n",
            "Epoch 35/120\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.1576 - accuracy: 0.5586 - val_loss: 1.1941 - val_accuracy: 0.5383\n",
            "Epoch 36/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 1.1522 - accuracy: 0.5637 - val_loss: 1.1579 - val_accuracy: 0.5503\n",
            "Epoch 37/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 1.1508 - accuracy: 0.5677 - val_loss: 1.1852 - val_accuracy: 0.5453\n",
            "Epoch 38/120\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.1468 - accuracy: 0.5687 - val_loss: 1.1489 - val_accuracy: 0.5581\n",
            "Epoch 39/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 1.1244 - accuracy: 0.5708 - val_loss: 1.1669 - val_accuracy: 0.5517\n",
            "Epoch 40/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 1.1218 - accuracy: 0.5720 - val_loss: 1.1582 - val_accuracy: 0.5639\n",
            "Epoch 41/120\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.1198 - accuracy: 0.5759 - val_loss: 1.1984 - val_accuracy: 0.5503\n",
            "Epoch 42/120\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 1.1040 - accuracy: 0.5861 - val_loss: 1.1139 - val_accuracy: 0.5743\n",
            "Epoch 43/120\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.1071 - accuracy: 0.5832 - val_loss: 1.1476 - val_accuracy: 0.5678\n",
            "Epoch 44/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 1.1079 - accuracy: 0.5794 - val_loss: 1.2129 - val_accuracy: 0.5656\n",
            "Epoch 45/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 1.0913 - accuracy: 0.5810 - val_loss: 1.1153 - val_accuracy: 0.5773\n",
            "Epoch 46/120\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.0729 - accuracy: 0.5945 - val_loss: 1.2001 - val_accuracy: 0.5536\n",
            "Epoch 47/120\n",
            "448/448 [==============================] - 25s 57ms/step - loss: 1.0922 - accuracy: 0.5880 - val_loss: 1.1337 - val_accuracy: 0.5706\n",
            "Epoch 48/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 1.0754 - accuracy: 0.5934 - val_loss: 1.1461 - val_accuracy: 0.5681\n",
            "Epoch 49/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 1.0762 - accuracy: 0.5975 - val_loss: 1.1065 - val_accuracy: 0.5871\n",
            "Epoch 50/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 1.0504 - accuracy: 0.6021 - val_loss: 1.3908 - val_accuracy: 0.4979\n",
            "Epoch 51/120\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.1314 - accuracy: 0.5828 - val_loss: 1.1248 - val_accuracy: 0.5790\n",
            "Epoch 52/120\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.0394 - accuracy: 0.6080 - val_loss: 1.0958 - val_accuracy: 0.5784\n",
            "Epoch 53/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 1.0135 - accuracy: 0.6238 - val_loss: 1.1014 - val_accuracy: 0.5848\n",
            "Epoch 54/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 1.0271 - accuracy: 0.6118 - val_loss: 1.1130 - val_accuracy: 0.5921\n",
            "Epoch 55/120\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.0096 - accuracy: 0.6146 - val_loss: 1.1188 - val_accuracy: 0.5851\n",
            "Epoch 56/120\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 1.0138 - accuracy: 0.6196 - val_loss: 1.0759 - val_accuracy: 0.5910\n",
            "Epoch 57/120\n",
            "448/448 [==============================] - 26s 59ms/step - loss: 1.0161 - accuracy: 0.6126 - val_loss: 1.1072 - val_accuracy: 0.5868\n",
            "Epoch 58/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 0.9992 - accuracy: 0.6154 - val_loss: 1.0677 - val_accuracy: 0.5991\n",
            "Epoch 59/120\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 0.9976 - accuracy: 0.6233 - val_loss: 1.2595 - val_accuracy: 0.5609\n",
            "Epoch 60/120\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 1.0057 - accuracy: 0.6224 - val_loss: 1.0717 - val_accuracy: 0.6010\n",
            "Epoch 61/120\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.0035 - accuracy: 0.6244 - val_loss: 1.3481 - val_accuracy: 0.5578\n",
            "Epoch 62/120\n",
            "448/448 [==============================] - 26s 59ms/step - loss: 0.9802 - accuracy: 0.6308 - val_loss: 1.0887 - val_accuracy: 0.5929\n",
            "Epoch 63/120\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 0.9683 - accuracy: 0.6322 - val_loss: 1.0806 - val_accuracy: 0.5946\n",
            "Epoch 64/120\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 0.9855 - accuracy: 0.6261 - val_loss: 1.0966 - val_accuracy: 0.5874\n",
            "Epoch 65/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 0.9683 - accuracy: 0.6385 - val_loss: 1.1535 - val_accuracy: 0.5821\n",
            "Epoch 66/120\n",
            "448/448 [==============================] - 27s 60ms/step - loss: 0.9569 - accuracy: 0.6494 - val_loss: 1.1384 - val_accuracy: 0.5815\n",
            "Epoch 67/120\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 0.9364 - accuracy: 0.6410 - val_loss: 1.0984 - val_accuracy: 0.5988\n",
            "Epoch 68/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 0.9785 - accuracy: 0.6304 - val_loss: 1.0781 - val_accuracy: 0.6094\n",
            "Epoch 69/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 0.9431 - accuracy: 0.6459 - val_loss: 1.1324 - val_accuracy: 0.5784\n",
            "Epoch 70/120\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 0.9447 - accuracy: 0.6474 - val_loss: 1.1072 - val_accuracy: 0.5865\n",
            "Epoch 71/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 0.9451 - accuracy: 0.6433 - val_loss: 1.0929 - val_accuracy: 0.5935\n",
            "Epoch 72/120\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 0.9202 - accuracy: 0.6539 - val_loss: 1.0515 - val_accuracy: 0.6063\n",
            "Epoch 73/120\n",
            "448/448 [==============================] - 25s 57ms/step - loss: 0.9317 - accuracy: 0.6484 - val_loss: 1.0706 - val_accuracy: 0.6041\n",
            "Epoch 74/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 0.8982 - accuracy: 0.6663 - val_loss: 1.1275 - val_accuracy: 0.5929\n",
            "Epoch 75/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 0.8945 - accuracy: 0.6612 - val_loss: 1.0807 - val_accuracy: 0.6102\n",
            "Epoch 76/120\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 0.9200 - accuracy: 0.6611 - val_loss: 1.0455 - val_accuracy: 0.6163\n",
            "Epoch 77/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 0.9056 - accuracy: 0.6596 - val_loss: 1.0940 - val_accuracy: 0.5960\n",
            "Epoch 78/120\n",
            "448/448 [==============================] - 25s 57ms/step - loss: 0.8817 - accuracy: 0.6679 - val_loss: 1.0723 - val_accuracy: 0.6057\n",
            "Epoch 79/120\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 0.8866 - accuracy: 0.6667 - val_loss: 1.1057 - val_accuracy: 0.6018\n",
            "Epoch 80/120\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 0.8953 - accuracy: 0.6590 - val_loss: 1.0661 - val_accuracy: 0.6105\n",
            "Epoch 81/120\n",
            "448/448 [==============================] - 25s 57ms/step - loss: 0.8824 - accuracy: 0.6678 - val_loss: 1.0978 - val_accuracy: 0.6049\n",
            "Epoch 82/120\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 0.8693 - accuracy: 0.6728 - val_loss: 1.0590 - val_accuracy: 0.6208\n",
            "Epoch 83/120\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 0.8659 - accuracy: 0.6743 - val_loss: 1.6261 - val_accuracy: 0.5578\n",
            "Epoch 84/120\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 0.8760 - accuracy: 0.6699 - val_loss: 1.0784 - val_accuracy: 0.6018\n",
            "Epoch 85/120\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 0.8595 - accuracy: 0.6821 - val_loss: 1.1781 - val_accuracy: 0.5868\n",
            "Epoch 86/120\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 0.8703 - accuracy: 0.6645 - val_loss: 1.0899 - val_accuracy: 0.6094\n",
            "Epoch 87/120\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 0.8317 - accuracy: 0.6918 - val_loss: 1.1445 - val_accuracy: 0.5901\n",
            "Epoch 88/120\n",
            "448/448 [==============================] - 25s 57ms/step - loss: 0.8509 - accuracy: 0.6775 - val_loss: 1.1268 - val_accuracy: 0.6057\n",
            "Epoch 89/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 0.8273 - accuracy: 0.6909 - val_loss: 1.1316 - val_accuracy: 0.5946\n",
            "Epoch 90/120\n",
            "448/448 [==============================] - 25s 57ms/step - loss: 0.8083 - accuracy: 0.6956 - val_loss: 1.0550 - val_accuracy: 0.6227\n",
            "Epoch 91/120\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 0.8250 - accuracy: 0.6929 - val_loss: 1.5294 - val_accuracy: 0.5706\n",
            "Epoch 92/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 0.8062 - accuracy: 0.6985 - val_loss: 1.0892 - val_accuracy: 0.6119\n",
            "Epoch 93/120\n",
            "448/448 [==============================] - 25s 57ms/step - loss: 0.8066 - accuracy: 0.6972 - val_loss: 1.1007 - val_accuracy: 0.6205\n",
            "Epoch 94/120\n",
            "448/448 [==============================] - 25s 57ms/step - loss: 0.7965 - accuracy: 0.6965 - val_loss: 1.0978 - val_accuracy: 0.6085\n",
            "Epoch 95/120\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 0.7839 - accuracy: 0.7062 - val_loss: 1.1258 - val_accuracy: 0.6147\n",
            "Epoch 96/120\n",
            "448/448 [==============================] - 26s 59ms/step - loss: 0.8128 - accuracy: 0.6987 - val_loss: 1.1019 - val_accuracy: 0.6163\n",
            "Epoch 97/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 0.8054 - accuracy: 0.7002 - val_loss: 1.1284 - val_accuracy: 0.6004\n",
            "Epoch 98/120\n",
            "448/448 [==============================] - 27s 59ms/step - loss: 0.8501 - accuracy: 0.6847 - val_loss: 1.0815 - val_accuracy: 0.6110\n",
            "Epoch 99/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 0.7995 - accuracy: 0.7033 - val_loss: 1.0883 - val_accuracy: 0.6116\n",
            "Epoch 100/120\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 0.7717 - accuracy: 0.7141 - val_loss: 1.0811 - val_accuracy: 0.6191\n",
            "Epoch 101/120\n",
            "448/448 [==============================] - 26s 59ms/step - loss: 0.7601 - accuracy: 0.7229 - val_loss: 1.0833 - val_accuracy: 0.6197\n",
            "Epoch 102/120\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 0.7483 - accuracy: 0.7244 - val_loss: 1.0969 - val_accuracy: 0.6252\n",
            "Epoch 103/120\n",
            "448/448 [==============================] - 26s 59ms/step - loss: 0.7573 - accuracy: 0.7177 - val_loss: 1.1160 - val_accuracy: 0.6291\n",
            "Epoch 104/120\n",
            "448/448 [==============================] - 27s 59ms/step - loss: 0.7363 - accuracy: 0.7262 - val_loss: 1.1242 - val_accuracy: 0.6160\n",
            "Epoch 105/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 0.7549 - accuracy: 0.7158 - val_loss: 1.1130 - val_accuracy: 0.6211\n",
            "Epoch 106/120\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 0.7513 - accuracy: 0.7235 - val_loss: 1.0926 - val_accuracy: 0.6236\n",
            "Epoch 107/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 0.7340 - accuracy: 0.7318 - val_loss: 1.0845 - val_accuracy: 0.6333\n",
            "Epoch 108/120\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 0.7181 - accuracy: 0.7377 - val_loss: 1.1137 - val_accuracy: 0.6225\n",
            "Epoch 109/120\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 0.7384 - accuracy: 0.7210 - val_loss: 1.1362 - val_accuracy: 0.6208\n",
            "Epoch 110/120\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 0.7422 - accuracy: 0.7277 - val_loss: 1.1288 - val_accuracy: 0.6163\n",
            "Epoch 111/120\n",
            "448/448 [==============================] - 25s 57ms/step - loss: 0.7127 - accuracy: 0.7339 - val_loss: 1.1137 - val_accuracy: 0.6250\n",
            "Epoch 112/120\n",
            "448/448 [==============================] - 26s 59ms/step - loss: 0.6930 - accuracy: 0.7453 - val_loss: 1.0999 - val_accuracy: 0.6177\n",
            "Epoch 113/120\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 0.7155 - accuracy: 0.7386 - val_loss: 1.1326 - val_accuracy: 0.6105\n",
            "Epoch 114/120\n",
            "448/448 [==============================] - 27s 59ms/step - loss: 0.7029 - accuracy: 0.7406 - val_loss: 1.1302 - val_accuracy: 0.6219\n",
            "Epoch 115/120\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 0.7195 - accuracy: 0.7371 - val_loss: 1.0941 - val_accuracy: 0.6261\n",
            "Epoch 116/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 0.7019 - accuracy: 0.7376 - val_loss: 1.1304 - val_accuracy: 0.6252\n",
            "Epoch 117/120\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 0.6953 - accuracy: 0.7399 - val_loss: 1.1596 - val_accuracy: 0.6174\n",
            "Epoch 118/120\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 0.6855 - accuracy: 0.7498 - val_loss: 1.1911 - val_accuracy: 0.6152\n",
            "Epoch 119/120\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 0.6737 - accuracy: 0.7513 - val_loss: 1.1123 - val_accuracy: 0.6297\n",
            "Epoch 120/120\n",
            "448/448 [==============================] - 26s 59ms/step - loss: 0.6710 - accuracy: 0.7538 - val_loss: 1.1755 - val_accuracy: 0.6172\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "cZvluWhSRkq4",
        "outputId": "7561ea98-b683-4bad-e16d-33a3edc3aa25"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "model.save('/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50oriz_SEED_SP5_120_Augg5.h5')\n",
        "\n",
        "#ffddfsgyghuuihtftfdd\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "num_epochs = range(len(accuracy))\n",
        "plt.plot(num_epochs, accuracy, 'r', label='Training acc')\n",
        "plt.plot(num_epochs, val_accuracy, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(num_epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(num_epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Pzozx-30LSe",
        "outputId": "b2c6e3a7-1124-4ce1-abc3-17e06c2ca80a"
      },
      "source": [
        "testloss = model.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "trainloss = model.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(trainloss[0]))\n",
        "print(\"Train Acc: \" + str(trainloss[1]))\n",
        "vallosz = model.evaluate(x_val, y_val) \n",
        "print(\"val Loss \" + str(vallosz[0]))\n",
        "print(\"val Acc: \" + str(vallosz[1]))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 2s 17ms/step - loss: 1.1140 - accuracy: 0.6381\n",
            "Test Loss 1.1140272617340088\n",
            "Test Acc: 0.6380607485771179\n",
            "898/898 [==============================] - 14s 15ms/step - loss: 0.5307 - accuracy: 0.8044\n",
            "Train Loss 0.5307044386863708\n",
            "Train Acc: 0.8043819069862366\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 1.1755 - accuracy: 0.6172\n",
            "val Loss 1.1755470037460327\n",
            "val Acc: 0.6171635389328003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ6YCHax59vt",
        "outputId": "4520b1a5-63a6-4d41-fea4-f4adfa94f7fa"
      },
      "source": [
        "from keras.models import load_model\n",
        "model_load = load_model('/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50oriz_SEED_SP5_120_Augg5.h5')\n",
        "\n",
        "model_load.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50ori\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 54, 54, 1)    0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 24, 24, 64)   3200        zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 24, 24, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 24, 24, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 11, 11, 64)   0           activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 11, 11, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 11, 11, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 11, 11, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 11, 11, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 11, 11, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 11, 11, 256)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 11, 11, 256)  0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 11, 11, 64)   16448       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 11, 11, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 11, 11, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 11, 11, 256)  0           activation_52[0][0]              \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 11, 11, 256)  0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 11, 11, 64)   16448       activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 11, 11, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 11, 11, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 11, 11, 256)  0           activation_55[0][0]              \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 11, 11, 256)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 6, 6, 128)    32896       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 6, 6, 128)    0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 6, 6, 128)    0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 6, 6, 512)    131584      activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 6, 6, 512)    2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 6, 6, 512)    0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 6, 6, 512)    0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 6, 6, 128)    0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 6, 6, 128)    0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 6, 6, 512)    0           activation_61[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 6, 6, 512)    0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 6, 6, 128)    0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 6, 6, 128)    0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 6, 6, 512)    0           activation_64[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 6, 6, 512)    0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 6, 6, 128)    0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 6, 6, 128)    0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 6, 6, 512)    0           activation_67[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 6, 6, 512)    0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 3, 3, 256)    131328      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 256)    0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 3, 3, 256)    0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 3, 3, 1024)   525312      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 3, 3, 1024)   4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 3, 3, 1024)   0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 3, 3, 1024)   0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 3, 3, 256)    0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 256)    0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 3, 3, 1024)   0           activation_73[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 1024)   0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 256)    0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 256)    0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 3, 3, 1024)   0           activation_76[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 1024)   0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 256)    0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 256)    0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 3, 3, 1024)   0           activation_79[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 1024)   0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 256)    0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 256)    0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 3, 3, 1024)   0           activation_82[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 1024)   0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 256)    0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 256)    0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 3, 3, 1024)   0           activation_85[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 1024)   0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 2, 2, 512)    524800      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 2, 2, 2048)   2099200     activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 2, 2, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 2, 2, 2048)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 2, 2, 2048)   0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 2, 2, 2048)   0           activation_91[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 2, 2, 2048)   0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 2, 2, 2048)   0           activation_94[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 2, 2, 2048)   0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 2048)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            14343       flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 23,595,783\n",
            "Trainable params: 23,542,663\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fpz7ehkO6Cat",
        "outputId": "b5b85097-cd63-4f48-9373-41a58ae0dd3e"
      },
      "source": [
        "testloss = model_load.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "\n",
        "trainloss = model_load.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(trainloss[0]))\n",
        "print(\"Train Acc: \" + str(trainloss[1]))\n",
        "\n",
        "vallosz = model_load.evaluate(x_val, y_val) \n",
        "print(\"val Loss \" + str(vallosz[0]))\n",
        "print(\"val Acc: \" + str(vallosz[1]))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 6s 16ms/step - loss: 1.1140 - accuracy: 0.6381\n",
            "Test Loss 1.1140272617340088\n",
            "Test Acc: 0.6380607485771179\n",
            "898/898 [==============================] - 13s 15ms/step - loss: 0.5307 - accuracy: 0.8044\n",
            "Train Loss 0.5307044386863708\n",
            "Train Acc: 0.8043819069862366\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 1.1755 - accuracy: 0.6172\n",
            "val Loss 1.1755470037460327\n",
            "val Acc: 0.6171635389328003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDwmru9p0gyj",
        "outputId": "8f8ceed8-6d1f-47cb-da59-aeefcc5ab4d5"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "#y_pred = model_load.predict(xtest)g\n",
        "\n",
        "test_prob = model_load.predict(xtest)\n",
        "test_pred = np.argmax(test_prob, axis=1)\n",
        "test_accuracy = np.mean(test_pred == ytest)\n",
        "\n",
        "print(test_accuracy)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6380607411535246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpHHR7Q6y9uU"
      },
      "source": [
        "emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "-0ha8DW80028",
        "outputId": "f4acd2f9-d564-4f4b-984f-dae67201357b"
      },
      "source": [
        "conf_mat = confusion_matrix(ytest, test_pred)\n",
        "##\n",
        "pd.DataFrame(conf_mat, columns=emotions.values(), index=emotions.values())\n",
        "\n",
        "fig, ax = plot_confusion_matrix(conf_mat=conf_mat,show_normed=True,show_absolute=False,figsize=(9, 9))\n",
        "fig.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDC2YQsIywNO",
        "outputId": "fdb3b1cd-16f3-437f-a99e-ad12951a9c2c"
      },
      "source": [
        "print(classification_report(ytest, test_pred, target_names=emotions.values()))\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry       0.54      0.54      0.54       480\n",
            "     Disgust       0.71      0.65      0.68        60\n",
            "        Fear       0.53      0.49      0.51       515\n",
            "       Happy       0.82      0.83      0.82       883\n",
            "         Sad       0.60      0.42      0.49       597\n",
            "    Surprise       0.72      0.78      0.75       397\n",
            "     Neutral       0.54      0.68      0.60       657\n",
            "\n",
            "    accuracy                           0.64      3589\n",
            "   macro avg       0.64      0.63      0.63      3589\n",
            "weighted avg       0.64      0.64      0.63      3589\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xfSSuZCuutf",
        "outputId": "a135ff76-f577-4614-f706-230ba80f73c0"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "dataread =pd.read_csv('/content/drive/MyDrive/Fer2013_backup/backUpfer2013.csv')\n",
        "\n",
        "#print(dataread.duplicated().value_counts)\n",
        "#(df[df.duplicated()])s\n",
        "\"\"\"dataread['Usage'].value_counts()\n",
        "dataread['emotion'].value_counts()\n",
        "\"\"\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    8989\n",
              "6    6198\n",
              "4    6077\n",
              "2    5121\n",
              "0    4953\n",
              "5    4002\n",
              "1     547\n",
              "Name: emotion, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncIVy0SZ_WgH"
      },
      "source": [
        "from numpy import expand_dims\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from matplotlib import pyplot\n",
        "#meload gambar\n",
        "img = load_img('')\n",
        "\n",
        "data = img_to_array(img)\n",
        "#meningkatkan dimension ke satu sampel\n",
        "sampels = \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2bP0roK-WpE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}