{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER2013_Resnet50_weightnone_fixTrainTestVal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-Qn1jsBTIBl0b7myLQxqa8WjCcfbamqM",
      "authorship_tag": "ABX9TyNaoxZMqJaoT0FNBHdTzXhh"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b86nukQOxN7l"
      },
      "source": [
        "Resnet-50 From Scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p8gxtGy0TWP",
        "outputId": "c343a441-42df-4057-b86f-008a3413f013"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "inputFolder = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth' \n",
        "for root, directories, filenames in os.walk(inputFolder): \n",
        "    for filename in filenames: print(os.path.join(root,filename))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Best_Model_resnet50Scracth1again.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe4.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth1again.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50ScracthSGD1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50AUGScracthadam3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD1try2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD4.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50oriSGD1st.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50SGD5stori.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editSGD5st.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editAdamst120epochBS128.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editAdamst120epochBS128_1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editAdamst120epochBS128+aug:vf_2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50oriAdamst120epochBS128_aug1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50oriAdamst120epochBS128_noaug1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_noAug_adam1_shuffalse1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50oriScracth_sena2.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsiscWIMBDX2",
        "outputId": "4dfe7bcf-430c-4eb5-8ea8-27d9f607dbea"
      },
      "source": [
        "%cd /content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "wLMSe510xNCJ",
        "outputId": "3da9f6f5-cb75-4f61-d978-1e7de9a074fc"
      },
      "source": [
        "#Create a directory to save our generated models.dasdas\n",
        "\n",
        "#os.mkdir(\"./modelscracth\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-cf55f19f3613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#os.mkdir(\"./modelscracth\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ls' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_kluusLxM1B",
        "outputId": "81c4acee-7482-4ee3-b88f-a1da55223479"
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:400: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfUSF_tAxNMP"
      },
      "source": [
        "#Define the identity block helper function.\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "   \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VdYtzhn1F0I"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path \n",
        "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b',padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd-O8ZMx1GAW"
      },
      "source": [
        "def ResNet50(input_shape = (48,48,1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    #X = ZeroPadding2D((1, 1))(X_input)\n",
        "    X = X_input\n",
        "    # Stage 1\n",
        "\n",
        "    X = Conv2D(8, (3, 3), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # removed maxpool\n",
        "    #X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='c')\n",
        "\n",
        "\n",
        "    # Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [64,64,256], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL . \n",
        "    X = AveragePooling2D((2,2), name='avg_pool')(X)\n",
        "    \n",
        "    # output layerds\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(512, activation = 'relu', name='fc1024' , kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GKsSwtp-GuL"
      },
      "source": [
        "\"\"\"def ResNet50ori(input_shape = (48, 48, 1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns: dsdsf\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50ori')\n",
        "\n",
        "    return model\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oWTDXlyBHM2"
      },
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        " \n",
        "dataset_path = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv'\n",
        "image_size=(48,48)\n",
        "#batch_size = 64\n",
        "\n",
        "def load_fer2013():\n",
        "    data = pd.read_csv(dataset_path)\n",
        "    data = (data[data['pixels'].notnull()])\n",
        "    pixels = data['pixels'].tolist()\n",
        "    width, height = 48, 48\n",
        "    faces = []\n",
        "    for pixel_sequence in pixels:\n",
        "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "        face = np.asarray(face).reshape(width, height)\n",
        "        face = cv2.resize(face.astype('uint8'),image_size)\n",
        "        faces.append(face.astype('float32'))\n",
        "    faces = np.asarray(faces)\n",
        "    faces = np.expand_dims(faces, -1)\n",
        "    emotions = (data['emotion'])#.values\n",
        "    return faces, emotions\n",
        " \n",
        "def preprocess_input(x, v2=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if v2:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x\n",
        " \n",
        "faces, emotions = load_fer2013()\n",
        "faces = preprocess_input(faces)\n",
        "#xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
        "#Data Augumentation\n",
        "data_generator = ImageDataGenerator(\n",
        "                        rotation_range=10,\n",
        "                        shear_range = 10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True,\n",
        "                        )\n",
        "#data_generator = ImageDataGenerator( )\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWLhavr-rSF5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "895f7f85-9930-46ca-c552-cbb571846a4e"
      },
      "source": [
        "\"\"\"\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.1,)\n",
        "x_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1,)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nxtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.1,)\\nx_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1,)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "RGhnYFXgaqL9",
        "outputId": "0e60da2f-3a44-4d06-910b-2e0f2fa4191a"
      },
      "source": [
        "\"\"\"print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (y_train.shape)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'print (\"validasi\",x_val.shape)\\nprint (y_val.shape)\\nprint (\"test\",xtest.shape)\\nprint (ytest.shape)\\nprint (\"train\",xtrain.shape)\\nprint (y_train.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rDS3hqhDSteM",
        "outputId": "8251bc3e-f013-4650-e313-74b202d11ff5"
      },
      "source": [
        "train_ratio = 0.80\n",
        "validation_ratio = 0.10\n",
        "test_ratio = 0.10\n",
        "\n",
        "# train is now 75% of the entire data set\n",
        "# the _junk suffix means that we drop that variable completely # the _junk suffix means that we drop that variable completely\n",
        "#x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=1 - train_ratio,random_state=42)\n",
        "\n",
        "# test is now 10% of the initial data set\n",
        "# validation is now 15% of the initial data set\n",
        "#x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "x_val, xtest, y_val, ytest = train_test_split(xtest, ytest, test_size=test_ratio/(test_ratio + validation_ratio), random_state=42) \n",
        "\n",
        "print(xtrain, x_val, xtest)\n",
        "\n",
        "\"\"\"X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2\"\"\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[-0.96862745]\n",
            "   [-0.96862745]\n",
            "   [-0.96862745]\n",
            "   ...\n",
            "   [-0.77254903]\n",
            "   [-0.7490196 ]\n",
            "   [-0.75686276]]\n",
            "\n",
            "  [[-0.92156863]\n",
            "   [-0.92941177]\n",
            "   [-0.9529412 ]\n",
            "   ...\n",
            "   [-0.02745098]\n",
            "   [ 0.05882359]\n",
            "   [ 0.05882359]]\n",
            "\n",
            "  [[-0.92941177]\n",
            "   [-0.92941177]\n",
            "   [-0.94509804]\n",
            "   ...\n",
            "   [-0.06666666]\n",
            "   [ 0.00392163]\n",
            "   [ 0.02745104]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.08235294]\n",
            "   [-0.06666666]\n",
            "   [-0.00392157]\n",
            "   ...\n",
            "   [-0.94509804]\n",
            "   [-0.96862745]\n",
            "   [-0.96862745]]\n",
            "\n",
            "  [[-0.88235295]\n",
            "   [-0.90588236]\n",
            "   [-0.8352941 ]\n",
            "   ...\n",
            "   [-0.9764706 ]\n",
            "   [-0.9843137 ]\n",
            "   [-0.9764706 ]]\n",
            "\n",
            "  [[-0.99215686]\n",
            "   [-0.99215686]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.9764706 ]\n",
            "   [-0.9764706 ]\n",
            "   [-0.9764706 ]]]\n",
            "\n",
            "\n",
            " [[[-0.7647059 ]\n",
            "   [-0.7490196 ]\n",
            "   [-0.6784314 ]\n",
            "   ...\n",
            "   [ 0.427451  ]\n",
            "   [ 0.27058828]\n",
            "   [ 0.22352946]]\n",
            "\n",
            "  [[-0.8117647 ]\n",
            "   [-0.70980394]\n",
            "   [-0.75686276]\n",
            "   ...\n",
            "   [ 0.41960788]\n",
            "   [ 0.254902  ]\n",
            "   [ 0.18431377]]\n",
            "\n",
            "  [[-0.77254903]\n",
            "   [-0.75686276]\n",
            "   [-0.8352941 ]\n",
            "   ...\n",
            "   [ 0.4666667 ]\n",
            "   [ 0.254902  ]\n",
            "   [ 0.1686275 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.34901965]\n",
            "   [ 0.36470592]\n",
            "   [-0.05098039]\n",
            "   ...\n",
            "   [-0.01176471]\n",
            "   [-0.12941176]\n",
            "   [-0.0745098 ]]\n",
            "\n",
            "  [[ 0.33333337]\n",
            "   [ 0.33333337]\n",
            "   [-0.21568626]\n",
            "   ...\n",
            "   [-0.06666666]\n",
            "   [-0.06666666]\n",
            "   [-0.10588235]]\n",
            "\n",
            "  [[ 0.36470592]\n",
            "   [ 0.27843142]\n",
            "   [-0.26274508]\n",
            "   ...\n",
            "   [-0.15294117]\n",
            "   [-0.09019607]\n",
            "   [-0.0745098 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.96862745]\n",
            "   [ 0.92156863]\n",
            "   [ 0.62352943]\n",
            "   ...\n",
            "   [-0.38823527]\n",
            "   [-0.32549018]\n",
            "   [-0.26274508]]\n",
            "\n",
            "  [[ 0.9529412 ]\n",
            "   [ 0.6627451 ]\n",
            "   [ 0.10588241]\n",
            "   ...\n",
            "   [-0.40392154]\n",
            "   [-0.34117645]\n",
            "   [-0.2862745 ]]\n",
            "\n",
            "  [[ 0.78039217]\n",
            "   [ 0.24705887]\n",
            "   [-0.19215685]\n",
            "   ...\n",
            "   [-0.5294118 ]\n",
            "   [-0.41176468]\n",
            "   [-0.34117645]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.28627455]\n",
            "   [ 0.2941177 ]\n",
            "   [ 0.3176471 ]\n",
            "   ...\n",
            "   [-0.35686272]\n",
            "   [-0.73333335]\n",
            "   [-0.96862745]]\n",
            "\n",
            "  [[ 0.34901965]\n",
            "   [ 0.27058828]\n",
            "   [ 0.28627455]\n",
            "   ...\n",
            "   [-0.41960782]\n",
            "   [-0.8980392 ]\n",
            "   [-0.94509804]]\n",
            "\n",
            "  [[ 0.3411765 ]\n",
            "   [ 0.26274514]\n",
            "   [ 0.26274514]\n",
            "   ...\n",
            "   [-0.5137255 ]\n",
            "   [-0.9843137 ]\n",
            "   [-0.9137255 ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.23921567]\n",
            "   [-0.27058822]\n",
            "   [-0.52156866]\n",
            "   ...\n",
            "   [ 0.16078436]\n",
            "   [ 0.03529418]\n",
            "   [ 0.01176476]]\n",
            "\n",
            "  [[-0.16862744]\n",
            "   [-0.30196077]\n",
            "   [-0.4823529 ]\n",
            "   ...\n",
            "   [ 0.254902  ]\n",
            "   [ 0.05098045]\n",
            "   [ 0.03529418]]\n",
            "\n",
            "  [[-0.38039213]\n",
            "   [-0.3098039 ]\n",
            "   [-0.4588235 ]\n",
            "   ...\n",
            "   [ 0.30980396]\n",
            "   [ 0.14509809]\n",
            "   [ 0.02745104]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.81960785]\n",
            "   [-0.9607843 ]\n",
            "   [-0.9607843 ]\n",
            "   ...\n",
            "   [-0.47450978]\n",
            "   [-0.15294117]\n",
            "   [ 0.45882356]]\n",
            "\n",
            "  [[-0.7882353 ]\n",
            "   [-0.92156863]\n",
            "   [-0.96862745]\n",
            "   ...\n",
            "   [-0.4352941 ]\n",
            "   [-0.19999999]\n",
            "   [ 0.4431373 ]]\n",
            "\n",
            "  [[-0.8901961 ]\n",
            "   [-0.88235295]\n",
            "   [-0.96862745]\n",
            "   ...\n",
            "   [-0.35686272]\n",
            "   [-0.16862744]\n",
            "   [ 0.27058828]]]\n",
            "\n",
            "\n",
            " [[[ 0.99215686]\n",
            "   [ 0.7882353 ]\n",
            "   [ 0.69411767]\n",
            "   ...\n",
            "   [ 0.37254906]\n",
            "   [ 0.27843142]\n",
            "   [ 0.24705887]]\n",
            "\n",
            "  [[ 0.92156863]\n",
            "   [ 0.6862745 ]\n",
            "   [ 0.6784314 ]\n",
            "   ...\n",
            "   [ 0.33333337]\n",
            "   [ 0.30196083]\n",
            "   [ 0.20000005]]\n",
            "\n",
            "  [[ 0.8117647 ]\n",
            "   [ 0.6313726 ]\n",
            "   [ 0.6392157 ]\n",
            "   ...\n",
            "   [ 0.27843142]\n",
            "   [ 0.35686278]\n",
            "   [ 0.16078436]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.77254903]\n",
            "   [ 0.64705884]\n",
            "   [ 0.7019608 ]\n",
            "   ...\n",
            "   [ 0.15294123]\n",
            "   [ 0.5137255 ]\n",
            "   [ 0.6       ]]\n",
            "\n",
            "  [[ 0.6784314 ]\n",
            "   [ 0.6784314 ]\n",
            "   [ 0.654902  ]\n",
            "   ...\n",
            "   [ 0.39607847]\n",
            "   [ 0.52156866]\n",
            "   [ 0.6156863 ]]\n",
            "\n",
            "  [[ 0.7254902 ]\n",
            "   [ 0.64705884]\n",
            "   [ 0.70980394]\n",
            "   ...\n",
            "   [ 0.4901961 ]\n",
            "   [ 0.70980394]\n",
            "   [ 0.75686276]]]\n",
            "\n",
            "\n",
            " [[[-0.06666666]\n",
            "   [-0.20784312]\n",
            "   [-0.85882354]\n",
            "   ...\n",
            "   [-0.99215686]\n",
            "   [-0.99215686]\n",
            "   [-0.9843137 ]]\n",
            "\n",
            "  [[-0.03529412]\n",
            "   [-0.5764706 ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.9843137 ]\n",
            "   [-0.9607843 ]\n",
            "   [-0.9843137 ]]\n",
            "\n",
            "  [[-0.26274508]\n",
            "   [-0.88235295]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-1.        ]\n",
            "   [-0.9607843 ]\n",
            "   [-0.99215686]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]]\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]]\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]]]] [[[[ 0.427451  ]\n",
            "   [ 0.36470592]\n",
            "   [ 0.28627455]\n",
            "   ...\n",
            "   [ 0.43529415]\n",
            "   [ 0.22352946]\n",
            "   [ 0.00392163]]\n",
            "\n",
            "  [[ 0.3803922 ]\n",
            "   [ 0.30980396]\n",
            "   [ 0.07450986]\n",
            "   ...\n",
            "   [ 0.34901965]\n",
            "   [ 0.2941177 ]\n",
            "   [ 0.11372554]]\n",
            "\n",
            "  [[ 0.41176474]\n",
            "   [ 0.12156868]\n",
            "   [-0.09803921]\n",
            "   ...\n",
            "   [ 0.19215691]\n",
            "   [ 0.26274514]\n",
            "   [ 0.17647064]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.5921569 ]\n",
            "   [ 0.64705884]\n",
            "   [ 0.62352943]\n",
            "   ...\n",
            "   [ 0.73333335]\n",
            "   [ 0.73333335]\n",
            "   [ 0.7176471 ]]\n",
            "\n",
            "  [[ 0.5686275 ]\n",
            "   [ 0.6392157 ]\n",
            "   [ 0.6313726 ]\n",
            "   ...\n",
            "   [ 0.7254902 ]\n",
            "   [ 0.7176471 ]\n",
            "   [ 0.6784314 ]]\n",
            "\n",
            "  [[ 0.5372549 ]\n",
            "   [ 0.60784316]\n",
            "   [ 0.6392157 ]\n",
            "   ...\n",
            "   [ 0.69411767]\n",
            "   [ 0.6784314 ]\n",
            "   [ 0.6392157 ]]]\n",
            "\n",
            "\n",
            " [[[-0.34117645]\n",
            "   [-0.34117645]\n",
            "   [-0.34117645]\n",
            "   ...\n",
            "   [-0.30196077]\n",
            "   [-0.29411763]\n",
            "   [-0.30196077]]\n",
            "\n",
            "  [[-0.3333333 ]\n",
            "   [-0.32549018]\n",
            "   [-0.3333333 ]\n",
            "   ...\n",
            "   [-0.30196077]\n",
            "   [-0.30196077]\n",
            "   [-0.30196077]]\n",
            "\n",
            "  [[-0.3333333 ]\n",
            "   [-0.32549018]\n",
            "   [-0.3333333 ]\n",
            "   ...\n",
            "   [-0.29411763]\n",
            "   [-0.3098039 ]\n",
            "   [-0.29411763]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.1372549 ]\n",
            "   [-0.1372549 ]\n",
            "   [-0.12156862]\n",
            "   ...\n",
            "   [ 0.45098042]\n",
            "   [ 0.33333337]\n",
            "   [-0.08235294]]\n",
            "\n",
            "  [[-0.1372549 ]\n",
            "   [-0.1372549 ]\n",
            "   [-0.11372548]\n",
            "   ...\n",
            "   [ 0.43529415]\n",
            "   [ 0.4431373 ]\n",
            "   [ 0.0196079 ]]\n",
            "\n",
            "  [[-0.12941176]\n",
            "   [-0.12941176]\n",
            "   [-0.12156862]\n",
            "   ...\n",
            "   [ 0.254902  ]\n",
            "   [ 0.49803925]\n",
            "   [ 0.24705887]]]\n",
            "\n",
            "\n",
            " [[[ 0.99215686]\n",
            "   [ 0.8509804 ]\n",
            "   [ 0.5058824 ]\n",
            "   ...\n",
            "   [ 0.9764706 ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 0.99215686]\n",
            "   [ 0.5137255 ]\n",
            "   [ 0.05882359]\n",
            "   ...\n",
            "   [ 0.9764706 ]\n",
            "   [ 1.        ]\n",
            "   [ 0.99215686]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 0.5764706 ]\n",
            "   [ 0.09019613]\n",
            "   ...\n",
            "   [ 0.9529412 ]\n",
            "   [ 1.        ]\n",
            "   [ 0.99215686]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.73333335]\n",
            "   [-0.7490196 ]\n",
            "   [-0.75686276]\n",
            "   ...\n",
            "   [-0.7490196 ]\n",
            "   [-0.73333335]\n",
            "   [-0.73333335]]\n",
            "\n",
            "  [[-0.7647059 ]\n",
            "   [-0.7647059 ]\n",
            "   [-0.78039217]\n",
            "   ...\n",
            "   [-0.79607844]\n",
            "   [-0.8039216 ]\n",
            "   [-0.7647059 ]]\n",
            "\n",
            "  [[-0.6862745 ]\n",
            "   [-0.7411765 ]\n",
            "   [-0.78039217]\n",
            "   ...\n",
            "   [-0.8352941 ]\n",
            "   [-0.78039217]\n",
            "   [-0.654902  ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.3490196 ]\n",
            "   [-0.16862744]\n",
            "   [ 0.52156866]\n",
            "   ...\n",
            "   [ 0.36470592]\n",
            "   [ 0.41960788]\n",
            "   [ 0.19215691]]\n",
            "\n",
            "  [[-0.36470586]\n",
            "   [-0.06666666]\n",
            "   [ 0.6156863 ]\n",
            "   ...\n",
            "   [ 0.32549024]\n",
            "   [ 0.49803925]\n",
            "   [ 0.27843142]]\n",
            "\n",
            "  [[-0.3960784 ]\n",
            "   [ 0.18431377]\n",
            "   [ 0.6627451 ]\n",
            "   ...\n",
            "   [ 0.27058828]\n",
            "   [ 0.4039216 ]\n",
            "   [ 0.48235297]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.38823533]\n",
            "   [ 0.23921573]\n",
            "   [ 0.27843142]\n",
            "   ...\n",
            "   [ 0.02745104]\n",
            "   [ 0.0196079 ]\n",
            "   [-0.24705881]]\n",
            "\n",
            "  [[ 0.41960788]\n",
            "   [ 0.33333337]\n",
            "   [ 0.30196083]\n",
            "   ...\n",
            "   [ 0.09803927]\n",
            "   [-0.19215685]\n",
            "   [-0.23137254]]\n",
            "\n",
            "  [[ 0.41176474]\n",
            "   [ 0.33333337]\n",
            "   [ 0.2941177 ]\n",
            "   ...\n",
            "   [-0.09019607]\n",
            "   [-0.34117645]\n",
            "   [-0.14509803]]]\n",
            "\n",
            "\n",
            " [[[ 0.15294123]\n",
            "   [ 0.07450986]\n",
            "   [ 0.00392163]\n",
            "   ...\n",
            "   [-0.18431371]\n",
            "   [-0.05098039]\n",
            "   [ 0.0196079 ]]\n",
            "\n",
            "  [[ 0.12156868]\n",
            "   [ 0.04313731]\n",
            "   [ 0.03529418]\n",
            "   ...\n",
            "   [-0.27058822]\n",
            "   [-0.09803921]\n",
            "   [-0.01176471]]\n",
            "\n",
            "  [[ 0.09019613]\n",
            "   [ 0.04313731]\n",
            "   [ 0.05882359]\n",
            "   ...\n",
            "   [-0.372549  ]\n",
            "   [-0.15294117]\n",
            "   [-0.0745098 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.13725495]\n",
            "   [ 0.05882359]\n",
            "   [-0.00392157]\n",
            "   ...\n",
            "   [-0.64705884]\n",
            "   [-0.3098039 ]\n",
            "   [ 0.04313731]]\n",
            "\n",
            "  [[ 0.01176476]\n",
            "   [-0.01176471]\n",
            "   [-0.01176471]\n",
            "   ...\n",
            "   [-0.6       ]\n",
            "   [-0.3098039 ]\n",
            "   [ 0.23921573]]\n",
            "\n",
            "  [[-0.11372548]\n",
            "   [-0.01960784]\n",
            "   [-0.01176471]\n",
            "   ...\n",
            "   [-0.4352941 ]\n",
            "   [-0.2862745 ]\n",
            "   [ 0.18431377]]]\n",
            "\n",
            "\n",
            " [[[-0.827451  ]\n",
            "   [-0.8509804 ]\n",
            "   [-0.85882354]\n",
            "   ...\n",
            "   [-0.69411767]\n",
            "   [-0.69411767]\n",
            "   [-0.7254902 ]]\n",
            "\n",
            "  [[-0.73333335]\n",
            "   [-0.6627451 ]\n",
            "   [-0.8039216 ]\n",
            "   ...\n",
            "   [-0.67058825]\n",
            "   [-0.67058825]\n",
            "   [-0.7176471 ]]\n",
            "\n",
            "  [[-0.7647059 ]\n",
            "   [-0.6392157 ]\n",
            "   [-0.7176471 ]\n",
            "   ...\n",
            "   [-0.6392157 ]\n",
            "   [-0.7019608 ]\n",
            "   [-0.7019608 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.56078434]\n",
            "   [-0.60784316]\n",
            "   [-0.6392157 ]\n",
            "   ...\n",
            "   [-0.5372549 ]\n",
            "   [-0.40392154]\n",
            "   [-0.3098039 ]]\n",
            "\n",
            "  [[-0.35686272]\n",
            "   [-0.44313723]\n",
            "   [-0.49019605]\n",
            "   ...\n",
            "   [-0.372549  ]\n",
            "   [-0.3098039 ]\n",
            "   [-0.23137254]]\n",
            "\n",
            "  [[-0.4352941 ]\n",
            "   [-0.38039213]\n",
            "   [-0.3333333 ]\n",
            "   ...\n",
            "   [-0.12941176]\n",
            "   [-0.09019607]\n",
            "   [-0.03529412]]]] [[[[-0.5058824 ]\n",
            "   [-0.372549  ]\n",
            "   [-0.17647058]\n",
            "   ...\n",
            "   [-0.42745095]\n",
            "   [-0.5921569 ]\n",
            "   [-0.4980392 ]]\n",
            "\n",
            "  [[-0.5686275 ]\n",
            "   [-0.38823527]\n",
            "   [-0.15294117]\n",
            "   ...\n",
            "   [-0.41176468]\n",
            "   [-0.5764706 ]\n",
            "   [-0.52156866]]\n",
            "\n",
            "  [[-0.60784316]\n",
            "   [-0.41176468]\n",
            "   [-0.19215685]\n",
            "   ...\n",
            "   [-0.42745095]\n",
            "   [-0.5686275 ]\n",
            "   [-0.5137255 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.99215686]\n",
            "   [-0.99215686]\n",
            "   [-0.99215686]\n",
            "   ...\n",
            "   [-0.96862745]\n",
            "   [-1.        ]\n",
            "   [-1.        ]]\n",
            "\n",
            "  [[-0.99215686]\n",
            "   [-0.99215686]\n",
            "   [-0.99215686]\n",
            "   ...\n",
            "   [-0.9843137 ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]]\n",
            "\n",
            "  [[-0.99215686]\n",
            "   [-0.99215686]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.9843137 ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]]]\n",
            "\n",
            "\n",
            " [[[ 0.3176471 ]\n",
            "   [ 0.24705887]\n",
            "   [ 0.27843142]\n",
            "   ...\n",
            "   [-0.84313726]\n",
            "   [-0.85882354]\n",
            "   [-0.8666667 ]]\n",
            "\n",
            "  [[ 0.41176474]\n",
            "   [ 0.27058828]\n",
            "   [ 0.2941177 ]\n",
            "   ...\n",
            "   [-0.8117647 ]\n",
            "   [-0.8509804 ]\n",
            "   [-0.8666667 ]]\n",
            "\n",
            "  [[ 0.5294118 ]\n",
            "   [ 0.254902  ]\n",
            "   [ 0.2941177 ]\n",
            "   ...\n",
            "   [-0.7019608 ]\n",
            "   [-0.81960785]\n",
            "   [-0.8509804 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.88235295]\n",
            "   [ 0.48235297]\n",
            "   [ 0.34901965]\n",
            "   ...\n",
            "   [-0.654902  ]\n",
            "   [-0.6392157 ]\n",
            "   [-0.6392157 ]]\n",
            "\n",
            "  [[ 0.6627451 ]\n",
            "   [ 0.3411765 ]\n",
            "   [ 0.39607847]\n",
            "   ...\n",
            "   [-0.5921569 ]\n",
            "   [-0.6       ]\n",
            "   [-0.7647059 ]]\n",
            "\n",
            "  [[ 0.41176474]\n",
            "   [ 0.41176474]\n",
            "   [ 0.41176474]\n",
            "   ...\n",
            "   [-0.5686275 ]\n",
            "   [-0.75686276]\n",
            "   [-0.7411765 ]]]\n",
            "\n",
            "\n",
            " [[[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.01960784]\n",
            "   [-0.23137254]\n",
            "   [-0.19215685]]\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [ 0.03529418]\n",
            "   [-0.03529412]\n",
            "   [ 0.12941182]]\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [ 0.2941177 ]\n",
            "   [ 0.37254906]\n",
            "   [ 0.38823533]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [ 0.92156863]\n",
            "   [ 0.92156863]\n",
            "   [ 0.92941177]]\n",
            "\n",
            "  [[-0.9843137 ]\n",
            "   [-1.        ]\n",
            "   [-0.99215686]\n",
            "   ...\n",
            "   [ 0.92156863]\n",
            "   [ 0.92941177]\n",
            "   [ 0.9137255 ]]\n",
            "\n",
            "  [[-0.6627451 ]\n",
            "   [-1.        ]\n",
            "   [-0.99215686]\n",
            "   ...\n",
            "   [ 0.92156863]\n",
            "   [ 0.92941177]\n",
            "   [ 0.8901961 ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 0.20784318]\n",
            "   [ 0.16078436]\n",
            "   [-0.0745098 ]\n",
            "   ...\n",
            "   [ 0.36470592]\n",
            "   [ 0.28627455]\n",
            "   [ 0.3803922 ]]\n",
            "\n",
            "  [[ 0.082353  ]\n",
            "   [ 0.04313731]\n",
            "   [-0.09803921]\n",
            "   ...\n",
            "   [ 0.36470592]\n",
            "   [ 0.254902  ]\n",
            "   [ 0.34901965]]\n",
            "\n",
            "  [[-0.01960784]\n",
            "   [-0.09019607]\n",
            "   [-0.1372549 ]\n",
            "   ...\n",
            "   [ 0.30196083]\n",
            "   [ 0.254902  ]\n",
            "   [ 0.32549024]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.4823529 ]\n",
            "   [-0.5686275 ]\n",
            "   [-0.49019605]]\n",
            "\n",
            "  [[-0.99215686]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.6156863 ]\n",
            "   [-0.4980392 ]\n",
            "   [-0.45098037]]\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.77254903]\n",
            "   [-0.54509807]\n",
            "   [-0.41176468]]]\n",
            "\n",
            "\n",
            " [[[-0.73333335]\n",
            "   [-0.73333335]\n",
            "   [-0.73333335]\n",
            "   ...\n",
            "   [ 0.45882356]\n",
            "   [ 0.39607847]\n",
            "   [ 0.3176471 ]]\n",
            "\n",
            "  [[-0.7411765 ]\n",
            "   [-0.7411765 ]\n",
            "   [-0.7411765 ]\n",
            "   ...\n",
            "   [ 0.43529415]\n",
            "   [ 0.3411765 ]\n",
            "   [ 0.28627455]]\n",
            "\n",
            "  [[-0.7411765 ]\n",
            "   [-0.7490196 ]\n",
            "   [-0.7490196 ]\n",
            "   ...\n",
            "   [ 0.37254906]\n",
            "   [ 0.3176471 ]\n",
            "   [ 0.254902  ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.96862745]\n",
            "   [-0.9607843 ]\n",
            "   [-0.96862745]\n",
            "   ...\n",
            "   [-0.46666664]\n",
            "   [-0.5137255 ]\n",
            "   [-0.54509807]]\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.44313723]\n",
            "   [-0.4823529 ]\n",
            "   [-0.47450978]]\n",
            "\n",
            "  [[-0.4588235 ]\n",
            "   [-0.58431375]\n",
            "   [-0.73333335]\n",
            "   ...\n",
            "   [-0.45098037]\n",
            "   [-0.44313723]\n",
            "   [-0.40392154]]]\n",
            "\n",
            "\n",
            " [[[-0.7254902 ]\n",
            "   [-0.8039216 ]\n",
            "   [-0.62352943]\n",
            "   ...\n",
            "   [-0.00392157]\n",
            "   [-0.00392157]\n",
            "   [-0.01176471]]\n",
            "\n",
            "  [[-0.79607844]\n",
            "   [-0.8039216 ]\n",
            "   [-0.6       ]\n",
            "   ...\n",
            "   [ 0.00392163]\n",
            "   [ 0.00392163]\n",
            "   [-0.00392157]]\n",
            "\n",
            "  [[-0.81960785]\n",
            "   [-0.8039216 ]\n",
            "   [-0.56078434]\n",
            "   ...\n",
            "   [-0.00392157]\n",
            "   [-0.01176471]\n",
            "   [ 0.00392163]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.7882353 ]\n",
            "   [-0.7882353 ]\n",
            "   [-0.7490196 ]\n",
            "   ...\n",
            "   [-0.01176471]\n",
            "   [-0.01176471]\n",
            "   [-0.02745098]]\n",
            "\n",
            "  [[-0.77254903]\n",
            "   [-0.75686276]\n",
            "   [-0.7490196 ]\n",
            "   ...\n",
            "   [-0.01176471]\n",
            "   [-0.02745098]\n",
            "   [-0.02745098]]\n",
            "\n",
            "  [[-0.7490196 ]\n",
            "   [-0.73333335]\n",
            "   [-0.7490196 ]\n",
            "   ...\n",
            "   [-0.02745098]\n",
            "   [-0.02745098]\n",
            "   [-0.03529412]]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\\n\\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKvEv321Stt5",
        "outputId": "19a65dcf-d22b-45e9-81e1-8d349a2c717c"
      },
      "source": [
        "print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validasi (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "test (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "train (28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH9Q-TegBR26"
      },
      "source": [
        "#hyperparameter and callback\n",
        "batch_size = 64\n",
        "num_epochs = 60\n",
        "input_shape = (48, 48, 1)\n",
        "num_classes = 7\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGsscQRJBR-h"
      },
      "source": [
        "#Compile the model.\n",
        "\n",
        "\n",
        "from keras.optimizers import Adam, SGD\n",
        "model = ResNet50(input_shape = (48, 48, 1), classes = 7)\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer= optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rodttDWeT2yP"
      },
      "source": [
        "#kita mau save model callbackshuhuhuhuhhg\n",
        "\"\"\"import os\n",
        "try:\n",
        "  os.mkdir('scratchcheckpoint')\n",
        "except:\n",
        "  pass\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV29sTjET28U"
      },
      "source": [
        "\"\"\"file_name = 'Best_Model_resnet50Scracth_sena1.h5'\n",
        "\n",
        "checkpoint_path = os.path.join('checkpoint',file_name)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_S6wUaPT3Jx"
      },
      "source": [
        "\"\"\"call_back = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
        "                                               monitor='val_accuracy',\n",
        "                                               verbose=1,\n",
        "                                               save_freq='epoch',\n",
        "                                               save_best_only=True,\n",
        "                                               save_weights_only=False,\n",
        "                                               mode='max')\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy53DHMGB-Mr",
        "outputId": "9903febe-6d32-4561-fdd9-7368bfa2c151"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 46, 46, 128)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 46, 46, 128)  0           activation_3[0][0]               \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 46, 46, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 46, 46, 128)  0           activation_6[0][0]               \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 46, 46, 128)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 23, 23, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 23, 23, 256)  0           activation_12[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 23, 23, 256)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 23, 23, 256)  0           activation_15[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 23, 23, 256)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 23, 23, 256)  0           activation_18[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 23, 23, 256)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 12, 12, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 12, 12, 512)  0           activation_24[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 12, 12, 512)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 12, 12, 512)  0           activation_27[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 12, 12, 512)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 12, 12, 512)  0           activation_30[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 12, 12, 512)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 12, 12, 512)  0           activation_33[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 12, 12, 512)  0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 12, 12, 512)  0           activation_36[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 12, 12, 512)  0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 6, 6, 1024)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 6, 6, 1024)   0           activation_42[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 6, 6, 1024)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 6, 6, 1024)   0           activation_45[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 6, 6, 1024)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgxCecVwCGEr"
      },
      "source": [
        "\"\"\"history = model.fit(data_generator.flow(xtrain, ytrain,),\n",
        "                        steps_per_epoch=len(xtrain) / batch_size,\n",
        "                        epochs=num_epochs, verbose=1,callbacks=call_back,\n",
        "                        validation_data= (xtest,ytest))\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2muXWns0sJSH",
        "outputId": "ae7c6384-37ca-4353-f218-518f41ffb0eb"
      },
      "source": [
        "history = model.fit(\n",
        "    data_generator.flow(xtrain, ytrain,),\n",
        "    steps_per_epoch=len(xtrain) / batch_size,\n",
        "    epochs=num_epochs,\n",
        "    shuffle=False, \n",
        "    verbose=1,\n",
        "    validation_data= (x_val,y_val))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "448/448 [==============================] - 107s 113ms/step - loss: 3.1317 - accuracy: 0.2269 - val_loss: 1.8076 - val_accuracy: 0.2112\n",
            "Epoch 2/60\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 1.7137 - accuracy: 0.3210 - val_loss: 2.1146 - val_accuracy: 0.2218\n",
            "Epoch 3/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.5453 - accuracy: 0.3984 - val_loss: 1.7512 - val_accuracy: 0.3296\n",
            "Epoch 4/60\n",
            "448/448 [==============================] - 49s 109ms/step - loss: 1.4468 - accuracy: 0.4394 - val_loss: 1.3586 - val_accuracy: 0.4720\n",
            "Epoch 5/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.3589 - accuracy: 0.4749 - val_loss: 1.3774 - val_accuracy: 0.4631\n",
            "Epoch 6/60\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 1.3137 - accuracy: 0.4948 - val_loss: 1.2798 - val_accuracy: 0.5049\n",
            "Epoch 7/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.2928 - accuracy: 0.5041 - val_loss: 1.3339 - val_accuracy: 0.4954\n",
            "Epoch 8/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.2414 - accuracy: 0.5270 - val_loss: 1.2272 - val_accuracy: 0.5408\n",
            "Epoch 9/60\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.2334 - accuracy: 0.5301 - val_loss: 1.2506 - val_accuracy: 0.5297\n",
            "Epoch 10/60\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 1.1963 - accuracy: 0.5412 - val_loss: 1.1809 - val_accuracy: 0.5534\n",
            "Epoch 11/60\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 1.1884 - accuracy: 0.5469 - val_loss: 1.1870 - val_accuracy: 0.5486\n",
            "Epoch 12/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.1636 - accuracy: 0.5596 - val_loss: 1.1390 - val_accuracy: 0.5678\n",
            "Epoch 13/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.1220 - accuracy: 0.5749 - val_loss: 1.6452 - val_accuracy: 0.4416\n",
            "Epoch 14/60\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 1.1036 - accuracy: 0.5796 - val_loss: 1.1746 - val_accuracy: 0.5631\n",
            "Epoch 15/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.1119 - accuracy: 0.5760 - val_loss: 1.2924 - val_accuracy: 0.5277\n",
            "Epoch 16/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.1041 - accuracy: 0.5816 - val_loss: 1.0939 - val_accuracy: 0.5885\n",
            "Epoch 17/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.0885 - accuracy: 0.5898 - val_loss: 1.1213 - val_accuracy: 0.5765\n",
            "Epoch 18/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.0790 - accuracy: 0.5916 - val_loss: 1.2439 - val_accuracy: 0.5291\n",
            "Epoch 19/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.0626 - accuracy: 0.6033 - val_loss: 1.1375 - val_accuracy: 0.5651\n",
            "Epoch 20/60\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 1.0499 - accuracy: 0.6050 - val_loss: 1.1739 - val_accuracy: 0.5578\n",
            "Epoch 21/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.0302 - accuracy: 0.6151 - val_loss: 1.0833 - val_accuracy: 0.5952\n",
            "Epoch 22/60\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 1.0144 - accuracy: 0.6135 - val_loss: 1.0843 - val_accuracy: 0.5921\n",
            "Epoch 23/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.0052 - accuracy: 0.6209 - val_loss: 1.2408 - val_accuracy: 0.5511\n",
            "Epoch 24/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.9968 - accuracy: 0.6260 - val_loss: 1.0929 - val_accuracy: 0.5907\n",
            "Epoch 25/60\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 0.9940 - accuracy: 0.6236 - val_loss: 1.0908 - val_accuracy: 0.5770\n",
            "Epoch 26/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.9796 - accuracy: 0.6278 - val_loss: 1.0730 - val_accuracy: 0.5921\n",
            "Epoch 27/60\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 0.9877 - accuracy: 0.6282 - val_loss: 1.0598 - val_accuracy: 0.6055\n",
            "Epoch 28/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.9717 - accuracy: 0.6335 - val_loss: 1.0390 - val_accuracy: 0.6174\n",
            "Epoch 29/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.9595 - accuracy: 0.6356 - val_loss: 1.1097 - val_accuracy: 0.5804\n",
            "Epoch 30/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.9548 - accuracy: 0.6417 - val_loss: 1.0194 - val_accuracy: 0.6174\n",
            "Epoch 31/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.9395 - accuracy: 0.6431 - val_loss: 1.0755 - val_accuracy: 0.5901\n",
            "Epoch 32/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.9491 - accuracy: 0.6413 - val_loss: 1.0545 - val_accuracy: 0.6057\n",
            "Epoch 33/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.9349 - accuracy: 0.6434 - val_loss: 1.0349 - val_accuracy: 0.6158\n",
            "Epoch 34/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.9348 - accuracy: 0.6498 - val_loss: 0.9902 - val_accuracy: 0.6347\n",
            "Epoch 35/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.9287 - accuracy: 0.6498 - val_loss: 1.0069 - val_accuracy: 0.6222\n",
            "Epoch 36/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.9162 - accuracy: 0.6548 - val_loss: 0.9799 - val_accuracy: 0.6258\n",
            "Epoch 37/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.9216 - accuracy: 0.6465 - val_loss: 1.0281 - val_accuracy: 0.6113\n",
            "Epoch 38/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.9129 - accuracy: 0.6552 - val_loss: 1.0636 - val_accuracy: 0.6088\n",
            "Epoch 39/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.8932 - accuracy: 0.6744 - val_loss: 1.0324 - val_accuracy: 0.6169\n",
            "Epoch 40/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.8823 - accuracy: 0.6709 - val_loss: 0.9819 - val_accuracy: 0.6400\n",
            "Epoch 41/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.8831 - accuracy: 0.6679 - val_loss: 1.0262 - val_accuracy: 0.6158\n",
            "Epoch 42/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.8810 - accuracy: 0.6690 - val_loss: 1.0023 - val_accuracy: 0.6272\n",
            "Epoch 43/60\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 0.8702 - accuracy: 0.6694 - val_loss: 0.9704 - val_accuracy: 0.6347\n",
            "Epoch 44/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.8785 - accuracy: 0.6689 - val_loss: 1.0057 - val_accuracy: 0.6241\n",
            "Epoch 45/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.8628 - accuracy: 0.6776 - val_loss: 0.9652 - val_accuracy: 0.6353\n",
            "Epoch 46/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.8553 - accuracy: 0.6786 - val_loss: 0.9688 - val_accuracy: 0.6411\n",
            "Epoch 47/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.8788 - accuracy: 0.6721 - val_loss: 1.0371 - val_accuracy: 0.6177\n",
            "Epoch 48/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.8568 - accuracy: 0.6746 - val_loss: 0.9811 - val_accuracy: 0.6358\n",
            "Epoch 49/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.8457 - accuracy: 0.6833 - val_loss: 1.0063 - val_accuracy: 0.6311\n",
            "Epoch 50/60\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 0.8381 - accuracy: 0.6863 - val_loss: 1.0114 - val_accuracy: 0.6372\n",
            "Epoch 51/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.8384 - accuracy: 0.6857 - val_loss: 0.9977 - val_accuracy: 0.6322\n",
            "Epoch 52/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.8222 - accuracy: 0.6977 - val_loss: 0.9497 - val_accuracy: 0.6445\n",
            "Epoch 53/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.8045 - accuracy: 0.6967 - val_loss: 0.9908 - val_accuracy: 0.6333\n",
            "Epoch 54/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.8288 - accuracy: 0.6881 - val_loss: 1.0840 - val_accuracy: 0.5893\n",
            "Epoch 55/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.8171 - accuracy: 0.6896 - val_loss: 1.0207 - val_accuracy: 0.6325\n",
            "Epoch 56/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.8025 - accuracy: 0.6983 - val_loss: 0.9817 - val_accuracy: 0.6375\n",
            "Epoch 57/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.8012 - accuracy: 0.6963 - val_loss: 0.9735 - val_accuracy: 0.6397\n",
            "Epoch 58/60\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 0.7969 - accuracy: 0.7011 - val_loss: 0.9256 - val_accuracy: 0.6673\n",
            "Epoch 59/60\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 0.7805 - accuracy: 0.7135 - val_loss: 0.9574 - val_accuracy: 0.6517\n",
            "Epoch 60/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.7792 - accuracy: 0.7081 - val_loss: 1.0530 - val_accuracy: 0.6289\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaXUP-8fDWRN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "outputId": "5b7e97c0-2cf4-4240-bf3d-35882e57a602"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "model.save('/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_seed_Aug_adam1_shuffalse1.h5')\n",
        "\n",
        "#gffhgffkjkjdskjjkjkjkjhjhnnnhjhhuyghhg\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "num_epochs = range(len(accuracy))\n",
        "plt.plot(num_epochs, accuracy, 'r', label='Training acc')\n",
        "plt.plot(num_epochs, val_accuracy, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(num_epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(num_epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_LxatO5J-pp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0fecc00-ab90-4563-bc26-92d67f7e15ab"
      },
      "source": [
        "testloss = model.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "trainloss = model.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(trainloss[0]))\n",
        "print(\"Train Acc: \" + str(trainloss[1]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 3s 26ms/step - loss: 1.0546 - accuracy: 0.6308\n",
            "Test Loss 1.0546095371246338\n",
            "Test Acc: 0.6308164000511169\n",
            "898/898 [==============================] - 24s 26ms/step - loss: 0.8397 - accuracy: 0.6909\n",
            "Train Loss 0.8397334814071655\n",
            "Train Acc: 0.6908634901046753\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swoRERVdKQ1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dea6d12-ce6c-46e2-a324-1cea49fc9885"
      },
      "source": [
        "testlosz = model.evaluate(x_val, y_val) \n",
        "print(\"val Loss \" + str(testlosz[0]))\n",
        "print(\"val Acc: \" + str(testlosz[1]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 3s 26ms/step - loss: 1.0530 - accuracy: 0.6289\n",
            "val Loss 1.0530248880386353\n",
            "val Acc: 0.6288659572601318\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5iaZIU6pPzk",
        "outputId": "83455515-8a03-4571-832c-dd02e97f855e"
      },
      "source": [
        "from keras.models import load_model\n",
        "model_load = load_model('/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_seed_Aug_adam1_shuffalse1.h5')\n",
        "\n",
        "model_load.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 46, 46, 128)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 46, 46, 128)  0           activation_3[0][0]               \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 46, 46, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 46, 46, 128)  0           activation_6[0][0]               \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 46, 46, 128)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 23, 23, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 23, 23, 256)  0           activation_12[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 23, 23, 256)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 23, 23, 256)  0           activation_15[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 23, 23, 256)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 23, 23, 256)  0           activation_18[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 23, 23, 256)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 12, 12, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 12, 12, 512)  0           activation_24[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 12, 12, 512)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 12, 12, 512)  0           activation_27[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 12, 12, 512)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 12, 12, 512)  0           activation_30[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 12, 12, 512)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 12, 12, 512)  0           activation_33[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 12, 12, 512)  0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 12, 12, 512)  0           activation_36[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 12, 12, 512)  0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 6, 6, 1024)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 6, 6, 1024)   0           activation_42[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 6, 6, 1024)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 6, 6, 1024)   0           activation_45[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 6, 6, 1024)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypc8clklx2p8",
        "outputId": "3ad2d84c-029f-4ca3-addb-44352c0d052e"
      },
      "source": [
        "#loss,acc = model_load.evaluate(xtrain,ytrain)\n",
        "\"\"\"print(\"loss:\",loss)\n",
        "print(\"acc:\",acc)kjjkj\"\"\"\n",
        "\n",
        "\n",
        "testdatamodel = model_load.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testdatamodel[0]))\n",
        "print(\"Test Acc: \" + str(testdatamodel[1]))\n",
        "\n",
        "traindata = model_load.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(traindata[0]))\n",
        "print(\"Train Acc: \" + str(traindata[1]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 7s 27ms/step - loss: 1.0546 - accuracy: 0.6308\n",
            "Test Loss 1.0546095371246338\n",
            "Test Acc: 0.6308164000511169\n",
            "898/898 [==============================] - 24s 26ms/step - loss: 0.8397 - accuracy: 0.6909\n",
            "Train Loss 0.8397334814071655\n",
            "Train Acc: 0.6908634901046753\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7mSww_U2O_q",
        "outputId": "7e3f69a8-d1e3-407d-d5c6-41abc7c37d08"
      },
      "source": [
        "valdata = model_load.evaluate(x_val, y_val) \n",
        "print(\"Val Loss \" + str(valdata[0]))\n",
        "print(\"Val Acc: \" + str(valdata[1]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 3s 26ms/step - loss: 1.0530 - accuracy: 0.6289\n",
            "Val Loss 1.0530248880386353\n",
            "Val Acc: 0.6288659572601318\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdU7uU3PYCnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33808f2d-d2a5-4ff1-a67a-df2cfd24fbc6"
      },
      "source": [
        "print (x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3589, 48, 48, 1)\n",
            "(3589,)\n",
            "(3589, 48, 48, 1)\n",
            "(3589,)\n",
            "(28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_Tf1qg8TKnx",
        "outputId": "d2f26bde-67cf-4c28-846e-83658d9d1166"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "#y_pred = model_load.predict(xtest)\n",
        "\n",
        "test_prob = model_load.predict(xtest)\n",
        "test_pred = np.argmax(test_prob, axis=1)\n",
        "test_accuracy = np.mean(test_pred == ytest)\n",
        "\n",
        "print(test_accuracy)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6308163833937029\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpwJv9V54_1M"
      },
      "source": [
        "\n",
        "emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "KMe4WL0T5BcJ",
        "outputId": "516071c7-54ff-4701-bd9d-acba63743f6f"
      },
      "source": [
        "conf_mat = confusion_matrix(ytest, test_pred)\n",
        "\n",
        "pd.DataFrame(conf_mat, columns=emotions.values(), index=emotions.values())\n",
        "\n",
        "\n",
        "\n",
        "fig, ax = plot_confusion_matrix(conf_mat=conf_mat,show_normed=True,show_absolute=False,figsize=(8, 8))\n",
        "fig.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW3FZjp-5DgF",
        "outputId": "e39308a4-abac-4547-e887-f2dac29da247"
      },
      "source": [
        "print(classification_report(ytest, test_pred, target_names=emotions.values()))\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry       0.55      0.49      0.52       480\n",
            "     Disgust       0.68      0.28      0.40        60\n",
            "        Fear       0.63      0.30      0.41       515\n",
            "       Happy       0.77      0.90      0.83       883\n",
            "         Sad       0.48      0.62      0.54       597\n",
            "    Surprise       0.86      0.62      0.73       397\n",
            "     Neutral       0.56      0.67      0.61       657\n",
            "\n",
            "    accuracy                           0.63      3589\n",
            "   macro avg       0.65      0.56      0.58      3589\n",
            "weighted avg       0.64      0.63      0.62      3589\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
