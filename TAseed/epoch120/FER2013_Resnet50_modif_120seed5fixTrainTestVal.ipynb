{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER2013_Resnet50_modif_120seed5fixTrainTestVal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-Qn1jsBTIBl0b7myLQxqa8WjCcfbamqM",
      "authorship_tag": "ABX9TyMFERGUM2KC1hboLGSOhJ1d"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b86nukQOxN7l"
      },
      "source": [
        "Resnet-50 From Scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p8gxtGy0TWP",
        "outputId": "3485ac0b-e31b-4719-8b67-938ea72b76fc"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "inputFolder = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth' \n",
        "for root, directories, filenames in os.walk(inputFolder): \n",
        "    for filename in filenames: print(os.path.join(root,filename))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Best_Model_resnet50Scracth1again.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe4.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth1again.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50ScracthSGD1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50AUGScracthadam3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD1try2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD4.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50oriSGD1st.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50SGD5stori.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editSGD5st.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editAdamst120epochBS128.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editAdamst120epochBS128_1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editAdamst120epochBS128+aug:vf_2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50oriAdamst120epochBS128_aug1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50oriAdamst120epochBS128_noaug1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_noAug_adam1_shuffalse1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_seed_Aug_adam1_shuffalse1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_seed_adam_shuffalse_noAug1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_seed_SGD_shuffalse_Aug1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_seed_SGD_shuffalse_Aug2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_seed_Aug_adam2_shuffalse2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_seed_SGD_60_shuffalse_Aug3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_seed1_SGD_30_shuffalse_Aug1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_seed2_SGD_30_shuffalse_Aug2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_seed3_SGD_30_shuffalse_Aug3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_seed3_Adam_30_shuffalse_Aug1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_seed4_Adam_30_shuffalse_Aug2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_seed5_Adam_30_shuffalse_Aug3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_seed1_SGD_90_shuffalse_Aug1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_seed3_SGD_90_shuffalse_Aug3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_seed2_SGD_90_shuffalse_Aug2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_seed4_SGD_90_shuffalse_Aug4.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_seed4_SGD_60_shuffalse_Aug4.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_seed5_SGD_90_shuffalse_Aug5.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_seed6_SGD_90_shuffalse_Aug6.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50oris_seed1_SGD_30_shuffalse_Aug1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50oris_seed2_SGD_30_shuffalse_Aug2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50oris_seed3_SGD_30_shuffalse_Aug3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50oris_seed4_SGD_30_shuffalse_Aug4.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50oris_seed5_SGD_30_shuffalse_Aug5.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50oris_seed6_SGD_30_shuffalse_Aug6.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50oris_seed1_SGD_60_shuffalse_Aug1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50oris_seed2_SGD_60_shuffalse_Aug2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50oris_seed3_SGD_60_shuffalse_Aug3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50oris_seed4_SGD_60_shuffalse_Aug4.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50oris_seed5_SGD_60_shuffalse_Aug5.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50oris_seed1_SGD_90_shuffalse_Aug1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50oris_seed2_SGD_90_shuffalse_Aug2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50oris_seed3_SGD_90_shuffalse_Aug3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50oris_seed4_SGD_90_shuffalse_Aug4.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50oris_seed5_SGD_90_shuffalse_Aug5.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50oris_seed6_SGD_90_shuffalse_Aug6.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50oris_seed6_SGD_60_shuffalse_Aug6.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50modifi_seed6_SGD_60_shuffalse_Aug6.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_seed_SGD_60_shuffalse_Aug3/saved_model.pb\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_seed_SGD_60_shuffalse_Aug3/keras_metadata.pb\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_seed_SGD_60_shuffalse_Aug3/variables/variables.data-00000-of-00001\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50edit_seed_SGD_60_shuffalse_Aug3/variables/variables.index\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50oriScracth_sena2.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsiscWIMBDX2",
        "outputId": "38fe5623-04af-4efb-e39a-ebc485fbec76"
      },
      "source": [
        "%cd /content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "wLMSe510xNCJ",
        "outputId": "3da9f6f5-cb75-4f61-d978-1e7de9a074fc"
      },
      "source": [
        "#Create a directory to save our generated models.dasdas\n",
        "\n",
        "#os.mkdir(\"./modelscracth\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-cf55f19f3613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#os.mkdir(\"./modelscracth\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ls' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_kluusLxM1B",
        "outputId": "36410ea8-9f4a-4581-dfa3-0178c7a2fce9"
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:400: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfUSF_tAxNMP"
      },
      "source": [
        "#Define the identity block helper function.\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "   \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VdYtzhn1F0I"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path \n",
        "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b',padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd-O8ZMx1GAW"
      },
      "source": [
        "def ResNet50(input_shape = (48,48,1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = X_input\n",
        "    # Stage 1\n",
        "\n",
        "    X = Conv2D(8, (3, 3), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # removed maxpool\n",
        "    #X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='c')\n",
        "\n",
        "\n",
        "    # Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [64,64,256], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL . \n",
        "    X = AveragePooling2D((2,2), name='avg_pool')(X)\n",
        "    \n",
        "    # output layerds\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(512, activation = 'relu', name='fc1024' , kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GKsSwtp-GuL"
      },
      "source": [
        "\"\"\"def ResNet50ori(input_shape = (48, 48, 1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns: dsdsf\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50ori')\n",
        "\n",
        "    return model\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oWTDXlyBHM2"
      },
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        " \n",
        "dataset_path = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv'\n",
        "image_size=(48,48)\n",
        "#batch_size = 64\n",
        "\n",
        "def load_fer2013():\n",
        "    data = pd.read_csv(dataset_path)\n",
        "    data = (data[data['pixels'].notnull()])\n",
        "    pixels = data['pixels'].tolist()\n",
        "    width, height = 48, 48\n",
        "    faces = []\n",
        "    for pixel_sequence in pixels:\n",
        "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "        face = np.asarray(face).reshape(width, height)\n",
        "        face = cv2.resize(face.astype('uint8'),image_size)\n",
        "        faces.append(face.astype('float32'))\n",
        "    faces = np.asarray(faces)\n",
        "    faces = np.expand_dims(faces, -1)\n",
        "    emotions = (data['emotion'])#.values\n",
        "    return faces, emotions\n",
        " \n",
        "def preprocess_input(x, v2=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if v2:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x\n",
        " \n",
        "faces, emotions = load_fer2013()\n",
        "faces = preprocess_input(faces)\n",
        "#xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
        "#Data Augumentation\n",
        "data_generator = ImageDataGenerator(\n",
        "                        rotation_range=10,\n",
        "                        shear_range = 10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True,\n",
        "                        )\n",
        "#data_generator = ImageDataGenerator( )\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "RGhnYFXgaqL9",
        "outputId": "0e60da2f-3a44-4d06-910b-2e0f2fa4191a"
      },
      "source": [
        "\"\"\"print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (y_train.shape)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'print (\"validasi\",x_val.shape)\\nprint (y_val.shape)\\nprint (\"test\",xtest.shape)\\nprint (ytest.shape)\\nprint (\"train\",xtrain.shape)\\nprint (y_train.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "rDS3hqhDSteM",
        "outputId": "bcc06d4c-223d-4d05-ba88-5a9fc9a30b95"
      },
      "source": [
        "train_ratio = 0.80\n",
        "validation_ratio = 0.10\n",
        "test_ratio = 0.10\n",
        "\n",
        "# train is now 75% of the entire data set\n",
        "# the _junk suffix means that we drop that variable completely # the _junk suffix means that we drop that variable completely\n",
        "#x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=1 - train_ratio,random_state=42)\n",
        "\n",
        "# test is now 10% of the initial data set\n",
        "# validation is now 15% of the initial data set\n",
        "#x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "x_val, xtest, y_val, ytest = train_test_split(xtest, ytest, test_size=test_ratio/(test_ratio + validation_ratio), random_state=42) \n",
        "\n",
        "#print(xtrain, x_val, xtest)\n",
        "\n",
        "\"\"\"X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2\"\"\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\\n\\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKvEv321Stt5",
        "outputId": "b809e8f5-dba6-4540-ac0e-e5c6a95fbf10"
      },
      "source": [
        "print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validasi (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "test (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "train (28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH9Q-TegBR26"
      },
      "source": [
        "#hyperparameter and callback\n",
        "batch_size = 64\n",
        "num_epochs = 120\n",
        "input_shape = (48, 48, 1)\n",
        "num_classes = 7\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGsscQRJBR-h"
      },
      "source": [
        "#Compile the model.gyg\n",
        "\n",
        "\n",
        "from keras.optimizers import Adam, SGD\n",
        "model = ResNet50(input_shape = (48, 48, 1), classes = 7)\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer= optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy53DHMGB-Mr",
        "outputId": "5477c22b-d62a-4101-b291-f542691f2926"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 46, 46, 128)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 46, 46, 128)  0           activation_3[0][0]               \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 46, 46, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 46, 46, 128)  0           activation_6[0][0]               \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 46, 46, 128)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 23, 23, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 23, 23, 256)  0           activation_12[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 23, 23, 256)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 23, 23, 256)  0           activation_15[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 23, 23, 256)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 23, 23, 256)  0           activation_18[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 23, 23, 256)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 12, 12, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 12, 12, 512)  0           activation_24[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 12, 12, 512)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 12, 12, 512)  0           activation_27[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 12, 12, 512)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 12, 12, 512)  0           activation_30[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 12, 12, 512)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 12, 12, 512)  0           activation_33[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 12, 12, 512)  0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 12, 12, 512)  0           activation_36[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 12, 12, 512)  0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 6, 6, 1024)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 6, 6, 1024)   0           activation_42[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 6, 6, 1024)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 6, 6, 1024)   0           activation_45[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 6, 6, 1024)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2muXWns0sJSH",
        "outputId": "a2b0479b-ae2f-4973-9111-59067a4636ba"
      },
      "source": [
        "history = model.fit(\n",
        "    data_generator.flow(xtrain, ytrain,),\n",
        "    steps_per_epoch=len(xtrain) / batch_size,\n",
        "    epochs=num_epochs,\n",
        "    shuffle=False, \n",
        "    verbose=1,\n",
        "    validation_data= (x_val,y_val))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/120\n",
            "448/448 [==============================] - 108s 115ms/step - loss: 2.2485 - accuracy: 0.2132 - val_loss: 1.9512 - val_accuracy: 0.1744\n",
            "Epoch 2/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.7858 - accuracy: 0.2552 - val_loss: 1.8110 - val_accuracy: 0.2633\n",
            "Epoch 3/120\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.7430 - accuracy: 0.2881 - val_loss: 1.7365 - val_accuracy: 0.2909\n",
            "Epoch 4/120\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.6744 - accuracy: 0.3319 - val_loss: 1.6441 - val_accuracy: 0.3500\n",
            "Epoch 5/120\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.5929 - accuracy: 0.3725 - val_loss: 1.5953 - val_accuracy: 0.3987\n",
            "Epoch 6/120\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.5187 - accuracy: 0.4106 - val_loss: 1.5685 - val_accuracy: 0.4035\n",
            "Epoch 7/120\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.4592 - accuracy: 0.4361 - val_loss: 1.4419 - val_accuracy: 0.4430\n",
            "Epoch 8/120\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 1.4157 - accuracy: 0.4526 - val_loss: 1.3908 - val_accuracy: 0.4698\n",
            "Epoch 9/120\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.3911 - accuracy: 0.4648 - val_loss: 1.4110 - val_accuracy: 0.4625\n",
            "Epoch 10/120\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.3380 - accuracy: 0.4854 - val_loss: 1.3605 - val_accuracy: 0.4762\n",
            "Epoch 11/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.3296 - accuracy: 0.4930 - val_loss: 1.3156 - val_accuracy: 0.4976\n",
            "Epoch 12/120\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 1.2931 - accuracy: 0.5034 - val_loss: 1.2629 - val_accuracy: 0.5252\n",
            "Epoch 13/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.2499 - accuracy: 0.5192 - val_loss: 1.2864 - val_accuracy: 0.4982\n",
            "Epoch 14/120\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.2176 - accuracy: 0.5387 - val_loss: 1.2457 - val_accuracy: 0.5241\n",
            "Epoch 15/120\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.2211 - accuracy: 0.5394 - val_loss: 1.2938 - val_accuracy: 0.5132\n",
            "Epoch 16/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.1975 - accuracy: 0.5464 - val_loss: 1.1968 - val_accuracy: 0.5417\n",
            "Epoch 17/120\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.1755 - accuracy: 0.5563 - val_loss: 1.2188 - val_accuracy: 0.5458\n",
            "Epoch 18/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.1697 - accuracy: 0.5484 - val_loss: 1.1931 - val_accuracy: 0.5386\n",
            "Epoch 19/120\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.1421 - accuracy: 0.5668 - val_loss: 1.2142 - val_accuracy: 0.5403\n",
            "Epoch 20/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.1285 - accuracy: 0.5724 - val_loss: 1.1631 - val_accuracy: 0.5539\n",
            "Epoch 21/120\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.1031 - accuracy: 0.5866 - val_loss: 1.1301 - val_accuracy: 0.5642\n",
            "Epoch 22/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.0920 - accuracy: 0.5867 - val_loss: 1.2485 - val_accuracy: 0.5280\n",
            "Epoch 23/120\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.0701 - accuracy: 0.5970 - val_loss: 1.1945 - val_accuracy: 0.5612\n",
            "Epoch 24/120\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 1.0609 - accuracy: 0.6022 - val_loss: 1.1329 - val_accuracy: 0.5726\n",
            "Epoch 25/120\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.0573 - accuracy: 0.5992 - val_loss: 1.1043 - val_accuracy: 0.5885\n",
            "Epoch 26/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.0467 - accuracy: 0.6028 - val_loss: 1.1813 - val_accuracy: 0.5631\n",
            "Epoch 27/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.0505 - accuracy: 0.6065 - val_loss: 1.1722 - val_accuracy: 0.5486\n",
            "Epoch 28/120\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.0376 - accuracy: 0.6086 - val_loss: 1.1453 - val_accuracy: 0.5748\n",
            "Epoch 29/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.0075 - accuracy: 0.6201 - val_loss: 1.1320 - val_accuracy: 0.5715\n",
            "Epoch 30/120\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 1.0038 - accuracy: 0.6177 - val_loss: 1.0649 - val_accuracy: 0.5963\n",
            "Epoch 31/120\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 0.9933 - accuracy: 0.6247 - val_loss: 1.2079 - val_accuracy: 0.5439\n",
            "Epoch 32/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.9922 - accuracy: 0.6261 - val_loss: 1.0250 - val_accuracy: 0.6099\n",
            "Epoch 33/120\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 0.9698 - accuracy: 0.6270 - val_loss: 1.0597 - val_accuracy: 0.5974\n",
            "Epoch 34/120\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.9717 - accuracy: 0.6298 - val_loss: 1.0494 - val_accuracy: 0.6133\n",
            "Epoch 35/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.9572 - accuracy: 0.6406 - val_loss: 1.0543 - val_accuracy: 0.5988\n",
            "Epoch 36/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.9587 - accuracy: 0.6395 - val_loss: 1.0537 - val_accuracy: 0.5977\n",
            "Epoch 37/120\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 0.9658 - accuracy: 0.6324 - val_loss: 1.1039 - val_accuracy: 0.5834\n",
            "Epoch 38/120\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.9500 - accuracy: 0.6412 - val_loss: 1.1420 - val_accuracy: 0.5729\n",
            "Epoch 39/120\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 0.9285 - accuracy: 0.6495 - val_loss: 1.0751 - val_accuracy: 0.5949\n",
            "Epoch 40/120\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.9085 - accuracy: 0.6617 - val_loss: 1.0521 - val_accuracy: 0.6147\n",
            "Epoch 41/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.9229 - accuracy: 0.6560 - val_loss: 1.0669 - val_accuracy: 0.6032\n",
            "Epoch 42/120\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 0.9078 - accuracy: 0.6560 - val_loss: 1.0624 - val_accuracy: 0.6027\n",
            "Epoch 43/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.9116 - accuracy: 0.6624 - val_loss: 1.0291 - val_accuracy: 0.6108\n",
            "Epoch 44/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.9073 - accuracy: 0.6573 - val_loss: 1.0306 - val_accuracy: 0.6163\n",
            "Epoch 45/120\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.8862 - accuracy: 0.6648 - val_loss: 1.0571 - val_accuracy: 0.6016\n",
            "Epoch 46/120\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 0.8742 - accuracy: 0.6691 - val_loss: 1.0286 - val_accuracy: 0.6191\n",
            "Epoch 47/120\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.8969 - accuracy: 0.6663 - val_loss: 1.0296 - val_accuracy: 0.6135\n",
            "Epoch 48/120\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.8786 - accuracy: 0.6693 - val_loss: 1.1135 - val_accuracy: 0.5857\n",
            "Epoch 49/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.8796 - accuracy: 0.6688 - val_loss: 1.0656 - val_accuracy: 0.6085\n",
            "Epoch 50/120\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 0.8578 - accuracy: 0.6809 - val_loss: 1.0246 - val_accuracy: 0.6339\n",
            "Epoch 51/120\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.8742 - accuracy: 0.6754 - val_loss: 1.0422 - val_accuracy: 0.6094\n",
            "Epoch 52/120\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.8481 - accuracy: 0.6813 - val_loss: 1.0192 - val_accuracy: 0.6124\n",
            "Epoch 53/120\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 0.8215 - accuracy: 0.6898 - val_loss: 1.0215 - val_accuracy: 0.6311\n",
            "Epoch 54/120\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.8333 - accuracy: 0.6869 - val_loss: 1.0127 - val_accuracy: 0.6247\n",
            "Epoch 55/120\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 0.8304 - accuracy: 0.6851 - val_loss: 1.0236 - val_accuracy: 0.6216\n",
            "Epoch 56/120\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.8131 - accuracy: 0.6934 - val_loss: 1.0623 - val_accuracy: 0.6219\n",
            "Epoch 57/120\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.8135 - accuracy: 0.6905 - val_loss: 0.9987 - val_accuracy: 0.6278\n",
            "Epoch 58/120\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.8002 - accuracy: 0.6983 - val_loss: 1.0570 - val_accuracy: 0.6283\n",
            "Epoch 59/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.7888 - accuracy: 0.7074 - val_loss: 0.9928 - val_accuracy: 0.6434\n",
            "Epoch 60/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.7974 - accuracy: 0.6985 - val_loss: 1.0219 - val_accuracy: 0.6297\n",
            "Epoch 61/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.7895 - accuracy: 0.7078 - val_loss: 1.0416 - val_accuracy: 0.6211\n",
            "Epoch 62/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.7875 - accuracy: 0.7128 - val_loss: 1.0422 - val_accuracy: 0.6333\n",
            "Epoch 63/120\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 0.7798 - accuracy: 0.7066 - val_loss: 0.9790 - val_accuracy: 0.6475\n",
            "Epoch 64/120\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 0.7679 - accuracy: 0.7116 - val_loss: 1.0028 - val_accuracy: 0.6311\n",
            "Epoch 65/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.7659 - accuracy: 0.7119 - val_loss: 1.0133 - val_accuracy: 0.6459\n",
            "Epoch 66/120\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 0.7571 - accuracy: 0.7169 - val_loss: 1.0592 - val_accuracy: 0.6255\n",
            "Epoch 67/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.7582 - accuracy: 0.7136 - val_loss: 1.1051 - val_accuracy: 0.6233\n",
            "Epoch 68/120\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.7605 - accuracy: 0.7134 - val_loss: 1.0029 - val_accuracy: 0.6350\n",
            "Epoch 69/120\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 0.7277 - accuracy: 0.7271 - val_loss: 0.9834 - val_accuracy: 0.6478\n",
            "Epoch 70/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.7546 - accuracy: 0.7171 - val_loss: 1.0750 - val_accuracy: 0.6319\n",
            "Epoch 71/120\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.7421 - accuracy: 0.7231 - val_loss: 1.0394 - val_accuracy: 0.6322\n",
            "Epoch 72/120\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.7516 - accuracy: 0.7197 - val_loss: 0.9918 - val_accuracy: 0.6486\n",
            "Epoch 73/120\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 0.7440 - accuracy: 0.7179 - val_loss: 1.0222 - val_accuracy: 0.6422\n",
            "Epoch 74/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.7035 - accuracy: 0.7371 - val_loss: 0.9963 - val_accuracy: 0.6450\n",
            "Epoch 75/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.6900 - accuracy: 0.7435 - val_loss: 1.0324 - val_accuracy: 0.6486\n",
            "Epoch 76/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.7189 - accuracy: 0.7307 - val_loss: 1.0730 - val_accuracy: 0.6314\n",
            "Epoch 77/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.7040 - accuracy: 0.7395 - val_loss: 0.9991 - val_accuracy: 0.6506\n",
            "Epoch 78/120\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.6976 - accuracy: 0.7373 - val_loss: 1.0703 - val_accuracy: 0.6381\n",
            "Epoch 79/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.7006 - accuracy: 0.7405 - val_loss: 0.9960 - val_accuracy: 0.6498\n",
            "Epoch 80/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.6925 - accuracy: 0.7408 - val_loss: 1.0842 - val_accuracy: 0.6300\n",
            "Epoch 81/120\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 0.6836 - accuracy: 0.7453 - val_loss: 1.0118 - val_accuracy: 0.6484\n",
            "Epoch 82/120\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 0.6753 - accuracy: 0.7518 - val_loss: 1.0294 - val_accuracy: 0.6537\n",
            "Epoch 83/120\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 0.6867 - accuracy: 0.7489 - val_loss: 1.0472 - val_accuracy: 0.6500\n",
            "Epoch 84/120\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 0.6755 - accuracy: 0.7481 - val_loss: 1.0363 - val_accuracy: 0.6403\n",
            "Epoch 85/120\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 0.6650 - accuracy: 0.7532 - val_loss: 1.0002 - val_accuracy: 0.6512\n",
            "Epoch 86/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.6794 - accuracy: 0.7406 - val_loss: 1.0599 - val_accuracy: 0.6397\n",
            "Epoch 87/120\n",
            "448/448 [==============================] - 49s 109ms/step - loss: 0.6533 - accuracy: 0.7586 - val_loss: 0.9893 - val_accuracy: 0.6648\n",
            "Epoch 88/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.6730 - accuracy: 0.7543 - val_loss: 1.0311 - val_accuracy: 0.6637\n",
            "Epoch 89/120\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 0.6295 - accuracy: 0.7642 - val_loss: 1.0774 - val_accuracy: 0.6317\n",
            "Epoch 90/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.6309 - accuracy: 0.7628 - val_loss: 1.0160 - val_accuracy: 0.6645\n",
            "Epoch 91/120\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 0.6434 - accuracy: 0.7623 - val_loss: 1.0469 - val_accuracy: 0.6489\n",
            "Epoch 92/120\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 0.6202 - accuracy: 0.7614 - val_loss: 1.0426 - val_accuracy: 0.6495\n",
            "Epoch 93/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.6251 - accuracy: 0.7785 - val_loss: 1.0372 - val_accuracy: 0.6495\n",
            "Epoch 94/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.6224 - accuracy: 0.7673 - val_loss: 1.1053 - val_accuracy: 0.6378\n",
            "Epoch 95/120\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 0.6158 - accuracy: 0.7718 - val_loss: 1.1063 - val_accuracy: 0.6275\n",
            "Epoch 96/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.6085 - accuracy: 0.7777 - val_loss: 1.0568 - val_accuracy: 0.6506\n",
            "Epoch 97/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.6090 - accuracy: 0.7748 - val_loss: 1.0983 - val_accuracy: 0.6459\n",
            "Epoch 98/120\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 0.6154 - accuracy: 0.7742 - val_loss: 1.0128 - val_accuracy: 0.6707\n",
            "Epoch 99/120\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 0.6018 - accuracy: 0.7708 - val_loss: 1.0673 - val_accuracy: 0.6475\n",
            "Epoch 100/120\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.6042 - accuracy: 0.7745 - val_loss: 1.0785 - val_accuracy: 0.6461\n",
            "Epoch 101/120\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 0.6049 - accuracy: 0.7735 - val_loss: 1.0713 - val_accuracy: 0.6581\n",
            "Epoch 102/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.5935 - accuracy: 0.7814 - val_loss: 1.0769 - val_accuracy: 0.6539\n",
            "Epoch 103/120\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 0.5889 - accuracy: 0.7875 - val_loss: 1.0793 - val_accuracy: 0.6545\n",
            "Epoch 104/120\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 0.5616 - accuracy: 0.7925 - val_loss: 1.0897 - val_accuracy: 0.6612\n",
            "Epoch 105/120\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 0.5646 - accuracy: 0.7922 - val_loss: 1.0280 - val_accuracy: 0.6707\n",
            "Epoch 106/120\n",
            "448/448 [==============================] - 49s 109ms/step - loss: 0.5776 - accuracy: 0.7921 - val_loss: 1.0700 - val_accuracy: 0.6559\n",
            "Epoch 107/120\n",
            "448/448 [==============================] - 49s 109ms/step - loss: 0.5412 - accuracy: 0.7997 - val_loss: 1.0506 - val_accuracy: 0.6584\n",
            "Epoch 108/120\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 0.5539 - accuracy: 0.7958 - val_loss: 1.0978 - val_accuracy: 0.6590\n",
            "Epoch 109/120\n",
            "448/448 [==============================] - 49s 110ms/step - loss: 0.5527 - accuracy: 0.7918 - val_loss: 1.0344 - val_accuracy: 0.6509\n",
            "Epoch 110/120\n",
            "448/448 [==============================] - 49s 110ms/step - loss: 0.5607 - accuracy: 0.7902 - val_loss: 1.0920 - val_accuracy: 0.6353\n",
            "Epoch 111/120\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 0.5469 - accuracy: 0.8011 - val_loss: 1.0683 - val_accuracy: 0.6553\n",
            "Epoch 112/120\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 0.5254 - accuracy: 0.8111 - val_loss: 1.0980 - val_accuracy: 0.6651\n",
            "Epoch 113/120\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 0.5490 - accuracy: 0.7954 - val_loss: 1.1355 - val_accuracy: 0.6492\n",
            "Epoch 114/120\n",
            "448/448 [==============================] - 49s 109ms/step - loss: 0.5381 - accuracy: 0.8029 - val_loss: 1.1628 - val_accuracy: 0.6545\n",
            "Epoch 115/120\n",
            "448/448 [==============================] - 49s 109ms/step - loss: 0.5158 - accuracy: 0.8135 - val_loss: 1.0705 - val_accuracy: 0.6523\n",
            "Epoch 116/120\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 0.5265 - accuracy: 0.8069 - val_loss: 1.1301 - val_accuracy: 0.6531\n",
            "Epoch 117/120\n",
            "448/448 [==============================] - 49s 109ms/step - loss: 0.5133 - accuracy: 0.8065 - val_loss: 1.1431 - val_accuracy: 0.6542\n",
            "Epoch 118/120\n",
            "448/448 [==============================] - 49s 109ms/step - loss: 0.5212 - accuracy: 0.8076 - val_loss: 1.1876 - val_accuracy: 0.6364\n",
            "Epoch 119/120\n",
            "448/448 [==============================] - 49s 109ms/step - loss: 0.5284 - accuracy: 0.8058 - val_loss: 1.0914 - val_accuracy: 0.6606\n",
            "Epoch 120/120\n",
            "448/448 [==============================] - 49s 108ms/step - loss: 0.4995 - accuracy: 0.8180 - val_loss: 1.1456 - val_accuracy: 0.6581\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaXUP-8fDWRN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "outputId": "e77edc3b-bcb6-4fe5-bfd4-6f7a918aedf5"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "model.save('/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50modifi_seed5_SGD_120_shuffalse_Aug5.h5')\n",
        "\n",
        "#fdsdsssaasyfyf\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "num_epochs = range(len(accuracy))\n",
        "plt.plot(num_epochs, accuracy, 'r', label='Training acc')\n",
        "plt.plot(num_epochs, val_accuracy, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(num_epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(num_epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_LxatO5J-pp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b773f455-66ac-4c71-caeb-749cc9b86b5c"
      },
      "source": [
        "testloss = model.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "trainloss = model.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(trainloss[0]))\n",
        "print(\"Train Acc: \" + str(trainloss[1]))\n",
        "\n",
        "vallosz = model.evaluate(x_val, y_val) \n",
        "print(\"val Loss \" + str(vallosz[0]))\n",
        "print(\"val Acc: \" + str(vallosz[1]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 3s 27ms/step - loss: 1.1277 - accuracy: 0.6643\n",
            "Test Loss 1.1277064085006714\n",
            "Test Acc: 0.6642518639564514\n",
            "898/898 [==============================] - 24s 27ms/step - loss: 0.5031 - accuracy: 0.8123\n",
            "Train Loss 0.5031320452690125\n",
            "Train Acc: 0.8123236894607544\n",
            "113/113 [==============================] - 3s 27ms/step - loss: 1.1456 - accuracy: 0.6581\n",
            "val Loss 1.1456096172332764\n",
            "val Acc: 0.6581220626831055\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5iaZIU6pPzk",
        "outputId": "011a386d-779a-4401-debc-52b9b2e8e05e"
      },
      "source": [
        "from keras.models import load_model\n",
        "model_load = load_model('/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_resnet50modifi_seed5_SGD_120_shuffalse_Aug5.h5')\n",
        "\n",
        "model_load.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 46, 46, 128)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 46, 46, 128)  0           activation_3[0][0]               \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 46, 46, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 46, 46, 128)  0           activation_6[0][0]               \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 46, 46, 128)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 23, 23, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 23, 23, 256)  0           activation_12[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 23, 23, 256)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 23, 23, 256)  0           activation_15[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 23, 23, 256)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 23, 23, 256)  0           activation_18[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 23, 23, 256)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 12, 12, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 12, 12, 512)  0           activation_24[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 12, 12, 512)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 12, 12, 512)  0           activation_27[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 12, 12, 512)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 12, 12, 512)  0           activation_30[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 12, 12, 512)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 12, 12, 512)  0           activation_33[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 12, 12, 512)  0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 12, 12, 512)  0           activation_36[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 12, 12, 512)  0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 6, 6, 1024)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 6, 6, 1024)   0           activation_42[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 6, 6, 1024)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 6, 6, 1024)   0           activation_45[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 6, 6, 1024)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypc8clklx2p8",
        "outputId": "e5c943ff-54ee-4a1b-f84b-aeb571cbcb6e"
      },
      "source": [
        "#loss,acc = model_load.evaluate(xtrain,ytrain)\n",
        "\"\"\"print(\"loss:\",loss)\n",
        "print(\"acc:\",acc)kjjkj\"\"\"\n",
        "\n",
        "\n",
        "testdatamodel = model_load.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testdatamodel[0]))\n",
        "print(\"Test Acc: \" + str(testdatamodel[1]))\n",
        "\n",
        "traindata = model_load.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(traindata[0]))\n",
        "print(\"Train Acc: \" + str(traindata[1]))\n",
        "\n",
        "valdata = model_load.evaluate(x_val, y_val) \n",
        "print(\"Val Loss \" + str(valdata[0]))\n",
        "print(\"Val Acc: \" + str(valdata[1]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 7s 27ms/step - loss: 1.1277 - accuracy: 0.6643\n",
            "Test Loss 1.1277064085006714\n",
            "Test Acc: 0.6642518639564514\n",
            "898/898 [==============================] - 24s 27ms/step - loss: 0.5031 - accuracy: 0.8123\n",
            "Train Loss 0.5031320452690125\n",
            "Train Acc: 0.8123236894607544\n",
            "113/113 [==============================] - 3s 27ms/step - loss: 1.1456 - accuracy: 0.6581\n",
            "Val Loss 1.1456096172332764\n",
            "Val Acc: 0.6581220626831055\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdU7uU3PYCnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3785e045-a618-4878-d860-822a21893401"
      },
      "source": [
        "print (x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3589, 48, 48, 1)\n",
            "(3589,)\n",
            "(3589, 48, 48, 1)\n",
            "(3589,)\n",
            "(28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_Tf1qg8TKnx",
        "outputId": "fadaf820-5d23-4af0-e697-0b359db1440b"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "#y_pred = model_load.predict(xtest)g\n",
        "\n",
        "test_prob = model_load.predict(xtest)\n",
        "test_pred = np.argmax(test_prob, axis=1)\n",
        "test_accuracy = np.mean(test_pred == ytest)\n",
        "\n",
        "print(test_accuracy)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6642518807467261\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpwJv9V54_1M"
      },
      "source": [
        "\n",
        "emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "KMe4WL0T5BcJ",
        "outputId": "45528fa3-9e97-4f0d-c40d-3e38bc2789e3"
      },
      "source": [
        "conf_mat = confusion_matrix(ytest, test_pred)\n",
        "\n",
        "pd.DataFrame(conf_mat, columns=emotions.values(), index=emotions.values())\n",
        "\n",
        "#ghg\n",
        "\n",
        "fig, ax = plot_confusion_matrix(conf_mat=conf_mat,show_normed=True,show_absolute=False,figsize=(8, 8))\n",
        "fig.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW3FZjp-5DgF",
        "outputId": "c29e7486-bc55-4277-f458-7df5191a452c"
      },
      "source": [
        "print(classification_report(ytest, test_pred, target_names=emotions.values()))\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry       0.58      0.57      0.58       480\n",
            "     Disgust       0.55      0.77      0.64        60\n",
            "        Fear       0.62      0.44      0.51       515\n",
            "       Happy       0.82      0.86      0.84       883\n",
            "         Sad       0.59      0.51      0.54       597\n",
            "    Surprise       0.77      0.74      0.76       397\n",
            "     Neutral       0.57      0.73      0.64       657\n",
            "\n",
            "    accuracy                           0.66      3589\n",
            "   macro avg       0.64      0.66      0.64      3589\n",
            "weighted avg       0.66      0.66      0.66      3589\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOnjWNnbuJjt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}