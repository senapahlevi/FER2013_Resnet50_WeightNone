{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER2013_Resnet50_weightnone_scratch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "18Zj-Yp1YlH0QWcuD4e7ugx8zCCcRS0jg",
      "authorship_tag": "ABX9TyMXVIQGUGGGVb8/6jaV3qcO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eWeoD7MRFlN",
        "outputId": "9de2f789-cf8f-45d2-908c-c8d810f09f40"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "inputFolder = '/content/drive/MyDrive/Fer2013_backup/' \n",
        "for root, directories, filenames in os.walk(inputFolder): \n",
        "    for filename in filenames: print(os.path.join(root,filename))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Fer2013_backup/backUpfer2013.csv\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/best_model_resnet50_modelB2_170false.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/best_model_resnet50_modelD2_170false.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50Scracth_tipe7.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50Scracth_tipe8.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50oriAUGScracthSGD2.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50oriAUGScracthSGD3.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50AUGScracthadam2.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50AUGScracthSGD4.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50AUGScracthAdam1.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50AUGScracthSGD5.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/fixcheckpoint/Best_Model_resnet50oriAUGScracthSGD2.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH8iEUJiRQS7",
        "outputId": "2fe8cbd0-fbfa-4843-c068-c51f6716a250"
      },
      "source": [
        "%cd /content/drive/MyDrive/Fer2013_backup/\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Fer2013_backup\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqZOFwxxRQaa",
        "outputId": "a8360a42-a394-4381-c377-6e0067de9394"
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:400: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUX-dSAgRQh4"
      },
      "source": [
        "#Define the identity block helper function.\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "   \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbdQH3mkRQra"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path \n",
        "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b',padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33XH76oKRQvh"
      },
      "source": [
        "def ResNet50(input_shape = (48,48,1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    #X = ZeroPadding2D((1, 1))(X_input)\n",
        "    X = X_input\n",
        "    # Stage 1\n",
        "\n",
        "    X = Conv2D(8, (3, 3), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # removed maxpool\n",
        "    #X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='c')\n",
        "\n",
        "\n",
        "    # Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [64,64,256], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL . \n",
        "    X = AveragePooling2D((2,2), name='avg_pool')(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(512, activation = 'relu', name='fc1024' , kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWuYK_f2zGJF"
      },
      "source": [
        "\"\"\"def ResNet50ori(input_shape = (48, 48, 1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50ori')\n",
        "\n",
        "    return model\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QQOxN2cRQy3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9985b870-5987-4451-b586-dc9c358c1423"
      },
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        " \n",
        "dataset_path = '/content/drive/MyDrive/Fer2013_backup/backUpfer2013.csv'\n",
        "image_size=(48,48)\n",
        "\n",
        "def load_fer2013():\n",
        "    data = pd.read_csv(dataset_path)\n",
        "    data = (data[data['pixels'].notnull()])\n",
        "    pixels = data['pixels'].tolist()\n",
        "    width, height = 48, 48\n",
        "    faces = []\n",
        "    for pixel_sequence in pixels:\n",
        "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "        face = np.asarray(face).reshape(width, height)\n",
        "        face = cv2.resize(face.astype('uint8'),image_size)\n",
        "        faces.append(face.astype('float32'))\n",
        "    faces = np.asarray(faces)\n",
        "    faces = np.expand_dims(faces, -1)\n",
        "    emotions = (data['emotion'])#.values\n",
        "    return faces, emotions\n",
        " \n",
        "def preprocess_input(x, v2=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if v2:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x\n",
        " \n",
        "faces, emotions = load_fer2013()\n",
        "faces = preprocess_input(faces)\n",
        "#xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
        "#Data Augumentationfgf\n",
        "data_generator = ImageDataGenerator(\n",
        "                        rotation_range=10,\n",
        "                        shear_range = 10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        vertical_flip=True,\n",
        "                        horizontal_flip=True)\n",
        "\"\"\"data_generator = ImageDataGenerator ()\"\"\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'data_generator = ImageDataGenerator ()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zCkwVdnKTm5",
        "outputId": "61c427a4-085a-47b6-d96f-63ffa731092e"
      },
      "source": [
        "train_ratio = 0.80\n",
        "validation_ratio = 0.10\n",
        "test_ratio = 0.10\n",
        "\n",
        "# train is now 75% of the entire data set\n",
        "# the _junk suffix means that we drop that variable completely # the _junk suffix means that we drop that variable completely\n",
        "#x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=1 - train_ratio)\n",
        "\n",
        "# test is now 10% of the initial data set\n",
        "# validation is now 15% of the initial data set\n",
        "#x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "x_val, xtest, y_val, ytest = train_test_split(xtest, ytest, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "\n",
        "print(xtrain, x_val, xtest)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[-0.3490196 ]\n",
            "   [-0.41176468]\n",
            "   [-0.46666664]\n",
            "   ...\n",
            "   [-0.56078434]\n",
            "   [-0.47450978]\n",
            "   [-0.23921567]]\n",
            "\n",
            "  [[-0.46666664]\n",
            "   [-0.45098037]\n",
            "   [-0.49019605]\n",
            "   ...\n",
            "   [-0.5686275 ]\n",
            "   [-0.40392154]\n",
            "   [-0.05098039]]\n",
            "\n",
            "  [[-0.5294118 ]\n",
            "   [-0.52156866]\n",
            "   [-0.5058824 ]\n",
            "   ...\n",
            "   [-0.4823529 ]\n",
            "   [-0.19215685]\n",
            "   [-0.09803921]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.9607843 ]\n",
            "   [-0.9529412 ]\n",
            "   [-0.9607843 ]\n",
            "   ...\n",
            "   [-0.5294118 ]\n",
            "   [-0.62352943]\n",
            "   [-0.9607843 ]]\n",
            "\n",
            "  [[-0.92156863]\n",
            "   [-0.92156863]\n",
            "   [-0.90588236]\n",
            "   ...\n",
            "   [-0.75686276]\n",
            "   [-0.7019608 ]\n",
            "   [-0.9372549 ]]\n",
            "\n",
            "  [[-0.90588236]\n",
            "   [-0.8745098 ]\n",
            "   [-0.9137255 ]\n",
            "   ...\n",
            "   [-0.8039216 ]\n",
            "   [-0.78039217]\n",
            "   [-0.9372549 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.60784316]\n",
            "   [ 0.62352943]\n",
            "   [ 0.654902  ]\n",
            "   ...\n",
            "   [-0.7882353 ]\n",
            "   [-0.7882353 ]\n",
            "   [-0.7647059 ]]\n",
            "\n",
            "  [[ 0.70980394]\n",
            "   [ 0.7411765 ]\n",
            "   [ 0.7647059 ]\n",
            "   ...\n",
            "   [-0.827451  ]\n",
            "   [-0.81960785]\n",
            "   [-0.81960785]]\n",
            "\n",
            "  [[ 0.8039216 ]\n",
            "   [ 0.8039216 ]\n",
            "   [ 0.7882353 ]\n",
            "   ...\n",
            "   [-0.7647059 ]\n",
            "   [-0.7490196 ]\n",
            "   [-0.7176471 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.49803925]\n",
            "   [ 0.43529415]\n",
            "   [ 0.41176474]\n",
            "   ...\n",
            "   [ 0.5058824 ]\n",
            "   [ 0.2313726 ]\n",
            "   [ 0.35686278]]\n",
            "\n",
            "  [[ 0.67058825]\n",
            "   [ 0.5294118 ]\n",
            "   [ 0.41176474]\n",
            "   ...\n",
            "   [ 0.5921569 ]\n",
            "   [ 0.52156866]\n",
            "   [ 0.6       ]]\n",
            "\n",
            "  [[ 0.6       ]\n",
            "   [ 0.62352943]\n",
            "   [ 0.5058824 ]\n",
            "   ...\n",
            "   [ 0.6784314 ]\n",
            "   [ 0.7254902 ]\n",
            "   [ 0.7176471 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.8901961 ]\n",
            "   [-0.30196077]\n",
            "   [-0.7176471 ]\n",
            "   ...\n",
            "   [-0.62352943]\n",
            "   [ 0.62352943]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 0.6       ]\n",
            "   [-0.58431375]\n",
            "   [-0.6784314 ]\n",
            "   ...\n",
            "   [-0.7490196 ]\n",
            "   [ 0.20784318]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 0.04313731]\n",
            "   [-0.7019608 ]\n",
            "   [-0.6       ]\n",
            "   ...\n",
            "   [-0.73333335]\n",
            "   [-0.31764704]\n",
            "   [ 0.9137255 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.99215686]\n",
            "   [ 0.99215686]\n",
            "   [ 0.99215686]\n",
            "   ...\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.9843137 ]]\n",
            "\n",
            "  [[ 0.99215686]\n",
            "   [ 0.99215686]\n",
            "   [ 0.99215686]\n",
            "   ...\n",
            "   [ 0.92941177]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 0.99215686]\n",
            "   [ 0.99215686]\n",
            "   [ 0.99215686]\n",
            "   ...\n",
            "   [ 0.14509809]\n",
            "   [ 0.4431373 ]\n",
            "   [ 0.8509804 ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [-0.2235294 ]\n",
            "   [-0.12156862]\n",
            "   [-0.14509803]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 0.99215686]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [-0.30196077]\n",
            "   [-0.14509803]\n",
            "   [-0.12941176]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 0.9764706 ]\n",
            "   ...\n",
            "   [-0.30196077]\n",
            "   [-0.12156862]\n",
            "   [-0.1607843 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 0.8509804 ]\n",
            "   [ 0.9843137 ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 0.8666667 ]\n",
            "   [ 1.        ]\n",
            "   [ 0.99215686]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 0.4039216 ]\n",
            "   [ 0.8745098 ]\n",
            "   [ 0.9764706 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.94509804]\n",
            "   [ 0.2313726 ]\n",
            "   [-0.6862745 ]\n",
            "   ...\n",
            "   [ 0.90588236]\n",
            "   [ 0.827451  ]\n",
            "   [ 0.88235295]]\n",
            "\n",
            "  [[ 0.654902  ]\n",
            "   [-0.38823527]\n",
            "   [-0.7019608 ]\n",
            "   ...\n",
            "   [ 0.96862745]\n",
            "   [ 0.84313726]\n",
            "   [ 0.9529412 ]]\n",
            "\n",
            "  [[ 0.10588241]\n",
            "   [-0.7411765 ]\n",
            "   [-0.6       ]\n",
            "   ...\n",
            "   [ 0.9607843 ]\n",
            "   [ 0.9137255 ]\n",
            "   [ 0.827451  ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.49803925]\n",
            "   [ 0.6156863 ]\n",
            "   [ 0.6313726 ]\n",
            "   ...\n",
            "   [-0.73333335]\n",
            "   [-0.7411765 ]\n",
            "   [-0.67058825]]\n",
            "\n",
            "  [[ 0.654902  ]\n",
            "   [ 0.64705884]\n",
            "   [ 0.60784316]\n",
            "   ...\n",
            "   [-0.6862745 ]\n",
            "   [-0.78039217]\n",
            "   [-0.7490196 ]]\n",
            "\n",
            "  [[ 0.654902  ]\n",
            "   [ 0.6392157 ]\n",
            "   [ 0.5529412 ]\n",
            "   ...\n",
            "   [-0.77254903]\n",
            "   [-0.7411765 ]\n",
            "   [-0.85882354]]]\n",
            "\n",
            "\n",
            " [[[ 0.2941177 ]\n",
            "   [ 0.4901961 ]\n",
            "   [ 0.5058824 ]\n",
            "   ...\n",
            "   [ 0.05098045]\n",
            "   [-0.05882353]\n",
            "   [-0.09803921]]\n",
            "\n",
            "  [[ 0.4039216 ]\n",
            "   [ 0.41960788]\n",
            "   [ 0.5058824 ]\n",
            "   ...\n",
            "   [ 0.10588241]\n",
            "   [-0.04313725]\n",
            "   [-0.10588235]]\n",
            "\n",
            "  [[ 0.33333337]\n",
            "   [ 0.45098042]\n",
            "   [ 0.45882356]\n",
            "   ...\n",
            "   [ 0.19215691]\n",
            "   [ 0.00392163]\n",
            "   [-0.03529412]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.13725495]\n",
            "   [ 0.04313731]\n",
            "   [-0.1372549 ]\n",
            "   ...\n",
            "   [-0.60784316]\n",
            "   [-0.62352943]\n",
            "   [-0.4980392 ]]\n",
            "\n",
            "  [[ 0.11372554]\n",
            "   [ 0.01176476]\n",
            "   [-0.20784312]\n",
            "   ...\n",
            "   [-0.6392157 ]\n",
            "   [-0.6313726 ]\n",
            "   [-0.47450978]]\n",
            "\n",
            "  [[ 0.06666672]\n",
            "   [-0.05098039]\n",
            "   [-0.14509803]\n",
            "   ...\n",
            "   [-0.69411767]\n",
            "   [-0.6313726 ]\n",
            "   [-0.45098037]]]] [[[[ 0.6156863 ]\n",
            "   [ 0.09803927]\n",
            "   [ 0.254902  ]\n",
            "   ...\n",
            "   [-0.19999999]\n",
            "   [ 0.12941182]\n",
            "   [ 0.30980396]]\n",
            "\n",
            "  [[ 0.4666667 ]\n",
            "   [ 0.05098045]\n",
            "   [ 0.16078436]\n",
            "   ...\n",
            "   [-0.19215685]\n",
            "   [ 0.11372554]\n",
            "   [ 0.28627455]]\n",
            "\n",
            "  [[ 0.3176471 ]\n",
            "   [-0.02745098]\n",
            "   [ 0.15294123]\n",
            "   ...\n",
            "   [-0.09803921]\n",
            "   [ 0.04313731]\n",
            "   [ 0.26274514]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.92156863]\n",
            "   [ 0.92156863]\n",
            "   [ 0.92156863]\n",
            "   ...\n",
            "   [ 0.92941177]\n",
            "   [ 0.9137255 ]\n",
            "   [ 0.90588236]]\n",
            "\n",
            "  [[ 0.92156863]\n",
            "   [ 0.92156863]\n",
            "   [ 0.92156863]\n",
            "   ...\n",
            "   [ 0.90588236]\n",
            "   [ 0.9137255 ]\n",
            "   [ 0.92156863]]\n",
            "\n",
            "  [[ 0.9137255 ]\n",
            "   [ 0.9137255 ]\n",
            "   [ 0.9137255 ]\n",
            "   ...\n",
            "   [ 0.8980392 ]\n",
            "   [ 0.8901961 ]\n",
            "   [ 0.90588236]]]\n",
            "\n",
            "\n",
            " [[[-0.75686276]\n",
            "   [-0.79607844]\n",
            "   [-0.8509804 ]\n",
            "   ...\n",
            "   [-0.654902  ]\n",
            "   [ 0.30980396]\n",
            "   [ 0.38823533]]\n",
            "\n",
            "  [[-0.7411765 ]\n",
            "   [-0.75686276]\n",
            "   [-0.77254903]\n",
            "   ...\n",
            "   [-0.827451  ]\n",
            "   [ 0.10588241]\n",
            "   [ 0.41960788]]\n",
            "\n",
            "  [[-0.77254903]\n",
            "   [-0.6313726 ]\n",
            "   [-0.5058824 ]\n",
            "   ...\n",
            "   [-0.92941177]\n",
            "   [-0.27843136]\n",
            "   [ 0.39607847]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.67058825]\n",
            "   [-0.9137255 ]\n",
            "   [-0.38823527]\n",
            "   ...\n",
            "   [-0.4823529 ]\n",
            "   [-0.46666664]\n",
            "   [-0.5137255 ]]\n",
            "\n",
            "  [[-0.9137255 ]\n",
            "   [-0.62352943]\n",
            "   [-0.60784316]\n",
            "   ...\n",
            "   [-0.5372549 ]\n",
            "   [-0.69411767]\n",
            "   [-0.7490196 ]]\n",
            "\n",
            "  [[-0.84313726]\n",
            "   [-0.73333335]\n",
            "   [-0.8352941 ]\n",
            "   ...\n",
            "   [-0.69411767]\n",
            "   [-0.84313726]\n",
            "   [-0.8509804 ]]]\n",
            "\n",
            "\n",
            " [[[-0.9843137 ]\n",
            "   [-0.9764706 ]\n",
            "   [-0.99215686]\n",
            "   ...\n",
            "   [-0.7882353 ]\n",
            "   [-0.8666667 ]\n",
            "   [-0.8745098 ]]\n",
            "\n",
            "  [[-0.96862745]\n",
            "   [-0.9764706 ]\n",
            "   [-0.94509804]\n",
            "   ...\n",
            "   [-0.8901961 ]\n",
            "   [-0.85882354]\n",
            "   [-0.8509804 ]]\n",
            "\n",
            "  [[-0.9607843 ]\n",
            "   [-0.9764706 ]\n",
            "   [-0.9843137 ]\n",
            "   ...\n",
            "   [-0.92156863]\n",
            "   [-0.9529412 ]\n",
            "   [-0.84313726]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.9607843 ]\n",
            "   [-0.92156863]\n",
            "   [-0.92941177]\n",
            "   ...\n",
            "   [-0.92156863]\n",
            "   [-0.9607843 ]\n",
            "   [-0.9529412 ]]\n",
            "\n",
            "  [[-0.96862745]\n",
            "   [-0.88235295]\n",
            "   [-0.92941177]\n",
            "   ...\n",
            "   [-0.9764706 ]\n",
            "   [-0.9607843 ]\n",
            "   [-0.9843137 ]]\n",
            "\n",
            "  [[-0.9607843 ]\n",
            "   [-0.84313726]\n",
            "   [-0.8980392 ]\n",
            "   ...\n",
            "   [-0.96862745]\n",
            "   [-0.9529412 ]\n",
            "   [-0.9843137 ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 0.16078436]\n",
            "   [-0.05098039]\n",
            "   [-0.18431371]\n",
            "   ...\n",
            "   [ 0.9372549 ]\n",
            "   [ 0.79607844]\n",
            "   [ 0.654902  ]]\n",
            "\n",
            "  [[-0.02745098]\n",
            "   [-0.03529412]\n",
            "   [-0.09803921]\n",
            "   ...\n",
            "   [ 0.92156863]\n",
            "   [ 0.92941177]\n",
            "   [ 0.79607844]]\n",
            "\n",
            "  [[ 0.12156868]\n",
            "   [ 0.28627455]\n",
            "   [-0.02745098]\n",
            "   ...\n",
            "   [ 0.8745098 ]\n",
            "   [ 0.90588236]\n",
            "   [ 0.92156863]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.9764706 ]\n",
            "   [-0.9764706 ]\n",
            "   [-0.9843137 ]\n",
            "   ...\n",
            "   [-0.5529412 ]\n",
            "   [-0.8745098 ]\n",
            "   [-0.27843136]]\n",
            "\n",
            "  [[-0.9607843 ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.52156866]\n",
            "   [-0.81960785]\n",
            "   [-0.4352941 ]]\n",
            "\n",
            "  [[-0.6862745 ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.5686275 ]\n",
            "   [-0.85882354]\n",
            "   [-0.38823527]]]\n",
            "\n",
            "\n",
            " [[[ 0.20784318]\n",
            "   [ 0.16078436]\n",
            "   [ 0.03529418]\n",
            "   ...\n",
            "   [-0.7882353 ]\n",
            "   [-0.9529412 ]\n",
            "   [-0.9372549 ]]\n",
            "\n",
            "  [[ 0.14509809]\n",
            "   [ 0.01176476]\n",
            "   [-0.12941176]\n",
            "   ...\n",
            "   [-0.6       ]\n",
            "   [-0.8745098 ]\n",
            "   [-0.94509804]]\n",
            "\n",
            "  [[ 0.09803927]\n",
            "   [ 0.09803927]\n",
            "   [-0.12941176]\n",
            "   ...\n",
            "   [-0.49019605]\n",
            "   [-0.7176471 ]\n",
            "   [-0.9372549 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.47450978]\n",
            "   [-0.5294118 ]\n",
            "   [-0.52156866]\n",
            "   ...\n",
            "   [ 0.4039216 ]\n",
            "   [ 0.45098042]\n",
            "   [ 0.4431373 ]]\n",
            "\n",
            "  [[-0.4980392 ]\n",
            "   [-0.52156866]\n",
            "   [-0.54509807]\n",
            "   ...\n",
            "   [ 0.39607847]\n",
            "   [ 0.41960788]\n",
            "   [ 0.427451  ]]\n",
            "\n",
            "  [[-0.3960784 ]\n",
            "   [-0.29411763]\n",
            "   [-0.12941176]\n",
            "   ...\n",
            "   [ 0.41960788]\n",
            "   [ 0.41176474]\n",
            "   [ 0.39607847]]]\n",
            "\n",
            "\n",
            " [[[-0.26274508]\n",
            "   [-0.2235294 ]\n",
            "   [-0.29411763]\n",
            "   ...\n",
            "   [-0.45098037]\n",
            "   [-0.5372549 ]\n",
            "   [-0.5294118 ]]\n",
            "\n",
            "  [[-0.3490196 ]\n",
            "   [-0.41960782]\n",
            "   [-0.3960784 ]\n",
            "   ...\n",
            "   [-0.09019607]\n",
            "   [-0.6392157 ]\n",
            "   [-0.6313726 ]]\n",
            "\n",
            "  [[-0.40392154]\n",
            "   [-0.35686272]\n",
            "   [-0.3333333 ]\n",
            "   ...\n",
            "   [-0.01960784]\n",
            "   [-0.46666664]\n",
            "   [-0.47450978]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.54509807]\n",
            "   [ 0.5686275 ]\n",
            "   [ 0.6392157 ]\n",
            "   ...\n",
            "   [-0.3333333 ]\n",
            "   [-0.4588235 ]\n",
            "   [-0.47450978]]\n",
            "\n",
            "  [[ 0.56078434]\n",
            "   [ 0.5372549 ]\n",
            "   [ 0.5372549 ]\n",
            "   ...\n",
            "   [-0.31764704]\n",
            "   [-0.4823529 ]\n",
            "   [-0.4980392 ]]\n",
            "\n",
            "  [[ 0.5137255 ]\n",
            "   [ 0.5294118 ]\n",
            "   [ 0.54509807]\n",
            "   ...\n",
            "   [-0.38823527]\n",
            "   [-0.42745095]\n",
            "   [-0.40392154]]]] [[[[-0.92156863]\n",
            "   [-0.9607843 ]\n",
            "   [-0.9843137 ]\n",
            "   ...\n",
            "   [-0.92156863]\n",
            "   [-0.94509804]\n",
            "   [-0.8745098 ]]\n",
            "\n",
            "  [[-0.9529412 ]\n",
            "   [-0.99215686]\n",
            "   [-0.9764706 ]\n",
            "   ...\n",
            "   [-0.9372549 ]\n",
            "   [-0.9372549 ]\n",
            "   [-0.85882354]]\n",
            "\n",
            "  [[-0.99215686]\n",
            "   [-0.99215686]\n",
            "   [-0.9607843 ]\n",
            "   ...\n",
            "   [-0.9607843 ]\n",
            "   [-0.9607843 ]\n",
            "   [-0.8117647 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.6       ]\n",
            "   [ 0.6156863 ]\n",
            "   [ 0.7254902 ]\n",
            "   ...\n",
            "   [-0.01960784]\n",
            "   [ 0.12156868]\n",
            "   [ 0.23921573]]\n",
            "\n",
            "  [[ 0.6784314 ]\n",
            "   [ 0.77254903]\n",
            "   [ 0.8352941 ]\n",
            "   ...\n",
            "   [ 0.9137255 ]\n",
            "   [ 0.8980392 ]\n",
            "   [ 0.7882353 ]]\n",
            "\n",
            "  [[ 0.67058825]\n",
            "   [ 0.7411765 ]\n",
            "   [ 0.7019608 ]\n",
            "   ...\n",
            "   [ 0.7647059 ]\n",
            "   [ 0.7411765 ]\n",
            "   [ 0.70980394]]]\n",
            "\n",
            "\n",
            " [[[-0.27843136]\n",
            "   [-0.19999999]\n",
            "   [-0.2235294 ]\n",
            "   ...\n",
            "   [-0.21568626]\n",
            "   [-0.6784314 ]\n",
            "   [-0.9529412 ]]\n",
            "\n",
            "  [[-0.23137254]\n",
            "   [-0.24705881]\n",
            "   [-0.31764704]\n",
            "   ...\n",
            "   [-0.42745095]\n",
            "   [-0.372549  ]\n",
            "   [-0.827451  ]]\n",
            "\n",
            "  [[-0.29411763]\n",
            "   [-0.31764704]\n",
            "   [-0.4823529 ]\n",
            "   ...\n",
            "   [-0.6392157 ]\n",
            "   [-0.47450978]\n",
            "   [-0.7882353 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.92941177]\n",
            "   [-0.9607843 ]\n",
            "   [-0.9764706 ]\n",
            "   ...\n",
            "   [-0.9137255 ]\n",
            "   [-0.9529412 ]\n",
            "   [-0.8980392 ]]\n",
            "\n",
            "  [[-0.94509804]\n",
            "   [-0.9529412 ]\n",
            "   [-0.94509804]\n",
            "   ...\n",
            "   [-0.9529412 ]\n",
            "   [-0.9529412 ]\n",
            "   [-0.9372549 ]]\n",
            "\n",
            "  [[-0.92156863]\n",
            "   [-0.90588236]\n",
            "   [-0.9372549 ]\n",
            "   ...\n",
            "   [-0.9764706 ]\n",
            "   [-0.9607843 ]\n",
            "   [-0.9529412 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.09019613]\n",
            "   [-0.20784312]\n",
            "   [-0.8509804 ]\n",
            "   ...\n",
            "   [-0.6       ]\n",
            "   [ 0.04313731]\n",
            "   [ 0.04313731]]\n",
            "\n",
            "  [[ 0.09019613]\n",
            "   [-0.30196077]\n",
            "   [-0.88235295]\n",
            "   ...\n",
            "   [-0.6862745 ]\n",
            "   [-0.01176471]\n",
            "   [ 0.05098045]]\n",
            "\n",
            "  [[ 0.09019613]\n",
            "   [-0.40392154]\n",
            "   [-0.8745098 ]\n",
            "   ...\n",
            "   [-0.7176471 ]\n",
            "   [-0.06666666]\n",
            "   [ 0.06666672]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.13725495]\n",
            "   [ 0.09019613]\n",
            "   [-0.00392157]\n",
            "   ...\n",
            "   [-0.00392157]\n",
            "   [ 0.15294123]\n",
            "   [ 0.1686275 ]]\n",
            "\n",
            "  [[ 0.15294123]\n",
            "   [ 0.10588241]\n",
            "   [ 0.00392163]\n",
            "   ...\n",
            "   [-0.00392157]\n",
            "   [ 0.16078436]\n",
            "   [ 0.20000005]]\n",
            "\n",
            "  [[ 0.1686275 ]\n",
            "   [ 0.12941182]\n",
            "   [ 0.0196079 ]\n",
            "   ...\n",
            "   [ 0.02745104]\n",
            "   [ 0.20000005]\n",
            "   [ 0.2313726 ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.8039216 ]\n",
            "   [-0.7490196 ]\n",
            "   [-0.8509804 ]\n",
            "   ...\n",
            "   [-0.8745098 ]\n",
            "   [-0.81960785]\n",
            "   [-0.78039217]]\n",
            "\n",
            "  [[-0.8352941 ]\n",
            "   [-0.81960785]\n",
            "   [-0.88235295]\n",
            "   ...\n",
            "   [-0.92156863]\n",
            "   [-0.85882354]\n",
            "   [-0.8117647 ]]\n",
            "\n",
            "  [[-0.8117647 ]\n",
            "   [-0.8666667 ]\n",
            "   [-0.8666667 ]\n",
            "   ...\n",
            "   [-0.92156863]\n",
            "   [-0.9137255 ]\n",
            "   [-0.8352941 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.09019613]\n",
            "   [ 0.07450986]\n",
            "   [ 0.18431377]\n",
            "   ...\n",
            "   [-0.9529412 ]\n",
            "   [-0.92156863]\n",
            "   [-0.9529412 ]]\n",
            "\n",
            "  [[ 0.07450986]\n",
            "   [ 0.09803927]\n",
            "   [-0.02745098]\n",
            "   ...\n",
            "   [-0.92941177]\n",
            "   [-0.9372549 ]\n",
            "   [-0.9529412 ]]\n",
            "\n",
            "  [[ 0.09803927]\n",
            "   [ 0.06666672]\n",
            "   [-0.5294118 ]\n",
            "   ...\n",
            "   [-0.9372549 ]\n",
            "   [-0.92156863]\n",
            "   [-0.92156863]]]\n",
            "\n",
            "\n",
            " [[[ 0.6313726 ]\n",
            "   [ 0.6313726 ]\n",
            "   [ 0.6313726 ]\n",
            "   ...\n",
            "   [-0.5372549 ]\n",
            "   [-0.56078434]\n",
            "   [-0.60784316]]\n",
            "\n",
            "  [[ 0.6392157 ]\n",
            "   [ 0.6313726 ]\n",
            "   [ 0.6392157 ]\n",
            "   ...\n",
            "   [-0.52156866]\n",
            "   [-0.58431375]\n",
            "   [-0.5921569 ]]\n",
            "\n",
            "  [[ 0.64705884]\n",
            "   [ 0.64705884]\n",
            "   [ 0.64705884]\n",
            "   ...\n",
            "   [-0.56078434]\n",
            "   [-0.5529412 ]\n",
            "   [-0.6       ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.7411765 ]\n",
            "   [ 0.7490196 ]\n",
            "   [ 0.75686276]\n",
            "   ...\n",
            "   [-0.67058825]\n",
            "   [-0.6627451 ]\n",
            "   [-0.6       ]]\n",
            "\n",
            "  [[ 0.7411765 ]\n",
            "   [ 0.7411765 ]\n",
            "   [ 0.75686276]\n",
            "   ...\n",
            "   [-0.69411767]\n",
            "   [-0.6627451 ]\n",
            "   [-0.6156863 ]]\n",
            "\n",
            "  [[ 0.7411765 ]\n",
            "   [ 0.7411765 ]\n",
            "   [ 0.75686276]\n",
            "   ...\n",
            "   [-0.7019608 ]\n",
            "   [-0.67058825]\n",
            "   [-0.62352943]]]\n",
            "\n",
            "\n",
            " [[[-0.1607843 ]\n",
            "   [-0.24705881]\n",
            "   [-0.3098039 ]\n",
            "   ...\n",
            "   [-0.64705884]\n",
            "   [-0.7176471 ]\n",
            "   [-0.70980394]]\n",
            "\n",
            "  [[-0.19999999]\n",
            "   [-0.30196077]\n",
            "   [-0.34117645]\n",
            "   ...\n",
            "   [-0.7490196 ]\n",
            "   [-0.7490196 ]\n",
            "   [-0.6862745 ]]\n",
            "\n",
            "  [[-0.21568626]\n",
            "   [-0.27843136]\n",
            "   [-0.38823527]\n",
            "   ...\n",
            "   [-0.7647059 ]\n",
            "   [-0.7176471 ]\n",
            "   [-0.69411767]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.33333337]\n",
            "   [ 0.13725495]\n",
            "   [-0.49019605]\n",
            "   ...\n",
            "   [-0.03529412]\n",
            "   [ 0.6392157 ]\n",
            "   [ 0.56078434]]\n",
            "\n",
            "  [[ 0.27843142]\n",
            "   [ 0.05882359]\n",
            "   [-0.6313726 ]\n",
            "   ...\n",
            "   [-0.1607843 ]\n",
            "   [ 0.6313726 ]\n",
            "   [ 0.5529412 ]]\n",
            "\n",
            "  [[ 0.2313726 ]\n",
            "   [-0.00392157]\n",
            "   [-0.7176471 ]\n",
            "   ...\n",
            "   [-0.27843136]\n",
            "   [ 0.6313726 ]\n",
            "   [ 0.54509807]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t--o7TREKTu2",
        "outputId": "5d55ea33-7c13-4c82-df2a-eff8e375f7da"
      },
      "source": [
        "print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validasi (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "test (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "train (28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ofOj3-fRREN"
      },
      "source": [
        "#hyperparameter and callback\n",
        "batch_size = 64\n",
        "num_epochs = 60\n",
        "input_shape = (48, 48, 1)\n",
        "num_classes = 7\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXikieAnRbYs"
      },
      "source": [
        "#Compile the model.\n",
        "\n",
        "\n",
        "from keras.optimizers import Adam, SGD\n",
        "model = ResNet50(input_shape = (48, 48, 1), classes = 7)\n",
        "optimizer = SGD(learning_rate=0.015)\n",
        "model.compile(optimizer= optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5JTFulCRbiX"
      },
      "source": [
        "\"\"\"#kita mau save model callbacks\n",
        "import os\n",
        "try:\n",
        "  os.mkdir('/content/drive/MyDrive/Fer2013_backup/scratchcheckpoint')\n",
        "except:\n",
        "  pass\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkceBySwRgFO"
      },
      "source": [
        "\"\"\"file_name = 'Best_Model_resnet50oriScracth_aug_tipe2.h5'\n",
        "\n",
        "checkpoint_path = os.path.join('checkpoint',file_name)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an3sDjjGRgO1"
      },
      "source": [
        "\"\"\"call_back = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
        "                                               monitor='val_accuracy',\n",
        "                                               verbose=1,\n",
        "                                               save_freq='epoch',\n",
        "                                               save_best_only=True,\n",
        "                                               save_weights_only=False,\n",
        "                                               mode='max')\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nefC0ZE8RgX5",
        "outputId": "aa7ef82a-aac5-47a1-f45b-128a332f9e04"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 46, 46, 128)  0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 46, 46, 128)  0           activation_52[0][0]              \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 46, 46, 128)  0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 46, 46, 128)  0           activation_55[0][0]              \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 46, 46, 128)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 23, 23, 256)  0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 23, 23, 256)  0           activation_61[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 23, 23, 256)  0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 23, 23, 256)  0           activation_64[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 23, 23, 256)  0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 23, 23, 256)  0           activation_67[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 23, 23, 256)  0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 12, 12, 512)  0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 12, 12, 512)  0           activation_73[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 12, 12, 512)  0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 12, 12, 512)  0           activation_76[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 12, 12, 512)  0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 12, 12, 512)  0           activation_79[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 12, 12, 512)  0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 12, 12, 512)  0           activation_82[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 12, 12, 512)  0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 12, 12, 512)  0           activation_85[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 12, 12, 512)  0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 6, 6, 1024)   0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 6, 6, 1024)   0           activation_91[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 6, 6, 1024)   0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 6, 6, 1024)   0           activation_94[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 6, 6, 1024)   0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVvpTr7-RkdR"
      },
      "source": [
        "\"\"\"history = model.fit(data_generator.flow(xtrain, ytrain,),\n",
        "                        steps_per_epoch=len(xtrain) / batch_size,\n",
        "                        epochs=num_epochs, verbose=1,callbacks=call_back,\n",
        "                        validation_data= (xtest,ytest))huhuhuh\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_tXyjuSz_IP",
        "outputId": "a9de156d-a43f-4d00-94c8-713dc3b74082"
      },
      "source": [
        "history = model.fit(\n",
        "    data_generator.flow(xtrain, ytrain,),\n",
        "    steps_per_epoch=len(xtrain) / batch_size,\n",
        "    epochs=num_epochs, \n",
        "    verbose=1,\n",
        "    validation_data= (x_val,y_val))\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "448/448 [==============================] - 60s 113ms/step - loss: 2.6633 - accuracy: 0.2333 - val_loss: 1.8368 - val_accuracy: 0.2474\n",
            "Epoch 2/60\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.7962 - accuracy: 0.2515 - val_loss: 1.8027 - val_accuracy: 0.2491\n",
            "Epoch 3/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.8021 - accuracy: 0.2370 - val_loss: 1.7948 - val_accuracy: 0.2497\n",
            "Epoch 4/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7979 - accuracy: 0.2477 - val_loss: 1.7926 - val_accuracy: 0.2644\n",
            "Epoch 5/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7799 - accuracy: 0.2613 - val_loss: 1.7805 - val_accuracy: 0.2639\n",
            "Epoch 6/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7805 - accuracy: 0.2619 - val_loss: 1.7575 - val_accuracy: 0.2767\n",
            "Epoch 7/60\n",
            "448/448 [==============================] - 49s 110ms/step - loss: 1.7738 - accuracy: 0.2608 - val_loss: 1.7564 - val_accuracy: 0.2750\n",
            "Epoch 8/60\n",
            "448/448 [==============================] - 46s 104ms/step - loss: 1.7642 - accuracy: 0.2672 - val_loss: 1.7267 - val_accuracy: 0.3043\n",
            "Epoch 9/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7583 - accuracy: 0.2890 - val_loss: 1.7149 - val_accuracy: 0.3093\n",
            "Epoch 10/60\n",
            "448/448 [==============================] - 46s 104ms/step - loss: 1.7429 - accuracy: 0.2883 - val_loss: 1.6898 - val_accuracy: 0.3335\n",
            "Epoch 11/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7286 - accuracy: 0.2973 - val_loss: 1.6988 - val_accuracy: 0.3076\n",
            "Epoch 12/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7078 - accuracy: 0.3179 - val_loss: 1.6580 - val_accuracy: 0.3405\n",
            "Epoch 13/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.6999 - accuracy: 0.3167 - val_loss: 1.6515 - val_accuracy: 0.3502\n",
            "Epoch 14/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.6805 - accuracy: 0.3300 - val_loss: 1.7165 - val_accuracy: 0.3374\n",
            "Epoch 15/60\n",
            "448/448 [==============================] - 49s 109ms/step - loss: 1.6710 - accuracy: 0.3321 - val_loss: 1.6138 - val_accuracy: 0.3594\n",
            "Epoch 16/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.6578 - accuracy: 0.3374 - val_loss: 1.5876 - val_accuracy: 0.3722\n",
            "Epoch 17/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.6279 - accuracy: 0.3555 - val_loss: 1.5720 - val_accuracy: 0.3879\n",
            "Epoch 18/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.6218 - accuracy: 0.3608 - val_loss: 1.5464 - val_accuracy: 0.3948\n",
            "Epoch 19/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 1.6026 - accuracy: 0.3697 - val_loss: 1.5721 - val_accuracy: 0.3851\n",
            "Epoch 20/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 1.5663 - accuracy: 0.3858 - val_loss: 1.5451 - val_accuracy: 0.3895\n",
            "Epoch 21/60\n",
            "448/448 [==============================] - 49s 110ms/step - loss: 1.5591 - accuracy: 0.3879 - val_loss: 1.5014 - val_accuracy: 0.4193\n",
            "Epoch 22/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.5341 - accuracy: 0.3974 - val_loss: 1.5073 - val_accuracy: 0.4213\n",
            "Epoch 23/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.5031 - accuracy: 0.4063 - val_loss: 1.4729 - val_accuracy: 0.4372\n",
            "Epoch 24/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 1.5116 - accuracy: 0.4135 - val_loss: 1.4593 - val_accuracy: 0.4391\n",
            "Epoch 25/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 1.5115 - accuracy: 0.4087 - val_loss: 1.4181 - val_accuracy: 0.4575\n",
            "Epoch 26/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.4875 - accuracy: 0.4137 - val_loss: 1.5084 - val_accuracy: 0.4068\n",
            "Epoch 27/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.4788 - accuracy: 0.4246 - val_loss: 1.4159 - val_accuracy: 0.4561\n",
            "Epoch 28/60\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.4551 - accuracy: 0.4361 - val_loss: 1.4147 - val_accuracy: 0.4664\n",
            "Epoch 29/60\n",
            "448/448 [==============================] - 50s 110ms/step - loss: 1.4520 - accuracy: 0.4369 - val_loss: 1.4121 - val_accuracy: 0.4675\n",
            "Epoch 30/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.4431 - accuracy: 0.4375 - val_loss: 1.4212 - val_accuracy: 0.4628\n",
            "Epoch 31/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 1.4286 - accuracy: 0.4456 - val_loss: 1.4345 - val_accuracy: 0.4386\n",
            "Epoch 32/60\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.3920 - accuracy: 0.4545 - val_loss: 1.3423 - val_accuracy: 0.4870\n",
            "Epoch 33/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.4099 - accuracy: 0.4500 - val_loss: 1.4223 - val_accuracy: 0.4511\n",
            "Epoch 34/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.3830 - accuracy: 0.4655 - val_loss: 1.3675 - val_accuracy: 0.4778\n",
            "Epoch 35/60\n",
            "448/448 [==============================] - 49s 110ms/step - loss: 1.3759 - accuracy: 0.4703 - val_loss: 1.3712 - val_accuracy: 0.4695\n",
            "Epoch 36/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.3553 - accuracy: 0.4742 - val_loss: 1.3656 - val_accuracy: 0.4751\n",
            "Epoch 37/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.3708 - accuracy: 0.4704 - val_loss: 1.3175 - val_accuracy: 0.4912\n",
            "Epoch 38/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.3370 - accuracy: 0.4827 - val_loss: 1.2729 - val_accuracy: 0.5057\n",
            "Epoch 39/60\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.3357 - accuracy: 0.4842 - val_loss: 1.3101 - val_accuracy: 0.4974\n",
            "Epoch 40/60\n",
            "448/448 [==============================] - 50s 110ms/step - loss: 1.3118 - accuracy: 0.4974 - val_loss: 1.4201 - val_accuracy: 0.4327\n",
            "Epoch 41/60\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.3254 - accuracy: 0.4904 - val_loss: 1.3241 - val_accuracy: 0.5238\n",
            "Epoch 42/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.3097 - accuracy: 0.4936 - val_loss: 1.3133 - val_accuracy: 0.4898\n",
            "Epoch 43/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.3156 - accuracy: 0.4870 - val_loss: 1.3296 - val_accuracy: 0.4890\n",
            "Epoch 44/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.2860 - accuracy: 0.5071 - val_loss: 1.2772 - val_accuracy: 0.5071\n",
            "Epoch 45/60\n",
            "448/448 [==============================] - 49s 110ms/step - loss: 1.2982 - accuracy: 0.4970 - val_loss: 1.2163 - val_accuracy: 0.5308\n",
            "Epoch 46/60\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.2893 - accuracy: 0.5002 - val_loss: 1.2208 - val_accuracy: 0.5417\n",
            "Epoch 47/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.2672 - accuracy: 0.5078 - val_loss: 1.2391 - val_accuracy: 0.5300\n",
            "Epoch 48/60\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.2651 - accuracy: 0.5102 - val_loss: 1.2487 - val_accuracy: 0.5261\n",
            "Epoch 49/60\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.2435 - accuracy: 0.5189 - val_loss: 1.2293 - val_accuracy: 0.5274\n",
            "Epoch 50/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 1.2452 - accuracy: 0.5245 - val_loss: 1.2033 - val_accuracy: 0.5405\n",
            "Epoch 51/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.2217 - accuracy: 0.5311 - val_loss: 1.2270 - val_accuracy: 0.5336\n",
            "Epoch 52/60\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.2622 - accuracy: 0.5141 - val_loss: 1.3128 - val_accuracy: 0.4951\n",
            "Epoch 53/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 1.2182 - accuracy: 0.5288 - val_loss: 1.2669 - val_accuracy: 0.5442\n",
            "Epoch 54/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.2304 - accuracy: 0.5335 - val_loss: 1.2089 - val_accuracy: 0.5414\n",
            "Epoch 55/60\n",
            "448/448 [==============================] - 49s 110ms/step - loss: 1.2101 - accuracy: 0.5373 - val_loss: 1.1844 - val_accuracy: 0.5500\n",
            "Epoch 56/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.2082 - accuracy: 0.5312 - val_loss: 1.1970 - val_accuracy: 0.5433\n",
            "Epoch 57/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.1908 - accuracy: 0.5504 - val_loss: 1.1894 - val_accuracy: 0.5375\n",
            "Epoch 58/60\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.1895 - accuracy: 0.5429 - val_loss: 1.1895 - val_accuracy: 0.5497\n",
            "Epoch 59/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.1974 - accuracy: 0.5417 - val_loss: 1.2854 - val_accuracy: 0.5277\n",
            "Epoch 60/60\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.1946 - accuracy: 0.5370 - val_loss: 1.1471 - val_accuracy: 0.5606\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZvluWhSRkq4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "outputId": "807ba71b-d3c8-4da4-fc1f-3dd17d7ef9c2"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "model.save('/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50AUGScracthSGD6.h5')\n",
        "\n",
        "#gffhgffkjkjdshufdfhuh\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "num_epochs = range(len(accuracy))\n",
        "plt.plot(num_epochs, accuracy, 'r', label='Training acc')\n",
        "plt.plot(num_epochs, val_accuracy, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(num_epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(num_epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Pzozx-30LSe",
        "outputId": "1b6173a3-335a-47d0-a67b-0e2b462f917d"
      },
      "source": [
        "testloss = model.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "trainloss = model.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(trainloss[0]))\n",
        "print(\"Train Acc: \" + str(trainloss[1]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 3s 28ms/step - loss: 1.1322 - accuracy: 0.5642\n",
            "Test Loss 1.1321736574172974\n",
            "Test Acc: 0.5642240047454834\n",
            "898/898 [==============================] - 25s 27ms/step - loss: 1.1075 - accuracy: 0.5809\n",
            "Train Loss 1.1074947118759155\n",
            "Train Acc: 0.5809327960014343\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ6YCHax59vt",
        "outputId": "09a721b8-6c6a-4e10-9409-5ee6c48c0990"
      },
      "source": [
        "from keras.models import load_model\n",
        "model_load = load_model('/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50AUGScracthSGD6.h5')\n",
        "\n",
        "model_load.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 46, 46, 128)  0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 46, 46, 128)  0           activation_52[0][0]              \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 46, 46, 128)  0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 46, 46, 128)  0           activation_55[0][0]              \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 46, 46, 128)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 23, 23, 256)  0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 23, 23, 256)  0           activation_61[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 23, 23, 256)  0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 23, 23, 256)  0           activation_64[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 23, 23, 256)  0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 23, 23, 256)  0           activation_67[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 23, 23, 256)  0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 12, 12, 512)  0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 12, 12, 512)  0           activation_73[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 12, 12, 512)  0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 12, 12, 512)  0           activation_76[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 12, 12, 512)  0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 12, 12, 512)  0           activation_79[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 12, 12, 512)  0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 12, 12, 512)  0           activation_82[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 12, 12, 512)  0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 12, 12, 512)  0           activation_85[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 12, 12, 512)  0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 6, 6, 1024)   0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 6, 6, 1024)   0           activation_91[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 6, 6, 1024)   0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 6, 6, 1024)   0           activation_94[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 6, 6, 1024)   0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fpz7ehkO6Cat",
        "outputId": "b6fe8f0d-a787-48e7-ff83-bb3bbb1e29aa"
      },
      "source": [
        "\n",
        "testloss = model_load.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "\n",
        "testloss = model_load.evaluate(xtrain, ytrain) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 7s 27ms/step - loss: 1.1322 - accuracy: 0.5642\n",
            "Test Loss 1.1321736574172974\n",
            "Test Acc: 0.5642240047454834\n",
            "898/898 [==============================] - 24s 27ms/step - loss: 1.1075 - accuracy: 0.5809\n",
            "Test Loss 1.1074947118759155\n",
            "Test Acc: 0.5809327960014343\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrQ63iiV6F-W",
        "outputId": "1536bbca-419e-47ba-e72b-d57f8bc6fcd3"
      },
      "source": [
        "testlosz = model_load.evaluate(xtrain, ytrain) \n",
        "print(\"Test Loss \" + str(testlosz[0]))\n",
        "print(\"Test Acc: \" + str(testlosz[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "898/898 [==============================] - 23s 26ms/step - loss: 1.3753 - accuracy: 0.4682\n",
            "Test Loss 1.3752880096435547\n",
            "Test Acc: 0.46818071603775024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDwmru9p0gyj",
        "outputId": "268e437e-9dd1-466c-8a93-b1187fb2e855"
      },
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "y_pred1 = model_load.predict(xtest)\n",
        "y_pred = np.argmax(y_pred1, axis=1)\n",
        "\n",
        "# Print f1, precision, and recall scores s\n",
        "print(precision_score(ytest, y_pred , average=\"macro\"))\n",
        "print(recall_score(ytest, y_pred , average=\"macro\"))\n",
        "print(f1_score(ytest, y_pred , average=\"macro\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4942733665224318\n",
            "0.4665306634077046\n",
            "0.4517686224169304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9L61nPWxpn1",
        "outputId": "c658c3a1-5b45-44a6-a382-1c3ab7a1567e"
      },
      "source": [
        "!pip install mlxtend\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (3.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from mlxtend) (57.0.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.1.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.10.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->mlxtend) (1.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.1->mlxtend) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=1.5.1->mlxtend) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COc9HoDyhWQ2"
      },
      "source": [
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "ypred = model_load.predict(xtest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "or0mwBSoaa6U",
        "outputId": "e2fa8e6d-730a-43d1-ada8-9010d956ea3b"
      },
      "source": [
        "mat = confusion_matrix(ytest,ypred)\n",
        "plot_confusion_matrix(conf_mat = mat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-dc1d28471ea1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mypred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 90\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICOVlE12cOpZ"
      },
      "source": [
        "ds"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}