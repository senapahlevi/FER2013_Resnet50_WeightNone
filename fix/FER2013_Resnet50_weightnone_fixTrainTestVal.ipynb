{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER2013_Resnet50_weightnone_fixTrainTestVal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-Qn1jsBTIBl0b7myLQxqa8WjCcfbamqM",
      "authorship_tag": "ABX9TyMgAXjmhaZMJwG1+4svHzaS"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b86nukQOxN7l"
      },
      "source": [
        "Resnet-50 From Scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p8gxtGy0TWP",
        "outputId": "de079ca5-af11-4662-aaf8-d90f38ba07aa"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "inputFolder = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth' \n",
        "for root, directories, filenames in os.walk(inputFolder): \n",
        "    for filename in filenames: print(os.path.join(root,filename))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Best_Model_resnet50Scracth1again.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe4.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth1again.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50ScracthSGD1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50AUGScracthadam3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD1try2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD4.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50oriScracth_sena2.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsiscWIMBDX2",
        "outputId": "f4c8a9c9-901f-4f44-d717-a645a446e1da"
      },
      "source": [
        "%cd /content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "wLMSe510xNCJ",
        "outputId": "3da9f6f5-cb75-4f61-d978-1e7de9a074fc"
      },
      "source": [
        "#Create a directory to save our generated models.dasdas\n",
        "\n",
        "#os.mkdir(\"./modelscracth\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-cf55f19f3613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#os.mkdir(\"./modelscracth\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ls' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_kluusLxM1B",
        "outputId": "27236e39-378c-4f8b-d1ef-3f51af3fa721"
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:400: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfUSF_tAxNMP"
      },
      "source": [
        "#Define the identity block helper function.\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "   \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VdYtzhn1F0I"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path \n",
        "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b',padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd-O8ZMx1GAW"
      },
      "source": [
        "\"\"\"def ResNet50(input_shape = (48,48,1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    #X = ZeroPadding2D((1, 1))(X_input)\n",
        "    X = X_input\n",
        "    # Stage 1\n",
        "\n",
        "    X = Conv2D(8, (3, 3), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # removed maxpool\n",
        "    #X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='c')\n",
        "\n",
        "\n",
        "    # Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [64,64,256], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL . \n",
        "    X = AveragePooling2D((2,2), name='avg_pool')(X)\n",
        "    \n",
        "    # output layerds\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(512, activation = 'relu', name='fc1024' , kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GKsSwtp-GuL"
      },
      "source": [
        "def ResNet50ori(input_shape = (48, 48, 1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns: dsdsf\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50ori')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3oWTDXlyBHM2",
        "outputId": "1c8044af-73b9-49ac-b8fa-7ecdde533ba5"
      },
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        " \n",
        "dataset_path = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv'\n",
        "image_size=(48,48)\n",
        "#batch_size = 64\n",
        "\n",
        "def load_fer2013():\n",
        "    data = pd.read_csv(dataset_path)\n",
        "    data = (data[data['pixels'].notnull()])\n",
        "    pixels = data['pixels'].tolist()\n",
        "    width, height = 48, 48\n",
        "    faces = []\n",
        "    for pixel_sequence in pixels:\n",
        "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "        face = np.asarray(face).reshape(width, height)\n",
        "        face = cv2.resize(face.astype('uint8'),image_size)\n",
        "        faces.append(face.astype('float32'))\n",
        "    faces = np.asarray(faces)\n",
        "    faces = np.expand_dims(faces, -1)\n",
        "    emotions = (data['emotion'])#.values\n",
        "    return faces, emotions\n",
        " \n",
        "def preprocess_input(x, v2=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if v2:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x\n",
        " \n",
        "faces, emotions = load_fer2013()\n",
        "faces = preprocess_input(faces)\n",
        "#xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
        "#Data Augumentation\n",
        "data_generator = ImageDataGenerator(\n",
        "                        rotation_range=10,\n",
        "                        shear_range = 10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True)\n",
        "\"\"\"data_generator = ImageDataGenerator( )\n",
        "\"\"\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'data_generator = ImageDataGenerator( )\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWLhavr-rSF5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "895f7f85-9930-46ca-c552-cbb571846a4e"
      },
      "source": [
        "\"\"\"\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.1,)\n",
        "x_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1,)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nxtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.1,)\\nx_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1,)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "RGhnYFXgaqL9",
        "outputId": "0e60da2f-3a44-4d06-910b-2e0f2fa4191a"
      },
      "source": [
        "\"\"\"print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (y_train.shape)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'print (\"validasi\",x_val.shape)\\nprint (y_val.shape)\\nprint (\"test\",xtest.shape)\\nprint (ytest.shape)\\nprint (\"train\",xtrain.shape)\\nprint (y_train.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rDS3hqhDSteM",
        "outputId": "3a9c9e79-9e16-4c82-b970-df3104d64753"
      },
      "source": [
        "train_ratio = 0.80\n",
        "validation_ratio = 0.10\n",
        "test_ratio = 0.10\n",
        "\n",
        "# train is now 75% of the entire data set\n",
        "# the _junk suffix means that we drop that variable completely # the _junk suffix means that we drop that variable completely\n",
        "#x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=1 - train_ratio)\n",
        "\n",
        "# test is now 10% of the initial data set\n",
        "# validation is now 15% of the initial data set\n",
        "#x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "x_val, xtest, y_val, ytest = train_test_split(xtest, ytest, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "\n",
        "print(xtrain, x_val, xtest)\n",
        "\n",
        "\"\"\"X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2\"\"\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[ 0.5372549 ]\n",
            "   [ 0.41960788]\n",
            "   [ 0.16078436]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 0.4431373 ]\n",
            "   [ 0.34901965]\n",
            "   [-0.0745098 ]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 0.11372554]\n",
            "   [ 0.39607847]\n",
            "   [-0.12941176]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.8901961 ]\n",
            "   [-0.8980392 ]\n",
            "   [-0.78039217]\n",
            "   ...\n",
            "   [-0.7176471 ]\n",
            "   [-0.7176471 ]\n",
            "   [-0.7254902 ]]\n",
            "\n",
            "  [[-0.8745098 ]\n",
            "   [-0.8509804 ]\n",
            "   [-0.6313726 ]\n",
            "   ...\n",
            "   [-0.75686276]\n",
            "   [-0.7647059 ]\n",
            "   [-0.75686276]]\n",
            "\n",
            "  [[-0.8509804 ]\n",
            "   [-0.70980394]\n",
            "   [-0.54509807]\n",
            "   ...\n",
            "   [-0.8117647 ]\n",
            "   [-0.77254903]\n",
            "   [-0.6862745 ]]]\n",
            "\n",
            "\n",
            " [[[-0.6627451 ]\n",
            "   [-0.7019608 ]\n",
            "   [-0.7019608 ]\n",
            "   ...\n",
            "   [-0.19215685]\n",
            "   [-0.3098039 ]\n",
            "   [-0.09019607]]\n",
            "\n",
            "  [[-0.654902  ]\n",
            "   [-0.7647059 ]\n",
            "   [-0.52156866]\n",
            "   ...\n",
            "   [-0.02745098]\n",
            "   [-0.05882353]\n",
            "   [-0.02745098]]\n",
            "\n",
            "  [[-0.6784314 ]\n",
            "   [-0.6862745 ]\n",
            "   [-0.4588235 ]\n",
            "   ...\n",
            "   [ 0.21568632]\n",
            "   [-0.10588235]\n",
            "   [-0.23921567]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.7254902 ]\n",
            "   [-0.6313726 ]\n",
            "   [-0.20784312]\n",
            "   ...\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   [-0.99215686]]\n",
            "\n",
            "  [[-0.11372548]\n",
            "   [ 0.5686275 ]\n",
            "   [ 0.8745098 ]\n",
            "   ...\n",
            "   [-0.69411767]\n",
            "   [-0.8117647 ]\n",
            "   [-0.94509804]]\n",
            "\n",
            "  [[ 0.5921569 ]\n",
            "   [ 0.827451  ]\n",
            "   [ 0.8117647 ]\n",
            "   ...\n",
            "   [-0.32549018]\n",
            "   [-0.3098039 ]\n",
            "   [-0.372549  ]]]\n",
            "\n",
            "\n",
            " [[[-0.94509804]\n",
            "   [-0.9843137 ]\n",
            "   [-0.70980394]\n",
            "   ...\n",
            "   [-0.38823527]\n",
            "   [-0.24705881]\n",
            "   [-0.7176471 ]]\n",
            "\n",
            "  [[-0.99215686]\n",
            "   [-0.64705884]\n",
            "   [-0.44313723]\n",
            "   ...\n",
            "   [-0.3098039 ]\n",
            "   [-0.30196077]\n",
            "   [-0.5921569 ]]\n",
            "\n",
            "  [[-0.77254903]\n",
            "   [-0.03529412]\n",
            "   [-0.54509807]\n",
            "   ...\n",
            "   [-0.21568626]\n",
            "   [-0.27058822]\n",
            "   [-0.5529412 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.9372549 ]\n",
            "   [-0.96862745]\n",
            "   [-0.9764706 ]\n",
            "   ...\n",
            "   [-0.38823527]\n",
            "   [-0.5058824 ]\n",
            "   [-0.6156863 ]]\n",
            "\n",
            "  [[-0.70980394]\n",
            "   [-0.8509804 ]\n",
            "   [-0.96862745]\n",
            "   ...\n",
            "   [-0.40392154]\n",
            "   [-0.5294118 ]\n",
            "   [-0.6392157 ]]\n",
            "\n",
            "  [[-0.52156866]\n",
            "   [-0.49019605]\n",
            "   [-0.54509807]\n",
            "   ...\n",
            "   [-0.4352941 ]\n",
            "   [-0.5372549 ]\n",
            "   [-0.6627451 ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.372549  ]\n",
            "   [-0.41960782]\n",
            "   [-0.38823527]\n",
            "   ...\n",
            "   [-0.46666664]\n",
            "   [-0.46666664]\n",
            "   [-0.4588235 ]]\n",
            "\n",
            "  [[-0.3960784 ]\n",
            "   [-0.41176468]\n",
            "   [-0.42745095]\n",
            "   ...\n",
            "   [-0.49019605]\n",
            "   [-0.4352941 ]\n",
            "   [-0.4588235 ]]\n",
            "\n",
            "  [[-0.34117645]\n",
            "   [-0.36470586]\n",
            "   [-0.4352941 ]\n",
            "   ...\n",
            "   [-0.4823529 ]\n",
            "   [-0.4588235 ]\n",
            "   [-0.44313723]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.5686275 ]\n",
            "   [-0.58431375]\n",
            "   [-0.60784316]\n",
            "   ...\n",
            "   [-0.6392157 ]\n",
            "   [-0.6       ]\n",
            "   [-0.58431375]]\n",
            "\n",
            "  [[-0.58431375]\n",
            "   [-0.60784316]\n",
            "   [-0.6156863 ]\n",
            "   ...\n",
            "   [-0.5764706 ]\n",
            "   [-0.5764706 ]\n",
            "   [-0.5686275 ]]\n",
            "\n",
            "  [[-0.6       ]\n",
            "   [-0.60784316]\n",
            "   [-0.60784316]\n",
            "   ...\n",
            "   [-0.56078434]\n",
            "   [-0.5058824 ]\n",
            "   [-0.44313723]]]\n",
            "\n",
            "\n",
            " [[[-0.6627451 ]\n",
            "   [-0.49019605]\n",
            "   [-0.4980392 ]\n",
            "   ...\n",
            "   [ 0.11372554]\n",
            "   [ 0.12941182]\n",
            "   [ 0.11372554]]\n",
            "\n",
            "  [[-0.6784314 ]\n",
            "   [-0.6392157 ]\n",
            "   [-0.5372549 ]\n",
            "   ...\n",
            "   [ 0.09803927]\n",
            "   [ 0.06666672]\n",
            "   [ 0.11372554]]\n",
            "\n",
            "  [[-0.75686276]\n",
            "   [-0.7411765 ]\n",
            "   [-0.5686275 ]\n",
            "   ...\n",
            "   [ 0.09019613]\n",
            "   [ 0.06666672]\n",
            "   [ 0.09019613]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.73333335]\n",
            "   [-0.7254902 ]\n",
            "   [-0.70980394]\n",
            "   ...\n",
            "   [ 0.13725495]\n",
            "   [ 0.09803927]\n",
            "   [ 0.09019613]]\n",
            "\n",
            "  [[-0.7254902 ]\n",
            "   [-0.7176471 ]\n",
            "   [-0.70980394]\n",
            "   ...\n",
            "   [ 0.11372554]\n",
            "   [ 0.10588241]\n",
            "   [ 0.09019613]]\n",
            "\n",
            "  [[-0.73333335]\n",
            "   [-0.7254902 ]\n",
            "   [-0.7176471 ]\n",
            "   ...\n",
            "   [ 0.09803927]\n",
            "   [ 0.09803927]\n",
            "   [ 0.09803927]]]\n",
            "\n",
            "\n",
            " [[[-0.30196077]\n",
            "   [-0.29411763]\n",
            "   [-0.29411763]\n",
            "   ...\n",
            "   [-0.3960784 ]\n",
            "   [-0.40392154]\n",
            "   [-0.40392154]]\n",
            "\n",
            "  [[-0.31764704]\n",
            "   [-0.30196077]\n",
            "   [-0.29411763]\n",
            "   ...\n",
            "   [-0.40392154]\n",
            "   [-0.40392154]\n",
            "   [-0.40392154]]\n",
            "\n",
            "  [[-0.32549018]\n",
            "   [-0.3098039 ]\n",
            "   [-0.30196077]\n",
            "   ...\n",
            "   [-0.40392154]\n",
            "   [-0.3960784 ]\n",
            "   [-0.40392154]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.77254903]\n",
            "   [-0.8352941 ]\n",
            "   [-0.8509804 ]\n",
            "   ...\n",
            "   [ 0.24705887]\n",
            "   [-0.20784312]\n",
            "   [-0.54509807]]\n",
            "\n",
            "  [[-0.7411765 ]\n",
            "   [-0.78039217]\n",
            "   [-0.75686276]\n",
            "   ...\n",
            "   [ 0.32549024]\n",
            "   [-0.12941176]\n",
            "   [-0.47450978]]\n",
            "\n",
            "  [[-0.81960785]\n",
            "   [-0.8509804 ]\n",
            "   [-0.81960785]\n",
            "   ...\n",
            "   [-0.26274508]\n",
            "   [-0.5294118 ]\n",
            "   [-0.5764706 ]]]] [[[[-0.90588236]\n",
            "   [-0.8980392 ]\n",
            "   [-0.90588236]\n",
            "   ...\n",
            "   [-0.96862745]\n",
            "   [-0.94509804]\n",
            "   [-0.94509804]]\n",
            "\n",
            "  [[-0.90588236]\n",
            "   [-0.8980392 ]\n",
            "   [-0.8980392 ]\n",
            "   ...\n",
            "   [-0.99215686]\n",
            "   [-0.94509804]\n",
            "   [-0.9372549 ]]\n",
            "\n",
            "  [[-0.8980392 ]\n",
            "   [-0.8901961 ]\n",
            "   [-0.8980392 ]\n",
            "   ...\n",
            "   [-0.92156863]\n",
            "   [-0.94509804]\n",
            "   [-0.92941177]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.75686276]\n",
            "   [-0.5921569 ]\n",
            "   [-0.5372549 ]\n",
            "   ...\n",
            "   [-0.4352941 ]\n",
            "   [-0.5294118 ]\n",
            "   [-0.4588235 ]]\n",
            "\n",
            "  [[-0.7647059 ]\n",
            "   [-0.56078434]\n",
            "   [-0.58431375]\n",
            "   ...\n",
            "   [-0.42745095]\n",
            "   [-0.5294118 ]\n",
            "   [-0.5372549 ]]\n",
            "\n",
            "  [[-0.7490196 ]\n",
            "   [-0.5529412 ]\n",
            "   [-0.6392157 ]\n",
            "   ...\n",
            "   [-0.42745095]\n",
            "   [-0.56078434]\n",
            "   [-0.5372549 ]]]\n",
            "\n",
            "\n",
            " [[[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.58431375]\n",
            "   [ 0.5686275 ]\n",
            "   [ 0.5529412 ]\n",
            "   ...\n",
            "   [-0.84313726]\n",
            "   [-0.84313726]\n",
            "   [-0.7254902 ]]\n",
            "\n",
            "  [[ 0.60784316]\n",
            "   [ 0.5764706 ]\n",
            "   [ 0.5372549 ]\n",
            "   ...\n",
            "   [-0.7882353 ]\n",
            "   [-0.79607844]\n",
            "   [-0.81960785]]\n",
            "\n",
            "  [[ 0.60784316]\n",
            "   [ 0.58431375]\n",
            "   [ 0.54509807]\n",
            "   ...\n",
            "   [-0.7411765 ]\n",
            "   [-0.7411765 ]\n",
            "   [-0.8352941 ]]]\n",
            "\n",
            "\n",
            " [[[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 0.2313726 ]\n",
            "   [ 0.07450986]\n",
            "   [ 0.09019613]]\n",
            "\n",
            "  [[ 0.99215686]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 0.20784318]\n",
            "   [ 0.17647064]\n",
            "   [ 0.03529418]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 0.10588241]\n",
            "   [ 0.20000005]\n",
            "   [ 0.10588241]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [-0.36470586]\n",
            "   [-0.23137254]\n",
            "   [-0.24705881]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [-0.35686272]\n",
            "   [-0.20784312]\n",
            "   [-0.18431371]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [-0.32549018]\n",
            "   [-0.19999999]\n",
            "   [-0.0745098 ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 0.6313726 ]\n",
            "   [ 0.64705884]\n",
            "   [ 0.6784314 ]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 0.67058825]\n",
            "   [ 0.6       ]\n",
            "   [ 0.6313726 ]]\n",
            "\n",
            "  [[ 0.99215686]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 0.56078434]\n",
            "   [ 0.58431375]\n",
            "   [ 0.58431375]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.254902  ]\n",
            "   [ 0.06666672]\n",
            "   [ 0.3176471 ]\n",
            "   ...\n",
            "   [ 0.7254902 ]\n",
            "   [ 0.70980394]\n",
            "   [ 0.69411767]]\n",
            "\n",
            "  [[ 0.23921573]\n",
            "   [-0.04313725]\n",
            "   [ 0.082353  ]\n",
            "   ...\n",
            "   [ 0.73333335]\n",
            "   [ 0.7176471 ]\n",
            "   [ 0.69411767]]\n",
            "\n",
            "  [[ 0.1686275 ]\n",
            "   [-0.02745098]\n",
            "   [-0.08235294]\n",
            "   ...\n",
            "   [ 0.7411765 ]\n",
            "   [ 0.7176471 ]\n",
            "   [ 0.69411767]]]\n",
            "\n",
            "\n",
            " [[[-0.69411767]\n",
            "   [-0.6627451 ]\n",
            "   [-0.5764706 ]\n",
            "   ...\n",
            "   [-0.9764706 ]\n",
            "   [-0.96862745]\n",
            "   [-0.96862745]]\n",
            "\n",
            "  [[-0.78039217]\n",
            "   [-0.69411767]\n",
            "   [-0.60784316]\n",
            "   ...\n",
            "   [-0.9764706 ]\n",
            "   [-0.96862745]\n",
            "   [-0.96862745]]\n",
            "\n",
            "  [[-0.7411765 ]\n",
            "   [-0.6862745 ]\n",
            "   [-0.64705884]\n",
            "   ...\n",
            "   [-0.96862745]\n",
            "   [-0.9764706 ]\n",
            "   [-0.9607843 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.8980392 ]\n",
            "   [-0.90588236]\n",
            "   [-0.90588236]\n",
            "   ...\n",
            "   [-0.92941177]\n",
            "   [-0.9372549 ]\n",
            "   [-0.9372549 ]]\n",
            "\n",
            "  [[-0.90588236]\n",
            "   [-0.90588236]\n",
            "   [-0.90588236]\n",
            "   ...\n",
            "   [-0.9372549 ]\n",
            "   [-0.94509804]\n",
            "   [-0.94509804]]\n",
            "\n",
            "  [[-0.90588236]\n",
            "   [-0.90588236]\n",
            "   [-0.9137255 ]\n",
            "   ...\n",
            "   [-0.94509804]\n",
            "   [-0.94509804]\n",
            "   [-0.9529412 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.05882359]\n",
            "   [ 0.05882359]\n",
            "   [ 0.05882359]\n",
            "   ...\n",
            "   [ 0.23921573]\n",
            "   [ 0.427451  ]\n",
            "   [ 0.5921569 ]]\n",
            "\n",
            "  [[ 0.05098045]\n",
            "   [ 0.06666672]\n",
            "   [ 0.05882359]\n",
            "   ...\n",
            "   [ 0.32549024]\n",
            "   [ 0.41176474]\n",
            "   [ 0.56078434]]\n",
            "\n",
            "  [[ 0.05098045]\n",
            "   [ 0.05882359]\n",
            "   [ 0.06666672]\n",
            "   ...\n",
            "   [ 0.4666667 ]\n",
            "   [ 0.5137255 ]\n",
            "   [ 0.6       ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.00392163]\n",
            "   [ 0.00392163]\n",
            "   [ 0.00392163]\n",
            "   ...\n",
            "   [ 0.78039217]\n",
            "   [ 0.78039217]\n",
            "   [ 0.7647059 ]]\n",
            "\n",
            "  [[ 0.01176476]\n",
            "   [ 0.0196079 ]\n",
            "   [ 0.0196079 ]\n",
            "   ...\n",
            "   [ 0.6392157 ]\n",
            "   [ 0.56078434]\n",
            "   [ 0.4901961 ]]\n",
            "\n",
            "  [[ 0.0196079 ]\n",
            "   [ 0.02745104]\n",
            "   [ 0.02745104]\n",
            "   ...\n",
            "   [ 0.45882356]\n",
            "   [ 0.38823533]\n",
            "   [ 0.32549024]]]] [[[[ 1.        ]\n",
            "   [ 0.5372549 ]\n",
            "   [-0.5294118 ]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 0.96862745]\n",
            "   [-0.14509803]\n",
            "   [-0.52156866]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 0.38823533]\n",
            "   [-0.58431375]\n",
            "   [-0.54509807]\n",
            "   ...\n",
            "   [ 0.9843137 ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 0.9843137 ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 0.2941177 ]\n",
            "   [ 0.23921573]\n",
            "   [ 0.2313726 ]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 0.99215686]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 0.34901965]\n",
            "   [ 0.2313726 ]\n",
            "   [ 0.20784318]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 0.99215686]\n",
            "   [ 0.9843137 ]\n",
            "   ...\n",
            "   [ 0.35686278]\n",
            "   [ 0.24705887]\n",
            "   [ 0.19215691]]]\n",
            "\n",
            "\n",
            " [[[ 0.3803922 ]\n",
            "   [ 0.39607847]\n",
            "   [ 0.4039216 ]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 0.3803922 ]\n",
            "   [ 0.4431373 ]\n",
            "   [ 0.4431373 ]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 0.30196083]\n",
            "   [ 0.41960788]\n",
            "   [ 0.27058828]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.28627455]\n",
            "   [ 0.41176474]\n",
            "   [ 0.49803925]\n",
            "   ...\n",
            "   [-0.8666667 ]\n",
            "   [-0.8352941 ]\n",
            "   [-0.81960785]]\n",
            "\n",
            "  [[ 0.2941177 ]\n",
            "   [ 0.41960788]\n",
            "   [ 0.4901961 ]\n",
            "   ...\n",
            "   [-0.8039216 ]\n",
            "   [-0.8117647 ]\n",
            "   [-0.7882353 ]]\n",
            "\n",
            "  [[ 0.3176471 ]\n",
            "   [ 0.41176474]\n",
            "   [ 0.4901961 ]\n",
            "   ...\n",
            "   [-0.827451  ]\n",
            "   [-0.81960785]\n",
            "   [-0.8117647 ]]]\n",
            "\n",
            "\n",
            " [[[-0.05882353]\n",
            "   [ 0.35686278]\n",
            "   [ 0.92156863]\n",
            "   ...\n",
            "   [ 0.37254906]\n",
            "   [ 0.8509804 ]\n",
            "   [ 0.99215686]]\n",
            "\n",
            "  [[-0.01960784]\n",
            "   [ 0.39607847]\n",
            "   [ 0.67058825]\n",
            "   ...\n",
            "   [ 0.6627451 ]\n",
            "   [ 0.7176471 ]\n",
            "   [ 0.99215686]]\n",
            "\n",
            "  [[ 0.3803922 ]\n",
            "   [ 0.24705887]\n",
            "   [ 0.28627455]\n",
            "   ...\n",
            "   [ 0.4666667 ]\n",
            "   [ 0.69411767]\n",
            "   [ 0.9372549 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.49019605]\n",
            "   [-0.49019605]\n",
            "   [-0.4980392 ]\n",
            "   ...\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.9843137 ]]\n",
            "\n",
            "  [[-0.4823529 ]\n",
            "   [-0.41176468]\n",
            "   [-0.47450978]\n",
            "   ...\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.9843137 ]]\n",
            "\n",
            "  [[-0.38039213]\n",
            "   [-0.38039213]\n",
            "   [-0.40392154]\n",
            "   ...\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.9843137 ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.7647059 ]\n",
            "   [-0.8352941 ]\n",
            "   [-0.7019608 ]\n",
            "   ...\n",
            "   [-0.94509804]\n",
            "   [-0.9607843 ]\n",
            "   [-0.96862745]]\n",
            "\n",
            "  [[-0.75686276]\n",
            "   [-0.8117647 ]\n",
            "   [-0.5921569 ]\n",
            "   ...\n",
            "   [-0.94509804]\n",
            "   [-0.9529412 ]\n",
            "   [-0.9529412 ]]\n",
            "\n",
            "  [[-0.7254902 ]\n",
            "   [-0.77254903]\n",
            "   [-0.5529412 ]\n",
            "   ...\n",
            "   [-0.9529412 ]\n",
            "   [-0.9843137 ]\n",
            "   [-0.94509804]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.6862745 ]\n",
            "   [ 0.6862745 ]\n",
            "   [ 0.7019608 ]\n",
            "   ...\n",
            "   [ 0.35686278]\n",
            "   [ 0.13725495]\n",
            "   [ 0.28627455]]\n",
            "\n",
            "  [[ 0.5764706 ]\n",
            "   [ 0.6784314 ]\n",
            "   [ 0.7019608 ]\n",
            "   ...\n",
            "   [ 0.22352946]\n",
            "   [ 0.16078436]\n",
            "   [ 0.4666667 ]]\n",
            "\n",
            "  [[ 0.4666667 ]\n",
            "   [ 0.5294118 ]\n",
            "   [ 0.7490196 ]\n",
            "   ...\n",
            "   [ 0.2313726 ]\n",
            "   [ 0.23921573]\n",
            "   [ 0.5529412 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.19215691]\n",
            "   [-0.7411765 ]\n",
            "   [-0.7647059 ]\n",
            "   ...\n",
            "   [ 0.4901961 ]\n",
            "   [ 0.4901961 ]\n",
            "   [ 0.48235297]]\n",
            "\n",
            "  [[-0.23921567]\n",
            "   [-0.78039217]\n",
            "   [-0.7882353 ]\n",
            "   ...\n",
            "   [ 0.4901961 ]\n",
            "   [ 0.4901961 ]\n",
            "   [ 0.48235297]]\n",
            "\n",
            "  [[-0.372549  ]\n",
            "   [-0.7882353 ]\n",
            "   [-0.7647059 ]\n",
            "   ...\n",
            "   [ 0.49803925]\n",
            "   [ 0.4901961 ]\n",
            "   [ 0.4901961 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.27058828]\n",
            "   [ 0.04313731]\n",
            "   [-0.372549  ]\n",
            "   ...\n",
            "   [ 0.47450984]\n",
            "   [ 0.4901961 ]\n",
            "   [ 0.49803925]]\n",
            "\n",
            "  [[ 0.27843142]\n",
            "   [ 0.17647064]\n",
            "   [-0.20784312]\n",
            "   ...\n",
            "   [ 0.48235297]\n",
            "   [ 0.4901961 ]\n",
            "   [ 0.49803925]]\n",
            "\n",
            "  [[ 0.27843142]\n",
            "   [ 0.18431377]\n",
            "   [ 0.03529418]\n",
            "   ...\n",
            "   [ 0.4901961 ]\n",
            "   [ 0.5058824 ]\n",
            "   [ 0.5058824 ]]]\n",
            "\n",
            "\n",
            " [[[-0.32549018]\n",
            "   [-0.5058824 ]\n",
            "   [-0.69411767]\n",
            "   ...\n",
            "   [-0.9529412 ]\n",
            "   [-0.9529412 ]\n",
            "   [-0.9843137 ]]\n",
            "\n",
            "  [[-0.7411765 ]\n",
            "   [-0.85882354]\n",
            "   [-0.92941177]\n",
            "   ...\n",
            "   [-0.9607843 ]\n",
            "   [-0.9607843 ]\n",
            "   [-0.9843137 ]]\n",
            "\n",
            "  [[-0.8666667 ]\n",
            "   [-0.92156863]\n",
            "   [-0.92941177]\n",
            "   ...\n",
            "   [-0.9764706 ]\n",
            "   [-0.9764706 ]\n",
            "   [-0.9764706 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.4666667 ]\n",
            "   [ 0.427451  ]\n",
            "   [ 0.36470592]\n",
            "   ...\n",
            "   [-0.9764706 ]\n",
            "   [-0.9764706 ]\n",
            "   [-0.9764706 ]]\n",
            "\n",
            "  [[ 0.52156866]\n",
            "   [ 0.47450984]\n",
            "   [ 0.39607847]\n",
            "   ...\n",
            "   [-0.9764706 ]\n",
            "   [-0.9764706 ]\n",
            "   [-0.9764706 ]]\n",
            "\n",
            "  [[ 0.5529412 ]\n",
            "   [ 0.47450984]\n",
            "   [ 0.4039216 ]\n",
            "   ...\n",
            "   [-0.9764706 ]\n",
            "   [-0.9764706 ]\n",
            "   [-0.9764706 ]]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\\n\\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKvEv321Stt5",
        "outputId": "e49bdfbe-5f95-40d6-b995-9d045c72b4f5"
      },
      "source": [
        "print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validasi (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "test (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "train (28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH9Q-TegBR26"
      },
      "source": [
        "#hyperparameter and callback\n",
        "batch_size = 64\n",
        "num_epochs = 60\n",
        "input_shape = (48, 48, 1)\n",
        "num_classes = 7\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGsscQRJBR-h"
      },
      "source": [
        "#Compile the model.\n",
        "\n",
        "\n",
        "from keras.optimizers import Adam, SGD\n",
        "model = ResNet50ori(input_shape = (48, 48, 1), classes = 7)\n",
        "optimizer = SGD(learning_rate=0.001)\n",
        "model.compile(optimizer= optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rodttDWeT2yP"
      },
      "source": [
        "#kita mau save model callbacks\n",
        "\"\"\"import os\n",
        "try:\n",
        "  os.mkdir('scratchcheckpoint')\n",
        "except:\n",
        "  pass\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV29sTjET28U"
      },
      "source": [
        "\"\"\"file_name = 'Best_Model_resnet50Scracth_sena1.h5'\n",
        "\n",
        "checkpoint_path = os.path.join('checkpoint',file_name)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_S6wUaPT3Jx"
      },
      "source": [
        "\"\"\"call_back = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
        "                                               monitor='val_accuracy',\n",
        "                                               verbose=1,\n",
        "                                               save_freq='epoch',\n",
        "                                               save_best_only=True,\n",
        "                                               save_weights_only=False,\n",
        "                                               mode='max')\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy53DHMGB-Mr",
        "outputId": "7ce186d9-17ee-49b6-fcd0-410eedfae51d"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50ori\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2D)  (None, 54, 54, 1)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 24, 24, 64)   3200        zero_padding2d[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 24, 24, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 24, 24, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 11, 11, 64)   0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 11, 11, 64)   4160        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 11, 11, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 11, 11, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 11, 11, 256)  16640       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 11, 11, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 11, 11, 256)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 11, 11, 256)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 11, 11, 64)   16448       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 11, 11, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 11, 11, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 11, 11, 256)  0           activation_3[0][0]               \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 11, 11, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 11, 11, 64)   16448       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 11, 11, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 11, 11, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 11, 11, 256)  0           activation_6[0][0]               \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 11, 11, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 6, 6, 128)    32896       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 6, 6, 128)    0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 6, 6, 128)    0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 6, 6, 512)    131584      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 6, 6, 512)    2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 6, 6, 512)    0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 6, 6, 512)    0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 6, 6, 128)    0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 6, 6, 128)    0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 6, 6, 512)    0           activation_12[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 6, 6, 512)    0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 6, 6, 128)    0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 6, 6, 128)    0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 6, 6, 512)    0           activation_15[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 6, 6, 512)    0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 6, 6, 128)    0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 6, 6, 128)    0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 6, 6, 512)    0           activation_18[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 6, 6, 512)    0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 3, 3, 256)    131328      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 3, 3, 256)    0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 3, 3, 256)    0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 3, 3, 1024)   525312      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 3, 3, 1024)   4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 3, 3, 1024)   0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 3, 3, 1024)   0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 3, 3, 256)    0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 3, 3, 256)    0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 3, 3, 1024)   0           activation_24[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 3, 3, 1024)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 3, 3, 256)    0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 3, 3, 256)    0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 3, 3, 1024)   0           activation_27[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 3, 3, 1024)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 3, 3, 256)    0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 3, 3, 256)    0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 3, 3, 1024)   0           activation_30[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 3, 3, 1024)   0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 3, 3, 256)    0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 3, 3, 256)    0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 3, 3, 1024)   0           activation_33[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 3, 3, 1024)   0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 3, 3, 256)    0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 3, 3, 256)    0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 3, 3, 1024)   0           activation_36[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 3, 3, 1024)   0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 2, 2, 512)    524800      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 2, 2, 2048)   2099200     activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 2, 2, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 2, 2, 2048)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 2, 2, 2048)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 2, 2, 2048)   0           activation_42[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 2, 2, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 2, 2, 2048)   0           activation_45[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 2, 2, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 2048)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            14343       flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,595,783\n",
            "Trainable params: 23,542,663\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgxCecVwCGEr"
      },
      "source": [
        "\"\"\"history = model.fit(data_generator.flow(xtrain, ytrain,),\n",
        "                        steps_per_epoch=len(xtrain) / batch_size,\n",
        "                        epochs=num_epochs, verbose=1,callbacks=call_back,\n",
        "                        validation_data= (xtest,ytest))\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2muXWns0sJSH",
        "outputId": "521b037a-d759-45db-e99e-7ea348fae54e"
      },
      "source": [
        "history = model.fit(\n",
        "    data_generator.flow(xtrain, ytrain,),\n",
        "    steps_per_epoch=len(xtrain) / batch_size,\n",
        "    epochs=num_epochs, \n",
        "    verbose=1,\n",
        "    validation_data= (x_val,y_val))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "448/448 [==============================] - 91s 67ms/step - loss: 2.0954 - accuracy: 0.1955 - val_loss: 1.9843 - val_accuracy: 0.2262\n",
            "Epoch 2/60\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.9622 - accuracy: 0.2202 - val_loss: 2.2258 - val_accuracy: 0.2416\n",
            "Epoch 3/60\n",
            "448/448 [==============================] - 25s 55ms/step - loss: 1.9461 - accuracy: 0.2230 - val_loss: 2.1257 - val_accuracy: 0.2282\n",
            "Epoch 4/60\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.9054 - accuracy: 0.2392 - val_loss: 1.9277 - val_accuracy: 0.2488\n",
            "Epoch 5/60\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.8936 - accuracy: 0.2368 - val_loss: 1.9812 - val_accuracy: 0.2569\n",
            "Epoch 6/60\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.8711 - accuracy: 0.2559 - val_loss: 1.8618 - val_accuracy: 0.2611\n",
            "Epoch 7/60\n",
            "448/448 [==============================] - 24s 54ms/step - loss: 1.8487 - accuracy: 0.2613 - val_loss: 1.8126 - val_accuracy: 0.2736\n",
            "Epoch 8/60\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 1.8576 - accuracy: 0.2580 - val_loss: 1.8121 - val_accuracy: 0.2647\n",
            "Epoch 9/60\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.8327 - accuracy: 0.2662 - val_loss: 1.8500 - val_accuracy: 0.2625\n",
            "Epoch 10/60\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 1.8307 - accuracy: 0.2645 - val_loss: 1.8563 - val_accuracy: 0.2814\n",
            "Epoch 11/60\n",
            "448/448 [==============================] - 25s 57ms/step - loss: 1.8098 - accuracy: 0.2795 - val_loss: 1.8301 - val_accuracy: 0.2781\n",
            "Epoch 12/60\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.8043 - accuracy: 0.2676 - val_loss: 1.8088 - val_accuracy: 0.3034\n",
            "Epoch 13/60\n",
            "448/448 [==============================] - 25s 55ms/step - loss: 1.8081 - accuracy: 0.2713 - val_loss: 1.8118 - val_accuracy: 0.2867\n",
            "Epoch 14/60\n",
            "448/448 [==============================] - 25s 57ms/step - loss: 1.7840 - accuracy: 0.2866 - val_loss: 1.8124 - val_accuracy: 0.3001\n",
            "Epoch 15/60\n",
            "448/448 [==============================] - 26s 59ms/step - loss: 1.7897 - accuracy: 0.2835 - val_loss: 1.7574 - val_accuracy: 0.3135\n",
            "Epoch 16/60\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 1.7736 - accuracy: 0.2869 - val_loss: 1.7667 - val_accuracy: 0.3107\n",
            "Epoch 17/60\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 1.7758 - accuracy: 0.2907 - val_loss: 1.7669 - val_accuracy: 0.3087\n",
            "Epoch 18/60\n",
            "448/448 [==============================] - 25s 55ms/step - loss: 1.7818 - accuracy: 0.2890 - val_loss: 1.8006 - val_accuracy: 0.3215\n",
            "Epoch 19/60\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.7720 - accuracy: 0.2991 - val_loss: 1.7284 - val_accuracy: 0.3249\n",
            "Epoch 20/60\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.7607 - accuracy: 0.2959 - val_loss: 1.7066 - val_accuracy: 0.3316\n",
            "Epoch 21/60\n",
            "448/448 [==============================] - 24s 53ms/step - loss: 1.7325 - accuracy: 0.3112 - val_loss: 1.7462 - val_accuracy: 0.3165\n",
            "Epoch 22/60\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 1.7320 - accuracy: 0.3105 - val_loss: 1.7120 - val_accuracy: 0.3396\n",
            "Epoch 23/60\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.7385 - accuracy: 0.3047 - val_loss: 1.7091 - val_accuracy: 0.3408\n",
            "Epoch 24/60\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.7193 - accuracy: 0.3198 - val_loss: 1.6739 - val_accuracy: 0.3422\n",
            "Epoch 25/60\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.7194 - accuracy: 0.3194 - val_loss: 1.6952 - val_accuracy: 0.3424\n",
            "Epoch 26/60\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 1.7094 - accuracy: 0.3211 - val_loss: 1.6828 - val_accuracy: 0.3419\n",
            "Epoch 27/60\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 1.6994 - accuracy: 0.3366 - val_loss: 1.7194 - val_accuracy: 0.3483\n",
            "Epoch 28/60\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 1.7004 - accuracy: 0.3362 - val_loss: 1.6719 - val_accuracy: 0.3653\n",
            "Epoch 29/60\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 1.7045 - accuracy: 0.3268 - val_loss: 1.6463 - val_accuracy: 0.3720\n",
            "Epoch 30/60\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.6903 - accuracy: 0.3301 - val_loss: 1.6338 - val_accuracy: 0.3689\n",
            "Epoch 31/60\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 1.6846 - accuracy: 0.3373 - val_loss: 1.6193 - val_accuracy: 0.3736\n",
            "Epoch 32/60\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 1.6752 - accuracy: 0.3400 - val_loss: 1.6221 - val_accuracy: 0.3725\n",
            "Epoch 33/60\n",
            "448/448 [==============================] - 26s 59ms/step - loss: 1.6783 - accuracy: 0.3300 - val_loss: 1.6156 - val_accuracy: 0.3775\n",
            "Epoch 34/60\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 1.6794 - accuracy: 0.3339 - val_loss: 1.6796 - val_accuracy: 0.3714\n",
            "Epoch 35/60\n",
            "448/448 [==============================] - 25s 57ms/step - loss: 1.6693 - accuracy: 0.3491 - val_loss: 1.6111 - val_accuracy: 0.3837\n",
            "Epoch 36/60\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 1.6746 - accuracy: 0.3469 - val_loss: 1.5850 - val_accuracy: 0.3820\n",
            "Epoch 37/60\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.6538 - accuracy: 0.3481 - val_loss: 1.6021 - val_accuracy: 0.3840\n",
            "Epoch 38/60\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 1.6443 - accuracy: 0.3486 - val_loss: 1.5972 - val_accuracy: 0.3842\n",
            "Epoch 39/60\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 1.6546 - accuracy: 0.3484 - val_loss: 1.5954 - val_accuracy: 0.3826\n",
            "Epoch 40/60\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.6439 - accuracy: 0.3595 - val_loss: 1.5871 - val_accuracy: 0.3920\n",
            "Epoch 41/60\n",
            "448/448 [==============================] - 26s 57ms/step - loss: 1.6511 - accuracy: 0.3534 - val_loss: 1.5997 - val_accuracy: 0.3934\n",
            "Epoch 42/60\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 1.6486 - accuracy: 0.3572 - val_loss: 1.5867 - val_accuracy: 0.3887\n",
            "Epoch 43/60\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.6295 - accuracy: 0.3692 - val_loss: 1.5674 - val_accuracy: 0.3996\n",
            "Epoch 44/60\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.6182 - accuracy: 0.3643 - val_loss: 1.5763 - val_accuracy: 0.4021\n",
            "Epoch 45/60\n",
            "448/448 [==============================] - 25s 57ms/step - loss: 1.6358 - accuracy: 0.3594 - val_loss: 1.6002 - val_accuracy: 0.4012\n",
            "Epoch 46/60\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.6126 - accuracy: 0.3713 - val_loss: 1.6296 - val_accuracy: 0.3892\n",
            "Epoch 47/60\n",
            "448/448 [==============================] - 25s 55ms/step - loss: 1.6121 - accuracy: 0.3653 - val_loss: 1.5417 - val_accuracy: 0.4135\n",
            "Epoch 48/60\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.6031 - accuracy: 0.3729 - val_loss: 1.5718 - val_accuracy: 0.3970\n",
            "Epoch 49/60\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.5948 - accuracy: 0.3786 - val_loss: 1.5403 - val_accuracy: 0.4132\n",
            "Epoch 50/60\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.5896 - accuracy: 0.3804 - val_loss: 1.5517 - val_accuracy: 0.4037\n",
            "Epoch 51/60\n",
            "448/448 [==============================] - 24s 54ms/step - loss: 1.5845 - accuracy: 0.3805 - val_loss: 1.5181 - val_accuracy: 0.4160\n",
            "Epoch 52/60\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 1.5943 - accuracy: 0.3819 - val_loss: 1.5516 - val_accuracy: 0.4163\n",
            "Epoch 53/60\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.5858 - accuracy: 0.3783 - val_loss: 1.5302 - val_accuracy: 0.4138\n",
            "Epoch 54/60\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.5891 - accuracy: 0.3816 - val_loss: 1.5145 - val_accuracy: 0.4205\n",
            "Epoch 55/60\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.5732 - accuracy: 0.3817 - val_loss: 1.5395 - val_accuracy: 0.4099\n",
            "Epoch 56/60\n",
            "448/448 [==============================] - 24s 54ms/step - loss: 1.5675 - accuracy: 0.3884 - val_loss: 1.5854 - val_accuracy: 0.4001\n",
            "Epoch 57/60\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.5708 - accuracy: 0.3910 - val_loss: 1.5102 - val_accuracy: 0.4230\n",
            "Epoch 58/60\n",
            "448/448 [==============================] - 26s 58ms/step - loss: 1.5662 - accuracy: 0.3820 - val_loss: 1.5369 - val_accuracy: 0.4207\n",
            "Epoch 59/60\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.5566 - accuracy: 0.4027 - val_loss: 1.5224 - val_accuracy: 0.4271\n",
            "Epoch 60/60\n",
            "448/448 [==============================] - 25s 56ms/step - loss: 1.5608 - accuracy: 0.3913 - val_loss: 1.5141 - val_accuracy: 0.4154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "GaXUP-8fDWRN",
        "outputId": "05860ab5-348b-48b7-a334-aabbf6c38bd7"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "model.save('/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50oriSGD1st.h5')\n",
        "\n",
        "#gffhgffkjkjdskjjkjkjkjhjhnnn\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "num_epochs = range(len(accuracy))\n",
        "plt.plot(num_epochs, accuracy, 'r', label='Training acc')\n",
        "plt.plot(num_epochs, val_accuracy, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(num_epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(num_epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_LxatO5J-pp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d230d4b-bc84-400f-ce93-c35861edf7d4"
      },
      "source": [
        "testloss = model.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "trainloss = model.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(trainloss[0]))\n",
        "print(\"Train Acc: \" + str(trainloss[1]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 2s 18ms/step - loss: 1.5276 - accuracy: 0.4012\n",
            "Test Loss 1.5276463031768799\n",
            "Test Acc: 0.4012259542942047\n",
            "898/898 [==============================] - 15s 17ms/step - loss: 1.4654 - accuracy: 0.4376\n",
            "Train Loss 1.4654247760772705\n",
            "Train Acc: 0.43763279914855957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swoRERVdKQ1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74516cc2-fe97-4189-d2c3-f69b93bc2029"
      },
      "source": [
        "testlosz = model.evaluate(x_val, y_val) \n",
        "print(\"Test Loss \" + str(testlosz[0]))\n",
        "print(\"Test Acc: \" + str(testlosz[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 3s 27ms/step - loss: 1.0969 - accuracy: 0.5949\n",
            "Test Loss 1.0968551635742188\n",
            "Test Acc: 0.5948732495307922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5iaZIU6pPzk",
        "outputId": "ae6badc0-fcc1-4413-8ebd-02a1728f8a6b"
      },
      "source": [
        "from keras.models import load_model\n",
        "model_load = load_model('/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50oriSGD1st.h5')\n",
        "\n",
        "model_load.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50ori\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2D)  (None, 54, 54, 1)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 24, 24, 64)   3200        zero_padding2d[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 24, 24, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 24, 24, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 11, 11, 64)   0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 11, 11, 64)   4160        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 11, 11, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 11, 11, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 11, 11, 256)  16640       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 11, 11, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 11, 11, 256)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 11, 11, 256)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 11, 11, 64)   16448       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 11, 11, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 11, 11, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 11, 11, 256)  0           activation_3[0][0]               \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 11, 11, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 11, 11, 64)   16448       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 11, 11, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 11, 11, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 11, 11, 256)  0           activation_6[0][0]               \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 11, 11, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 6, 6, 128)    32896       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 6, 6, 128)    0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 6, 6, 128)    0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 6, 6, 512)    131584      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 6, 6, 512)    2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 6, 6, 512)    0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 6, 6, 512)    0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 6, 6, 128)    0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 6, 6, 128)    0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 6, 6, 512)    0           activation_12[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 6, 6, 512)    0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 6, 6, 128)    0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 6, 6, 128)    0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 6, 6, 512)    0           activation_15[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 6, 6, 512)    0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 6, 6, 128)    0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 6, 6, 128)    0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 6, 6, 512)    0           activation_18[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 6, 6, 512)    0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 3, 3, 256)    131328      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 3, 3, 256)    0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 3, 3, 256)    0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 3, 3, 1024)   525312      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 3, 3, 1024)   4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 3, 3, 1024)   0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 3, 3, 1024)   0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 3, 3, 256)    0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 3, 3, 256)    0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 3, 3, 1024)   0           activation_24[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 3, 3, 1024)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 3, 3, 256)    0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 3, 3, 256)    0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 3, 3, 1024)   0           activation_27[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 3, 3, 1024)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 3, 3, 256)    0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 3, 3, 256)    0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 3, 3, 1024)   0           activation_30[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 3, 3, 1024)   0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 3, 3, 256)    0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 3, 3, 256)    0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 3, 3, 1024)   0           activation_33[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 3, 3, 1024)   0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 3, 3, 256)    0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 3, 3, 256)    0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 3, 3, 1024)   0           activation_36[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 3, 3, 1024)   0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 2, 2, 512)    524800      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 2, 2, 2048)   2099200     activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 2, 2, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 2, 2, 2048)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 2, 2, 2048)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 2, 2, 2048)   0           activation_42[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 2, 2, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 2, 2, 2048)   0           activation_45[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 2, 2, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 2048)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            14343       flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,595,783\n",
            "Trainable params: 23,542,663\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypc8clklx2p8",
        "outputId": "24d08561-f336-4ea3-c945-3e66f2b43222"
      },
      "source": [
        "#loss,acc = model_load.evaluate(xtrain,ytrain)\n",
        "\"\"\"print(\"loss:\",loss)\n",
        "print(\"acc:\",acc)kjjkj\"\"\"\n",
        "\n",
        "\n",
        "testloss = model_load.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "\n",
        "testloss = model_load.evaluate(xtrain, ytrain) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 6s 18ms/step - loss: 1.5276 - accuracy: 0.4012\n",
            "Test Loss 1.5276463031768799\n",
            "Test Acc: 0.4012259542942047\n",
            "898/898 [==============================] - 15s 17ms/step - loss: 1.4654 - accuracy: 0.4376\n",
            "Test Loss 1.4654247760772705\n",
            "Test Acc: 0.43763279914855957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7mSww_U2O_q",
        "outputId": "cebc0485-5222-4785-8c9c-e80fbcd79296"
      },
      "source": [
        "testlosz = model_load.evaluate(x_val, y_val) \n",
        "print(\"Test Loss \" + str(testlosz[0]))\n",
        "print(\"Test Acc: \" + str(testlosz[1]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 2s 18ms/step - loss: 1.5141 - accuracy: 0.4154\n",
            "Test Loss 1.5140790939331055\n",
            "Test Acc: 0.4154360592365265\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdU7uU3PYCnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "511535a9-da87-4184-f0d7-178cc738a4e8"
      },
      "source": [
        "print (x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3589, 48, 48, 1)\n",
            "(3589,)\n",
            "(3589, 48, 48, 1)\n",
            "(3589,)\n",
            "(28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_Tf1qg8TKnx",
        "outputId": "6352a892-0312-453f-f037-1abcaf6495b3"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "#y_pred = model_load.predict(xtest)\n",
        "\n",
        "test_prob = model_load.predict(xtest)\n",
        "test_pred = np.argmax(test_prob, axis=1)\n",
        "test_accuracy = np.mean(test_pred == ytest)\n",
        "\n",
        "print(test_accuracy)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.40122596823627754\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpwJv9V54_1M"
      },
      "source": [
        "\n",
        "emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "KMe4WL0T5BcJ",
        "outputId": "86efa630-6142-463c-ae89-42bad1a65899"
      },
      "source": [
        "conf_mat = confusion_matrix(ytest, test_pred)\n",
        "\n",
        "pd.DataFrame(conf_mat, columns=emotions.values(), index=emotions.values())\n",
        "\n",
        "\n",
        "\n",
        "fig, ax = plot_confusion_matrix(conf_mat=conf_mat,show_normed=True,show_absolute=False,figsize=(8, 8))\n",
        "fig.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdwAAAHgCAYAAAAPG9wjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXhM5//G8fdhRGmRCJLMBLFVJNZI7PtOYim11FJK69td9/VXbXVRdKF7tVWqal8ise+7xlZaWxvEkgWl6JrI5Pz+SBpGqCBzBr1f1+VqzjzPyXw+nTPPPWfmGIZpmoiIiIh75fN0ASIiIv8FClwRERELKHBFREQsoMAVERGxgAJXRETEAgpcERERC9g8XcD5ivuWMANLl/V0GZYrkN/wdAkekZqe4ekSPOLU32c9XYJYzLewl6dL8IiM/+DfOk08fJCTJ3656KJ+XQVuYOmyxC5b5+kyLFeq2C2eLsEjDv7yp6dL8Ig5u5M9XYLH/Ff/2n+/WoGeLsEj0pz/vQe8U6uGlxzTW8oiIiIWUOCKiIhYQIErIiJiAQWuiIiIBRS4IiIiFlDgioiIWECBKyIiYgEFroiIiAUUuCIiIhZQ4IqIiFhAgSsiImIBBa6IiIgFFLgiIiIWUOCKiIhYQIErIiJiAQWuiIiIBRS4IiIiFlDgioiIWECBKyIiYgEFroiIiAUUuCIiIhZQ4IqIiFhAgSsiImIBBa6IiIgFbvrAXblsMc3rVqdJRCgfjxmVYzw1NZWHBvWlSUQonds05vChgwCcPXuWJx66lzaNw2lRvyYfjc657/Vs8aKFVA+tTGhwRUaNfCvHeGpqKn179yQ0uCKNG9TlYEJC9tioEcMJDa5I9dDKLFm8yMKqr92a5Ytp16gmbepXY+wHb+cY37RhLV1bNyA0sCgLY2e7jN17V2ciKtv5X79uVpWbp/bGreLtu1szqm8LVn77aY7xjXO/5b1BHRhzX0c+ebQnRxN+BuDnzWv54H+deW9QBz74X2fit26wuvRrsjduFe/0b82ofi1YOTln39/FfMvoezvw/uCOfDrkgr7v78zoezvwwf2d2bftxup7xdLFNKlTjYa1Q/jwIutTamoqDwzsS8PaIUS1aszhQwkAzJo+mTZN6mT/Ke1biJ0/bLe4+qu3atliWtarTvOIUD65xJr+yL19aR4Ryh1tG3Mka01PS0vj6UcG065JOB2a1WHjutVWl+7ewDUMo51hGHsNw4g3DOM5d97XxTidTl569jEmTI1m6bptzJ01nZ/27naZM3XSeIp5+7B6004G3f8Ib736IgDzomeSlprK4jWbmbdsPd9O+CI7jK93TqeTxx59iOiYBWzbsYvpUyaze9culznjx32Jj7cPO/fE88iQx3nxhWcB2L1rF9OnTmHr9p3MjV3IkEcexOl0eqKNK+Z0Ohn2whN8Pmk2sau2MG/OdOIveLwDAkszfMxnRN3RI8f+gx58jBEffGFVuXkqw+kkeswr3PPWlzz+1UK+Xx6bHSz/qNmyI49/OZ8hn8fQtOd9zPvkTQAKF/Oh/xtjefzL+XR/bhTThj/liRauSobTydz3X+Ge4V/y+LiFbL9I3zVadOSxL+bz6NgYmvS8j3mfZvZ9azEf+r8+lse+mE/3Z2+svp1OJ//3zBAmTotmxYbviZ45jZ/2uB7rU74ZTzFvb9Zt2cV9DzzCm6/8HwBdu9/F4tVxLF4dx5hPx1GmbBCh1Wp4oo0r5nQ6efm5x/hqSjSL1m0jZvZ0fr7gOT5t0niKevuwYtNOBt7/CCOGZa7pUyaOA2Dh6s18PT2WN4c+R0ZGhqX1uy1wDcPID3wEtAdCgLsMwwhx1/1dzPdbNxFUrgJlgsrh5eVFxzu6s2RBrMucJQti6darDwAdOnVl3ZqVmKaJYRj8+eefpKen8/fff1GggBdFihSxsvyrtikujgoVKlKufHm8vLzo3rMXsTHRLnNiY6Lp068/AF273cnK5cswTZPYmGi69+xFwYIFCSpXjgoVKrIpLs4TbVyxHds2UyaoPKXLZj7eHTrfybJFro93YOmyVA6phpEv56Ffv3Fzbr3tNqvKzVOH92zH11EWX3sZbAW8qNEikl3rl7rMueXWc8dv2t9/gWEA4KgUStESfgD4BVXibNrfpKelWlf8Nfin7+L/9N08kt2X6dsgs2/7Ddz391sy17ayQZnP8c5du7N4QYzLnMXzY+jeqy8AkZ27snb1CkzTdJkTPXMqnbp2t6zua7V96ybKBp1b06O65FzTly6IpVvPzDW9fceurM9a0+P37qFB42YAlChZiiLFivHD91ssrd+dZ7h1gHjTNPebppkGTAE6u/H+ckhJTiLAHpi9HWB3kJKcmGOO3ZE5x2azUaRoUX49eYIOnbpSuHBhIkLLUb/m7Qx+6DG8fYpbWf5VS0pKJDCwdPa2wxFIYmJizjmlM+fYbDaKFivGiRMnSEzMuW9Skuu+16ujKUkEOM493v4BDo6mJHuwIuuc+eUoxUoFZG8XK+HPmeNHc8zbMGciI/s0Z8HYEXR6eGiO8R9XL8RRKRSbV0G31ptXzvxylGIlz/VdtKQ/p3+5eN+j+jZn4dgRdLxE3/YbqO/k5AuOdbuD5OQklzkp582x2WwUzVrbzhczewadu/Z0f8F5JOWCvgPsDo5esKafvw6cv6ZXqVqNpQtjSU9P5/DBBH7cvo2kxCOW1u/OwHUAh8/bPpJ12w3h+62byJc/P3E/7mftlt18/vEYDiUc8HRZItekfpd+PDNpBe0HP8Pybz5yGTt64CcWjB3JHY+/5qHq3Kd+l348/c0K2t13kb4TfmLh5zdn3/9m6+Y4bilUmOCQUE+XYonuvfvjb3fQuVVDXvu/pwmLqEf+/PktrcHjF00ZhjHYMIzNhmFsPnnieJ7+bv8AO8lJ517BJCcl4h/gyDHnn1c56enp/HbmDD7FfYmeOY1mLdtQoEABSpQsRe269dlh8dsPV8tud3DkyLnXOomJR3A4HDnnHM6ck56ezpnTp/H19cXhyLmv3X5jvE7y87eTfN4r1pTkRPz8A/5lj5tH0RJ+nD527mz+9C8pFC3pd8n51ZtHsXPdknPzjycz8eUH6fH82/g6yrq11rxUtIQfp4+f6/vM8RSKlfj3vnetv6DvoQ/S/bm38bXfOH0HBFxwrCclEhBgd5njf96c9PR0zmStbf+YO2s6XbrlvJbheuZ/Qd/JSYn4XbCmn78OnL+m22w2Xnp9FPNWfsfYidP57cwpylWoZGn97gzcRKD0eduBWbe5ME1zrGma4aZphhf3LZmnBdSoFc6B/fEcOphAWloaMbOn07pdpMucVu0imTllEgDz586iQeOmGIaBIzCQ9WtWAvDnH3+wbXMcFSpVztP63CU8IoL4+J9JOHCAtLQ0pk+dQmRUJ5c5kVGdmDRxAgCzZs6gafMWGIZBZFQnpk+dQmpqKgkHDhAf/zMRdep4oo0rVq1mbQ4e2MeRQ5mP9/zoGbRoG3n5HW8CgcHVOZF4kJPJh0k/m8b25fMIqd/SZc4vRxKyf96zcQUlHEEA/PX7Gb56/j7a3fs0QVVrW1j1tQsMrs4v5/e9Yh5VGly6770X9D3+hftod9+N13eNsH/WtsznePSs6bRuF+Uyp3X7KKZP+QaAedGzaNi4GUbW5/YZGRnERM+8oT6/BaheK5yEA/EczlrTY+dMp9UFa3rLdpHMnJq5pi+ImUX9Rplr+l9//smff/wBwJqVy8if30alylUsrd/mxt+9CahkGEY5MoO2F9DbjfeXg81mY9hb73F39444M5z06N2f24NDeGf4MKrXDKN1+yh69hnA4w8OpElEKN7ePnz4+UQA7h54P089OphWDcMwTZPud/WjSmg1K8u/ajabjffGfEjHyLY4nU76DxhISGgow14ZSljtcKI6dmLAwEEMHNCP0OCK+PgUZ+KkKQCEhIbSrXsPalUPwWazMfr9jyx/2+Vq2Ww2XnrzHQbd1ZkMp5Nuve6mUuUQ3h/5GlVrhNGibSQ/fL+Fhwf24sypU6xYsoAPR71B7KrNAPTp3Jr98T/x55+/0zSsEq+/8zGNm7f2cFe5kz+/jU6PvMy4Z+8hw+kkvH13/MrdzuKvRhN4e1VCGrZi/ZyJxG9ZR35bAQoVKUqPZ0cCsH72RE4kHWTZxA9ZNvFDAAaNHM9tPr7/dpfXhfP7NjOy+g66nSVfjcZRuSohDVqxYc5E4rdm9X1bUbpn9b1hTmbfyyd+yPKsvgeOuDH6ttlsvDZyNH3u7EiG00nPPv2pXCWEUW++So1atWnTPopefQcw5P6BNKwdgrdPcT7+4uvs/TeuX4PdHkjZoPIe7OLK2Ww2Xhn+Hv17dCQjw0n3uzLX9PfeGka1mmG0ape5pj/x4ECaR4RSzMeH98dmruknfjlO/x4dyZcvH34Bdt79+EvL6zcuvGotT3+5YXQARgP5gXGmab7xb/Or16xtxi5b57Z6rlelit3i6RI84uAvf3q6BI+Ys/u/cSHXxbhxubmu9asVePlJN6E053/vAe/UqiE/fL/FuNiYO89wMU1zPjDfnfchIiJyI/D4RVMiIiL/BQpcERERCyhwRURELKDAFRERsYACV0RExAIKXBEREQsocEVERCygwBUREbGAAldERMQCClwRERELKHBFREQsoMAVERGxgAJXRETEAgpcERERCyhwRURELKDAFRERsYACV0RExAIKXBEREQsocEVERCygwBUREbGAAldERMQCClwRERELKHBFREQsoMAVERGxgAJXRETEAgpcERERC9g8XUAOhuHpCsQif/yd7ukSPKKe3cfTJXjMsoRfPF2CR9zild/TJXjEkZTfPV2C5dKdGZcc0xmuiIiIBRS4IiIiFlDgioiIWECBKyIiYgEFroiIiAUUuCIiIhZQ4IqIiFhAgSsiImIBBa6IiIgFFLgiIiIWUOCKiIhYQIErIiJiAQWuiIiIBRS4IiIiFlDgioiIWECBKyIiYgEFroiIiAUUuCIiIhZQ4IqIiFhAgSsiImIBBa6IiIgFFLgiIiIWUOCKiIhYQIErIiJiAQWuiIiIBW76wF25bDHN61SjSXgIH48elWM8NTWVhwb1pUl4CJ1bN+bwoQQAzp49yxMPDqJNo9q0qFeDj94baXHl12bxooVUD61MaHBFRo18K8d4amoqfXv3JDS4Io0b1OVgQkL22KgRwwkNrkj10MosWbzIwqqv3fpVS+naojadm9Xkq0/ezTG+9bt19I5qTJ2KxVk6f47LWHLiYR7s14VurSK4s3Udko4ctKrsPPHdmmX0a1eH3m3CmTR2dI7xaV99TP/I+gzs1JgnBnQhJfFw9tjC2ZPp0zaCPm0jWDh7spVlX7P4zav5aFBbPrynNeumjs0xvmXeZD69vyNjH+zM+Cfu4vjBeJfx08eSeKtLLTbM+NKqkvPEsiWLqFsrlIjqwYx5J+f6lJqayqC7exNRPZg2zRpw6GCCy/iRw4co6+fNh2NyPk+uZxtWLaVH6wjubBHG15++l2N8W9w67u7UlIaVS7B8QbTL2AcjhnJXu/r0bFuXd4Y9i2maVpUNuDFwDcMYZxjGMcMwfnTXfVyO0+nkpWeGMGFaNEvXf8/cWdP4ac9ulzlTvxlPMW9vVm/exaAHHuGtV/8PgHnRM0lLS2Px2i3MW76Bbyd8kR3G1zun08ljjz5EdMwCtu3YxfQpk9m9a5fLnPHjvsTH24ede+J5ZMjjvPjCswDs3rWL6VOnsHX7TubGLmTIIw/idDo90cYVczqdvDX0Sd4fP4MZi+NYNHcm+3/e4zLH3xHIq6M+oV2n7jn2f/nJ+7l78KPMXLqJr+csx8e3pFWlXzOn08mYYc8w4vNpTIhdz/J5s0iId+29UpVqfDZjGePmrqFp20589vYrAJw59SsTPhrFJ1MX8+m0JUz4aBS/nT7lgS6uXIbTycKPhtH79S94YOw8flwZmyNQqzbryP2fxjD442jqd7+XJWOHu4wvHvsWFcMbW1n2NXM6nTz7xKNMnRXDus07mDV9Cnt3uz7HJ00Yh7e3N5t27OH+h4bw6ksvuIy/9NzTtGzdzsqyr5nT6eTtV57mvS+nM3nhRhbHzuTABc9xP3tpXhr5EW063uly+46t37Fjy3d8M28t385fz+4d29j63Tory3frGe54wKOP5vdbNxFUrgJlgsrj5eVFxzu6s2RBjMucJQti6NarLwAdOnVl3eoVmKaJYRj8+ecfpKen8/fff1HAy4siRYp6oo0rtikujgoVKlKufGbf3Xv2IjbG9ZVebEw0ffr1B6BrtztZuXwZpmkSGxNN9569KFiwIEHlylGhQkU2xcV5oo0rtnP7FkqXLU9gmXIU8PKiTceurFwyz2WOPbAslapUxcjneujv/3kP6c506jVuAUDhW2+jUKHCltV+rfbs2IqjTDnspYMo4OVFiw53sG7ZApc5teo15pasnkJqhHM8JQmATWuXE96gGUW9fShSzJvwBs2IW7PM8h6uRtLeHfgElMUnoDT5C3gR2jSSvRtcay94623ZP5/9+y8wjOztPeuX4uPnoGTZSpbVnBe2bo6jXPkKBJXLfI7fcWdPFsxzXdsWzIuhV59+AHS6oxtrVi7PPqObHxNNmaAgKlcJsbz2a7Fr+xYCy5bHUSbzOG8d2ZXVS+e7zLEHlqFScM7nuIFBWmoqZ8+mcTYtlfT0sxQvYe2LarcFrmmaq4GT7vr9uZGSnESAIzB7O8DuICU5Kcccuz1zjs1mo0jRovx68gQdOnWlcOFbiQgJon6NSgx+6DG8fYpbWv/VSkpKJDCwdPa2wxFIYmJizjmlM+fYbDaKFivGiRMnSEzMuW9Skuu+16tjKUn4BTiyt/38HRxPSc7VvgcPxFOkaDGeur8PvSMbMfrN/7thzuwBjh9NpuR5vZf0t3P86KV7nzfjG+o0aXnevvZc73s9OXPiKEVL+mdvFy3hx28njuaYt2nuJD68pxXLvhxF2wcy38VK++sP1k/7nCZ9H7as3rySnJSEPfDc2mZ3OEi+4HmanJSEI9D1OX7yxAl+//133n9vFE8//5KlNeeF40eTKXXecV7qCo7VamF1qF2vMVH1g4msH0zdxi0oV7Gyu0q9qJv+M9yr9f3WTeTLn4+4nQdYu3UPn380hkMJ+z1dlriJMz2dbZs28NgLr/N19EoSDycQM2OSp8tyi8Vzp7F35/f0GvSIp0uxTESnPjz81VJaDHqKtZM/AWDVNx9St2t/vArd6uHqrDXyzWHc/9AQbrvttstPvokcTthPwr69zF27k5h1u9iyYQ3fb1pvaQ02S+/tIgzDGAwMBrJfjeUV/wA7yYlHsreTkxLxP++V/D9zkpKOEOAIJD09nd/OnMGnuC/RM6bSrEUbChQoQImSpahdtz47vt9KmaDyeVqjO9jtDo4cOXdBTGLiERwOR845hw8TGJjZ95nTp/H19cXhyLmv3e667/WqlL+do8nnXuUfTUmkpH9Arvb1C3BQuUo1AsuUA6BZ6yh+2LYJerql1DxX0i+A4+f1fjwliZJ+OXvfvH4l33z6LmMmxuDlVTB73+/j1rnsW7NOQ7fXnBeK+vpx5nhK9vaZX45SxNfvkvOrNo1kwQevAJC4Zzu71yxi2Rdv8/cfZzCMfNi8ChLRqa+7y75mAXY7SUfOrW1JiYkEXPA8DbDbSTxyGLvj3HO8uK8vWzfFETNnFq++9DynT58iX7583FKwIPfe/5DVbVyxkn4BHDvvOD92ieP8YlYtiaVqzQgKZ33EUL9pK37YtomaEQ3cUuvFePwM1zTNsaZphpumGV48jy9SqVErnAP74zl08ABpaWnEzJ5O6/ZRLnNatYti5pRvAJg/dxYNGjfDMAwcgaVZv2YlAH/+8QfbNsdRoZK1bz9crfCICOLjfybhQGbf06dOITKqk8ucyKhOTJo4AYBZM2fQtHkLDMMgMqoT06dOITU1lYQDB4iP/5mIOnU80cYVC6kexuGEfSQeTuBsWhqLY2bRtFWHXO/725nT/HriFwA2bVhN+UrB7iw3T1WuVosjB/eTfOQgZ9PSWD5/Ng1atHeZ8/OuHbz78pO8+fEklwvCIhq1YNO6Ffx2+hS/nT7FpnUriGjUwuoWroq9cjVOJiXwa8phnGfT2LlqHrfXc639RGJC9s8/x62kuKMsAAPe+ZZHv17Oo18vp26X/jTq9b8bImwBatWOYP++eA4mZD7HZ8+YSrsOrmtbuw5RTJk0EYC5s2fSuGlzDMMgdslKtu2KZ9uueP734KM89tRzN0TYAlSpHsbhg/tIOpx5nC+ZN4vGLdtffkfAzx7I1rh1pKenk372LNvi1hFU4XY3V+zK42e47mSz2Rg2YjR3d++I0+mkR+/+3B4cwjvDX6V6zdq0bh9Fz74DePyBgTQJD8HbuzgffvE1AHcPup+nHhlMqwa1ME2T7r3vpkpoNQ93lDs2m433xnxIx8i2OJ1O+g8YSEhoKMNeGUpY7XCiOnZiwMBBDBzQj9Dgivj4FGfipCkAhISG0q17D2pVD8FmszH6/Y/Inz+/hzvKHZvNxjOvvs3Dd3fFmeGkc/e+VLi9Cp+8+wYh1WrRtHUHdm7fwlP39+XM6VOsWbaAz0YPZ/ri78ifPz+PvfAa9/fphIlJlao1uaNXf0+3lGs2m40hL43g6UHdychw0r5bb8pVCmbc+8OpXLUmDVu055NRL/PXn3/w8mMDAfALCOTNTyZR1NuHux98iv91bwVA/wefoqi3jyfbybV8+W20e3Ao3754L2aGkxptulEqqBIrvx5DQKWqVK7fks1zv2H/tg3kt9m45baidHpyhKfLvmY2m4233hlD9y6RZDid9O43gOCQUIa/9go1w2rTPrIjffoP5MF7BxBRPRhvHx8+H3/jf0Ris9l46uWRDLmnGxlOJ1Hd+1D+9iqMHf0mwVVr0qRVB3bt2MqzD/TjtzOnWLt8IZ+PeYvJCzfQol1ntmxYTZ/IhhgY1GvSMtdhnVcMd/09JMMwJgPNgBLAUeBl0zT/9S+6Va9Z24xdbu176teDUkULeroEj9h15IynS/CI31LTPV2CxyxL+MXTJXjEkEbX/0dR7hCf8runS7DcgC7N2f3DNuNiY247wzVN8y53/W4REZEbjcc/wxUREfkvUOCKiIhYQIErIiJiAQWuiIiIBRS4IiIiFlDgioiIWECBKyIiYgEFroiIiAUUuCIiIhZQ4IqIiFhAgSsiImIBBa6IiIgFFLgiIiIWUOCKiIhYQIErIiJiAQWuiIiIBRS4IiIiFlDgioiIWECBKyIiYgEFroiIiAUUuCIiIhZQ4IqIiFhAgSsiImIBBa6IiIgFFLgiIiIWUOCKiIhYwObpAs6XLx/cUkCvAf4r/j7r9HQJHnHsr789XYLH1PQv4ukSPOLAsT88XYJHlCxa0NMlWM6W37jkmNJNRETEAgpcERERCyhwRURELKDAFRERsYACV0RExAIKXBEREQsocEVERCygwBUREbGAAldERMQCClwRERELKHBFREQsoMAVERGxgAJXRETEAgpcERERCyhwRURELKDAFRERsYACV0RExAIKXBEREQsocEVERCygwBUREbGAAldERMQCClwRERELKHBFREQsoMAVERGxgAJXRETEAgpcERERC9z0gbt8ySIahIVSt0YV3n93ZI7x1NRU7hvQm7o1qtCueUMOHUwA4NDBBMqWKkqLhuG0aBjO0489ZHHl12bxooVUD61MaHBFRo18K8d4amoqfXv3JDS4Io0b1OVgQkL22KgRwwkNrkj10MosWbzIwqqv3cbVS+nVtg49WtVm4mejc4x/v2k993RpRpMqJVmxMNpl7ONRr9A3sgF9IxuwdN4sq0rOM9+vW8GQLo15pFND5oz7MMd47MTPeLxrM57q0Yph/+vB8aQj2WM9a5fm6Z6tebpna0YMGWBh1ddu27oVPNK5EQ91bMCscR/kGJ878TOGdG3K491b8srgHhw7r2+AP3//jfva1Obz4S9YVXKeWL9qKd1ahnNH81qM/+S9HONb49bRt2MT6lXyZdn8c8f65g2r6R3ZKPtPw2A/Vi6OtbL0a7Jq+WJa1a9B8zpV+fT9t3OMx21YS6eW9bk9oAgLYma7jM2c8g0t6lajRd1qzJzyjVUlZ7O56xcbhlEa+BrwA0xgrGmaY9x1fxfjdDp57skhTIuej90RSNtm9WnbIYrKwSHZc779+iu8vX34bvtuZs+Yymsvv8Dn478FoGy58ixft9nKkvOE0+nksUcfYt6CJTgCA2lUL4KoqE5UCTnX9/hxX+Lj7cPOPfFMmzqFF194lm++ncruXbuYPnUKW7fvJDkpiQ7tWvHDrp/Inz+/BzvKHafTyTuvPsPor2ZRyt/Ovd1a0qhlO8pVDM6e4xcQyItvfcTkL10Daf2KxezduZ3x0as5m5bKw307Ub9pK269rajVbVyVDKeTL996kf/7ZDK+fgE836cD4U3bEFjh9uw5QcFVeWvSAgoWKsTiaRP4ZszrPD7iUwC8Ct7CqKlLPFX+VXM6nXw+/AWGfjoFX78Anu3TgYimbSl9Xt/lgqsyctICChYqzMJpE5g4+jWeHPlZ9vjkj0YSElbXE+VfNafTyciXn+LDr+fg52+nf5fmNGnVnvKVzh3r/vZAXh75Md984foiJLx+E76dtxaA06d+pWvzWtRr3MLS+q+W0+nklWcfZ8L0WPztDu5o05iWbSOpVLlK9hy7ozQj3x/L5x+7xs2pX0/ywdtvMmfJWgzDoHOrhrRqF0kxbx/L6nfnGW468KRpmiFAPeAhwzBCLrNPntq6eRPlylcgqFx5vLy86NKtBwvnxbjMWTgvhh539QOgY5durF25AtM0rSwzz22Ki6NChYqUK5/Zd/eevYiNcT2bi42Jpk+//gB07XYnK5cvwzRNYmOi6d6zFwULFiSoXDkqVKjIprg4T7RxxXbv2EJg2XI4ygRRwMuLlpFdWbN0gcucgMAyVAwOxcjneugf2LeHmhENsNlsFCp8KxWDQ9i4epmV5V+T+B+34V86CL/AstgKeNGgbWc2rXR9d6JqREMKFioEQKXqtTl5NNkTpeapf/r2DyxLgf5R/y4AACAASURBVAJeNLpI39UiGlKwUGEAbq8exonz+t63awenTx6nRv2mltZ9rXZu30LpsuUJzDrWW0d1Y9WS+S5z7IFlqVSlao5j/XzLFkRTv2lrbsn6/3O92751M2XLVaBMUDm8vLyIuuNOli50PTsPLFOW4NBq5Lug79UrltKwaQu8fYpTzNuHhk1bsGq5tS8y3Ra4pmkmm6a5Nevn34DdgMNd93cxKcmJ2AMDs7ftdgcpSUkuc5KTE3FkzbHZbBQpWoyTJ08AmW8rt2wUQZf2Ldm4fq11hV+jpKREAgNLZ287HIEkJibmnFM6c47NZqNosWKcOHGCxMSc+yYlue57vTp+NJlS/ucOsVL+do7nMlQqBlfluzXL+PuvPzl18gRbN67lWPKN0TfAyWMp+PrZs7d9/QI4eTzlkvOXz5lMzYbNs7fPpqXyXO/2vHh3FHErFrq11rx08lgKJfzP9V3cL4ATxy79mC+bPZmwRplncxkZGUx451X6PzHU7XXmteMpyfgFnDvW/QJyf6yfb0nsTNp27JaXpbnV0ZQkAhzn+vYPcHA0Oelf9jhv3+QkAhzn8sDfnvt984rb3lI+n2EYQUAt4LuLjA0GBgMEli5jRTm54ucfwNad+yju68v2bVsZ0PtOVn/3PUWK3hhvMcqVqduoBXt+2Mb/erbDu7gvobUiyHcDvI1+NVbPm8n+Xdt55YuZ2bd9PP87ipcK4OiRgwwb3IMyFYPxLx3kuSLdYNW8mezbtYPXvszse+G08YQ1auHyQuW/5JdjKcTv3UX9Ji09Xcp/htsvmjIM4zZgJvCYaZpnLhw3TXOsaZrhpmmG+5Yokaf37R/gIOnIuQskkpIS8be7PrkCAhwkZs1JT0/ntzOnKV7cl4IFC1Lc1xeAGrXCCCpXnn3xP+dpfe5itzs4cuRw9nZi4hEcDkfOOYcz56Snp3Pm9Gl8fX1xOHLua7db+sbEVSvpF8CxlHNnpcdSkijpF5Dr/fs/8CQT5q5mzPjZYJqUDqrojjLdongpf04cPfdq/cTRZIqX9M8xb8fG1cz+8n2eGT2eAl4Fz9s/8/+TX2BZQsLrk7DnR/cXnQeKl/Lnl5RzfZ88moxvqZyP+faNq5n5xRieH3Ou75+2b2HB1K+4v30dvn5vGKtiZzBxzBuW1X4tSvoHcPS8d2COJl/ZsQ6wZN5smrWJwlagQF6X5zZ+/naSz3u3LiU5Eb+A3L1g8guwk5x4Lg9SknK/b15xa+AahlGAzLCdZJqm5Zd91qodzv798RxMOEBaWhpzZk6jbYcolzltO0QxbfJEAGLmzKRR02YYhsEvvxzH6XQCkHBgP/v3xVM2qJzVLVyV8IgI4uN/JuFAZt/Tp04hMqqTy5zIqE5MmjgBgFkzZ9C0eQsMwyAyqhPTp04hNTWVhAMHiI//mYg6dTzRxhULrhbGkYT9JB0+yNm0NJbNm0Wjlu1yta/T6eT0rycBiN+zk/i9O6nTqPll9rp+VAitSfKhAxxLPET62TTWL4omvFkblzkH9vzI5288xzPvfUWx4ude3P5+5hRn01IBOPPrSfZ+v4nA8rdzI6iY1ffRxEOcPZvG2kXRhDd17Xv/nh/47PVneW70eJe+Hxv+EZ8t3MynC+K4+/GhNI26k35DXrS6hasSUj2MQwn7SDycwNm0NJbEzqRJq/ZX9DsWx9xYbycDVK9Vm4T98Rw+mEBaWhqxs2fQsm1krvZt0rwVa1ct4/SpXzl96lfWrlpGk+at3FyxK3depWwAXwK7TdN81133829sNhvDR42m1x2ROJ0Z3NWvP8FVQhnx+ivUCKtNuw4d6X33PTw8eAB1a1TB28eHz77KvFR847o1jHzjVWwFCpAvXz5Gjv4Qn+LFPdHGFbPZbLw35kM6RrbF6XTSf8BAQkJDGfbKUMJqhxPVsRMDBg5i4IB+hAZXxMenOBMnTQEgJDSUbt17UKt6CDabjdHvf3RDXKEMmX0/PnQkTwy6E6fTSdSdfShfqQqfj3mT4Kq1aNyyPbt3bOX5h/rx25nTrFuxkC/ef4tJ8zeQnn6WB3t3AKDwbUUYOuozbDZLPnHJE/ltNgY++zpvPNibjIwMmnfuSekKlZn68SgqhNQgvFkbvnnvNf7+8w/efeZ/AJTwd/DsmPEk7v+ZsW88Rz7DIMM06XLPwy5XN1/P8tts3PvcG7z2QG8yMpy06NyLMhUrM/njkVQMqUFEs7Z8ndX3O08PBqBEgIPnx0zwcOXXxmaz8cwro3i0fzecGU46de9Lhdur8Ol7b1ClWi2aturAzu1beeaBvpw5fYq1yxby2ZjhTFu0EYCkIwc5mpxIWN1GHu7kythsNl5+610G9OxEhtPJnb3v5vbgEN57axjVaobRql0UO7Zt5oEBvTh9+hTLF89nzMjXWbhmC94+xXn4iefo0qYxAI88+TzePtau6Ya7rsg1DKMRsAb4AcjIuvkF0zTnX2qfmmG1zcWrNrqlnutZ0UI3zls6eWnrgV89XYJHJP7xl6dL8Jj8huHpEjyiTNEb4yrgvFb8Ni9Pl2C5zq0b8sP3Wy96oLvtJbxpmmuB/+azS0RE5AI3/TdNiYiIXA8UuCIiIhZQ4IqIiFhAgSsiImIBBa6IiIgFFLgiIiIWUOCKiIhYQIErIiJiAQWuiIiIBRS4IiIiFlDgioiIWECBKyIiYgEFroiIiAUUuCIiIhZQ4IqIiFhAgSsiImIBBa6IiIgFFLgiIiIWUOCKiIhYQIErIiJiAQWuiIiIBRS4IiIiFlDgioiIWECBKyIiYgEFroiIiAVsni7gfPkMg0IF8nu6DLFIBb/bPF2CR7Rs+pKnS/CYbfNHeLoEj/D3vsXTJXiG6ekCrGfLd+nzWJ3hioiIWECBKyIiYgEFroiIiAUUuCIiIhZQ4IqIiFhAgSsiImIBBa6IiIgFFLgiIiIWUOCKiIhY4JLfNGUYxm+c+54QI+u/ZtbPpmmaRd1cm4iIyE3jkoFrmmYRKwsRERG5meXqLWXDMBoZhnFP1s8lDMMo596yREREbi6XDVzDMF4GngWez7rJC/jGnUWJiIjcbHJzhnsH0An4A8A0zSRAbzeLiIhcgdwEbpppmiZZF1AZhnGre0sSERG5+eQmcKcZhvEZ4G0Yxn3AUuBz95YlIiJyc7nsP0BvmubbhmG0Bs4AtwNDTdNc4vbKREREbiKXDdwsPwCFyHxb+Qf3lSMiInJzys1VyvcCcUBX4E5go2EYA91dmIiIyM0kN2e4TwO1TNM8AWAYhi+wHhjnzsJERERuJrm5aOoE8Nt5279l3SYiIiK59G/fpfxE1o/xwHeGYUST+RluZ2CHBbWJiIjcNP7tLeV/vtxiX9aff0S7rxwREZGb07/94wWvWlmIiIjIzeyyF00ZhlESeAYIBW7553bTNFu4sS4REZGbSm4umpoE7AHKAa8CCcAmN9YkIiJy08lN4PqapvklcNY0zVWmaQ4Ebpiz2yWLFxJWvQo1Qm/n3VEjcoynpqYyoG8vaoTeTvPG9Tl4MAGA5cuW0KRBBPXCa9CkQQSrVi63uPJrs3jRQqqHViY0uCKjRr6VYzw1NZW+vXsSGlyRxg3qcjAhIXts1IjhhAZXpHpoZZYsXmRh1ddu+dJFNKwdSr2aVfjg3ZE5xlNTUxk8oDf1alahfYuGHMp6vAF2/biDyFaNaVK3Bs3q1+Lvv/+2sPJr17pBFbbPfokfo1/mqXta5xgf+WRXNk55jo1TnmPHnKEkrz73/+f3ze9nj00f/T8ry75ma1YsoX2jWrRtUJ3PP3gnx/imjWvp2qYhVUsXY1Hs7Ozbd/+4g14dWxDVLJzOLesyP3qGlWVfs6WLFxJRI4SwqpV57+2Lr20D+91FWNXKtGpSP/tY37IpjsZ1a9O4bm0a1Q0jNnqOxZVfm6WLFxJRM4Swav/S9913EVatMq2antf35jga16tN43pZfc+1vu/c/D3cs1n/TTYMIxJIAopfbifDMG4BVgMFs+5nhmmaL19toVfD6XTy5GOPED1vEQ5HIM0a1aVDVEeCq4Rkz/l6/Di8fXzYvvMnZkybwssvPsf4b6bg61uCqTOiCbDb2bXzR+7o2J69+w9bWf5VczqdPPboQ8xbsARHYCCN6kUQFdWJKiHn+h4/7kt8vH3YuSeeaVOn8OILz/LNt1PZvWsX06dOYev2nSQnJdGhXSt+2PUT+fPn92BHueN0Onn+ySFMmzOfAEcg7ZrXp02HKCoHn+v726+/wtvbh43f72bOjKm8/vILjB3/Lenp6Tw0eAAffvYVodVqcPLkCQoUKODBbq5MvnwGo5/rQeQDH5J49BRrJz1N7Kof2LM/JXvOM+/Myv75gV5NqVE5MHv7r9Sz1OuV84XZ9c7pdPLaC0/w5ZS5+AU46NGhCc3bdqDi7VWy59gdpRk++jPGfTrGZd9bChXirTFjCSpfkWMpyXRr14hGzVpRtJi31W1cMafTydOPP8rs2IXYHYG0aFyP9pGua9vE8eMo5u3D1h/3MnP6VF75v+cZN3EyVUKrsmLdd9hsNlKSk2lcL4x2kVHYbLn94kHPcTqdPP3Eo8yO+Ze+J2T1/UNW3y89z7ivJ1MlpCor1l7Qdwdr+87NGe7rhmEUA54EngK+AB7PxX6pQAvTNGsANYF2hmHUu+pKr8LmTXGUr1CBcuXK4+XlRbfuPZkXO9dlzrzYaO7qczcAXbreycqVyzFNkxo1axFgtwNQJSSUv/7+i9TUVCvLv2qb4uKoUKEi5cpn9t29Zy9iY1wvLo+NiaZPv/4AdO12JyuXL8M0TWJjounesxcFCxYkqFw5KlSoyKa4OE+0ccW2bdlEufIVKJv1eHfp2oNF82Jc5iyaH0OP3v0AiOrSjbWrVmCaJiuXLyEktBqh1WoAULy47w3xIuMfEVWD2Hf4FxIST3A23cn0RVuJalb9kvN7tKvNtIVbLKzQPXZs20yZoPKULlsOLy8vOnS+k+WL5rnMcZQuS+WQquTL57rclatQiaDyFQEo5R+Ab4mSnDzxi2W1X4stmzPXtqCsY73rnT2Yf8HatmDeXO7qm3msd76jG6uy1rbChQtnh0xq6t8YhmF5/Vdry+Y4ype/TN+xc7mrz/XZ92UD1zTNWNM0T5um+aNpms1N06xtmubcXOxnmqb5e9Zmgaw/5jXWe0WSkxIJDCydvW13OEhKTLxgTlL2HJvNRtGixTh5wvV7PaJnz6RmzTAKFizo/qLzQNIFfTscgSRe0HdSUiKBpc/ru1gxTpw4QWJizn2Tklz3vV4lJyVid5w7awtwOEhOTnKdk3xujs1mo0jRYpw8eYL98T9jGAa97oikdeM6fDj6bUtrv1b2UsU4cvTX7O3Eo7/iKFnsonPLBPhQ1u7Lyk17s2+7xcvG2knPsGrCk3T8l6C+3hxLScLffu4x9wtwcPSCxzw3dmzbzNm0NMoElc/L8twmOSkJh+P8tS2Q5CTXvpPOm3Ph2rY57jvq165Ow4iavDvm4xvi7Bay+g68oO/ki/R9iTV986bvqB9enYZ1avLu+9b3/W9ffPEB/xKQpmk+erlfbhhGfmALUBH4yDTN7y4yZzAwGKB06TK5KNlau3ftZOj/Pc+c2IWeLkXcKD09ne82rGfhyvUUKlSY7p3aUqNmGI2b3TCXK+Ra97a1mbPsezIyzj29K3cYStLx0wQ5fFk49lF+jE/iwJEb42zvWh07msKzj9zH8DGf5TgLvlmF16nLhi072LtnNw/edw+t2rbjlltuufyON7jwiLps2JzV9+B7aNXG2r7/7ejaTGZYXurPZZmm6TRNsyYQCNQxDKPqReaMNU0z3DTN8BIlS15p/f8qwO7gyJFzn7smJSZidzgumGPPnpOens6ZM6cp7usLQOKRI/Tu2Y2xX4ynfPkKeVqbO9kv6Dsx8QiOC/q22x0cOXxe36dP4+vri8ORc1+73XXf61WA3UFS4pHs7eTERAIC7K5zAs7NSU9P57czpyle3Be73UG9ho3w9S1B4cKFadmmHTu2b7O0/muRdOw0gX4+2dsOPx8Sj5++6Nw729Zm2sLNrvtnzU1IPMHqzT9TMzjwYrted0r520lJOveYH01OxO+Cx/zf/P7bGe7v143HnhtKzdp13FGiWwTY7SQmnr+2Hcn+COwf9vPmXLi2/aNycBVuve02du/80f1F54EAu53EIxf0HXCRvi+xpv+jcnAVbr31NnbvsrbvSwauaZoT/u3PldyJaZqngBVAu2st+ErUDo9gf3w8CQkHSEtLY+b0qXSI7Ogyp0NkJyZP+hqAObNm0LRpcwzD4NSpU3Tv2pFXX3uTeg0aWln2NQuPiCA+/mcSDmT2PX3qFCKjOrnMiYzqxKSJmQ/jrJkzaNq8BYZhEBnVielTp5CamkrCgQPEx/9MRJ0bYyGqGRbO/n3xHMx6vOfMmkabDlEuc9p0iGLatxMBiJ0zk4ZNmmEYBs1atmHPzh/5888/SU9PZ8PaNdweXOVid3Nd2rzzIBXLlKSs3ZcCtvx0bxvGvJU5v4H19iA/fIoWZuP2A9m3eRcphFeBzDe7fL1vpX7N8uw+72Kr61m1mrU5eGAfRw4lkJaWxvzoGTRv0yFX+6alpfHIoLvo3L03baPucHOleSusdgT74s8d67NmTKP9BWtbuw4dmfxN5rEePXsmTbLWtoMJB0hPTwfg0KGD/Lx3L2XKBlndwlUJqx3Bvn2X6TuyI5Mn5aLvn/ZSpkyQpfW77Q3srC/MOGua5inDMAoBrYGc13C7kc1mY9R773NHx/Y4nU769b+HKiGhvD7sZcLCatMhqhN3DxjI4IF3UyP0dnx8ivPVxG8BGPvpR+zfF8+I4a8zYvjrAMyJWUjJUqWsbOGq2Gw23hvzIR0j2+J0Ouk/YCAhoaEMe2UoYbXDierYiQEDBzFwQD9Cgyvi41OciZOmABASGkq37j2oVT0Em83G6Pc/umEuHrLZbLz59mju6hqJ05nBXX37E1wllBFvvELNWrVp26Ejvfvdw8ODB1CvZhW8fXz4bNw3AHj7+PC/h4fQrnl9DMOgZet2tG6bu4X7euB0ZvD4iGnEfPwQ+fMZTIjeyO79Kbz0QCRbdx1i3qrMf8a6e9vaTF/k+gZVcHl/PnjxLjLMDPIZ+Xj7qyUuVzdfz2w2G//3xjvc27sLGU4nXXv1o1LlEN4f+RpVa4TRom0kP3y/hUcG3cWZU6dYsWQBH7z9BrErN7MwZhabN67j1MmTzJmaeRy8OfozqlS9/j/DttlsjHx3DN06dcDpdNLn7gFUCQnlzWEvUzMsnA5RHek3YCD3D+pPWNXK+Pj48OXXmWvbhvXrGPPOSGy2AuTLl4+3R3+Ib4kSHu4od2w2GyPfGUO3zhf0/VpW35Ed6dd/IPff25+wall9Tziv73c927dhmu65jskwjOrABCA/mWfS00zTHPZv+4TVDjdXrbsxrojNSwVs/43PjS50+s+zl590EwpqmpuL/G9O2+Zb+pr7uuHvffN/PnpRll4me31o3qgu27Zuvugl0G47wzVNcwdQy12/X0RE5EZy2VMrwzBuNwxjmWEYP2ZtVzcM4//cX5qIiMjNIzfvZX4OPE/WN05lnbn2cmdRIiIiN5vcBG5h0zQv/GA13R3FiIiI3KxyE7i/GIZRgayPvw3DuBNIdmtVIiIiN5ncXDT1EDAWCDYMIxE4APR1a1UiIiI3mcsGrmma+4FWhmHcCuQzTfM395clIiJyc7ls4BqGMfSCbQAu93dqRURE5JzcvKX8x3k/3wJEAbvdU46IiMjNKTdvKb9z/rZhGG8Di9xWkYiIyE3oar5TsDCZ//qPiIiI5FJuPsP9gXPfiJkfKAno81sREZErkJvPcM//983SgaOmaeqLL0RERK7AvwauYRj5gUWmaQZbVI+IiMhN6V8/wzVN0wnsNQyjjEX1iIiI3JRy85ayD7DTMIw4zvsrQqZpdnJbVSIiIjeZ3ATuS26vQkRE5CaXm8DtYJrms+ffYBjGCGCVe0oSERG5+eTm7+G2vsht7fO6EBERkZvZJc9wDcN4AHgQKG8Yxo7zhooA69xdmIiIyM3k395S/hZYAAwHnjvv9t9M0zzp1qpERERuMpcMXNM0TwOngbusK0dEROTmdDXfpSwiIiJXSIErIiJiAQWuiIiIBRS4IiIiFsjNF19YJsM0+fus09NlWK6A7b/5uuevtP/eYw3w3sdPeboEj3ljWbynS/CI0V1CPV2CRxw7k+rpEix31plxybH/5kovIiJiMQWuiIiIBRS4IiIiFlDgioiIWECBKyIiYgEFroiIiAUUuCIiIhZQ4IqIiFhAgSsiImIBBa6IiIgFFLgiIiIWUOCKiIhYQIErIiJiAQWuiIiIBRS4IiIiFlDgioiIWECBKyIiYgEFroiIiAUUuCIiIhZQ4IqIiFhAgSsiImIBBa6IiIgFFLgiIiIWUOCKiIhYQIErIiJiAQWuiIiIBW76wF2+ZBH1w0KpU6MK7787Msd4amoq9w3oTZ0aVWjXvCGHDiYAcOhgAmVKFaV5w3CaNwznqccesrjya7N40UKqh1YmNLgio0a+lWM8NTWVvr17EhpckcYN6nIwISF7bNSI4YQGV6R6aGWWLF5kYdXXbtWyxbSoV51mEaF8MmZUjvHU1FQevrcvzSJC6dK2MUcOHQQgLS2Npx8ZTLsm4bRvVoeN61ZbXfo127lxFS/3asHQ7s1Y9PUnOcaXTv6CV3u35vV+7Rj9SB9OJB/JHpv90VsM69OWYX3asnlprJVlX7OkHeuIfrozc57syI8x4y4579CmpXzTryYn9u8EIPW3Uyx5816m3FufuAnDrSo3zyxbsoi6tUKJqBHMmHcuvrYN6t+biBrBtGneIHtt+8eRw4co6+/Nh2PetajivLFmxRI6NK5F24bV+fzDd3KMb964lm5tG1KtTDEWxc7Ovn33jzu4q2MLOjYPp0uruiyInmFl2YAFgWsYRn7DMLYZhmH5s9jpdPLsk0OYPDOGtZu2M2vGVPbu2eUyZ9LXX1HM24e47bv530OP8trLL2SPBZUrz4p1m1mxbjNvj/7I6vKvmtPp5LFHHyI6ZgHbduxi+pTJ7N7l2vf4cV/i4+3Dzj3xPDLkcV584VkAdu/axfSpU9i6fSdzYxcy5JEHcTqdnmjjijmdToY+9xjjp0SzeN025s6ezs97d7vMmTZpPMW8fVi5aSeD7n+Et4a9CMCUiZkL9cLVm5k4PZY3hj5HRkaG1S1ctQynkylvD+Xhd8Yz9NvFbFo6l+QDP7vMKX17KM+Pm8v/TVxIrebtmf1x5guxH9Yt59BPP/LihHk8+8Vsln77OX/98Zsn2rhiGRlO4iYMp8XTH9FxxCwSNizkVOK+HPPO/vUHexZ9S4kK1bJvy1+gIDW6PUTYXU9YWXKeyFzbHmXqrBjWbdrBrBlTLrK2jcPb25tN2/dw/0NDeHXoCy7jLz3/NC1bt7Oy7GvmdDp5/cUn+OybWcSs2Mz8OdOJ/8n1OR7gKM2b731GZJceLrcXKlSI4WPGErNiM2O/mcPwV57lzOlTVpZvyRnuEGD3ZWe5wdbNmyhXvgJB5crj5eXFHd16sHBejMuchfNi6HlXPwA6dunGmpUrME3TE+XmmU1xcVSoUJFy5TP77t6zF7Ex0S5zYmOi6dOvPwBdu93JyuXLME2T2JhouvfsRcGCBQkqV44KFSqyKS7OE21cse1bN1E2qAJlgsrh5eVFxy7dWbLA9XXekgWxdOvZB4D2Hbuyfs1KTNPk5717qN+4GQAlSpaiaLFi7Ph+i9UtXLWEXdspGViWko4y2Ap4Ed6qI9vXLHGZU7l2fbxuKQRA+dBa/HosBYDkhJ+pVLMO+W02ChYqjKNiMLs2rrK8h6txYt+PFPErTZFSgeS3FSCoXluObFmZY972mR8REjWAfAW8sm+z3VKIUpVrkf+8224UWzfHXbC29WRBrOvatmBeDL16Z65tnbp0Y83K5dlr2/yYaMqUDaJylRDLa78WP2zbTJmg8pQum/kcb9/5TpYvmucyx1G6LJVDqpIvn2u8BVWoRFD5igCU8g/A17ckJ0/8Ylnt4ObANQwjEIgEvnDn/VxKSnIijsDA7O0Au4PkpKRLzrHZbBQpWoyTJ08AmW8rt2gUQef2Ldm4fq11hV+jpKREAgNLZ287HIEkJibmnFM6c47NZqNosWKcOHGCxMSc+yYlue57vUpJTiLAce7x9rc7SEl2rf1oyrk5mY93UX49eYIqVauxdGEs6enpHD6YwA/bt5GceIQbxanjKfj4BWRv+5T059TxlEvOXxc7ldB6TQEIrFiFnRtXk/b3X/x+6iR7t27g16PJbq85L/z56zEKF/fP3i5c3I8/fz3mMudEwm7+OHGUwJpNrC7PbZKTk7Cfd6zbHQ6SLzjWk5OScAS6PsdPnjjB77//zvvvjeLp51+ytOa8cDQlCX/7ec/xAAfHUpL+ZY+L27FtM2fPplEmqHxelndZNjf//tHAM0CRS00wDGMwMBggsHQZN5eTe37+AWzduY/ivr5s37aV/r3vZM1331OkaFFPlyZu0KN3f/b9tIdOrRriKF2G2hH1yJ8/v6fLcovvFs7m4J4feOKjKQCE1G3Cwd07GPW/btzmXZzyVcMwbpLezYwMtkx6mwaDh3m6lOvGyDeHcf/DQ7jttts8XYpHHD+awnOP3sfw0Z/lOAt2N7cFrmEYUcAx0zS3GIbR7FLzTNMcC4wFqBlWO0/fy/UPcJB45NxZSnJSIgF2+0Xn2B2BpKen89uZ0xQv7othGBQsWBCAGrXCCCpXnn3xP1MzrHZelugWdruDI0cOZ28nJh7B4XDknHP4MIGBmX2fOX0aX19fHI6c+9rtrvter/wD7C5npSlJ/9/efYdHUa5vHP++ZAmIAkmQkoJ0SaEEEjhIkY5AQpEqVYTfsaGCx4oVPSoKKKDYb9QYmQAAIABJREFUsR1A6S0oCIpYUKkCUiVAgBSKVAFNyOb9/ZE1JASPHMjOUu7PdXGRybyz8zyZzdw7s5OdFMoF5629bLnsMcEhf27vYwR6tveTz52+yKpr+2ZUqlLNsdovVEDpcnmOSg8f2EtA6XL5xm1e+R0LP3qd+1+fQmH/IjnfbzfgHtoNuAeA954eQtnylbxfdAEoFliGk4dOH8mfPLSPYoFlcqZP/XGCo8nbWfzC/wHw+9GDLB0zlGb3j6VU5SjH6y0owcEhpOZ6rqempBB8xnM9OCSElOQ9Ofu2Y0ePElSqFGtWrSBh7iyeeXIYR48eoVChQhQtWoT/u+PivzC0bLkQ9qbm+h1PS6FMuZD/skRex387xp39uzLkkaeoHVPfGyX+V96M90ZAR2NMEjAFaGGMmeTF9eVTJyaWHTsS2ZW0k4yMDGbPnMZN7ePzjLmpfTxTP5kIQMKcmTRu2gxjDL/+eiDnYqGknTvYsT2RChUvjZ1QbL16JCZuI2lndt/Tp04hLr5jnjFx8R2ZPPEjAGbNnEHT5i0wxhAX35HpU6eQnp5O0s6dJCZuo15955+Y56NWnViSdiayZ1cSGRkZJMyZTqu2cXnGtGobx8ypkwFYkDCLGxo3xRjD7ydPcvLECQC+Xfolfn4uqlWPcLyH81Uhohb7k5P4NXUPmacyWPVFArUat8ozZs/WjXz80uPcNfJdSgRdm/P9LLeb40cPA5CcuJmUxC1E1G/iaP3nq1TlKH7bu5vj+1NwZ54i6cfPCavbNGe+f7HidH9zKTePWcDNYxZwbZWal3zYAtSJqceO7bn3bVNpG5d339a2fTxTPs7et82bM5MmTZtjjGH+oqX8tDGRnzYmcsfd9zH0gUcvibAFqBEdw66d20nenf07vmDuDJq3aX9Oy2ZkZHDvoF506tabm+Jv9nKlZ+e1I1xr7TBgGIDnCPdBa21fb63vbFwuFy+OGkvPm+Nwu7Po3e9WwiOiePG54UTXjaFt+w706X8bg28fQP3aEQQGBvL2B9mvCX5Y9i0jn38GV+HCFCpUiFFjxxMYFORk+efN5XIxZtx4OsTdhNvt5tYBA4mMiuLZ4U9RNyaW+A4dGTBwEAMH9CMqvCqBgUFMnOw5vRgVRdfuPahTKxKXy8XYV1+/ZE6tulwunhkxhv49OpCV5aZ7r1u5PjySV158lprRdWndNp6efQZw/90DaVYvipKBgbz2TvYO6eCvB+jfowOFChWiXHAIr7zxno+7+d/4uVzc8q9neO3+/mS5s2gY352QyteT8O4rXBdek9pNWjPz9RGk/36Cd5/I3rkGlg3h7pETcGdm8vJd2Vd0Fr36Gm57egx+Lm+/21QwCvm5qNf/Ub4cdRc2K4sqN3YiIKwq62a+QVClSMrXbfZfl599fztO/X6CrMxTJK/+ihaPvElAaBVnir8ALpeLF0ePo3vnOLKy3PTuN4DwiChGPDec6DoxtIvrQJ/+A7n7nwOoVzucgMBA3v1gsq/LvmAul4vHn3uZf/buTFaWm5t79qNa9UheG/VvomrXpUWbOH5eu5r7BvXi2NEjfLV4AeNffp6Er1axMGEWq5cv48jhQ8yelr2ff2HM20TUqOVY/caJK3JzBW78fxsXXTfGLv76R6/Xc7EpflVhX5fgE3uP/OHrEnxi4ba/vpjpcrds+1Ffl+ATYztf2kfU52v/sXRfl+C47u2asGHdGnO2eY68jLXWLgWWOrEuERGRi9Fl/0lTIiIiFwMFroiIiAMUuCIiIg5Q4IqIiDhAgSsiIuIABa6IiIgDFLgiIiIOUOCKiIg4QIErIiLiAAWuiIiIAxS4IiIiDlDgioiIOECBKyIi4gAFroiIiAMUuCIiIg5Q4IqIiDhAgSsiIuIABa6IiIgDFLgiIiIOUOCKiIg4QIErIiLiAAWuiIiIAxS4IiIiDlDgioiIOECBKyIi4gAFroiIiANcvi4gN4PB36XXAFeKQ8czfF2CT/wjJMjXJfhMy8plfF2CT8SNX+brEnxi7t0NfV2C4/wKmb+cp3QTERFxgAJXRETEAQpcERERByhwRUREHKDAFRERcYACV0RExAEKXBEREQcocEVERBygwBUREXGAAldERMQBClwREREHKHBFREQcoMAVERFxgAJXRETEAQpcERERByhwRUREHKDAFRERcYACV0RExAEKXBEREQcocEVERBygwBUREXGAAldERMQBClwREREHKHBFREQcoMAVERFxwGUfuF8sWkhs7Ujq1KjOmNEv5Zufnp7Obf16UadGdVreeAO7diUB8NWXi2nasD4N60XTtGF9vl66xOHKL8yizxdSK6o6UeFVGTXyxXzz09PT6du7J1HhVWnS8B/sSkrKmTfqpRFEhVelVlR1Fi/63MGqL9z3X39BlxYxdGoWzQdvvpJv/prly+gd34T6VYP44rM5eealpezh7n6d6dqqHt1a1yc1eZdTZReIZUu/4OYWMXRsGs0Hb+TvffXyZfSOa0K9Kvl7j60cyC3tGnNLu8YM/b9bnCq5QHyzZBE3NYqmVYOavP3a6HzzV/7wHZ1bNyQitAQLE2bnmTeoVydirg/h9r5dnSq3wBzZupx1L/dj7ajepC6dnG/+gdULWP1cJ35+dRA/vzqI/Svn55q3kLWj+7B2dB8OrF7oZNkXbMkXn9MoJooG0RG89srIfPPT09O5fUBvGkRH0K5FI3Z79um7dyVRsWwJWjaOpWXjWB4eOtjhysHlzQc3xiQBvwFuINNaG+vN9Z3J7Xbz4P33MWf+QkJCw2jepAHt4joQHhGZM2bih+8TEBDITxu2MnP6VIY/MYwPJn5CUKlrmTJjDsEhIWzauIGuHduzeftuJ8s/b263m6H3DebTBYsJDQujcYN6xMd3JCLydN8fvv8egQGBbNySyLSpU3j8sUeY9PFUNm/axPSpU1izbiNpqam0b9uKnzf9gp+fnw87Ojdut5sXn3qANybOoWy5UPp1ak7TVu2pXC08Z0y50DCeGfUmE999Ld/yTz9wJwMHP0CDJi04eeI4ptCl83rU7Xbz0lMP8Mak7N77dmxO09Z5ew8OCWP46LP3XqToVUxZ8J2TJRcIt9vNM8P+xQfTEigXHErXtk1o2SaOqtUjcsYEh5bnxXFv894b4/ItP+juofzx++9M+c97TpZ9wWyWm6R54wgfNBr/EqXZ+PqdBEQ0oljZinnGlarZnIqdhub5XubJY6R8+RE17nkbjGHDa7cTGNkI11XFHezg/LjdboY9MIRpcz4jODSMts1voE37eKqHn963ffyfDwgICOTHtZuZM2Mqzz39GO98+DEAFSpV5svvVvmqfEeOcJtba6OdDluA1atWULlKFSpWqoy/vz9du/Xgs/nz8oz57NN59OrbD4BON3fl66VLsNZSO7oOwSEhAERERvH7H7+Tnp7udAvnZeWKFVSpUpVKlbP77t7zFuYnzM0zZn7CXPr0uxWALl27sXTJl1hrmZ8wl+49b6FIkSJUrFSJKlWqsnLFCl+08T/buG415StUJuy6ShT296dNhy4sXfxpnjEhYRWoFlEjX5ju2LaFTHcmDZq0AKDY1ddw1VXFHKv9Qm1Yu5qwXL3f1KELSxed0Xv5ClwfUYNC5tJ5IfF31v+0igqVKnNdhUr4+/sT17kbX3w+P8+YsOsqEB5Zk0JneQHVsElzrr76GqfKLTDH92yhaKlQigaFUMhVmKDaLTi8edk5LXvkl5WUrBaLq1gJXFcVp2S1WI5svTR+x39avZJKlatQwbNP79ylB59/mpBnzOefJdCjd/Y+Pb5zV777+iustb4oN5/L5zfvLNJSUwkNLZ8zHRIaRlpq6l+OcblclChRkkMHD+YZM2/OLGpH16FIkSLeL7oApKamEBZ2uu/Q0DBSUlLyjymfq++SJTl48CApKfmXTU3Nu+zFav/eVMoGh+ZMly0XyoG9aee07K6diRQvUZIH7+xD77jGjH3hCdxut7dKLXAH9qVSLuR072WCQ9m/79x6B8hI/4M+HZrSv3NLvjojsC5m+9JSKRcSljNdLjiUfWnn3velKuPYAfxLls6Z9i9RmlNHD+Qbd2jjN6wfN5BfJj9F+pH9AJw627LH8i97MUpLTSEk9PT2Dg4NJS3tjH162ukxLpeL4iVKcuhQ9j59964kWjWuR+f2Lfnxe+fP6Hj1lDJggUXGGAu8ba19x8vrK3CbN23k6SeGMTthga9LES9yZ2by08of+Hj+N5QLKc+weweQMGMynXv293Vpjvh02QbKlAshefdO7ujVkarhkZSvUNnXZckFCAhvSKnaLSnk8mff8nnsmD6CiH+O8XVZPlO2XDCrN24nKKgU635aw219uvH1j2spXqKEYzV4+wi3sbW2LtAOGGyMufHMAcaY240xq4wxqw7+WrCvsoJDQkhJ2ZMznZqSnHOa+GxjMjMzOXbsKEGlSgGQkpxM31u68daED6hUuUqB1uZNISGhJCef7jslJZnQ0ND8Y/bk6vvoUUqVKkVoaP5lQ0LyLnuxKlMuhH1pp4/G9+1NoXS54HNatmxwKNUjahJ2XSVcLhfNWsezZcM6b5Va4EqXDWFvrjMR+9NSKFP23HqH7J8dQNh1lYht0JitG9cXeI3eUDY4hL2pyTnTe9NSKBt87n1fqvxLlCYj1xFtxrEDFM511ApQ+OqSFHL5A1CmXhwnUn7J/v7Zli2Rd9mLVXBIKKkpp7d3WkoKwcFn7NODT4/JzMzkt2NHCQoqRZEiRQgKyt63165TlwqVKrM9cZtzxePlwLXWpnj+3w/MBuqfZcw71tpYa21sqWsLdqPXjanH9sREkpJ2kpGRwcwZ02gX1yHPmHbtO/DJpIkAzJ09kxubNscYw5EjR+jRtSNPP/sCDW5oVKB1eVtsvXokJm4jaWd239OnTiEuvmOeMXHxHZk88SMAZs2cQdPmLTDGEBffkelTp5Cenk7Szp0kJm6jXv18m+2iFFmrLnuStpOyJ4lTGRksSphF01btz3nZ344d5fDBXwFY+cM3eS44uthF1c7b++cJs2ja+tx6P3b0MBme6xMOHzrI2tU/XjK914yOIWnHdvbsSiIjI4NP58ygZZs4X5flddeEVeePX5P541AaWZmnOLRuCYERDfOMyTh2+q2xw5u/p2iZ6wAIuL4eR7etJPP338j8/TeObltJwPX1HK3/fEXXjWXH9kR2efbpc2ZNo037+Dxj2rSPZ9rH2fv0+XNm0ujGZhhj+PXXAzlvE+3auYOd2xOpULGSo/V77ZSyMeZqoJC19jfP122AZ721vrNxuVyMemUcXTu2x+1207f/ACIio3j+2aepUzeW9vEd6DdgIHcMupU6NaoTGBjI+//Jvprt3bdeZ+f2REaOeI6RI54DYHbCAkqXKeNkC+fF5XIxZtx4OsTdhNvt5tYBA4mMiuLZ4U9RNyaW+A4dGTBwEAMH9CMqvCqBgUFMnDwFgMioKLp270GdWpG4XC7Gvvr6JXGFMmT3/fAzo7mnfxfcWW46de9LlesjePOV54msWYemrduzcd1qHryzL8eOHuHbLxfw9tgRTF+0HD8/P4Y+9m/u7NMRiyWiRjQ333Krr1s6Zy6Xi0eeHc3g/l3Icrvp2OPsvT9wR3bv33y5gLfGjGDG4uXsTPyF5x8bijGFsDaL2+66/5IJXJfLxVMvvMygXp1wu91069WfauGRjHvp39SIrkvLm+JY/9NqBg+8hWNHjvDV4gW8Oup5Pvsm+0rVXp1as2PbL5w8eZwmdarxwitv0KR5ax939feMn4uKHYew9f2HsDaL0rHtKFa2EsmL3+fq0OoERjZi7/czObL5e0whP/yKFadKt0cBcBUrQUiL/mwYfwcAoS1uxVXMudOqF8LlcvHC6LH06hKH251Fr763Eh4RxUvPDye6Tgw3te9A7363cc/tA2gQHUFAYCBvvz8JgB+XfcvIF56hcOHCFDKFGDlmPIFBQY7Wb7x19ZYxpjLZR7WQHewfW2uf/2/L1Kkba5cuW+6Vei5mRQpfGoFW0DYlH/N1CT5hjK8r8J1rinr7spGLU78PVvq6BJ+Ye3fDvx90mWnTtAHrflp91t9yrz37rbU7gNreenwREZFLyWX9Z0EiIiIXCwWuiIiIAxS4IiIiDlDgioiIOECBKyIi4gAFroiIiAMUuCIiIg5Q4IqIiDhAgSsiIuIABa6IiIgDFLgiIiIOUOCKiIg4QIErIiLiAAWuiIiIAxS4IiIiDlDgioiIOECBKyIi4gAFroiIiAMUuCIiIg5Q4IqIiDhAgSsiIuIABa6IiIgDFLgiIiIOUOCKiIg4QIErIiLiAAWuiIiIA1y+LiA3i8WdZX1dhjikdIkivi7BJ6b/nOLrEnymfMmivi7BJxbc19jXJfjEjPXJvi7BcUf/OPWX83SEKyIi4gAFroiIiAMUuCIiIg5Q4IqIiDhAgSsiIuIABa6IiIgDFLgiIiIOUOCKiIg4QIErIiLiAAWuiIiIAxS4IiIiDlDgioiIOECBKyIi4gAFroiIiAMUuCIiIg5Q4IqIiDhAgSsiIuIABa6IiIgDFLgiIiIOUOCKiIg4QIErIiLiAAWuiIiIAxS4IiIiDlDgioiIOECBKyIi4oDLPnC/XPw59etEEVsrnLEvj8w3Pz09nUH9exNbK5zWzRqye1dSnvnJe3ZzXdkAxo97xaGKC8aizxdSK6o6UeFVGTXyxXzz09PT6du7J1HhVWnS8B/sSkrKmTfqpRFEhVelVlR1Fi/63MGqC8bSLxfRrH5NmsRG8vrYUfnmp6enc/egvjSJjaRj6ybs2Z0EwKlTp7j/7kG0bhxDiwa1GT8m//PlYrZl+de82K8VL/RuzpeT38o3//u5HzPqtna8PCie1+7pwd6kbQCcOHqYN4b2ZljbmswaO9zhqi/c2mVfMaRzE+7t2Ig574/PN3/+xLe5v0szHuzRimfv6MGB1OSceT1jyvNQz9Y81LM1Lw0Z4GDVF+6LRQupHx1JTM3qjB39Ur756enpDOzfi5ia1WnV9IacfdvqVSu4sUEMNzaIock/6jJ/3hyHK78wG35YypM9W/B4t6Ys+M8b+eYv/mQCT/dqxTN92/LKPb05mHZ6e898fQTD+7RheJ82rPwiwcmyAS8HrjEmwBgzwxizxRiz2RhzgzfXdya3283D/7qPabMS+H7VemZNn8KWzZvyjJn00fsEBASwav0W7ho8hGeefCzP/CcefYiWrds6WfYFc7vdDL1vMHMTFvDT+k1Mn/IJmzfl7fvD998jMCCQjVsSuXfI/Tz+2CMAbN60ielTp7Bm3UbmzV/IkHvvxu12+6KN8+J2u3ni4SF8NG0uX36/lnmzpvHLls15xkyd9CElAwL4dtUm/u+uexnxzBMAfDp3JhkZGSz+bjWfLvmBjz+akBPGF7sst5tZ44bzz5fe5+GPPuenJQk5gfqnuq068NAHC3jgvfk073U7815/HgCXfxHaDvwXHe4a5ovSL0iW2817Lz7OY+MnMWbmVyxbOIfk7b/kGVMxvAYvTl7A6Glf0KBlHJPGPZczz79IUUZNXcyoqYt5ZNyHDld//nL2bbPn88Pqn5k5fepf7NsCWf3zVu66ZyjDn8zevhGRNVjy3XK++XE10+d8yr/uvYvMzExftPE/y3K7+fjlp7jvlQ955pPFrFw8j9SdeZ/n5a+P5LEPEnh60kLqtmjHzNdHALB+2RJ2b93Ikx99xrAJc1j08bv8fuI3R+v39hHuOGChtTYcqA1s/pvxBWrNqhVUqlyFipUq4+/vz83derLg07yvahZ8msAtffoB0PHmrnyzdAnWWgA+TZhLhYoVCY+IdLLsC7ZyxQqqVKlKpcrZfXfveQvzE+bmGTM/YS59+t0KQJeu3Vi65EustcxPmEv3nrdQpEgRKlaqRJUqVVm5YoUv2jgva9espGKlKlSomN17h5u7s2hB3m2+aEEC3W7pC0D7jl1Y9s1XWGsxxnDy5AkyMzP544/fKezvT/HiJXzRxv9s95Z1lAqtQKmQ63AV9qdOi3g2Lvsiz5iiVxfP+Trjj5MYYwAoclUxKteKxeXv72jNBSFxw0+UK1+RsmEVcBX2p+FNnVi5NO9ZmRr1GlHkqqsAqFYrhkP70nxRaoFafca+rUu3HiyYPy/PmM/mz8vZt3XKtW8rVqwYLpcLgPT0P3KeB5eCnZvWUiasAqVDs5/n9Vp1YN03i/KMCY9pSJGi2du7clQdDu/fC0Dazm1Ui66Pn8tFkauKEVYlnI0/fO1o/V4LXGNMSeBG4D0Aa22GtfaIt9Z3NmmpqYSGheVMh4SGkpaakm9MSFh5AFwuFyVKluTQwYMcP36cV8eM4qFhTzpZcoFITU0hzNMTQGhoGCkpKfnHlM/b98GDB0lJyb9s6hk/s4vZ3rRUQkJPb/PgkFD2paXmHxOSPcblclG8RAkOHzpI+45dKFbsamIjK9KgdjVuHzyUgMAgR+s/X0cP7COgdHDOdMnS5Th6YF++cd/NnsgLvZsz/62X6HzfU06W6BWH9u+lVNmQnOlSZYM5dGDvX45fMucTohs1z5k+lZHOo73b8Xj/eFZ8tdCrtRak7H3b6d/TkNAw0s54nuce43K5KFEie98GsGrlcm6IrUXj+tG8/OobOQF8sTtyYB9BZU5v74AywRw+y/P8T98lTKPGDc0ACKsWwcYfvyb9j9/57cghtq75gUP7nX3x5c2fciXgAPCBMaY2sBoYYq094cV1FpiRLzzLXYOHcM011/i6FHHI2jUr8fMrxMqNOzl65DDd4lrSuGkLKlSs7OvSCkzjm/vR+OZ+rPliHl9MfJ1ew0b7uiTHfPPpTHZsWsfwCTNzvvfGZ8sJKhPMvuRdPHt7D66rGk658hV9V6RDYuv9gx9WrWfrls0Mvv02WrVpS9GiRX1dVoH6ceFsdm1Zz4NvTAUg6h83krR5PS/d3oXiAaWoXKMuhQo5exmTN9fmAuoCb1pr6wAngEfPHGSMud0Ys8oYs+rgr78WaAHBISGkJJ9+wzw1JYXgkNB8Y1KT9wCQmZnJsaNHCSpVitUrVzD8yWFER1blrTdeZczoF3n3rdcLtD5vCQkJJdnTE0BKSjKhoaH5x+zJ23epUqUIDc2/bMgZP7OLWbngEFJTTm/ztNQUygaH5B/juXAmMzOT344dIzCoFHNnTKVpizYULlyYa0uXIfYfN7B+7RpH6z9fJUuX5ciB06/Wjx7YS8nSZf9yfHSLeDZ8t9iJ0rwqqEw5Du47fWR3cF8aQaXL5Ru3/sdvmP3eqzw89kMK+xfJtXz2WYGyYRWIjL2BpC0bvF90Acjet53+PU1NSSb4jOd57jGZmZkcO5a9b8utengEV199DZs3XRp9B5Quy6H9p7f3kf1pBJ7leb5pxXd89uF4Bo+ckGd7xw24h6f+s4D7X50E1lL2OmdfTHszcJOBZGvtcs/0DLIDOA9r7TvW2lhrbWypa68t0ALqxNRjx/ZEdiXtJCMjg9kzptKufXyeMW3bxzNl8kQA5s2eSZOmzTHG8OnipazdlMjaTYncefd93P/go/zzzsEFWp+3xNarR2LiNpJ2Zvc9feoU4uI75hkTF9+RyRM/AmDWzBk0bd4CYwxx8R2ZPnUK6enpJO3cSWLiNurVr++LNs5L7Tqx7NyRyO5d2b0nzJ5O63Z5t3nrtvHMmDIJgM/mzaJhk2YYYwgJK8/33y4F4OSJE6xZtYKq1ao73cJ5KV+9Fr8mJ3EwbQ+ZpzL4acl8ohq2zDPmQPLOnK83//gV14ZWdLjKglclKpq03TvZn7KbzFMZfP/5XGKbtckzZueWDbz7/KM8POYDSgad3sccP3aEUxnpABw7fIita1cSVvl6R+s/X3XP2LfNmjGNtnEd8oxpF9chZ982N9e+bVfSzpyLpPbs3sW2X7Zy3XUVnW7hvFSMqM3+PUn8mpr9PF/5RQK1m7TOM2b31g1MGvkYg0dNoESu7Z3ldnP86GEAkhM3k7x9C5H1mzhav9dOKVtr9xpj9hhjqltrtwItgU1/t1xBcrlcvPTyOLp3jsPtdtO73wDCI6MY8e/hRNeNoV1cB/reOpC7/m8AsbXCCQgMZMKHk50s0StcLhdjxo2nQ9xNuN1ubh0wkMioKJ4d/hR1Y2KJ79CRAQMHMXBAP6LCqxIYGMTEyVMAiIyKomv3HtSpFYnL5WLsq6/j5+fn447Oncvl4t8vjaVf9w643W569r6V6uGRvDziGWpGx9CmXTw9+w5g6F0DaRIbSUBAEOMn/AeAWwfdyQP33k7LhnWw1tKjd38iomr6uKNz4+dy0WXI07zz0ABsVhb123WjXKXrWfj+GMKq16RGo1Ysmz2RX1Z/j5+fi6uKl6DXsNN/MvVczxv54+Rx3KdOseG7xdw++kPKVazmw47OjZ/LxcBHnuP5u3uTlZVF8049KV+lOlPfGEWVyNrENmvDpDH/5o+TJ3jl4TsAuLZcKI+M+5CUHdt45/lHKWQMWdbS+bZ7CKtyaQSuy+Vi5Mvj6NapPW63mz79BxARGcUL/36aOnVjc/Ztd/7frcTUrE5gYCATPvoYgB+/X8bYV0ZS2FWYQoUKMWrseAr6YMdb/Fwuej3wLGOH9icry02j+B6EVL6eue+8QoWImkQ3ac2M8SNIP3mStx+/G4CgsqHcM2oC7sxTjLqzOwBFr76GQU+Pwc/h967Nn1fkeuXBjYkGJgD+wA7gNmvt4b8aH103xi75dvlfzb5sFStyaVywUNAOHEv3dQk+Mf3nS+citIJWvuTl9T7huWp1/V+f3r+czVif/PeDLjPP39aBpM3rz3rpt1f39NbatUCsN9chIiJyKbjsP2lKRETkYqDAFRERcYACV0RExAEKXBEREQcocEVERBygwBUREXGAAldERMQBClwREREHKHBFREQcoMAVERFxgAJXRETEAQpcERERByhwRUR5eiqIAAAHQElEQVREHKDAFRERcYACV0RExAEKXBEREQcocEVERBygwBUREXGAAldERMQBClwREREHKHBFREQcoMAVERFxgAJXRETEAQpcERERByhwRUREHKDAFRERcYCx1vq6hhzGmAPALh+t/lrgVx+t25fU95VFfV9Z1LfzKlhrS59txkUVuL5kjFllrY31dR1OU99XFvV9ZVHfFxedUhYREXGAAldERMQBCtzT3vF1AT6ivq8s6vvKor4vInoPV0RExAE6whUREXHAFR+4xpi2xpitxphEY8yjvq7HKcaY940x+40xG3xdi1OMMeWNMV8ZYzYZYzYaY4b4uianGGOKGmNWGGPWeXp/xtc1OcUY42eM+ckYM9/XtTjJGJNkjPnZGLPWGLPK1/U4xRgTYIyZYYzZYozZbIy5wdc1/emKPqVsjPEDfgFaA8nASqCXtXaTTwtzgDHmRuA48B9rbQ1f1+MEY0wwEGytXWOMKQ6sBjpfIdvbAFdba48bYwoD3wFDrLU/+rg0rzPG/AuIBUpYa+N9XY9TjDFJQKy19or6O1xjzEfAt9baCcYYf6CYtfaIr+sCHeHWBxKttTustRnAFKCTj2tyhLX2G+CQr+twkrU2zVq7xvP1b8BmINS3VTnDZjvumSzs+XfZv9o2xoQBccAEX9ci3meMKQncCLwHYK3NuFjCFhS4ocCeXNPJXCE74CudMaYiUAdY7ttKnOM5tboW2A8sttZeCb2PBR4GsnxdiA9YYJExZrUx5nZfF+OQSsAB4APP2wgTjDFX+7qoP13pgStXIGPMNcBMYKi19piv63GKtdZtrY0GwoD6xpjL+q0EY0w8sN9au9rXtfhIY2ttXaAdMNjzNtLlzgXUBd601tYBTgAXzbU5V3rgpgDlc02Heb4nlynP+5czgcnW2lm+rscXPKfYvgLa+roWL2sEdPS8lzkFaGGMmeTbkpxjrU3x/L8fmE32W2iXu2QgOdfZmxlkB/BF4UoP3JVANWNMJc+b67cA83xck3iJ58Kh94DN1tpXfF2Pk4wxpY0xAZ6vryL7QsEtvq3Ku6y1w6y1YdbaimT/bi+x1vb1cVmOMMZc7bkwEM8p1TbAZf8XCdbavcAeY0x1z7daAhfNRZEuXxfgS9baTGPMPcDngB/wvrV2o4/LcoQx5hOgGXCtMSYZeNpa+55vq/K6RkA/4GfPe5kAj1lrP/NhTU4JBj7yXJlfCJhmrb2i/kzmClMWmJ39GhMX8LG1dqFvS3LMvcBkz0HUDuA2H9eT44r+syARERGnXOmnlEVERByhwBUREXGAAldERMQBClwREREHKHBFREQcoMAVuUQYY5r9eccbY0zH/3Z3K88dU+4+j3UMN8Y8eK7fP2PMh8aYbv/DuipeSXerElHgiviY529j/yfW2nnW2hf/y5AA4H8OXBHxHgWuiJd4juC2GGMme+7LOcMYU8wzL8kY85IxZg3Q3RjTxhjzgzFmjTFmuufznv+8X/MWz7guuR57gDFmvOfrssaY2Z573a4zxjQEXgSqeO6FOsoz7iFjzEpjzPrc98M1xjxujPnFGPMdUJ2/YYz5p+dx1hljZv7Zk0crY8wqz+PFe8b7GWNG5Vr3HRf6sxW5FClwRbyrOvCGtTYCOEbeo86Dng+X/wJ4AmjlmV4F/MsYUxR4F+gAxADl/mIdrwJfW2trk/25sRvJ/sD27dbaaGvtQ8aYNkA1sj9PNxqIMcbcaIyJIftjD6OB9kC9c+hplrW2nmd9m4FBueZV9KwjDnjL08Mg4Ki1tp7n8f9pjKl0DusRuaxc0R/tKOKAPdbaZZ6vJwH3AaM901M9/zcAIoFlno/i8wd+AMKBndbabQCeD94/223WWgD9IfuOQMBRY0zgGWPaeP795Jm+huwALg7Mttae9KzjXD5LvIYx5jmyT1tfQ/ZHo/5pmrU2C9hmjNnh6aENUCvX+7slPev+5RzWJXLZUOCKeNeZn52ae/qE539D9v1pe+UeaIyJLsA6DDDCWvv2GesYeh6P9SHQ2Vq7zhgzgOzP5P7T2fo1wL3W2tzB/Oc9iUWuGDqlLOJd1xljbvB83Rv47ixjfgQaGWOqQs6dXq4n+24+FY0xVTzjep1lWYAvgbs8y/oZY0oCv5F99Pqnz4GBud4bDjXGlAG+ATobY67y3F2mwzn0VBxI89zqsM8Z87obYwp5aq4MbPWs+y7PeIwx119MNwUXcYoCV8S7tpJ98+/NQCDw5pkDrLUHgAHAJ8aY9XhOJ1tr/yD7FPKnnoum9v/FOoYAzY0xPwOrgUhr7UGyT1FvMMaMstYuAj4GfvCMmwEUt9auIfvU9jpgAdm3rPw7TwLLgWXkv8XfbmCF57Hu9PQwgexbpK3x/BnQ2+jsmlyBdLcgES/xnDKdb62t4eNSROQioCNcERERB+gIV0RExAE6whUREXGAAldERMQBClwREREHKHBFREQcoMAVERFxgAJXRETEAf8PqHAq8cnOdI8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW3FZjp-5DgF",
        "outputId": "1ab8b09d-0347-4181-c93f-31f0b717d358"
      },
      "source": [
        "print(classification_report(ytest, test_pred, target_names=emotions.values()))\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry       0.27      0.08      0.13       482\n",
            "     Disgust       0.00      0.00      0.00        50\n",
            "        Fear       0.26      0.19      0.22       507\n",
            "       Happy       0.49      0.75      0.59       920\n",
            "         Sad       0.28      0.41      0.33       592\n",
            "    Surprise       0.49      0.50      0.49       371\n",
            "     Neutral       0.46      0.29      0.35       667\n",
            "\n",
            "    accuracy                           0.40      3589\n",
            "   macro avg       0.32      0.32      0.30      3589\n",
            "weighted avg       0.38      0.40      0.37      3589\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}