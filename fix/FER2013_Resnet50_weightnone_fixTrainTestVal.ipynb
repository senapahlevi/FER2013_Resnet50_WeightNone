{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER2013_Resnet50_weightnone_scratch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "18Zj-Yp1YlH0QWcuD4e7ugx8zCCcRS0jg",
      "authorship_tag": "ABX9TyOOSdAnyOLd0a+6fdF/aIga"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eWeoD7MRFlN",
        "outputId": "0e2d5d4c-8f6c-4a8a-a287-b9e9ec1da464"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "inputFolder = '/content/drive/MyDrive/Fer2013_backup/' \n",
        "for root, directories, filenames in os.walk(inputFolder): \n",
        "    for filename in filenames: print(os.path.join(root,filename))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Fer2013_backup/backUpfer2013.csv\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/best_model_resnet50_modelB2_170false.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/best_model_resnet50_modelD2_170false.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50Scracth_tipe7.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50Scracth_tipe8.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50oriAUGScracthSGD2.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50oriAUGScracthSGD3.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50AUGScracthadam2.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/fixcheckpoint/Best_Model_resnet50oriAUGScracthSGD2.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH8iEUJiRQS7",
        "outputId": "b8dc5ae5-25e2-48a2-d113-6f008b17d0e9"
      },
      "source": [
        "%cd /content/drive/MyDrive/Fer2013_backup/\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Fer2013_backup\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqZOFwxxRQaa",
        "outputId": "d646c3e3-740a-4fe6-a3b2-ebae64fd96a3"
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:400: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUX-dSAgRQh4"
      },
      "source": [
        "#Define the identity block helper function.\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "   \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbdQH3mkRQra"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path \n",
        "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b',padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33XH76oKRQvh"
      },
      "source": [
        "def ResNet50(input_shape = (48,48,1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    #X = ZeroPadding2D((1, 1))(X_input)\n",
        "    X = X_input\n",
        "    # Stage 1\n",
        "\n",
        "    X = Conv2D(8, (3, 3), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # removed maxpool\n",
        "    #X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='c')\n",
        "\n",
        "\n",
        "    # Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [64,64,256], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL . \n",
        "    X = AveragePooling2D((2,2), name='avg_pool')(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(512, activation = 'relu', name='fc1024' , kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWuYK_f2zGJF"
      },
      "source": [
        "\"\"\"def ResNet50ori(input_shape = (48, 48, 1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50ori')\n",
        "\n",
        "    return model\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QQOxN2cRQy3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "61046188-5d10-4566-c08b-a7b11bf842eb"
      },
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        " \n",
        "dataset_path = '/content/drive/MyDrive/Fer2013_backup/backUpfer2013.csv'\n",
        "image_size=(48,48)\n",
        "\n",
        "def load_fer2013():\n",
        "    data = pd.read_csv(dataset_path)\n",
        "    data = (data[data['pixels'].notnull()])\n",
        "    pixels = data['pixels'].tolist()\n",
        "    width, height = 48, 48\n",
        "    faces = []\n",
        "    for pixel_sequence in pixels:\n",
        "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "        face = np.asarray(face).reshape(width, height)\n",
        "        face = cv2.resize(face.astype('uint8'),image_size)\n",
        "        faces.append(face.astype('float32'))\n",
        "    faces = np.asarray(faces)\n",
        "    faces = np.expand_dims(faces, -1)\n",
        "    emotions = (data['emotion'])#.values\n",
        "    return faces, emotions\n",
        " \n",
        "def preprocess_input(x, v2=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if v2:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x\n",
        " \n",
        "faces, emotions = load_fer2013()\n",
        "faces = preprocess_input(faces)\n",
        "#xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
        "#Data Augumentationfgf\n",
        "data_generator = ImageDataGenerator(\n",
        "                        rotation_range=10,\n",
        "                        shear_range = 10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        vertical_flip=True,\n",
        "                        horizontal_flip=True)\n",
        "\"\"\"data_generator = ImageDataGenerator ()\"\"\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'data_generator = ImageDataGenerator ()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zCkwVdnKTm5",
        "outputId": "ce802fd2-0bfe-4fb3-f6f7-b123f2c3ba17"
      },
      "source": [
        "train_ratio = 0.80\n",
        "validation_ratio = 0.10\n",
        "test_ratio = 0.10\n",
        "\n",
        "# train is now 75% of the entire data set\n",
        "# the _junk suffix means that we drop that variable completely # the _junk suffix means that we drop that variable completely\n",
        "#x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=1 - train_ratio)\n",
        "\n",
        "# test is now 10% of the initial data set\n",
        "# validation is now 15% of the initial data set\n",
        "#x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "x_val, xtest, y_val, ytest = train_test_split(xtest, ytest, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "\n",
        "print(xtrain, x_val, xtest)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[-0.26274508]\n",
            "   [-0.23137254]\n",
            "   [-0.01960784]\n",
            "   ...\n",
            "   [-0.85882354]\n",
            "   [-0.827451  ]\n",
            "   [-0.81960785]]\n",
            "\n",
            "  [[-0.25490195]\n",
            "   [-0.18431371]\n",
            "   [ 0.082353  ]\n",
            "   ...\n",
            "   [-0.827451  ]\n",
            "   [-0.81960785]\n",
            "   [-0.8117647 ]]\n",
            "\n",
            "  [[-0.24705881]\n",
            "   [-0.1372549 ]\n",
            "   [ 0.13725495]\n",
            "   ...\n",
            "   [-0.77254903]\n",
            "   [-0.8039216 ]\n",
            "   [-0.79607844]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.32549018]\n",
            "   [-0.3333333 ]\n",
            "   [-0.38039213]\n",
            "   ...\n",
            "   [-0.5137255 ]\n",
            "   [-0.41176468]\n",
            "   [-0.34117645]]\n",
            "\n",
            "  [[-0.34117645]\n",
            "   [-0.3490196 ]\n",
            "   [-0.3960784 ]\n",
            "   ...\n",
            "   [-0.49019605]\n",
            "   [-0.3960784 ]\n",
            "   [-0.3960784 ]]\n",
            "\n",
            "  [[-0.372549  ]\n",
            "   [-0.372549  ]\n",
            "   [-0.38823527]\n",
            "   ...\n",
            "   [-0.49019605]\n",
            "   [-0.41960782]\n",
            "   [-0.41176468]]]\n",
            "\n",
            "\n",
            " [[[-0.6627451 ]\n",
            "   [-0.69411767]\n",
            "   [-0.6862745 ]\n",
            "   ...\n",
            "   [ 0.05882359]\n",
            "   [ 0.06666672]\n",
            "   [ 0.082353  ]]\n",
            "\n",
            "  [[-0.6313726 ]\n",
            "   [-0.67058825]\n",
            "   [-0.6392157 ]\n",
            "   ...\n",
            "   [ 0.07450986]\n",
            "   [ 0.082353  ]\n",
            "   [ 0.09019613]]\n",
            "\n",
            "  [[-0.6313726 ]\n",
            "   [-0.6313726 ]\n",
            "   [-0.5921569 ]\n",
            "   ...\n",
            "   [ 0.09019613]\n",
            "   [ 0.09803927]\n",
            "   [ 0.09803927]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.49019605]\n",
            "   [-0.49019605]\n",
            "   [-0.49019605]\n",
            "   ...\n",
            "   [ 0.11372554]\n",
            "   [ 0.05882359]\n",
            "   [ 0.01176476]]\n",
            "\n",
            "  [[-0.49019605]\n",
            "   [-0.4588235 ]\n",
            "   [-0.47450978]\n",
            "   ...\n",
            "   [ 0.254902  ]\n",
            "   [ 0.07450986]\n",
            "   [ 0.01176476]]\n",
            "\n",
            "  [[-0.4980392 ]\n",
            "   [-0.44313723]\n",
            "   [-0.4823529 ]\n",
            "   ...\n",
            "   [ 0.254902  ]\n",
            "   [ 0.06666672]\n",
            "   [ 0.01176476]]]\n",
            "\n",
            "\n",
            " [[[ 0.6392157 ]\n",
            "   [ 0.5686275 ]\n",
            "   [ 0.52156866]\n",
            "   ...\n",
            "   [ 0.5294118 ]\n",
            "   [ 0.64705884]\n",
            "   [ 0.69411767]]\n",
            "\n",
            "  [[ 0.6156863 ]\n",
            "   [ 0.56078434]\n",
            "   [ 0.4901961 ]\n",
            "   ...\n",
            "   [ 0.5372549 ]\n",
            "   [ 0.56078434]\n",
            "   [ 0.6392157 ]]\n",
            "\n",
            "  [[ 0.58431375]\n",
            "   [ 0.5372549 ]\n",
            "   [ 0.45098042]\n",
            "   ...\n",
            "   [ 0.5372549 ]\n",
            "   [ 0.5372549 ]\n",
            "   [ 0.6313726 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.9529412 ]\n",
            "   [ 0.94509804]\n",
            "   [ 0.79607844]\n",
            "   ...\n",
            "   [ 0.9529412 ]\n",
            "   [ 0.9529412 ]\n",
            "   [ 0.9529412 ]]\n",
            "\n",
            "  [[ 0.94509804]\n",
            "   [ 0.9607843 ]\n",
            "   [ 0.9372549 ]\n",
            "   ...\n",
            "   [ 0.8745098 ]\n",
            "   [ 0.9529412 ]\n",
            "   [ 0.9529412 ]]\n",
            "\n",
            "  [[ 0.9529412 ]\n",
            "   [ 0.9529412 ]\n",
            "   [ 0.9529412 ]\n",
            "   ...\n",
            "   [ 0.70980394]\n",
            "   [ 0.85882354]\n",
            "   [ 0.9529412 ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.17647058]\n",
            "   [-0.15294117]\n",
            "   [-0.27843136]\n",
            "   ...\n",
            "   [-0.7647059 ]\n",
            "   [-0.5764706 ]\n",
            "   [-0.38039213]]\n",
            "\n",
            "  [[-0.12941176]\n",
            "   [-0.18431371]\n",
            "   [-0.3098039 ]\n",
            "   ...\n",
            "   [-0.75686276]\n",
            "   [-0.56078434]\n",
            "   [-0.35686272]]\n",
            "\n",
            "  [[-0.12156862]\n",
            "   [-0.2235294 ]\n",
            "   [-0.2862745 ]\n",
            "   ...\n",
            "   [-0.77254903]\n",
            "   [-0.58431375]\n",
            "   [-0.3490196 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.6156863 ]\n",
            "   [-0.62352943]\n",
            "   [-0.6392157 ]\n",
            "   ...\n",
            "   [-0.31764704]\n",
            "   [-0.30196077]\n",
            "   [-0.27843136]]\n",
            "\n",
            "  [[-0.67058825]\n",
            "   [-0.67058825]\n",
            "   [-0.654902  ]\n",
            "   ...\n",
            "   [-0.3333333 ]\n",
            "   [-0.29411763]\n",
            "   [-0.27843136]]\n",
            "\n",
            "  [[-0.70980394]\n",
            "   [-0.6784314 ]\n",
            "   [-0.6627451 ]\n",
            "   ...\n",
            "   [-0.3333333 ]\n",
            "   [-0.32549018]\n",
            "   [-0.29411763]]]\n",
            "\n",
            "\n",
            " [[[-0.5294118 ]\n",
            "   [-0.5294118 ]\n",
            "   [-0.5294118 ]\n",
            "   ...\n",
            "   [-0.1372549 ]\n",
            "   [-0.1372549 ]\n",
            "   [-0.10588235]]\n",
            "\n",
            "  [[-0.5294118 ]\n",
            "   [-0.5294118 ]\n",
            "   [-0.5294118 ]\n",
            "   ...\n",
            "   [-0.1372549 ]\n",
            "   [-0.11372548]\n",
            "   [-0.10588235]]\n",
            "\n",
            "  [[-0.5372549 ]\n",
            "   [-0.5372549 ]\n",
            "   [-0.54509807]\n",
            "   ...\n",
            "   [-0.15294117]\n",
            "   [-0.14509803]\n",
            "   [-0.11372548]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.8039216 ]\n",
            "   [-0.79607844]\n",
            "   [-0.8509804 ]\n",
            "   ...\n",
            "   [-0.45098037]\n",
            "   [-0.41176468]\n",
            "   [-0.40392154]]\n",
            "\n",
            "  [[-0.79607844]\n",
            "   [-0.827451  ]\n",
            "   [-0.7019608 ]\n",
            "   ...\n",
            "   [-0.44313723]\n",
            "   [-0.41960782]\n",
            "   [-0.41176468]]\n",
            "\n",
            "  [[-0.7882353 ]\n",
            "   [-0.84313726]\n",
            "   [-0.3490196 ]\n",
            "   ...\n",
            "   [-0.42745095]\n",
            "   [-0.4352941 ]\n",
            "   [-0.41960782]]]\n",
            "\n",
            "\n",
            " [[[-0.36470586]\n",
            "   [-0.31764704]\n",
            "   [-0.42745095]\n",
            "   ...\n",
            "   [-0.84313726]\n",
            "   [-0.78039217]\n",
            "   [-0.7490196 ]]\n",
            "\n",
            "  [[-0.3960784 ]\n",
            "   [-0.3098039 ]\n",
            "   [-0.41176468]\n",
            "   ...\n",
            "   [-0.79607844]\n",
            "   [-0.78039217]\n",
            "   [-0.7254902 ]]\n",
            "\n",
            "  [[-0.36470586]\n",
            "   [-0.41960782]\n",
            "   [-0.41960782]\n",
            "   ...\n",
            "   [-0.8117647 ]\n",
            "   [-0.7882353 ]\n",
            "   [-0.7490196 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.20000005]\n",
            "   [ 0.19215691]\n",
            "   [ 0.19215691]\n",
            "   ...\n",
            "   [-0.4352941 ]\n",
            "   [-0.4352941 ]\n",
            "   [-0.41960782]]\n",
            "\n",
            "  [[ 0.2313726 ]\n",
            "   [ 0.23921573]\n",
            "   [ 0.17647064]\n",
            "   ...\n",
            "   [-0.4352941 ]\n",
            "   [-0.4352941 ]\n",
            "   [-0.42745095]]\n",
            "\n",
            "  [[ 0.19215691]\n",
            "   [ 0.12941182]\n",
            "   [ 0.16078436]\n",
            "   ...\n",
            "   [-0.4352941 ]\n",
            "   [-0.4352941 ]\n",
            "   [-0.4352941 ]]]] [[[[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 0.99215686]\n",
            "   ...\n",
            "   [ 0.99215686]\n",
            "   [ 0.99215686]\n",
            "   [ 0.99215686]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 0.99215686]\n",
            "   ...\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.99215686]\n",
            "   [ 0.99215686]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 0.99215686]\n",
            "   ...\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.99215686]\n",
            "   [ 0.99215686]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.6156863 ]\n",
            "   [-0.6392157 ]\n",
            "   [-0.6784314 ]\n",
            "   ...\n",
            "   [-0.19215685]\n",
            "   [ 0.0196079 ]\n",
            "   [ 0.12941182]]\n",
            "\n",
            "  [[-0.6862745 ]\n",
            "   [-0.70980394]\n",
            "   [-0.73333335]\n",
            "   ...\n",
            "   [-0.12941176]\n",
            "   [ 0.00392163]\n",
            "   [ 0.10588241]]\n",
            "\n",
            "  [[-0.62352943]\n",
            "   [-0.7490196 ]\n",
            "   [-0.7647059 ]\n",
            "   ...\n",
            "   [-0.00392157]\n",
            "   [-0.09019607]\n",
            "   [ 0.09019613]]]\n",
            "\n",
            "\n",
            " [[[-0.3098039 ]\n",
            "   [-0.58431375]\n",
            "   [-0.58431375]\n",
            "   ...\n",
            "   [ 0.5294118 ]\n",
            "   [ 0.5294118 ]\n",
            "   [ 0.427451  ]]\n",
            "\n",
            "  [[-0.25490195]\n",
            "   [-0.5529412 ]\n",
            "   [-0.67058825]\n",
            "   ...\n",
            "   [ 0.5372549 ]\n",
            "   [ 0.54509807]\n",
            "   [ 0.45882356]]\n",
            "\n",
            "  [[-0.19215685]\n",
            "   [-0.5372549 ]\n",
            "   [-0.6627451 ]\n",
            "   ...\n",
            "   [ 0.3411765 ]\n",
            "   [ 0.5764706 ]\n",
            "   [ 0.41176474]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.52156866]\n",
            "   [-0.6       ]\n",
            "   [-0.5529412 ]\n",
            "   ...\n",
            "   [-0.17647058]\n",
            "   [-0.372549  ]\n",
            "   [-0.64705884]]\n",
            "\n",
            "  [[-0.52156866]\n",
            "   [-0.5921569 ]\n",
            "   [-0.52156866]\n",
            "   ...\n",
            "   [-0.12156862]\n",
            "   [-0.3098039 ]\n",
            "   [-0.4823529 ]]\n",
            "\n",
            "  [[-0.46666664]\n",
            "   [-0.54509807]\n",
            "   [-0.46666664]\n",
            "   ...\n",
            "   [-0.04313725]\n",
            "   [-0.2235294 ]\n",
            "   [-0.29411763]]]\n",
            "\n",
            "\n",
            " [[[-0.9372549 ]\n",
            "   [-0.94509804]\n",
            "   [-0.92941177]\n",
            "   ...\n",
            "   [ 0.21568632]\n",
            "   [ 0.20000005]\n",
            "   [ 0.20000005]]\n",
            "\n",
            "  [[-0.9529412 ]\n",
            "   [-0.9529412 ]\n",
            "   [-0.92941177]\n",
            "   ...\n",
            "   [ 0.10588241]\n",
            "   [ 0.19215691]\n",
            "   [ 0.16078436]]\n",
            "\n",
            "  [[-0.9607843 ]\n",
            "   [-0.9529412 ]\n",
            "   [-0.9529412 ]\n",
            "   ...\n",
            "   [-0.01960784]\n",
            "   [ 0.20000005]\n",
            "   [ 0.12156868]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.75686276]\n",
            "   [ 0.75686276]\n",
            "   [ 0.78039217]\n",
            "   ...\n",
            "   [ 0.7019608 ]\n",
            "   [ 0.58431375]\n",
            "   [ 0.4431373 ]]\n",
            "\n",
            "  [[ 0.7019608 ]\n",
            "   [ 0.8509804 ]\n",
            "   [ 0.75686276]\n",
            "   ...\n",
            "   [ 0.6784314 ]\n",
            "   [ 0.56078434]\n",
            "   [ 0.4039216 ]]\n",
            "\n",
            "  [[ 0.7019608 ]\n",
            "   [ 0.73333335]\n",
            "   [ 0.77254903]\n",
            "   ...\n",
            "   [ 0.654902  ]\n",
            "   [ 0.5529412 ]\n",
            "   [ 0.38823533]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 0.58431375]\n",
            "   [ 0.6       ]\n",
            "   [ 0.6       ]\n",
            "   ...\n",
            "   [-0.7490196 ]\n",
            "   [-0.81960785]\n",
            "   [-0.4823529 ]]\n",
            "\n",
            "  [[ 0.6       ]\n",
            "   [ 0.60784316]\n",
            "   [ 0.6156863 ]\n",
            "   ...\n",
            "   [-0.7019608 ]\n",
            "   [-0.85882354]\n",
            "   [-0.6627451 ]]\n",
            "\n",
            "  [[ 0.60784316]\n",
            "   [ 0.60784316]\n",
            "   [ 0.6313726 ]\n",
            "   ...\n",
            "   [-0.70980394]\n",
            "   [-0.85882354]\n",
            "   [-0.6784314 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.75686276]\n",
            "   [-0.75686276]\n",
            "   [-0.7647059 ]\n",
            "   ...\n",
            "   [ 0.654902  ]\n",
            "   [ 0.64705884]\n",
            "   [ 0.6392157 ]]\n",
            "\n",
            "  [[-0.75686276]\n",
            "   [-0.7647059 ]\n",
            "   [-0.7647059 ]\n",
            "   ...\n",
            "   [ 0.6784314 ]\n",
            "   [ 0.654902  ]\n",
            "   [ 0.64705884]]\n",
            "\n",
            "  [[-0.7490196 ]\n",
            "   [-0.7490196 ]\n",
            "   [-0.77254903]\n",
            "   ...\n",
            "   [ 0.6784314 ]\n",
            "   [ 0.67058825]\n",
            "   [ 0.6627451 ]]]\n",
            "\n",
            "\n",
            " [[[-0.7254902 ]\n",
            "   [-0.7254902 ]\n",
            "   [-0.73333335]\n",
            "   ...\n",
            "   [-0.5529412 ]\n",
            "   [-0.5529412 ]\n",
            "   [-0.5529412 ]]\n",
            "\n",
            "  [[-0.7254902 ]\n",
            "   [-0.7254902 ]\n",
            "   [-0.73333335]\n",
            "   ...\n",
            "   [-0.54509807]\n",
            "   [-0.54509807]\n",
            "   [-0.54509807]]\n",
            "\n",
            "  [[-0.73333335]\n",
            "   [-0.7254902 ]\n",
            "   [-0.73333335]\n",
            "   ...\n",
            "   [-0.5372549 ]\n",
            "   [-0.5294118 ]\n",
            "   [-0.5372549 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.3960784 ]\n",
            "   [-0.15294117]\n",
            "   [-0.14509803]\n",
            "   ...\n",
            "   [-0.41960782]\n",
            "   [-0.3960784 ]\n",
            "   [-0.38823527]]\n",
            "\n",
            "  [[-0.18431371]\n",
            "   [-0.16862744]\n",
            "   [-0.16862744]\n",
            "   ...\n",
            "   [-0.372549  ]\n",
            "   [-0.372549  ]\n",
            "   [-0.372549  ]]\n",
            "\n",
            "  [[-0.17647058]\n",
            "   [-0.16862744]\n",
            "   [-0.1607843 ]\n",
            "   ...\n",
            "   [-0.36470586]\n",
            "   [-0.36470586]\n",
            "   [-0.372549  ]]]\n",
            "\n",
            "\n",
            " [[[ 0.9764706 ]\n",
            "   [ 0.99215686]\n",
            "   [ 0.7490196 ]\n",
            "   ...\n",
            "   [-0.2862745 ]\n",
            "   [-0.46666664]\n",
            "   [-0.45098037]]\n",
            "\n",
            "  [[ 0.9764706 ]\n",
            "   [ 1.        ]\n",
            "   [ 0.1686275 ]\n",
            "   ...\n",
            "   [-0.372549  ]\n",
            "   [-0.30196077]\n",
            "   [-0.4823529 ]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 0.8039216 ]\n",
            "   [-0.3490196 ]\n",
            "   ...\n",
            "   [-0.5686275 ]\n",
            "   [-0.24705881]\n",
            "   [-0.36470586]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.62352943]\n",
            "   [-0.67058825]\n",
            "   [-0.6       ]\n",
            "   ...\n",
            "   [-0.5686275 ]\n",
            "   [-0.62352943]\n",
            "   [-0.6627451 ]]\n",
            "\n",
            "  [[-0.60784316]\n",
            "   [-0.67058825]\n",
            "   [-0.5921569 ]\n",
            "   ...\n",
            "   [-0.5686275 ]\n",
            "   [-0.64705884]\n",
            "   [-0.6784314 ]]\n",
            "\n",
            "  [[-0.6       ]\n",
            "   [-0.6784314 ]\n",
            "   [-0.6       ]\n",
            "   ...\n",
            "   [-0.5921569 ]\n",
            "   [-0.6862745 ]\n",
            "   [-0.6627451 ]]]] [[[[-0.6       ]\n",
            "   [-0.6156863 ]\n",
            "   [-0.5764706 ]\n",
            "   ...\n",
            "   [-0.6392157 ]\n",
            "   [-0.52156866]\n",
            "   [-0.42745095]]\n",
            "\n",
            "  [[-0.6156863 ]\n",
            "   [-0.6313726 ]\n",
            "   [-0.67058825]\n",
            "   ...\n",
            "   [-0.52156866]\n",
            "   [-0.58431375]\n",
            "   [-0.4823529 ]]\n",
            "\n",
            "  [[-0.60784316]\n",
            "   [-0.6392157 ]\n",
            "   [-0.6784314 ]\n",
            "   ...\n",
            "   [-0.5921569 ]\n",
            "   [-0.6862745 ]\n",
            "   [-0.6       ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.38039213]\n",
            "   [-0.60784316]\n",
            "   [-0.5294118 ]\n",
            "   ...\n",
            "   [-0.40392154]\n",
            "   [-0.3490196 ]\n",
            "   [-0.31764704]]\n",
            "\n",
            "  [[-0.4588235 ]\n",
            "   [-0.67058825]\n",
            "   [-0.5058824 ]\n",
            "   ...\n",
            "   [-0.38039213]\n",
            "   [-0.34117645]\n",
            "   [-0.32549018]]\n",
            "\n",
            "  [[-0.52156866]\n",
            "   [-0.6627451 ]\n",
            "   [-0.5686275 ]\n",
            "   ...\n",
            "   [-0.3490196 ]\n",
            "   [-0.3333333 ]\n",
            "   [-0.30196077]]]\n",
            "\n",
            "\n",
            " [[[ 0.96862745]\n",
            "   [ 0.79607844]\n",
            "   [ 0.3411765 ]\n",
            "   ...\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]]\n",
            "\n",
            "  [[ 0.81960785]\n",
            "   [ 0.34901965]\n",
            "   [ 0.18431377]\n",
            "   ...\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]]\n",
            "\n",
            "  [[ 0.33333337]\n",
            "   [ 0.12156868]\n",
            "   [ 0.20784318]\n",
            "   ...\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.2862745 ]\n",
            "   [-0.11372548]\n",
            "   [ 0.07450986]\n",
            "   ...\n",
            "   [ 0.22352946]\n",
            "   [ 0.45882356]\n",
            "   [ 0.5294118 ]]\n",
            "\n",
            "  [[-0.3333333 ]\n",
            "   [-0.16862744]\n",
            "   [ 0.05882359]\n",
            "   ...\n",
            "   [ 0.3411765 ]\n",
            "   [ 0.4039216 ]\n",
            "   [ 0.5137255 ]]\n",
            "\n",
            "  [[-0.3490196 ]\n",
            "   [-0.12941176]\n",
            "   [ 0.0196079 ]\n",
            "   ...\n",
            "   [ 0.33333337]\n",
            "   [ 0.37254906]\n",
            "   [ 0.52156866]]]\n",
            "\n",
            "\n",
            " [[[-0.4352941 ]\n",
            "   [-0.7254902 ]\n",
            "   [-0.6784314 ]\n",
            "   ...\n",
            "   [-0.69411767]\n",
            "   [-0.6862745 ]\n",
            "   [-0.56078434]]\n",
            "\n",
            "  [[-0.6862745 ]\n",
            "   [-0.64705884]\n",
            "   [-0.6784314 ]\n",
            "   ...\n",
            "   [-0.654902  ]\n",
            "   [-0.7176471 ]\n",
            "   [-0.67058825]]\n",
            "\n",
            "  [[-0.7411765 ]\n",
            "   [-0.6156863 ]\n",
            "   [-0.6862745 ]\n",
            "   ...\n",
            "   [-0.6627451 ]\n",
            "   [-0.7411765 ]\n",
            "   [-0.69411767]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.5294118 ]\n",
            "   [ 0.5058824 ]\n",
            "   [ 0.427451  ]\n",
            "   ...\n",
            "   [-0.4588235 ]\n",
            "   [-0.7254902 ]\n",
            "   [-0.7411765 ]]\n",
            "\n",
            "  [[ 0.54509807]\n",
            "   [ 0.5372549 ]\n",
            "   [ 0.5137255 ]\n",
            "   ...\n",
            "   [-0.29411763]\n",
            "   [-0.7647059 ]\n",
            "   [-0.7254902 ]]\n",
            "\n",
            "  [[ 0.6       ]\n",
            "   [ 0.5921569 ]\n",
            "   [ 0.54509807]\n",
            "   ...\n",
            "   [-0.20784312]\n",
            "   [-0.75686276]\n",
            "   [-0.6862745 ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.40392154]\n",
            "   [-0.4588235 ]\n",
            "   [-0.27058822]\n",
            "   ...\n",
            "   [-0.5529412 ]\n",
            "   [-0.58431375]\n",
            "   [-0.6       ]]\n",
            "\n",
            "  [[-0.3960784 ]\n",
            "   [-0.35686272]\n",
            "   [-0.20784312]\n",
            "   ...\n",
            "   [-0.5294118 ]\n",
            "   [-0.56078434]\n",
            "   [-0.58431375]]\n",
            "\n",
            "  [[-0.38823527]\n",
            "   [-0.24705881]\n",
            "   [-0.1372549 ]\n",
            "   ...\n",
            "   [-0.49019605]\n",
            "   [-0.5294118 ]\n",
            "   [-0.56078434]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.2235294 ]\n",
            "   [-0.2235294 ]\n",
            "   [-0.26274508]\n",
            "   ...\n",
            "   [-0.56078434]\n",
            "   [-0.5764706 ]\n",
            "   [-0.5921569 ]]\n",
            "\n",
            "  [[-0.25490195]\n",
            "   [-0.29411763]\n",
            "   [-0.30196077]\n",
            "   ...\n",
            "   [-0.5686275 ]\n",
            "   [-0.5764706 ]\n",
            "   [-0.6       ]]\n",
            "\n",
            "  [[-0.3098039 ]\n",
            "   [-0.31764704]\n",
            "   [-0.31764704]\n",
            "   ...\n",
            "   [-0.58431375]\n",
            "   [-0.58431375]\n",
            "   [-0.654902  ]]]\n",
            "\n",
            "\n",
            " [[[-0.6392157 ]\n",
            "   [-0.6392157 ]\n",
            "   [-0.654902  ]\n",
            "   ...\n",
            "   [ 0.73333335]\n",
            "   [ 0.6       ]\n",
            "   [ 0.20000005]]\n",
            "\n",
            "  [[-0.654902  ]\n",
            "   [-0.654902  ]\n",
            "   [-0.64705884]\n",
            "   ...\n",
            "   [ 0.7019608 ]\n",
            "   [ 0.77254903]\n",
            "   [ 0.49803925]]\n",
            "\n",
            "  [[-0.64705884]\n",
            "   [-0.6313726 ]\n",
            "   [-0.64705884]\n",
            "   ...\n",
            "   [ 0.70980394]\n",
            "   [ 0.8039216 ]\n",
            "   [ 0.7254902 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.10588241]\n",
            "   [ 0.254902  ]\n",
            "   [ 0.34901965]\n",
            "   ...\n",
            "   [-0.0745098 ]\n",
            "   [ 0.06666672]\n",
            "   [ 0.18431377]]\n",
            "\n",
            "  [[ 0.11372554]\n",
            "   [ 0.21568632]\n",
            "   [ 0.34901965]\n",
            "   ...\n",
            "   [-0.03529412]\n",
            "   [ 0.06666672]\n",
            "   [ 0.21568632]]\n",
            "\n",
            "  [[ 0.00392163]\n",
            "   [ 0.18431377]\n",
            "   [ 0.34901965]\n",
            "   ...\n",
            "   [ 0.01176476]\n",
            "   [ 0.06666672]\n",
            "   [ 0.254902  ]]]\n",
            "\n",
            "\n",
            " [[[-0.96862745]\n",
            "   [-0.94509804]\n",
            "   [-0.94509804]\n",
            "   ...\n",
            "   [-0.92156863]\n",
            "   [-0.9372549 ]\n",
            "   [-0.94509804]]\n",
            "\n",
            "  [[-0.9764706 ]\n",
            "   [-0.9843137 ]\n",
            "   [-0.9843137 ]\n",
            "   ...\n",
            "   [-0.94509804]\n",
            "   [-0.92156863]\n",
            "   [-0.94509804]]\n",
            "\n",
            "  [[-0.9529412 ]\n",
            "   [-0.96862745]\n",
            "   [-0.9843137 ]\n",
            "   ...\n",
            "   [-0.9137255 ]\n",
            "   [-0.92156863]\n",
            "   [-0.9607843 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.81960785]\n",
            "   [ 0.7176471 ]\n",
            "   [ 0.43529415]\n",
            "   ...\n",
            "   [-0.38823527]\n",
            "   [-0.52156866]\n",
            "   [-0.5921569 ]]\n",
            "\n",
            "  [[ 0.8509804 ]\n",
            "   [ 0.7490196 ]\n",
            "   [ 0.5764706 ]\n",
            "   ...\n",
            "   [-0.54509807]\n",
            "   [-0.6313726 ]\n",
            "   [-0.70980394]]\n",
            "\n",
            "  [[ 0.8352941 ]\n",
            "   [ 0.7647059 ]\n",
            "   [ 0.64705884]\n",
            "   ...\n",
            "   [-0.7019608 ]\n",
            "   [-0.7647059 ]\n",
            "   [-0.827451  ]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t--o7TREKTu2",
        "outputId": "093d8091-8229-4410-b898-25bab791cc9f"
      },
      "source": [
        "print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validasi (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "test (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "train (28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ofOj3-fRREN"
      },
      "source": [
        "#hyperparameter and callback\n",
        "batch_size = 64\n",
        "num_epochs = 60\n",
        "input_shape = (48, 48, 1)\n",
        "num_classes = 7\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXikieAnRbYs"
      },
      "source": [
        "#Compile the model.\n",
        "\n",
        "\n",
        "from keras.optimizers import Adam, SGD\n",
        "model = ResNet50(input_shape = (48, 48, 1), classes = 7)\n",
        "optimizer = SGD(learning_rate=0.001)\n",
        "model.compile(optimizer= optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5JTFulCRbiX"
      },
      "source": [
        "\"\"\"#kita mau save model callbacks\n",
        "import os\n",
        "try:\n",
        "  os.mkdir('/content/drive/MyDrive/Fer2013_backup/scratchcheckpoint')\n",
        "except:\n",
        "  pass\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkceBySwRgFO"
      },
      "source": [
        "\"\"\"file_name = 'Best_Model_resnet50oriScracth_aug_tipe2.h5'\n",
        "\n",
        "checkpoint_path = os.path.join('checkpoint',file_name)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an3sDjjGRgO1"
      },
      "source": [
        "\"\"\"call_back = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
        "                                               monitor='val_accuracy',\n",
        "                                               verbose=1,\n",
        "                                               save_freq='epoch',\n",
        "                                               save_best_only=True,\n",
        "                                               save_weights_only=False,\n",
        "                                               mode='max')\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nefC0ZE8RgX5",
        "outputId": "2a9d973e-f4be-4206-ea2f-c7ee924577eb"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 46, 46, 128)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 46, 46, 128)  0           activation_3[0][0]               \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 46, 46, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 46, 46, 128)  0           activation_6[0][0]               \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 46, 46, 128)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 23, 23, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 23, 23, 256)  0           activation_12[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 23, 23, 256)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 23, 23, 256)  0           activation_15[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 23, 23, 256)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 23, 23, 256)  0           activation_18[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 23, 23, 256)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 12, 12, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 12, 12, 512)  0           activation_24[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 12, 12, 512)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 12, 12, 512)  0           activation_27[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 12, 12, 512)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 12, 12, 512)  0           activation_30[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 12, 12, 512)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 12, 12, 512)  0           activation_33[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 12, 12, 512)  0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 12, 12, 512)  0           activation_36[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 12, 12, 512)  0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 6, 6, 1024)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 6, 6, 1024)   0           activation_42[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 6, 6, 1024)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 6, 6, 1024)   0           activation_45[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 6, 6, 1024)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVvpTr7-RkdR"
      },
      "source": [
        "\"\"\"history = model.fit(data_generator.flow(xtrain, ytrain,),\n",
        "                        steps_per_epoch=len(xtrain) / batch_size,\n",
        "                        epochs=num_epochs, verbose=1,callbacks=call_back,\n",
        "                        validation_data= (xtest,ytest))\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_tXyjuSz_IP",
        "outputId": "729e5c34-1e6b-4757-c7ec-c680e2d73f97"
      },
      "source": [
        "history = model.fit(\n",
        "    data_generator.flow(xtrain, ytrain,),\n",
        "    steps_per_epoch=len(xtrain) / batch_size,\n",
        "    epochs=num_epochs, \n",
        "    verbose=1,\n",
        "    validation_data= (x_val,y_val))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "448/448 [==============================] - 106s 114ms/step - loss: 2.1944 - accuracy: 0.1997 - val_loss: 1.8442 - val_accuracy: 0.2424\n",
            "Epoch 2/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.8864 - accuracy: 0.2235 - val_loss: 2.0395 - val_accuracy: 0.2143\n",
            "Epoch 3/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.8402 - accuracy: 0.2328 - val_loss: 1.8255 - val_accuracy: 0.2379\n",
            "Epoch 4/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.8095 - accuracy: 0.2543 - val_loss: 1.8192 - val_accuracy: 0.2410\n",
            "Epoch 5/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.8017 - accuracy: 0.2477 - val_loss: 1.8296 - val_accuracy: 0.2332\n",
            "Epoch 6/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.7950 - accuracy: 0.2529 - val_loss: 1.7974 - val_accuracy: 0.2474\n",
            "Epoch 7/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7896 - accuracy: 0.2586 - val_loss: 1.7917 - val_accuracy: 0.2491\n",
            "Epoch 8/60\n",
            "448/448 [==============================] - 49s 109ms/step - loss: 1.7892 - accuracy: 0.2601 - val_loss: 1.7738 - val_accuracy: 0.2586\n",
            "Epoch 9/60\n",
            "448/448 [==============================] - 49s 110ms/step - loss: 1.7769 - accuracy: 0.2594 - val_loss: 1.7837 - val_accuracy: 0.2538\n",
            "Epoch 10/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7812 - accuracy: 0.2596 - val_loss: 1.7741 - val_accuracy: 0.2558\n",
            "Epoch 11/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7747 - accuracy: 0.2697 - val_loss: 1.7787 - val_accuracy: 0.2530\n",
            "Epoch 12/60\n",
            "448/448 [==============================] - 49s 110ms/step - loss: 1.7798 - accuracy: 0.2620 - val_loss: 1.7661 - val_accuracy: 0.2669\n",
            "Epoch 13/60\n",
            "448/448 [==============================] - 49s 110ms/step - loss: 1.7654 - accuracy: 0.2686 - val_loss: 1.7685 - val_accuracy: 0.2664\n",
            "Epoch 14/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7698 - accuracy: 0.2714 - val_loss: 1.7547 - val_accuracy: 0.2680\n",
            "Epoch 15/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.7760 - accuracy: 0.2676 - val_loss: 1.7577 - val_accuracy: 0.2725\n",
            "Epoch 16/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7610 - accuracy: 0.2755 - val_loss: 1.7450 - val_accuracy: 0.2770\n",
            "Epoch 17/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7594 - accuracy: 0.2765 - val_loss: 1.7447 - val_accuracy: 0.2823\n",
            "Epoch 18/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7476 - accuracy: 0.2795 - val_loss: 1.7418 - val_accuracy: 0.2814\n",
            "Epoch 19/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.7500 - accuracy: 0.2737 - val_loss: 1.7276 - val_accuracy: 0.2845\n",
            "Epoch 20/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7400 - accuracy: 0.2848 - val_loss: 1.7354 - val_accuracy: 0.2811\n",
            "Epoch 21/60\n",
            "448/448 [==============================] - 49s 110ms/step - loss: 1.7437 - accuracy: 0.2871 - val_loss: 1.7216 - val_accuracy: 0.2881\n",
            "Epoch 22/60\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.7447 - accuracy: 0.2812 - val_loss: 1.7207 - val_accuracy: 0.2965\n",
            "Epoch 23/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7409 - accuracy: 0.2887 - val_loss: 1.7406 - val_accuracy: 0.2825\n",
            "Epoch 24/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7435 - accuracy: 0.2830 - val_loss: 1.7233 - val_accuracy: 0.2856\n",
            "Epoch 25/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7210 - accuracy: 0.3022 - val_loss: 1.7296 - val_accuracy: 0.2825\n",
            "Epoch 26/60\n",
            "448/448 [==============================] - 49s 110ms/step - loss: 1.7329 - accuracy: 0.2898 - val_loss: 1.7098 - val_accuracy: 0.3018\n",
            "Epoch 27/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7346 - accuracy: 0.2913 - val_loss: 1.7071 - val_accuracy: 0.3020\n",
            "Epoch 28/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.7289 - accuracy: 0.2991 - val_loss: 1.7122 - val_accuracy: 0.3040\n",
            "Epoch 29/60\n",
            "448/448 [==============================] - 50s 110ms/step - loss: 1.7143 - accuracy: 0.3000 - val_loss: 1.6992 - val_accuracy: 0.3062\n",
            "Epoch 30/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7225 - accuracy: 0.3003 - val_loss: 1.7012 - val_accuracy: 0.2995\n",
            "Epoch 31/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7222 - accuracy: 0.2997 - val_loss: 1.7212 - val_accuracy: 0.2909\n",
            "Epoch 32/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7156 - accuracy: 0.2948 - val_loss: 1.6948 - val_accuracy: 0.3070\n",
            "Epoch 33/60\n",
            "448/448 [==============================] - 49s 110ms/step - loss: 1.7061 - accuracy: 0.3077 - val_loss: 1.7046 - val_accuracy: 0.3026\n",
            "Epoch 34/60\n",
            "448/448 [==============================] - 50s 110ms/step - loss: 1.7196 - accuracy: 0.2978 - val_loss: 1.6810 - val_accuracy: 0.3126\n",
            "Epoch 35/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.7147 - accuracy: 0.3130 - val_loss: 1.6901 - val_accuracy: 0.3123\n",
            "Epoch 36/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7235 - accuracy: 0.3001 - val_loss: 1.6854 - val_accuracy: 0.3151\n",
            "Epoch 37/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7010 - accuracy: 0.3067 - val_loss: 1.6814 - val_accuracy: 0.3079\n",
            "Epoch 38/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7046 - accuracy: 0.3096 - val_loss: 1.6803 - val_accuracy: 0.3062\n",
            "Epoch 39/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7061 - accuracy: 0.3026 - val_loss: 1.6802 - val_accuracy: 0.3149\n",
            "Epoch 40/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.6968 - accuracy: 0.3141 - val_loss: 1.6813 - val_accuracy: 0.3137\n",
            "Epoch 41/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.6982 - accuracy: 0.3062 - val_loss: 1.6702 - val_accuracy: 0.3165\n",
            "Epoch 42/60\n",
            "448/448 [==============================] - 49s 110ms/step - loss: 1.6898 - accuracy: 0.3194 - val_loss: 1.6767 - val_accuracy: 0.3090\n",
            "Epoch 43/60\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.6881 - accuracy: 0.3198 - val_loss: 1.6670 - val_accuracy: 0.3221\n",
            "Epoch 44/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.6897 - accuracy: 0.3092 - val_loss: 1.6586 - val_accuracy: 0.3268\n",
            "Epoch 45/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.6879 - accuracy: 0.3193 - val_loss: 1.6658 - val_accuracy: 0.3282\n",
            "Epoch 46/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.6903 - accuracy: 0.3169 - val_loss: 1.6571 - val_accuracy: 0.3324\n",
            "Epoch 47/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.6868 - accuracy: 0.3274 - val_loss: 1.6566 - val_accuracy: 0.3277\n",
            "Epoch 48/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.6766 - accuracy: 0.3253 - val_loss: 1.6542 - val_accuracy: 0.3252\n",
            "Epoch 49/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 1.6869 - accuracy: 0.3154 - val_loss: 1.6540 - val_accuracy: 0.3341\n",
            "Epoch 50/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.6781 - accuracy: 0.3194 - val_loss: 1.6465 - val_accuracy: 0.3402\n",
            "Epoch 51/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.6800 - accuracy: 0.3176 - val_loss: 1.6417 - val_accuracy: 0.3366\n",
            "Epoch 52/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.6730 - accuracy: 0.3262 - val_loss: 1.6567 - val_accuracy: 0.3316\n",
            "Epoch 53/60\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.6699 - accuracy: 0.3258 - val_loss: 1.6415 - val_accuracy: 0.3346\n",
            "Epoch 54/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.6653 - accuracy: 0.3329 - val_loss: 1.6506 - val_accuracy: 0.3357\n",
            "Epoch 55/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.6654 - accuracy: 0.3311 - val_loss: 1.6300 - val_accuracy: 0.3511\n",
            "Epoch 56/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.6682 - accuracy: 0.3307 - val_loss: 1.6639 - val_accuracy: 0.3332\n",
            "Epoch 57/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.6584 - accuracy: 0.3289 - val_loss: 1.6437 - val_accuracy: 0.3274\n",
            "Epoch 58/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.6555 - accuracy: 0.3314 - val_loss: 1.6390 - val_accuracy: 0.3461\n",
            "Epoch 59/60\n",
            "448/448 [==============================] - 49s 110ms/step - loss: 1.6598 - accuracy: 0.3330 - val_loss: 1.6265 - val_accuracy: 0.3544\n",
            "Epoch 60/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.6491 - accuracy: 0.3406 - val_loss: 1.6230 - val_accuracy: 0.3566\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZvluWhSRkq4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "outputId": "7acf4e4f-5c74-4031-8fac-0638709f4439"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "model.save('/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50AUGScracthSGD4.h5')\n",
        "\n",
        "#gffhgffkjkjdshufdfh\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "num_epochs = range(len(accuracy))\n",
        "plt.plot(num_epochs, accuracy, 'r', label='Training acc')\n",
        "plt.plot(num_epochs, val_accuracy, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(num_epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(num_epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Pzozx-30LSe",
        "outputId": "3704572b-aba4-49d5-ba37-b218ecb7214d"
      },
      "source": [
        "testloss = model.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "trainloss = model.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(trainloss[0]))\n",
        "print(\"Train Acc: \" + str(trainloss[1]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 3s 26ms/step - loss: 1.6355 - accuracy: 0.3500\n",
            "Test Loss 1.6354917287826538\n",
            "Test Acc: 0.349958211183548\n",
            "898/898 [==============================] - 24s 26ms/step - loss: 1.6199 - accuracy: 0.3572\n",
            "Train Loss 1.6198561191558838\n",
            "Train Acc: 0.3572050631046295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ6YCHax59vt",
        "outputId": "9c254847-43cb-43a7-c581-beeaf97c9d58"
      },
      "source": [
        "from keras.models import load_model\n",
        "model_load = load_model('/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50AUGScracthSGD4.h5')\n",
        "\n",
        "model_load.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 46, 46, 128)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 46, 46, 128)  0           activation_3[0][0]               \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 46, 46, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 46, 46, 128)  0           activation_6[0][0]               \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 46, 46, 128)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 23, 23, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 23, 23, 256)  0           activation_12[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 23, 23, 256)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 23, 23, 256)  0           activation_15[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 23, 23, 256)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 23, 23, 256)  0           activation_18[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 23, 23, 256)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 12, 12, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 12, 12, 512)  0           activation_24[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 12, 12, 512)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 12, 12, 512)  0           activation_27[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 12, 12, 512)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 12, 12, 512)  0           activation_30[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 12, 12, 512)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 12, 12, 512)  0           activation_33[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 12, 12, 512)  0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 12, 12, 512)  0           activation_36[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 12, 12, 512)  0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 6, 6, 1024)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 6, 6, 1024)   0           activation_42[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 6, 6, 1024)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 6, 6, 1024)   0           activation_45[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 6, 6, 1024)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fpz7ehkO6Cat",
        "outputId": "978b277b-c9be-4165-d480-b6c78634dac9"
      },
      "source": [
        "\n",
        "testloss = model_load.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "\n",
        "testloss = model_load.evaluate(xtrain, ytrain) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 7s 26ms/step - loss: 1.6355 - accuracy: 0.3500\n",
            "Test Loss 1.6354917287826538\n",
            "Test Acc: 0.349958211183548\n",
            "898/898 [==============================] - 24s 26ms/step - loss: 1.6199 - accuracy: 0.3572\n",
            "Test Loss 1.6198561191558838\n",
            "Test Acc: 0.3572050631046295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrQ63iiV6F-W",
        "outputId": "cb4537a5-13bc-4494-8d60-5c50b0d4d3cd"
      },
      "source": [
        "testlosz = model_load.evaluate(xtrain, ytrain) \n",
        "print(\"Test Loss \" + str(testlosz[0]))\n",
        "print(\"Test Acc: \" + str(testlosz[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1010/1010 [==============================] - 15s 15ms/step - loss: 1.6199 - accuracy: 0.3715\n",
            "Test Loss 1.6198930740356445\n",
            "Test Acc: 0.3715090751647949\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDwmru9p0gyj",
        "outputId": "2a791150-af50-4ce1-f8e0-158a7bc3420f"
      },
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "y_pred1 = model_load.predict(xtest)\n",
        "y_pred = np.argmax(y_pred1, axis=1)\n",
        "\n",
        "# Print f1, precision, and recall scores s\n",
        "print(precision_score(ytest, y_pred , average=\"macro\"))\n",
        "print(recall_score(ytest, y_pred , average=\"macro\"))\n",
        "print(f1_score(ytest, y_pred , average=\"macro\"))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2775807606803474\n",
            "0.28320513145036535\n",
            "0.2650076787185113\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COc9HoDyhWQ2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or0mwBSoaa6U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICOVlE12cOpZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}