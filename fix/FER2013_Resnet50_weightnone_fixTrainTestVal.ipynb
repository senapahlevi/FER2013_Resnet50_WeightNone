{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER2013_Resnet50_weightnone_fixTrainTestVal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-Qn1jsBTIBl0b7myLQxqa8WjCcfbamqM",
      "authorship_tag": "ABX9TyNPm3eFTZFHpRNzob1iH2d8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b86nukQOxN7l"
      },
      "source": [
        "Resnet-50 From Scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p8gxtGy0TWP",
        "outputId": "de079ca5-af11-4662-aaf8-d90f38ba07aa"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "inputFolder = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth' \n",
        "for root, directories, filenames in os.walk(inputFolder): \n",
        "    for filename in filenames: print(os.path.join(root,filename))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Best_Model_resnet50Scracth1again.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe4.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth1again.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50ScracthSGD1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50AUGScracthadam3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD1try2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD4.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50oriScracth_sena2.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsiscWIMBDX2",
        "outputId": "f4c8a9c9-901f-4f44-d717-a645a446e1da"
      },
      "source": [
        "%cd /content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "wLMSe510xNCJ",
        "outputId": "3da9f6f5-cb75-4f61-d978-1e7de9a074fc"
      },
      "source": [
        "#Create a directory to save our generated models.dasdas\n",
        "\n",
        "#os.mkdir(\"./modelscracth\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-cf55f19f3613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#os.mkdir(\"./modelscracth\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ls' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_kluusLxM1B",
        "outputId": "27236e39-378c-4f8b-d1ef-3f51af3fa721"
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:400: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfUSF_tAxNMP"
      },
      "source": [
        "#Define the identity block helper function.\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "   \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VdYtzhn1F0I"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path \n",
        "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b',padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd-O8ZMx1GAW"
      },
      "source": [
        "def ResNet50(input_shape = (48,48,1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    #X = ZeroPadding2D((1, 1))(X_input)\n",
        "    X = X_input\n",
        "    # Stage 1\n",
        "\n",
        "    X = Conv2D(8, (3, 3), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # removed maxpool\n",
        "    #X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='c')\n",
        "\n",
        "\n",
        "    # Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [64,64,256], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL . \n",
        "    X = AveragePooling2D((2,2), name='avg_pool')(X)\n",
        "    \n",
        "    # output layerds\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(512, activation = 'relu', name='fc1024' , kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GKsSwtp-GuL"
      },
      "source": [
        "\"\"\"def ResNet50ori(input_shape = (48, 48, 1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns: dsdsf\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50ori')\n",
        "\n",
        "    return model\"\"\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3oWTDXlyBHM2",
        "outputId": "654bdb8d-36ef-4bfe-f6f5-882fb3493438"
      },
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        " \n",
        "dataset_path = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv'\n",
        "image_size=(48,48)\n",
        "#batch_size = 64\n",
        "\n",
        "def load_fer2013():\n",
        "    data = pd.read_csv(dataset_path)\n",
        "    data = (data[data['pixels'].notnull()])\n",
        "    pixels = data['pixels'].tolist()\n",
        "    width, height = 48, 48\n",
        "    faces = []\n",
        "    for pixel_sequence in pixels:\n",
        "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "        face = np.asarray(face).reshape(width, height)\n",
        "        face = cv2.resize(face.astype('uint8'),image_size)\n",
        "        faces.append(face.astype('float32'))\n",
        "    faces = np.asarray(faces)\n",
        "    faces = np.expand_dims(faces, -1)\n",
        "    emotions = (data['emotion'])#.values\n",
        "    return faces, emotions\n",
        " \n",
        "def preprocess_input(x, v2=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if v2:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x\n",
        " \n",
        "faces, emotions = load_fer2013()\n",
        "faces = preprocess_input(faces)\n",
        "#xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
        "#Data Augumentation\n",
        "data_generator = ImageDataGenerator(\n",
        "                        rotation_range=10,\n",
        "                        shear_range = 10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True)\n",
        "\"\"\"data_generator = ImageDataGenerator( )\n",
        "\"\"\""
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'data_generator = ImageDataGenerator( )\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWLhavr-rSF5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "895f7f85-9930-46ca-c552-cbb571846a4e"
      },
      "source": [
        "\"\"\"\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.1,)\n",
        "x_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1,)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nxtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.1,)\\nx_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1,)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "RGhnYFXgaqL9",
        "outputId": "0e60da2f-3a44-4d06-910b-2e0f2fa4191a"
      },
      "source": [
        "\"\"\"print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (y_train.shape)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'print (\"validasi\",x_val.shape)\\nprint (y_val.shape)\\nprint (\"test\",xtest.shape)\\nprint (ytest.shape)\\nprint (\"train\",xtrain.shape)\\nprint (y_train.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rDS3hqhDSteM",
        "outputId": "e0ebe502-bc93-441d-f3df-b0fc62612b9a"
      },
      "source": [
        "train_ratio = 0.80\n",
        "validation_ratio = 0.10\n",
        "test_ratio = 0.10\n",
        "\n",
        "# train is now 75% of the entire data set\n",
        "# the _junk suffix means that we drop that variable completely # the _junk suffix means that we drop that variable completely\n",
        "#x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=1 - train_ratio)\n",
        "\n",
        "# test is now 10% of the initial data set\n",
        "# validation is now 15% of the initial data set\n",
        "#x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "x_val, xtest, y_val, ytest = train_test_split(xtest, ytest, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "\n",
        "print(xtrain, x_val, xtest)\n",
        "\n",
        "\"\"\"X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2\"\"\""
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[ 0.01176476]\n",
            "   [ 0.02745104]\n",
            "   [-0.01176471]\n",
            "   ...\n",
            "   [-0.92156863]\n",
            "   [-0.32549018]\n",
            "   [ 0.12941182]]\n",
            "\n",
            "  [[ 0.03529418]\n",
            "   [ 0.02745104]\n",
            "   [ 0.00392163]\n",
            "   ...\n",
            "   [-0.92156863]\n",
            "   [-0.20784312]\n",
            "   [ 0.05098045]]\n",
            "\n",
            "  [[ 0.04313731]\n",
            "   [ 0.02745104]\n",
            "   [ 0.082353  ]\n",
            "   ...\n",
            "   [-0.9843137 ]\n",
            "   [-0.4823529 ]\n",
            "   [ 0.05098045]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.92941177]\n",
            "   [-0.9764706 ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.4588235 ]\n",
            "   [-0.41176468]\n",
            "   [-0.41176468]]\n",
            "\n",
            "  [[-0.96862745]\n",
            "   [-0.9764706 ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.6       ]\n",
            "   [-0.4588235 ]\n",
            "   [-0.38039213]]\n",
            "\n",
            "  [[-0.9529412 ]\n",
            "   [-0.96862745]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.7411765 ]\n",
            "   [-0.6156863 ]\n",
            "   [-0.5294118 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.05882359]\n",
            "   [-0.38039213]\n",
            "   [-0.54509807]\n",
            "   ...\n",
            "   [ 0.1686275 ]\n",
            "   [ 0.16078436]\n",
            "   [ 0.16078436]]\n",
            "\n",
            "  [[ 0.00392163]\n",
            "   [-0.5372549 ]\n",
            "   [-0.5764706 ]\n",
            "   ...\n",
            "   [ 0.12156868]\n",
            "   [ 0.1686275 ]\n",
            "   [ 0.16078436]]\n",
            "\n",
            "  [[-0.26274508]\n",
            "   [-0.62352943]\n",
            "   [-0.58431375]\n",
            "   ...\n",
            "   [-0.08235294]\n",
            "   [ 0.16078436]\n",
            "   [ 0.16078436]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.082353  ]\n",
            "   [ 0.082353  ]\n",
            "   [ 0.09803927]\n",
            "   ...\n",
            "   [-0.36470586]\n",
            "   [-0.372549  ]\n",
            "   [-0.372549  ]]\n",
            "\n",
            "  [[ 0.082353  ]\n",
            "   [ 0.05882359]\n",
            "   [ 0.04313731]\n",
            "   ...\n",
            "   [-0.29411763]\n",
            "   [-0.54509807]\n",
            "   [-0.6784314 ]]\n",
            "\n",
            "  [[-0.01176471]\n",
            "   [-0.01176471]\n",
            "   [ 0.04313731]\n",
            "   ...\n",
            "   [-0.03529412]\n",
            "   [-0.1372549 ]\n",
            "   [-0.42745095]]]\n",
            "\n",
            "\n",
            " [[[ 0.99215686]\n",
            "   [ 0.8509804 ]\n",
            "   [ 0.3411765 ]\n",
            "   ...\n",
            "   [ 0.12156868]\n",
            "   [ 0.48235297]\n",
            "   [ 0.5372549 ]]\n",
            "\n",
            "  [[ 0.9764706 ]\n",
            "   [ 0.8745098 ]\n",
            "   [ 0.22352946]\n",
            "   ...\n",
            "   [-0.04313725]\n",
            "   [ 0.19215691]\n",
            "   [ 0.43529415]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 0.78039217]\n",
            "   [ 0.00392163]\n",
            "   ...\n",
            "   [-0.17647058]\n",
            "   [ 0.11372554]\n",
            "   [ 0.6862745 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.6313726 ]\n",
            "   [ 0.5764706 ]\n",
            "   [ 0.5921569 ]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 0.60784316]\n",
            "   [ 0.5921569 ]\n",
            "   [ 0.6       ]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 0.4901961 ]\n",
            "   [ 0.5686275 ]\n",
            "   [ 0.6       ]\n",
            "   ...\n",
            "   [ 0.99215686]\n",
            "   [ 0.99215686]\n",
            "   [ 1.        ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.54509807]\n",
            "   [-0.64705884]\n",
            "   [-0.62352943]\n",
            "   ...\n",
            "   [-0.6862745 ]\n",
            "   [-0.58431375]\n",
            "   [-0.6       ]]\n",
            "\n",
            "  [[-0.5921569 ]\n",
            "   [-0.5686275 ]\n",
            "   [-0.7019608 ]\n",
            "   ...\n",
            "   [-0.16862744]\n",
            "   [ 0.1686275 ]\n",
            "   [ 0.082353  ]]\n",
            "\n",
            "  [[-0.7019608 ]\n",
            "   [-0.27843136]\n",
            "   [-0.45098037]\n",
            "   ...\n",
            "   [-0.1607843 ]\n",
            "   [-0.2235294 ]\n",
            "   [ 0.2313726 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.5529412 ]\n",
            "   [-0.69411767]\n",
            "   [-0.5294118 ]\n",
            "   ...\n",
            "   [-0.58431375]\n",
            "   [-0.6392157 ]\n",
            "   [-0.54509807]]\n",
            "\n",
            "  [[-0.62352943]\n",
            "   [-0.7176471 ]\n",
            "   [-0.5921569 ]\n",
            "   ...\n",
            "   [-0.49019605]\n",
            "   [-0.5058824 ]\n",
            "   [-0.58431375]]\n",
            "\n",
            "  [[-0.5294118 ]\n",
            "   [-0.67058825]\n",
            "   [-0.52156866]\n",
            "   ...\n",
            "   [-0.12156862]\n",
            "   [-0.52156866]\n",
            "   [-0.5921569 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.7490196 ]\n",
            "   [ 0.52156866]\n",
            "   [-0.00392157]\n",
            "   ...\n",
            "   [-0.94509804]\n",
            "   [-0.9137255 ]\n",
            "   [-0.78039217]]\n",
            "\n",
            "  [[ 0.654902  ]\n",
            "   [ 0.3411765 ]\n",
            "   [-0.1372549 ]\n",
            "   ...\n",
            "   [-0.92156863]\n",
            "   [-0.92941177]\n",
            "   [-0.7882353 ]]\n",
            "\n",
            "  [[ 0.5058824 ]\n",
            "   [ 0.1686275 ]\n",
            "   [-0.21568626]\n",
            "   ...\n",
            "   [-0.8666667 ]\n",
            "   [-0.92156863]\n",
            "   [-0.84313726]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.54509807]\n",
            "   [-0.7490196 ]\n",
            "   [-0.7411765 ]\n",
            "   ...\n",
            "   [ 0.8666667 ]\n",
            "   [ 0.45882356]\n",
            "   [-0.24705881]]\n",
            "\n",
            "  [[-0.52156866]\n",
            "   [-0.6862745 ]\n",
            "   [-0.7254902 ]\n",
            "   ...\n",
            "   [ 0.5137255 ]\n",
            "   [ 0.254902  ]\n",
            "   [-0.49019605]]\n",
            "\n",
            "  [[-0.5058824 ]\n",
            "   [-0.6156863 ]\n",
            "   [-0.7411765 ]\n",
            "   ...\n",
            "   [ 0.3176471 ]\n",
            "   [-0.01960784]\n",
            "   [-0.70980394]]]\n",
            "\n",
            "\n",
            " [[[-0.0745098 ]\n",
            "   [-0.03529412]\n",
            "   [-0.05098039]\n",
            "   ...\n",
            "   [-0.05098039]\n",
            "   [ 0.082353  ]\n",
            "   [ 0.12941182]]\n",
            "\n",
            "  [[-0.0745098 ]\n",
            "   [-0.06666666]\n",
            "   [-0.05882353]\n",
            "   ...\n",
            "   [-0.03529412]\n",
            "   [ 0.01176476]\n",
            "   [ 0.05882359]]\n",
            "\n",
            "  [[-0.23137254]\n",
            "   [-0.16862744]\n",
            "   [ 0.09019613]\n",
            "   ...\n",
            "   [ 0.00392163]\n",
            "   [ 0.02745104]\n",
            "   [ 0.04313731]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.3333333 ]\n",
            "   [-0.52156866]\n",
            "   [-0.654902  ]\n",
            "   ...\n",
            "   [ 0.75686276]\n",
            "   [ 0.69411767]\n",
            "   [ 0.427451  ]]\n",
            "\n",
            "  [[-0.14509803]\n",
            "   [-0.2862745 ]\n",
            "   [-0.5058824 ]\n",
            "   ...\n",
            "   [ 0.7411765 ]\n",
            "   [ 0.60784316]\n",
            "   [-0.35686272]]\n",
            "\n",
            "  [[-0.15294117]\n",
            "   [-0.12156862]\n",
            "   [-0.12156862]\n",
            "   ...\n",
            "   [ 0.7254902 ]\n",
            "   [-0.12156862]\n",
            "   [-0.92156863]]]] [[[[-0.2235294 ]\n",
            "   [ 0.19215691]\n",
            "   [ 0.36470592]\n",
            "   ...\n",
            "   [-0.96862745]\n",
            "   [-0.9843137 ]\n",
            "   [-0.9764706 ]]\n",
            "\n",
            "  [[-0.00392157]\n",
            "   [ 0.30196083]\n",
            "   [ 0.03529418]\n",
            "   ...\n",
            "   [-0.8745098 ]\n",
            "   [-0.9372549 ]\n",
            "   [-0.90588236]]\n",
            "\n",
            "  [[ 0.254902  ]\n",
            "   [ 0.02745104]\n",
            "   [-0.32549018]\n",
            "   ...\n",
            "   [-0.8509804 ]\n",
            "   [-0.81960785]\n",
            "   [-0.81960785]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.70980394]\n",
            "   [-0.7254902 ]\n",
            "   [-0.75686276]\n",
            "   ...\n",
            "   [-0.7019608 ]\n",
            "   [-0.7254902 ]\n",
            "   [-0.7176471 ]]\n",
            "\n",
            "  [[-0.69411767]\n",
            "   [-0.7019608 ]\n",
            "   [-0.7411765 ]\n",
            "   ...\n",
            "   [-0.6784314 ]\n",
            "   [-0.7019608 ]\n",
            "   [-0.7254902 ]]\n",
            "\n",
            "  [[-0.6784314 ]\n",
            "   [-0.6862745 ]\n",
            "   [-0.7176471 ]\n",
            "   ...\n",
            "   [-0.6862745 ]\n",
            "   [-0.6862745 ]\n",
            "   [-0.7176471 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.21568632]\n",
            "   [ 0.254902  ]\n",
            "   [ 0.26274514]\n",
            "   ...\n",
            "   [-0.52156866]\n",
            "   [-0.4980392 ]\n",
            "   [-0.49019605]]\n",
            "\n",
            "  [[ 0.22352946]\n",
            "   [ 0.254902  ]\n",
            "   [ 0.27843142]\n",
            "   ...\n",
            "   [-0.5137255 ]\n",
            "   [-0.5058824 ]\n",
            "   [-0.5137255 ]]\n",
            "\n",
            "  [[ 0.22352946]\n",
            "   [ 0.27843142]\n",
            "   [ 0.2941177 ]\n",
            "   ...\n",
            "   [-0.5058824 ]\n",
            "   [-0.52156866]\n",
            "   [-0.52156866]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.27058828]\n",
            "   [ 0.28627455]\n",
            "   [ 0.2941177 ]\n",
            "   ...\n",
            "   [-0.4980392 ]\n",
            "   [-0.8980392 ]\n",
            "   [-0.8666667 ]]\n",
            "\n",
            "  [[ 0.15294123]\n",
            "   [ 0.20000005]\n",
            "   [ 0.27058828]\n",
            "   ...\n",
            "   [-0.7176471 ]\n",
            "   [-0.88235295]\n",
            "   [-0.85882354]]\n",
            "\n",
            "  [[ 0.17647064]\n",
            "   [ 0.18431377]\n",
            "   [ 0.19215691]\n",
            "   ...\n",
            "   [-0.7647059 ]\n",
            "   [-0.8666667 ]\n",
            "   [-0.85882354]]]\n",
            "\n",
            "\n",
            " [[[ 0.45098042]\n",
            "   [ 0.18431377]\n",
            "   [ 0.11372554]\n",
            "   ...\n",
            "   [-0.05882353]\n",
            "   [ 0.20784318]\n",
            "   [ 0.37254906]]\n",
            "\n",
            "  [[ 0.27058828]\n",
            "   [ 0.13725495]\n",
            "   [-0.05882353]\n",
            "   ...\n",
            "   [ 0.20784318]\n",
            "   [ 0.28627455]\n",
            "   [ 0.45882356]]\n",
            "\n",
            "  [[ 0.15294123]\n",
            "   [-0.00392157]\n",
            "   [-0.2235294 ]\n",
            "   ...\n",
            "   [ 0.2941177 ]\n",
            "   [ 0.3176471 ]\n",
            "   [ 0.5294118 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.427451  ]\n",
            "   [ 0.4431373 ]\n",
            "   [ 0.41176474]\n",
            "   ...\n",
            "   [ 0.17647064]\n",
            "   [ 0.14509809]\n",
            "   [ 0.1686275 ]]\n",
            "\n",
            "  [[ 0.45098042]\n",
            "   [ 0.45098042]\n",
            "   [ 0.4039216 ]\n",
            "   ...\n",
            "   [ 0.082353  ]\n",
            "   [ 0.00392163]\n",
            "   [ 0.01176476]]\n",
            "\n",
            "  [[ 0.47450984]\n",
            "   [ 0.4666667 ]\n",
            "   [ 0.45098042]\n",
            "   ...\n",
            "   [ 0.09803927]\n",
            "   [ 0.03529418]\n",
            "   [ 0.02745104]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.12941176]\n",
            "   [-0.1372549 ]\n",
            "   [-0.1607843 ]\n",
            "   ...\n",
            "   [-0.84313726]\n",
            "   [-0.8039216 ]\n",
            "   [-0.27058822]]\n",
            "\n",
            "  [[-0.09019607]\n",
            "   [-0.11372548]\n",
            "   [-0.2235294 ]\n",
            "   ...\n",
            "   [-0.77254903]\n",
            "   [-0.8980392 ]\n",
            "   [-0.44313723]]\n",
            "\n",
            "  [[-0.06666666]\n",
            "   [-0.09803921]\n",
            "   [-0.1372549 ]\n",
            "   ...\n",
            "   [-0.84313726]\n",
            "   [-0.88235295]\n",
            "   [-0.5372549 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.13725495]\n",
            "   [ 0.15294123]\n",
            "   [ 0.24705887]\n",
            "   ...\n",
            "   [ 0.01176476]\n",
            "   [ 0.05882359]\n",
            "   [ 0.05098045]]\n",
            "\n",
            "  [[ 0.2313726 ]\n",
            "   [ 0.1686275 ]\n",
            "   [ 0.2313726 ]\n",
            "   ...\n",
            "   [ 0.35686278]\n",
            "   [ 0.01176476]\n",
            "   [ 0.06666672]]\n",
            "\n",
            "  [[ 0.27843142]\n",
            "   [ 0.22352946]\n",
            "   [ 0.28627455]\n",
            "   ...\n",
            "   [ 0.6862745 ]\n",
            "   [ 0.52156866]\n",
            "   [ 0.12941182]]]\n",
            "\n",
            "\n",
            " [[[-0.3098039 ]\n",
            "   [-0.36470586]\n",
            "   [-0.38823527]\n",
            "   ...\n",
            "   [-0.46666664]\n",
            "   [-0.3960784 ]\n",
            "   [-0.02745098]]\n",
            "\n",
            "  [[-0.31764704]\n",
            "   [-0.3490196 ]\n",
            "   [-0.35686272]\n",
            "   ...\n",
            "   [-0.4588235 ]\n",
            "   [-0.35686272]\n",
            "   [ 0.00392163]]\n",
            "\n",
            "  [[-0.24705881]\n",
            "   [-0.24705881]\n",
            "   [-0.31764704]\n",
            "   ...\n",
            "   [-0.45098037]\n",
            "   [-0.38039213]\n",
            "   [ 0.12941182]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.5137255 ]\n",
            "   [-0.92941177]\n",
            "   [-0.8666667 ]\n",
            "   ...\n",
            "   [-0.5529412 ]\n",
            "   [-0.15294117]\n",
            "   [-0.52156866]]\n",
            "\n",
            "  [[-0.36470586]\n",
            "   [-0.7254902 ]\n",
            "   [-0.9607843 ]\n",
            "   ...\n",
            "   [-0.41960782]\n",
            "   [-0.10588235]\n",
            "   [-0.62352943]]\n",
            "\n",
            "  [[-0.26274508]\n",
            "   [-0.4588235 ]\n",
            "   [-0.8509804 ]\n",
            "   ...\n",
            "   [-0.47450978]\n",
            "   [-0.15294117]\n",
            "   [-0.67058825]]]\n",
            "\n",
            "\n",
            " [[[ 0.5294118 ]\n",
            "   [ 0.5529412 ]\n",
            "   [ 0.5921569 ]\n",
            "   ...\n",
            "   [-0.10588235]\n",
            "   [ 0.10588241]\n",
            "   [ 0.20784318]]\n",
            "\n",
            "  [[ 0.5764706 ]\n",
            "   [ 0.5529412 ]\n",
            "   [ 0.5921569 ]\n",
            "   ...\n",
            "   [-0.12156862]\n",
            "   [-0.01176471]\n",
            "   [ 0.12941182]]\n",
            "\n",
            "  [[ 0.6156863 ]\n",
            "   [ 0.5764706 ]\n",
            "   [ 0.5686275 ]\n",
            "   ...\n",
            "   [-0.18431371]\n",
            "   [-0.0745098 ]\n",
            "   [ 0.03529418]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.23921567]\n",
            "   [-0.23921567]\n",
            "   [-0.24705881]\n",
            "   ...\n",
            "   [ 0.7411765 ]\n",
            "   [ 0.7490196 ]\n",
            "   [ 0.7490196 ]]\n",
            "\n",
            "  [[-0.24705881]\n",
            "   [-0.24705881]\n",
            "   [-0.24705881]\n",
            "   ...\n",
            "   [ 0.7019608 ]\n",
            "   [ 0.7019608 ]\n",
            "   [ 0.6784314 ]]\n",
            "\n",
            "  [[-0.26274508]\n",
            "   [-0.26274508]\n",
            "   [-0.23921567]\n",
            "   ...\n",
            "   [ 0.654902  ]\n",
            "   [ 0.6313726 ]\n",
            "   [ 0.60784316]]]] [[[[ 0.9764706 ]\n",
            "   [ 0.99215686]\n",
            "   [ 0.99215686]\n",
            "   ...\n",
            "   [ 0.7019608 ]\n",
            "   [ 0.4666667 ]\n",
            "   [ 0.30196083]]\n",
            "\n",
            "  [[ 0.9529412 ]\n",
            "   [ 0.96862745]\n",
            "   [ 0.9607843 ]\n",
            "   ...\n",
            "   [ 0.8039216 ]\n",
            "   [ 0.69411767]\n",
            "   [ 0.67058825]]\n",
            "\n",
            "  [[ 0.92941177]\n",
            "   [ 0.94509804]\n",
            "   [ 0.92941177]\n",
            "   ...\n",
            "   [ 0.8117647 ]\n",
            "   [ 0.77254903]\n",
            "   [ 0.79607844]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.3411765 ]\n",
            "   [ 0.45882356]\n",
            "   [ 0.5529412 ]\n",
            "   ...\n",
            "   [ 0.1686275 ]\n",
            "   [ 0.16078436]\n",
            "   [ 0.14509809]]\n",
            "\n",
            "  [[ 0.45098042]\n",
            "   [ 0.3803922 ]\n",
            "   [ 0.427451  ]\n",
            "   ...\n",
            "   [ 0.15294123]\n",
            "   [ 0.17647064]\n",
            "   [ 0.17647064]]\n",
            "\n",
            "  [[ 0.45882356]\n",
            "   [ 0.38823533]\n",
            "   [ 0.30980396]\n",
            "   ...\n",
            "   [ 0.1686275 ]\n",
            "   [ 0.20784318]\n",
            "   [ 0.20000005]]]\n",
            "\n",
            "\n",
            " [[[ 0.03529418]\n",
            "   [ 0.02745104]\n",
            "   [ 0.02745104]\n",
            "   ...\n",
            "   [-0.16862744]\n",
            "   [-0.17647058]\n",
            "   [-0.19215685]]\n",
            "\n",
            "  [[ 0.03529418]\n",
            "   [ 0.04313731]\n",
            "   [ 0.02745104]\n",
            "   ...\n",
            "   [-0.16862744]\n",
            "   [-0.16862744]\n",
            "   [-0.18431371]]\n",
            "\n",
            "  [[ 0.03529418]\n",
            "   [ 0.04313731]\n",
            "   [ 0.04313731]\n",
            "   ...\n",
            "   [-0.16862744]\n",
            "   [-0.18431371]\n",
            "   [-0.18431371]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.01176476]\n",
            "   [-0.10588235]\n",
            "   [-0.5294118 ]\n",
            "   ...\n",
            "   [-0.11372548]\n",
            "   [-0.18431371]\n",
            "   [-0.25490195]]\n",
            "\n",
            "  [[-0.44313723]\n",
            "   [-0.6       ]\n",
            "   [-0.6784314 ]\n",
            "   ...\n",
            "   [-0.02745098]\n",
            "   [-0.12941176]\n",
            "   [-0.1607843 ]]\n",
            "\n",
            "  [[-0.7882353 ]\n",
            "   [-0.84313726]\n",
            "   [-0.7176471 ]\n",
            "   ...\n",
            "   [-0.02745098]\n",
            "   [-0.06666666]\n",
            "   [-0.16862744]]]\n",
            "\n",
            "\n",
            " [[[ 0.8352941 ]\n",
            "   [ 0.81960785]\n",
            "   [ 0.7882353 ]\n",
            "   ...\n",
            "   [-0.78039217]\n",
            "   [-0.75686276]\n",
            "   [-0.7411765 ]]\n",
            "\n",
            "  [[ 0.827451  ]\n",
            "   [ 0.8117647 ]\n",
            "   [ 0.7882353 ]\n",
            "   ...\n",
            "   [-0.78039217]\n",
            "   [-0.7647059 ]\n",
            "   [-0.73333335]]\n",
            "\n",
            "  [[ 0.827451  ]\n",
            "   [ 0.8117647 ]\n",
            "   [ 0.78039217]\n",
            "   ...\n",
            "   [-0.75686276]\n",
            "   [-0.77254903]\n",
            "   [-0.7647059 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.38823533]\n",
            "   [ 0.37254906]\n",
            "   [ 0.4039216 ]\n",
            "   ...\n",
            "   [-0.09019607]\n",
            "   [-0.1607843 ]\n",
            "   [-0.2235294 ]]\n",
            "\n",
            "  [[ 0.34901965]\n",
            "   [ 0.30980396]\n",
            "   [ 0.32549024]\n",
            "   ...\n",
            "   [-0.1607843 ]\n",
            "   [-0.25490195]\n",
            "   [-0.25490195]]\n",
            "\n",
            "  [[ 0.35686278]\n",
            "   [ 0.33333337]\n",
            "   [ 0.30196083]\n",
            "   ...\n",
            "   [-0.2235294 ]\n",
            "   [-0.3098039 ]\n",
            "   [-0.3490196 ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.42745095]\n",
            "   [-0.4588235 ]\n",
            "   [-0.42745095]\n",
            "   ...\n",
            "   [ 0.33333337]\n",
            "   [ 0.34901965]\n",
            "   [ 0.11372554]]\n",
            "\n",
            "  [[-0.41960782]\n",
            "   [-0.5058824 ]\n",
            "   [-0.49019605]\n",
            "   ...\n",
            "   [ 0.38823533]\n",
            "   [ 0.2941177 ]\n",
            "   [ 0.15294123]]\n",
            "\n",
            "  [[-0.42745095]\n",
            "   [-0.49019605]\n",
            "   [-0.41176468]\n",
            "   ...\n",
            "   [ 0.20000005]\n",
            "   [ 0.28627455]\n",
            "   [ 0.16078436]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.0745098 ]\n",
            "   [-0.09019607]\n",
            "   [ 0.16078436]\n",
            "   ...\n",
            "   [ 0.03529418]\n",
            "   [ 0.12941182]\n",
            "   [ 0.14509809]]\n",
            "\n",
            "  [[-0.01960784]\n",
            "   [-0.03529412]\n",
            "   [ 0.05882359]\n",
            "   ...\n",
            "   [ 0.00392163]\n",
            "   [ 0.06666672]\n",
            "   [ 0.12156868]]\n",
            "\n",
            "  [[ 0.04313731]\n",
            "   [ 0.05882359]\n",
            "   [ 0.0196079 ]\n",
            "   ...\n",
            "   [-0.01176471]\n",
            "   [ 0.02745104]\n",
            "   [ 0.10588241]]]\n",
            "\n",
            "\n",
            " [[[-0.46666664]\n",
            "   [-0.27843136]\n",
            "   [-0.6862745 ]\n",
            "   ...\n",
            "   [-0.81960785]\n",
            "   [-0.46666664]\n",
            "   [-0.81960785]]\n",
            "\n",
            "  [[-0.18431371]\n",
            "   [-0.25490195]\n",
            "   [-0.5764706 ]\n",
            "   ...\n",
            "   [-0.94509804]\n",
            "   [-0.7882353 ]\n",
            "   [-0.81960785]]\n",
            "\n",
            "  [[ 0.03529418]\n",
            "   [-0.23137254]\n",
            "   [-0.47450978]\n",
            "   ...\n",
            "   [-1.        ]\n",
            "   [-0.88235295]\n",
            "   [-0.79607844]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.81960785]\n",
            "   [ 0.8039216 ]\n",
            "   [ 0.90588236]\n",
            "   ...\n",
            "   [ 0.5921569 ]\n",
            "   [ 0.6313726 ]\n",
            "   [ 0.75686276]]\n",
            "\n",
            "  [[ 0.8117647 ]\n",
            "   [ 0.8666667 ]\n",
            "   [ 0.77254903]\n",
            "   ...\n",
            "   [ 0.6313726 ]\n",
            "   [ 0.77254903]\n",
            "   [ 0.6627451 ]]\n",
            "\n",
            "  [[ 0.6862745 ]\n",
            "   [ 0.92156863]\n",
            "   [ 0.827451  ]\n",
            "   ...\n",
            "   [ 0.77254903]\n",
            "   [ 0.7019608 ]\n",
            "   [ 0.6313726 ]]]\n",
            "\n",
            "\n",
            " [[[-0.4823529 ]\n",
            "   [-0.44313723]\n",
            "   [-0.3960784 ]\n",
            "   ...\n",
            "   [-0.8117647 ]\n",
            "   [-0.81960785]\n",
            "   [-0.8117647 ]]\n",
            "\n",
            "  [[-0.47450978]\n",
            "   [-0.44313723]\n",
            "   [-0.3960784 ]\n",
            "   ...\n",
            "   [-0.8039216 ]\n",
            "   [-0.81960785]\n",
            "   [-0.7882353 ]]\n",
            "\n",
            "  [[-0.47450978]\n",
            "   [-0.4588235 ]\n",
            "   [-0.41176468]\n",
            "   ...\n",
            "   [-0.7647059 ]\n",
            "   [-0.8117647 ]\n",
            "   [-0.8352941 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.27843136]\n",
            "   [ 1.        ]\n",
            "   [ 0.41176474]\n",
            "   ...\n",
            "   [-0.5372549 ]\n",
            "   [-0.5372549 ]\n",
            "   [-0.56078434]]\n",
            "\n",
            "  [[-0.62352943]\n",
            "   [ 0.73333335]\n",
            "   [ 0.94509804]\n",
            "   ...\n",
            "   [-0.5372549 ]\n",
            "   [-0.5529412 ]\n",
            "   [-0.58431375]]\n",
            "\n",
            "  [[-0.73333335]\n",
            "   [ 0.17647064]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [-0.5686275 ]\n",
            "   [-0.58431375]\n",
            "   [-0.62352943]]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\\n\\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKvEv321Stt5",
        "outputId": "384eb7c3-99cc-443d-846e-1425c49cb7cb"
      },
      "source": [
        "print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validasi (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "test (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "train (28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH9Q-TegBR26"
      },
      "source": [
        "#hyperparameter and callback\n",
        "batch_size = 64\n",
        "num_epochs = 60\n",
        "input_shape = (48, 48, 1)\n",
        "num_classes = 7\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGsscQRJBR-h"
      },
      "source": [
        "#Compile the model.\n",
        "\n",
        "\n",
        "from keras.optimizers import Adam, SGD\n",
        "model = ResNet50(input_shape = (48, 48, 1), classes = 7)\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer= optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rodttDWeT2yP"
      },
      "source": [
        "#kita mau save model callbacks\n",
        "\"\"\"import os\n",
        "try:\n",
        "  os.mkdir('scratchcheckpoint')\n",
        "except:\n",
        "  pass\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV29sTjET28U"
      },
      "source": [
        "\"\"\"file_name = 'Best_Model_resnet50Scracth_sena1.h5'\n",
        "\n",
        "checkpoint_path = os.path.join('checkpoint',file_name)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_S6wUaPT3Jx"
      },
      "source": [
        "\"\"\"call_back = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
        "                                               monitor='val_accuracy',\n",
        "                                               verbose=1,\n",
        "                                               save_freq='epoch',\n",
        "                                               save_best_only=True,\n",
        "                                               save_weights_only=False,\n",
        "                                               mode='max')\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy53DHMGB-Mr",
        "outputId": "b453080e-57dd-43d8-d9ed-b60f95540fad"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 46, 46, 128)  0           add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_33 (Add)                    (None, 46, 46, 128)  0           activation_101[0][0]             \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 46, 46, 128)  0           add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, 46, 46, 128)  0           activation_104[0][0]             \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 46, 46, 128)  0           add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_35 (Add)                    (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 23, 23, 256)  0           add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_36 (Add)                    (None, 23, 23, 256)  0           activation_110[0][0]             \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 23, 23, 256)  0           add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_37 (Add)                    (None, 23, 23, 256)  0           activation_113[0][0]             \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 23, 23, 256)  0           add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_38 (Add)                    (None, 23, 23, 256)  0           activation_116[0][0]             \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 23, 23, 256)  0           add_38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_39 (Add)                    (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 12, 12, 512)  0           add_39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_40 (Add)                    (None, 12, 12, 512)  0           activation_122[0][0]             \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 12, 12, 512)  0           add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_41 (Add)                    (None, 12, 12, 512)  0           activation_125[0][0]             \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 12, 12, 512)  0           add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_42 (Add)                    (None, 12, 12, 512)  0           activation_128[0][0]             \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 12, 12, 512)  0           add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_43 (Add)                    (None, 12, 12, 512)  0           activation_131[0][0]             \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 12, 12, 512)  0           add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_44 (Add)                    (None, 12, 12, 512)  0           activation_134[0][0]             \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 12, 12, 512)  0           add_44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_45 (Add)                    (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 6, 6, 1024)   0           add_45[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_46 (Add)                    (None, 6, 6, 1024)   0           activation_140[0][0]             \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 6, 6, 1024)   0           add_46[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_47 (Add)                    (None, 6, 6, 1024)   0           activation_143[0][0]             \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 6, 6, 1024)   0           add_47[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgxCecVwCGEr"
      },
      "source": [
        "\"\"\"history = model.fit(data_generator.flow(xtrain, ytrain,),\n",
        "                        steps_per_epoch=len(xtrain) / batch_size,\n",
        "                        epochs=num_epochs, verbose=1,callbacks=call_back,\n",
        "                        validation_data= (xtest,ytest))\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2muXWns0sJSH",
        "outputId": "52e8e8d1-c467-4b30-91c7-b4a33a7012cc"
      },
      "source": [
        "history = model.fit(\n",
        "    data_generator.flow(xtrain, ytrain,),\n",
        "    steps_per_epoch=len(xtrain) / batch_size,\n",
        "    epochs=num_epochs, \n",
        "    verbose=1,\n",
        "    validation_data= (x_val,y_val))\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "448/448 [==============================] - 64s 116ms/step - loss: 3.6387 - accuracy: 0.2342 - val_loss: 1.8369 - val_accuracy: 0.2237\n",
            "Epoch 2/60\n",
            "448/448 [==============================] - 49s 109ms/step - loss: 1.7502 - accuracy: 0.2839 - val_loss: 1.8243 - val_accuracy: 0.3029\n",
            "Epoch 3/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.6047 - accuracy: 0.3713 - val_loss: 1.5395 - val_accuracy: 0.4007\n",
            "Epoch 4/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.5020 - accuracy: 0.4175 - val_loss: 1.9660 - val_accuracy: 0.2979\n",
            "Epoch 5/60\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.4466 - accuracy: 0.4340 - val_loss: 1.4501 - val_accuracy: 0.4372\n",
            "Epoch 6/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.3872 - accuracy: 0.4693 - val_loss: 1.3877 - val_accuracy: 0.4603\n",
            "Epoch 7/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.3320 - accuracy: 0.4862 - val_loss: 1.3176 - val_accuracy: 0.4932\n",
            "Epoch 8/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.3006 - accuracy: 0.5011 - val_loss: 1.3115 - val_accuracy: 0.4915\n",
            "Epoch 9/60\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.2542 - accuracy: 0.5178 - val_loss: 1.3129 - val_accuracy: 0.5199\n",
            "Epoch 10/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.2603 - accuracy: 0.5198 - val_loss: 1.2354 - val_accuracy: 0.5238\n",
            "Epoch 11/60\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.2139 - accuracy: 0.5384 - val_loss: 1.1974 - val_accuracy: 0.5419\n",
            "Epoch 12/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.2068 - accuracy: 0.5433 - val_loss: 1.4343 - val_accuracy: 0.5063\n",
            "Epoch 13/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.1582 - accuracy: 0.5653 - val_loss: 1.3565 - val_accuracy: 0.4960\n",
            "Epoch 14/60\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.1741 - accuracy: 0.5571 - val_loss: 1.1477 - val_accuracy: 0.5534\n",
            "Epoch 15/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 1.1394 - accuracy: 0.5669 - val_loss: 1.1691 - val_accuracy: 0.5548\n",
            "Epoch 16/60\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.1296 - accuracy: 0.5707 - val_loss: 1.2026 - val_accuracy: 0.5489\n",
            "Epoch 17/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 1.1362 - accuracy: 0.5691 - val_loss: 1.1289 - val_accuracy: 0.5748\n",
            "Epoch 18/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.1018 - accuracy: 0.5769 - val_loss: 1.1746 - val_accuracy: 0.5447\n",
            "Epoch 19/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.0863 - accuracy: 0.5889 - val_loss: 1.2883 - val_accuracy: 0.5291\n",
            "Epoch 20/60\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.0671 - accuracy: 0.5902 - val_loss: 1.1361 - val_accuracy: 0.5720\n",
            "Epoch 21/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.0696 - accuracy: 0.6001 - val_loss: 1.0938 - val_accuracy: 0.5826\n",
            "Epoch 22/60\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.0545 - accuracy: 0.6008 - val_loss: 1.0457 - val_accuracy: 0.6077\n",
            "Epoch 23/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 1.0222 - accuracy: 0.6147 - val_loss: 1.0890 - val_accuracy: 0.5779\n",
            "Epoch 24/60\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.0244 - accuracy: 0.6157 - val_loss: 1.0495 - val_accuracy: 0.5974\n",
            "Epoch 25/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.0267 - accuracy: 0.6127 - val_loss: 1.0579 - val_accuracy: 0.5935\n",
            "Epoch 26/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.0089 - accuracy: 0.6212 - val_loss: 1.0405 - val_accuracy: 0.6032\n",
            "Epoch 27/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.0049 - accuracy: 0.6188 - val_loss: 1.0667 - val_accuracy: 0.6127\n",
            "Epoch 28/60\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.0108 - accuracy: 0.6180 - val_loss: 1.0516 - val_accuracy: 0.6021\n",
            "Epoch 29/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.9970 - accuracy: 0.6274 - val_loss: 1.0183 - val_accuracy: 0.6102\n",
            "Epoch 30/60\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 0.9942 - accuracy: 0.6286 - val_loss: 1.0479 - val_accuracy: 0.6119\n",
            "Epoch 31/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.9696 - accuracy: 0.6356 - val_loss: 1.0148 - val_accuracy: 0.6225\n",
            "Epoch 32/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 0.9892 - accuracy: 0.6279 - val_loss: 1.0096 - val_accuracy: 0.6205\n",
            "Epoch 33/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 0.9509 - accuracy: 0.6402 - val_loss: 1.0210 - val_accuracy: 0.6169\n",
            "Epoch 34/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 0.9506 - accuracy: 0.6446 - val_loss: 1.0014 - val_accuracy: 0.6172\n",
            "Epoch 35/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 0.9574 - accuracy: 0.6400 - val_loss: 1.0008 - val_accuracy: 0.6205\n",
            "Epoch 36/60\n",
            "448/448 [==============================] - 49s 110ms/step - loss: 0.9415 - accuracy: 0.6501 - val_loss: 1.0645 - val_accuracy: 0.6077\n",
            "Epoch 37/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 0.9395 - accuracy: 0.6501 - val_loss: 1.0258 - val_accuracy: 0.6113\n",
            "Epoch 38/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 0.9265 - accuracy: 0.6523 - val_loss: 0.9873 - val_accuracy: 0.6291\n",
            "Epoch 39/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 0.9242 - accuracy: 0.6516 - val_loss: 0.9627 - val_accuracy: 0.6386\n",
            "Epoch 40/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 0.9062 - accuracy: 0.6578 - val_loss: 0.9977 - val_accuracy: 0.6130\n",
            "Epoch 41/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 0.8960 - accuracy: 0.6612 - val_loss: 1.0487 - val_accuracy: 0.6160\n",
            "Epoch 42/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 0.9232 - accuracy: 0.6501 - val_loss: 1.0343 - val_accuracy: 0.6219\n",
            "Epoch 43/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 0.9060 - accuracy: 0.6655 - val_loss: 0.9861 - val_accuracy: 0.6239\n",
            "Epoch 44/60\n",
            "448/448 [==============================] - 49s 110ms/step - loss: 0.8968 - accuracy: 0.6659 - val_loss: 0.9737 - val_accuracy: 0.6350\n",
            "Epoch 45/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 0.8981 - accuracy: 0.6625 - val_loss: 0.9740 - val_accuracy: 0.6261\n",
            "Epoch 46/60\n",
            "448/448 [==============================] - 49s 110ms/step - loss: 0.9040 - accuracy: 0.6620 - val_loss: 0.9638 - val_accuracy: 0.6400\n",
            "Epoch 47/60\n",
            "448/448 [==============================] - 49s 110ms/step - loss: 0.8845 - accuracy: 0.6665 - val_loss: 0.9980 - val_accuracy: 0.6358\n",
            "Epoch 48/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 0.8808 - accuracy: 0.6735 - val_loss: 0.9859 - val_accuracy: 0.6361\n",
            "Epoch 49/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 0.8688 - accuracy: 0.6708 - val_loss: 0.9932 - val_accuracy: 0.6191\n",
            "Epoch 50/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 0.8949 - accuracy: 0.6625 - val_loss: 1.0467 - val_accuracy: 0.6208\n",
            "Epoch 51/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 0.8551 - accuracy: 0.6817 - val_loss: 0.9967 - val_accuracy: 0.6278\n",
            "Epoch 52/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 0.8585 - accuracy: 0.6777 - val_loss: 0.9652 - val_accuracy: 0.6425\n",
            "Epoch 53/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 0.8471 - accuracy: 0.6836 - val_loss: 1.0229 - val_accuracy: 0.6222\n",
            "Epoch 54/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 0.8551 - accuracy: 0.6830 - val_loss: 0.9744 - val_accuracy: 0.6461\n",
            "Epoch 55/60\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 0.8488 - accuracy: 0.6829 - val_loss: 0.9953 - val_accuracy: 0.6280\n",
            "Epoch 56/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 0.8383 - accuracy: 0.6794 - val_loss: 1.0028 - val_accuracy: 0.6400\n",
            "Epoch 57/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 0.8431 - accuracy: 0.6850 - val_loss: 0.9799 - val_accuracy: 0.6436\n",
            "Epoch 58/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 0.8280 - accuracy: 0.6932 - val_loss: 0.9814 - val_accuracy: 0.6431\n",
            "Epoch 59/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 0.8306 - accuracy: 0.6933 - val_loss: 1.0102 - val_accuracy: 0.6339\n",
            "Epoch 60/60\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 0.8195 - accuracy: 0.6928 - val_loss: 0.9574 - val_accuracy: 0.6512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "GaXUP-8fDWRN",
        "outputId": "83a68295-c059-4fd2-c735-5aa5d5a33a4c"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "model.save('/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editSGD5st.h5')\n",
        "\n",
        "#gffhgffkjkjdskjjkjkjkjhjhnnnhjhhu\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "num_epochs = range(len(accuracy))\n",
        "plt.plot(num_epochs, accuracy, 'r', label='Training acc')\n",
        "plt.plot(num_epochs, val_accuracy, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(num_epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(num_epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xUZdbA8d+BBAKElhBAqUFpSieAgnQLqAuKFbEgWFBeC1YsK6jrroXXVXZt2NBdVnQtWLC9oAiILSBSQ1FAgmggEAgEQkLO+8czkz7JJGQymcz5fj7zmZk7t5ybcs885T6PqCrGGGPCV41gB2CMMSa4LBEYY0yYs0RgjDFhzhKBMcaEOUsExhgT5iwRGGNMmLNEYCqUiHwiIldV9LrBJCJbReT0AOxXReREz+vnReTP/qxbjuOME5HPyxtnCfsdIiLJFb1fU/kigh2ACT4ROZDvbV0gEzjqeX+9qs7xd1+qOjIQ61Z3qjqpIvYjIm2BLUCkqmZ79j0H8Pt3aMKPJQKDqkZ7X4vIVuAaVV1QeD0RifBeXIwx1YdVDRmfvEV/EblbRH4HXhWRxiLykYjsEpG9ntct822zSESu8bweLyJLRWSGZ90tIjKynOvGi8hiEUkXkQUi8oyI/NtH3P7E+LCIfO3Z3+ci0iTf51eIyDYRSRWR+0r4+fQTkd9FpGa+ZeeLyCrP674i8o2IpInIThH5p4jU8rGv2SLyl3zv7/Rs85uITCi07jki8qOI7BeR7SIyPd/Hiz3PaSJyQERO9f5s823fX0R+EJF9nuf+/v5sSiIinT3bp4nIWhEZle+zs0VknWefO0TkDs/yJp7fT5qI7BGRJSJi16VKZj9wU5rmQAzQBrgO9zfzqud9a+AQ8M8Stu8HbACaAI8DL4uIlGPd/wDfA7HAdOCKEo7pT4yXAVcDTYFagPfCdBLwnGf/x3uO15JiqOp3wEFgWKH9/sfz+igwxXM+pwLDgRtLiBtPDCM88ZwBtAcKt08cBK4EGgHnADeIyHmezwZ5nhuparSqflNo3zHAfGCm59yeBOaLSGyhcyjysykl5kjgQ+Bzz3Y3AXNEpKNnlZdx1Yz1gS7AF57ltwPJQBzQDLgXsHFvKpklAlOaHGCaqmaq6iFVTVXVd1Q1Q1XTgUeAwSVsv01VX1TVo8BrwHG4f3i/1xWR1kAf4AFVPaKqS4EPfB3QzxhfVdWNqnoIeAvo4Vl+IfCRqi5W1Uzgz56fgS9vAGMBRKQ+cLZnGaq6XFW/VdVsVd0KvFBMHMW52BPfGlU9iEt8+c9vkaquVtUcVV3lOZ4/+wWXODap6r88cb0BJAF/yreOr59NSU4BooFHPb+jL4CP8PxsgCzgJBFpoKp7VXVFvuXHAW1UNUtVl6gNgFbpLBGY0uxS1cPeNyJSV0Re8FSd7MdVRTTKXz1SyO/eF6qa4XkZXcZ1jwf25FsGsN1XwH7G+Hu+1xn5Yjo+/749F+JUX8fCffsfIyK1gTHAClXd5omjg6fa43dPHH/FlQ5KUyAGYFuh8+snIl96qr72AZP83K9339sKLdsGtMj33tfPptSYVTV/0sy/3wtwSXKbiHwlIqd6lj8BbAY+F5FfRGSqf6dhKpIlAlOawt/Obgc6Av1UtQF5VRG+qnsqwk4gRkTq5lvWqoT1jyXGnfn37TlmrK+VVXUd7oI3koLVQuCqmJKA9p447i1PDLjqrfz+gysRtVLVhsDz+fZb2rfp33BVZvm1Bnb4EVdp+21VqH4/d7+q+oOqjsZVG83DlTRQ1XRVvV1V2wGjgNtEZPgxxmLKyBKBKav6uDr3NE9987RAH9DzDTsRmC4itTzfJv9UwibHEuPbwLkicpqnYfchSv8/+Q9wCy7h/LdQHPuBAyLSCbjBzxjeAsaLyEmeRFQ4/vq4EtJhEemLS0Beu3BVWe187PtjoIOIXCYiESJyCXASrhrnWHyHKz3cJSKRIjIE9zua6/mdjRORhqqahfuZ5ACIyLkicqKnLWgfrl2lpKo4EwCWCExZPQXUAXYD3wKfVtJxx+EaXFOBvwBv4u53KE65Y1TVtcBk3MV9J7AX15hZEm8d/Requjvf8jtwF+l04EVPzP7E8InnHL7AVZt8UWiVG4GHRCQdeADPt2vPthm4NpGvPT1xTim071TgXFypKRW4Czi3UNxlpqpHcBf+kbif+7PAlaqa5FnlCmCrp4psEu73Ca4xfAFwAPgGeFZVvzyWWEzZibXLmFAkIm8CSaoa8BKJMdWdlQhMSBCRPiJygojU8HSvHI2razbGHCO7s9iEiubAu7iG22TgBlX9MbghGVM9WNWQMcaEOasaMsaYMBdyVUNNmjTRtm3bBjsMY4wJKcuXL9+tqnHFfRZyiaBt27YkJiYGOwxjjAkpIlL4jvJcVjVkjDFhzhKBMcaEOUsExhgT5kKujcAYU/mysrJITk7m8OHDpa9sgioqKoqWLVsSGRnp9zaWCIwxpUpOTqZ+/fq0bdsW3/MKmWBTVVJTU0lOTiY+Pt7v7axqyBhTqsOHDxMbG2tJoIoTEWJjY8tccrNEYIzxiyWB0FCe31P4JII1a+D++yG1pMmmjDEm/IRPIti0CR55BLb7nOHQGFNFpaam0qNHD3r06EHz5s1p0aJF7vsjR46UuG1iYiI333xzqcfo379/hcS6aNEizj333ArZV2UJWGOxiLQCXsdNVK7ALFV9utA644C7cdPspeNGlPwpIAHFxLjnPXsCsntjTODExsaycuVKAKZPn050dDR33HFH7ufZ2dlERBR/OUtISCAhIaHUYyxbtqxigg1BgSwRZAO3q+pJwCnAZBE5qdA6W4DBqtoVeBiYFbBovInAqoaMqRbGjx/PpEmT6NevH3fddRfff/89p556Kj179qR///5s2LABKPgNffr06UyYMIEhQ4bQrl07Zs6cmbu/6Ojo3PWHDBnChRdeSKdOnRg3bhzeUZo//vhjOnXqRO/evbn55ptL/ea/Z88ezjvvPLp168Ypp5zCqlWrAPjqq69ySzQ9e/YkPT2dnTt3MmjQIHr06EGXLl1YsmRJhf/MfAlYiUBVd+Km+kNV00VkPdACWJdvnfwp+FugZaDiIdYz/7iVCIw5NrfeCp5v5xWmRw946qkyb5acnMyyZcuoWbMm+/fvZ8mSJURERLBgwQLuvfde3nnnnSLbJCUl8eWXX5Kenk7Hjh254YYbivS5//HHH1m7di3HH388AwYM4OuvvyYhIYHrr7+exYsXEx8fz9ixY0uNb9q0afTs2ZN58+bxxRdfcOWVV7Jy5UpmzJjBM888w4ABAzhw4ABRUVHMmjWLs846i/vuu4+jR4+SkZFR5p9HeVXKfQQi0hboiZvg2peJwCcBC6JxY/dsicCYauOiiy6iZs2aAOzbt4+rrrqKTZs2ISJkZWUVu80555xD7dq1qV27Nk2bNuWPP/6gZcuC30H79u2bu6xHjx5s3bqV6Oho2rVrl9s/f+zYscyaVXIlxtKlS3OT0bBhw0hNTWX//v0MGDCA2267jXHjxjFmzBhatmxJnz59mDBhAllZWZx33nn06NHjmH42ZRHwRCAi0cA7wK2qut/HOkNxieA0H59fB1wH0Lp16/IFUqeOe1jVkDHHphzf3AOlXr16ua///Oc/M3ToUN577z22bt3KkCFDit2mdu3aua9r1qxJdnZ2udY5FlOnTuWcc87h448/ZsCAAXz22WcMGjSIxYsXM3/+fMaPH89tt93GlVdeWaHH9SWgvYZEJBKXBOao6rs+1ukGvASMVtVir9KqOktVE1Q1IS6u2OG0/RMbayUCY6qpffv20aJFCwBmz55d4fvv2LEjv/zyC1u3bgXgzTffLHWbgQMHMmfOHMC1PTRp0oQGDRrw888/07VrV+6++2769OlDUlIS27Zto1mzZlx77bVcc801rFixosLPwZeAJQJxdzW8DKxX1Sd9rNMaNw/tFaq6MVCx5IqJsURgTDV11113cc8999CzZ88K/wYPUKdOHZ599llGjBhB7969qV+/Pg0bNixxm+nTp7N8+XK6devG1KlTee211wB46qmn6NKlC926dSMyMpKRI0eyaNEiunfvTs+ePXnzzTe55ZZbKvwcfAnYnMUichqwBFgN5HgW3wu0BlDV50XkJeACwDthQraqltjPKyEhQcs9Mc3QoZCdDZXYGm9MdbB+/Xo6d+4c7DCC7sCBA0RHR6OqTJ48mfbt2zNlypRgh1VEcb8vEVnu6/oayF5DS3H3B5S0zjXANYGKoYjYWFi/vtIOZ4ypXl588UVee+01jhw5Qs+ePbn++uuDHVKFCK/RR2NirLHYGFNuU6ZMqZIlgGMVPkNMQF4bQYCqw4wxJhSFVyKIjYWsLDh4MNiRGGNMlRFeicCGmTDGmCLCMxFYF1JjjMkVXonAxhsyJiQNHTqUzz77rMCyp556ihtuuMHnNkOGDMHb1fzss88mLS2tyDrTp09nxowZJR573rx5rFuXO0QaDzzwAAsWLChL+MWqSsNVh1cisKohY0LS2LFjmTt3boFlc+fO9WvgN3CjhjZq1Khcxy6cCB566CFOP/30cu2rqgrPRGAlAmNCyoUXXsj8+fNzJ6HZunUrv/32GwMHDuSGG24gISGBk08+mWnTphW7fdu2bdm9ezcAjzzyCB06dOC0007LHaoa3D0Cffr0oXv37lxwwQVkZGSwbNkyPvjgA+6880569OjBzz//zPjx43n77bcBWLhwIT179qRr165MmDCBzMzM3ONNmzaNXr160bVrV5KSkko8v2APVx1+9xGAJQJjjkEwRqGOiYmhb9++fPLJJ4wePZq5c+dy8cUXIyI88sgjxMTEcPToUYYPH86qVavo1q1bsftZvnw5c+fOZeXKlWRnZ9OrVy969+4NwJgxY7j22msBuP/++3n55Ze56aabGDVqFOeeey4XXnhhgX0dPnyY8ePHs3DhQjp06MCVV17Jc889x6233gpAkyZNWLFiBc8++ywzZszgpZde8nl+wR6uOrxKBFFRULeuVQ0ZE4LyVw/lrxZ666236NWrFz179mTt2rUFqnEKW7JkCeeffz5169alQYMGjBo1KvezNWvWMHDgQLp27cqcOXNYu3ZtifFs2LCB+Ph4OnToAMBVV13F4sWLcz8fM2YMAL17984dqM6XpUuXcsUVVwDFD1c9c+ZM0tLSiIiIoE+fPrz66qtMnz6d1atXU79+/RL37Y/wKhGAjUBqzDEK1ijUo0ePZsqUKaxYsYKMjAx69+7Nli1bmDFjBj/88AONGzdm/PjxHD58uFz7Hz9+PPPmzaN79+7Mnj2bRYsWHVO83qGsj2UY68oarjq8SgRgI5AaE6Kio6MZOnQoEyZMyC0N7N+/n3r16tGwYUP++OMPPvmk5LmtBg0axLx58zh06BDp6el8+OGHuZ+lp6dz3HHHkZWVlTt0NED9+vVJT08vsq+OHTuydetWNm/eDMC//vUvBg8eXK5zC/Zw1eFXIrDxhowJWWPHjuX888/PrSLyDtvcqVMnWrVqxYABA0rcvlevXlxyySV0796dpk2b0qdPn9zPHn74Yfr160dcXBz9+vXLvfhfeumlXHvttcycOTO3kRggKiqKV199lYsuuojs7Gz69OnDpEmTynVe3rmUu3XrRt26dQsMV/3ll19So0YNTj75ZEaOHMncuXN54okniIyMJDo6mtdff71cx8wvYMNQB8oxDUMNcNFFsHYtlFCPaIwpyIahDi1lHYbaqoaMMSbMhWciSE21EUiNMcYj/BJBbKybpezAgWBHYkxICbVq5HBVnt9T+CUCu6nMmDKLiooiNTXVkkEVp6qkpqYSFRVVpu3Cs9cQuOqhNm2CG4sxIaJly5YkJyeza9euYIdiShEVFUXLli3LtE34JQIbgdSYMouMjCQ+Pj7YYZgACVjVkIi0EpEvRWSdiKwVkVuKWUdEZKaIbBaRVSLSK1Dx5LKqIWOMKSCQJYJs4HZVXSEi9YHlIvJ/qpq/A/9IoL3n0Q94zvMcODYUtTHGFBCwEoGq7lTVFZ7X6cB6oEWh1UYDr6vzLdBIRI4LVEyAlQiMMaaQSuk1JCJtgZ7Ad4U+agFsz/c+maLJAhG5TkQSRSTxmBurateGevUsERhjjEfAE4GIRAPvALeq6v7y7ENVZ6lqgqomxMXFHXtQNt6QMcbkCmgiEJFIXBKYo6rvFrPKDqBVvvctPcsCy4aiNsaYXIHsNSTAy8B6VX3Sx2ofAFd6eg+dAuxT1Z2BiilXOcYbSk6GvXsDFI8xxgRRIHsNDQCuAFaLiHdiu3uB1gCq+jzwMXA2sBnIAK4OYDx5YmJgzZoybXL22XDKKTBrVoBiMsaYIAlYIlDVpYCUso4CkwMVg0/lqBrasgWOPz5A8RhjTBCF31hDkFc15Oe4KRkZbow6a1YwxlRH4ZsIsrOhmOnniuPtsWqJwBhTHYVnIijjeEMpKWVa3RhjQkp4JoIy3l3sTQRpaXD0aIBiMsaYIAnvRODnTWXeRKDqkoExxlQn4ZkIylk1VIZNjDEmZIRnIihn1VAZNjHGmJAR3omgjFVDYInAGFP9hGciqFULoqPLVCJo3Ni9tkRgjKluwjMRQJnGG0pJgU6d3GtLBMaY6ia8E0EZqoY6dHCvbfRqY0x1E76JwM/xhlRdIjjuOGjUyEoExpjqJ3wTgZ8lgrQ0NxpF06blGr3aGGOqvPBOBH5c1b09hpo2tflsjDHVU/gmAu9VvZQRSPMnAisRGGOqo7BJBIcOwS+/5FsQE+MGDtpf8jTKhROBNRYbY6qbsEkEH30EJ5wA/frB3/8OO6Sl+6CUr/hWIjDGVHdhkwj694fHH3cNv7fdBq3uuJhBfMVzs2pw5Ijv7byJoEkTlwj27oWcnMqJ2RhjKkPYJIIWLeDOO2H5cti4ER6a+CupxHLjo214/33f26WkuAQQGemeVWHfvsqL2xhjAi1giUBEXhGRFBEpdpZ4EWkoIh+KyE8islZEKmfieqB9e7h/ykG+ox8Amzf7XjclxVULQZkHLTXGmJAQyBLBbGBECZ9PBtapandgCPC/IlIrgPEUFBtLNAeJi85gyxbfq+VPBGUcq84YY0JCwBKBqi4GSvrurEB9EREg2rNudqDiKcIzilx8w71lTgRWIjDGVCfBbCP4J9AZ+A1YDdyiqsU2w4rIdSKSKCKJu7wzyR8rzwikbeumWCIwxoS1YCaCs4CVwPFAD+CfItKguBVVdZaqJqhqQlxcXMVFEBtLfK0d/Ppr8XMRZ2W5i74lAmNMdRbMRHA18K46m4EtQKdKjSAmhnjZSlYW7NhR9OPdu92zNxHYnATGmOoomIngV2A4gIg0AzoCv5S4RUWLiSH+qOsyVFz1UP6byQAiIqBhQ0sExpjqJZDdR98AvgE6ikiyiEwUkUkiMsmzysNAfxFZDSwE7lbV3YGKp1ixscQfXg/4lwjAhpkwxlQ/EYHasaqOLeXz34AzA3V8v8TE0Hr/UkRg69aiH/tKBFYiMMZUJ2FzZ3GxYmKovfd3WrTQMpUILBEYY6qT8E4EsbGQk0N8q6M+E0FEhJuZzMsSgTGmugnvRODpDxrf/JDPRNC0KYjkLbPJaYwx1Y0lAiC+STo7dkBmZsGP899Mln+TPXtsBFJjTPUR3onAM4pcfMM9qMKvvxb82FciyMkpdT4bY4wJGeGdCFq6yWniszYCRbuQ+koEYNVDxpjqI7wTQZs20LYt8UmfAJYIjDHhKbwTAcCwYRz/7btERhbsQnrwIGRkWCIwxlR/lgiGD6fmvj20aZ5ZIBEUdw8B5E1OY3cXG2OqC0sEw4YBEB+1069EYCUCY0x1Y4mgeXM4+WTiM9b5lQhsBFJjTHVjiQBg+HDi//iW3bvhwAG3yFciiIyE+vUtERhjqg9LBOASQXbBLqTeRFDcPDg2zIQxpjqxRAAwaBBtxd1N5h2FNCUFoqOhbt2iq8fGWmOxMab6sEQA0KgR8T0aAgVLBIWrhbysRGCMqU4sEXjEndWLuhxky4YjgCUCY0z4sETgIacPJ54tbFnhrvCWCIwx4cISgVf//sTX2MaWzW5YUX8SgWolxmeMMQFiicCrTh3ij8tky54G5OTArl0lJ4KjRyE9vXJDNMaYQAjk5PWviEiKiKwpYZ0hIrJSRNaKyFeBisVf8d3qk54Tzebv93D0qO9EYMNMGGOqk0CWCGYDI3x9KCKNgGeBUap6MnBRAGPxS/zg1gB89+9NQMklArB2AmNM9RCwRKCqi4GSLpWXAe+q6q+e9VMCFYu/4k8/AYDvFh0CLBEYY8JDMNsIOgCNRWSRiCwXkSt9rSgi14lIoogk7tq1K2ABxbePAOC7ze5Kb4nAGBMOgpkIIoDewDnAWcCfRaRDcSuq6ixVTVDVhLjixnyoIA0aQEzdQ/yU2QmwRGCMCQ/BTATJwGeqelBVdwOLge5BjAeA+LZKFrUQ0dxG4cK8icAai40x1UEwE8H7wGkiEiEidYF+wPogxgNA/El1AIiN2EdERPHr1KrlxiGyEoExpjrwKxGIyC0i0kCcl0VkhYicWco2bwDfAB1FJFlEJorIJBGZBKCq64FPgVXA98BLquqzq2lliY8XAJpm7YDt232uZ3cXG2OqCx/feYuYoKpPi8hZQGPgCuBfwOe+NlDVsaXtVFWfAJ7wM4ZKER/vnpuSAv96H+69t9j1LBEYY6oLf6uGxPN8NvAvVV2bb1m1kpsI4hRefdXnOBKWCIwx1YW/iWC5iHyOSwSfiUh9ICdwYQVPbiLodhxs3gxff13sejEx1lhsjKke/E0EE4GpQB9VzQAigasDFlUQtWnjGoLbnd4O6tWD2bOLXS821koExpjqwd9EcCqwQVXTRORy4H5gX+DCCp6oKFi7Fm6cUhsuvhjefBMOHiyyno1AaoypLvxNBM8BGSLSHbgd+Bl4PWBRBVnr1lC7NjB+vJvN/p13iqwTEwPZ2XmT3RtjTKjyNxFkq6oCo4F/quozQP3AhVVFDBwIJ5zgGo0LsbuLjTHVhb+JIF1E7sF1G50vIjVw7QTVm4grFSxalDeZsYclAmNMdeFvIrgEyMTdT/A70JIq1v8/YK680iWE114rsNiGmTDGVBd+JQLPxX8O0FBEzgUOq2q1bSMooHVrGD7c9R7Kyesx6x2HyEoExphQ5+8QExfjhoG4CLgY+E5ELgxkYFXK1VfDtm3wVd4kalY1ZIypLvwdYuI+3D0EKQAiEgcsAN4OVGBVyvnnQ8OG8PTTMHQoAI0bu48sERhjQp2/bQQ1Cs0gllqGbUNfnTpw993w/vswfz7g7jeoW9cSgTEm9Pl7Mf9URD4TkfEiMh6YD3wcuLCqoNtvh86d4X/+BzIyABtmwhhTPfjbWHwnMAvo5nnMUtW7AxlYlVOrFjz3HGzdCn/5C2DDTBhjqgd/2whQ1XeAorfYhpPBg+Gqq+CJJ+Dyy4mJOYndu4MdlDHGHJsSSwQiki4i+4t5pIvI/soKskp54gmoXx9uuIFePZVvv4XVq4MdlDHGlF+JiUBV66tqg2Ie9VW1QWUFWaXExcHjj8Pixdzbbi6NG8NNN1WNweeSk32Omm2MMT6FT8+fijRhAvTvT8z0m3nkngN89RX897/BDgqmTXO9W3fsCHYkxphQYomgPGrUgOefh717uWbtFHr0gDvuKHa06kq1di1kZcHf/x7cOIwxoSVgiUBEXhGRFBEpcUJ6EekjItkhd6dy165w223UfPUl/nHNT2zfDo8+GrxwVGHDBvf6+eetN5Mxxn+BLBHMBkaUtIKI1AQeAz4PYByBM20atGnDaf+8lMsuOcoTT8AvvwQnlJQUSEuDa65xJZNnnglOHMaY0BOwRKCqi4HSvpfehOuSmlLKelVTvXru3oKkJB5v9Q8iItx9Z8HgLQ1ceCGce64bDSPYVVXGmNAQtDYCEWkBnI+b/ay0da8TkUQRSdy1a1fggyuLkSPhkkto8Y+p3D9pF/PmwedBKN8kJbnnTp1g6lR3x/PLL1d+HMaY0BPMxuKngLtVNae0FVV1lqomqGpCXFxcJYRWRk89BVFRTEm8nBNOUG65xU1jWZmSktyQSK1awYABbnK1GTPgyJHKjcMYE3qCmQgSgLkishW4EHhWRM4LYjzl17w5PPYYtb/6nCfOXkRSErxeybM1bNgAHTq4Dk3gSgXbt8Mbb1RuHMaY0CMawDuhRKQt8JGqdillvdme9Uod1johIUETExMrJL4KlZMDgwah65Po12Ynf6RGsnEj1K5dOYc/4QTo0wfmznXvVaFnT1ciWLMmL0EYY8KTiCxX1YTiPgtk99E3gG+AjiKSLCITRWSSiEwK1DGDqkYNeOEFZP8+Hol5kl9/hVmzKufQhw+7sfA6dsxbJuJKBevXu9GzjTHGl4CWCAKhypYIvKZPRx98kGHHJbHuaAd++UWoVy+wh1yzxt3W8J//wNixecuzs11yiI2F775zycEYE56CUiIIW9OmIffeyyM7ryYlRZj5v1kBP6S3x1D+EgFARIQbB+mHH9xMm8YYUxxLBBVNBB55hP4zx3IOH/H4Q4dJ25oW0EN67yHo0KHoZ337umcbIdUY44slgkC56Sb+8lgt0o7WZ0afN93QoAGSlOS6jUZHF/2si6eZ3hKBMcYXSwQB1OOuM7lk6B88tXscKX3PhVWrAnKcDRuKVgt5NWgAbdpYIjDG+GaJIMAeer4Zh2vW42/7J7s7vebPr9D9q7oSQadOvtfp2tUSgTHGN7+nqjTl06EDXHWVMHP2NSysNYSTzl3BySOWcdLEU2nfwXXjyciAQ4fcc1YWnHEGfvc0+v13SE/3XSIAVz306afunoJatSrgpIwx1YolgkowYwY0ayas+jGe7xc34M1Pm8Gnvte/9Vb/5xTIP8aQL127uq6kGza418YYk58lgkrQuDH89a8AEZATx8G7prHhfz9kc5fziZh6B3Vj61CnjhsraMYMdyPaffdBkyal79vfRACuesgSgTGmMEsEla1GDerNeJBeXdvRa+JE+GCNGxfCc7fXtGlu2st//AMefLD03W3Y4KqRWrTwvU7Hju6eAmsnMMYUxxqLg+Wqq1wx4a234J//zF188o8HL6AAAB2iSURBVMkwerRLBOnppe8mKcld6Eu6a7hWLVdiqOxE8Nln8Kc/wdGjlXtcY0zZWCIIpjvugFGj3Gw2336bu/iee2DvXv/GKiqp62h+weg59NRT8NFH8NNPlXtcY0zZWCIIpho1YPZsaNkSLr4Ydu8GoF8/GDYMnnwSMjN9b37okBs6oqT2Aa+uXeHXX2HfvooJvTRpabBwoXu9ZEnlHNMYUz6WCIKtcWN4+2036fDll7vhrHGlgt9+K3leg02b3H0E/iYCcAPUVYaPPnJdYWvXhsWLK+eYxpjysURQFfTqBTNnukr1Rx4BYPhwSEiAxx7zPduZr8HmipO/51BlePddOP54V9BZssQlLGNM1WSJoKq49lpXIpg2DS64ALnjdu7pNp+ff4a3Z2wttsU1Kck1ErdvX/ruW7d2w01URiI4eNDdwDZmDAweDLt25Q2MZ4ypeiwRVBUi8PzzbkKBNWvg2Wc575U/0Yn1PHpPGjposGtBzmfDBneBr1vXv9136VI5ieDTT137xZgxMGiQW2bVQ8ZUXZYIqpJ69WDOHHeFz8igxh+/c/cDtfmJHnz8XSwMGeLGlPAobYyhwrw9hwJdTfPOO+5muIED4cQToVkzazA2piqzRFBViUDTpoy7vx3t2sGE+m+xYVMNOO002LIFVZcvypIIunRxvXl27Ahc2JmZrqH4vPPcTWwirlRgJQJjqi5LBFVcZKRnwNJatRke/R2/7KoPAwawY2ESBw/611DsVRkNxgsWuBvhxozJWzZwoOu6arOkGVM1BXLy+ldEJEVEiu2wKCLjRGSViKwWkWUi0j1QsYS6Tp3cBfbQ0VoMr/8d23NakHT+Pe6zDjl+76cyEsG777pG6eHD85Z52wmsesiYqimQJYLZwIgSPt8CDFbVrsDDgB/30Yavrl3h889hT3othkUtY1HkGQB0vLIf3HknLF9eauV/TIzr0hmoewmys+H9992wEvmHu+7SBRo1suohY6qqgCUCVV0M7Cnh82Wq6u0G8y3QMlCxVBe9e8Mnn8DO3ZE8svdG6kdlcVzP5vD00+6mgw4d3P0IJSjLUBN797oerR984N/6ixdDaipccEHB5TVrujl5LBEYUzVVlTaCicAnvj4UketEJFFEEnft2lWJYVU9/fvDhx9CVBR07haJfPSh60n00kvQvDnccot77UPXrrB+ve+b1Lx27HBVOnPmwOTJJQ914fXOO64r61lnFf1s0CDXuJ2SUvp+jDGVK+iJQESG4hLB3b7WUdVZqpqgqglxcXGVF1wVNXQofP11vkHpYmJg4kRYtAjOPNNdufMNYpdf167uor5pk+/9b9zovsFv3QoPPADJyfDKKyXHlJMD770HI0cWf1/DwIHu2doJjKl6gpoIRKQb8BIwWlVTgxlLqOnVC7oXbl6vWRPeeMMNYjdmDOzcWWS70hqMExNdEsjIcHll+nRXCvnb30ouFXz7rTtc4Wohr9693cQ7Vj1kTNUTtEQgIq2Bd4ErVHVjsOKodmJiYN48N8zohRe6iYrz6dzZ5YviEsHCha60Ua8eLF3qLt4ibtSL7dvdQKm+zJ7tGojPOaf4z2vVglNPtRKBMVVRILuPvgF8A3QUkWQRmSgik0RkkmeVB4BY4FkRWSkiiYGKJex07QqvvgrLlrk2g3yiotzYRKtXZuf2Mtq3z02NMGIEtG3rNuvQIW+bM86AU05x8+gUyiuAm2DtxRfh+utd11FfBg6ElSsrbyhsY4x/AjZVpaqOLeXza4BrAnX8sHfxxbBihRu+tG1b12/0p5/gp5/ouuV/WJ7UhZzGfXgtdgpTf7uZXZkNmDBsG0/8+zgaN69dYFfeUsHIke6b/3XX5X32008wYYKrTpoxo+SQBg1yuefrr+Hssyv8jI0x5aWqIfXo3bu3Gj9lZ6uedZaqu/6q1q6t2ru3PtTzXQXVhLgtCqqn1vpBf6C3W+e001RTU4vsKidHtV8/1TZtVDMz3bLdu1XbtlVt0UJ1587Swzl4UDUiQnXq1Io9TWNM6YBE9XFdDXqvIRNANWu6W30//hjWrYMDByAxkR4Png/Ab5Ft+de/4OvDCSSkL4LXXoPvv8/rMpSPt1SwbZubLCc7Gy65xE2e8847rudqaerWdbc7WIOxMVWLaIjNGJKQkKCJidaccCxyctxNYqefDtHRhT5cvBhGj3ZTi82f71qMPVTdNJq7drmplmfOdN1Kr77a/2PfdZebyzgtzb/hs40xFUNElqtqQnGfWYkgDNWo4UYHLZIEwFXkL1vmWpUHD3alCQ9vqWDrVpcEJk8uWxIA186QlQW3326zlhlTVVgiMEV17gzffOOGNh01ys2e9t57sH8/Z5/tBpQ780z4+9/LvuuhQ+Huu90cPKU1LhtjKodVDRnfDhyAm25yjQDp6W6Cgf79OXrGCGoMHICc1BnKcad3To6biO2tt9zjoosCELsxpoCSqoYsEZjSZWW5EsKnn8Jnn7luqV6xsXDSSa4UMXSo67Zao/SC5uHDrmSxfDl88YW7e9kYEziWCEzFSkmBH390PZHWr3ePdetgzx53RX/uOejWrdTd7N7t7jZOS3N55sQTKyF2Y8KUJQITeDk5rl/pnXe68atvvhkefBDq1y9xs02bXDKIiXHJIDa2kuI1JsxYryETeDVqwPjxbqzpa65xfUQ7dXJDXWzb5rOLUPv2bjKbbdvgiitcPvHl6FHXU+mxxwJzCsaEK0sEpmLFxLguQd98A82aufEn2raFJk3coEV33+1ucss3IcKAAS5vfPIJPPqo713feSc8+yxMnQpPPBH4UzEmXFjVkAmco0dda/CKFXmP1avdyHVdu8I//uHuVcAVGMaNgzffdPMzDx1acFcvvACTJrlOTCkpbr2XXnLTMBhjSldS1VDQxw4q68PGGgpxmZmq//2vauvWbmyjSy5R/fVXVVVNT1ft1Em1WTPV337L2+T//k+1Zk3Vs892wydlZqqOGKFao4bq228fWzgbN6refLPq3Ll5YyiFik2bVH/5JdhRmFBBCWMNBf3CXtaHJYJq4uBB1WnTVKOiVOvWVX3oIdXERF3zdZrWrZujgwerZmWprl+v2rChapcuqvv25W1+4IBq//6qtWq5RJHfnj2q8+ervvWW74t7To7qyy+r1qunKuL+E5o1U73vPtVt2wJ10hVn3z4Xb6NGqj/+GOxoTCiwRGCqri1bVMeM0dwRUkFfj7pWQXVy/EfaLm6fNm2ao1u3Ft10zx7Vrl3dxfzJJ1WvvVb1pJMK7EpbtlR96imXOPJvd+GF7vOhQ92F/+OPVf/0J1fKqFHDvV63rvTwc3Lco7LddVde8oqLU01KCtyx9u1zSdmENksEpupbt0713XfdFf2mm/S61p+4kbM5pN80PEv1/vsL1hd5/Pabart27i+5USPVkSNV//IX1S+/dBf3wYPdZ7Gxqg8/rPrRRy45RESoPvqoq2rKb+tWVyqIjVVt3Fh12TLfIf/6q+opp6j26ePfMNwVZdMm1chI1fHjVTdsUG3a1J1TccnyWG3e7Epkxx/vfi6hVBX1yiuqF1ygeuhQsCOpGiwRmJBz6JDq1eNz9P2/rFIdPdrV30RGql5+uasLOngwd90DB1wV0tGjxe9r6VLVc87JKyV06KCamFjy8X/5RfXEE1Xr1HHJo7AlS9wFuH59V7PVrp27QFeG0aNVo6Pz8uLKlS4JnnBCsbmy3I4cUe3b1yWCkSNdSUlE9YwzSq52qwrWrHHVhqB6003BjqZqsERgQt+mTa5VNzra/dlGRrpJdO6/X3XBAtWUFNWMjBLraVauVH3hhYLVRCX54w/V3r1dQ/Vrr+Utf/55d/j27V1B5ttvXQmiaVPV5cuP8TxLsWCBO/2//rXg8mXLXBVZly5uwqCKcO+97lhvvune//qr6vTpqq1aueXDhlXNKqPMTNWePV2V2dVXu1jnzQt2VMFnicBUH+nprs7nrrvc19WaNbVAo0CNGi5ZNG+u2quXSxQ//FDuivz9+1WHD3e7fvRR1euvd69HjlTduzdvvaQk1xEqOtpdrP2RmekSia+STGFZWe5CHx9ffHXHggVuErqEhIIN6+WxaJH79j9hQtHPsrNV//lP93O4995jO04g/PnPLrZ331U9fNj9GcTEqG7f7v8+cnJU//1v1d9/D1yclS0oiQB4BUgB1vj4XICZwGZgFdDLn/1aIjAF7NvnEsPMmap/+5uryL71VtdyPGiQSwzg5tO84Qb39fall1yDweTJrqF66FDVG290X/uTkopcmQ8fdr1cvblm6tSibQuqqsnJ7kIdGenCWbnS5a389u5V/c9/3P4aNHD76927aM+n4jz7rFu/pC6zH3zg2j8GDixQe1YmqamuzaF9+6Lx53fNNS6e+fPLd5xA+P57993giivylm3c6BL0oEHF/96K88or7tz69q3aVWBlEaxEMAjoVUIiOBv4xJMQTgG+82e/lghMmezapTp7tur557vK/Pylh8aNVTt3dpMxe6ucvK3OZ56p+sgjrt4nK0uPHlV9/HH3LbMke/e6C07+wzRrpjpggOqQIe4iDa4aaeJE1f/937xbKk4/3RVeirNnj6t+Gjy49MLN3Lnu2/yZZ7okVhY5OS43RkT4jsUrI0O1e3f3bbsqdLnNyHD3obRsWbC0pqr6+uvuZzx9eun7+f1396cRH++2ufXWwMTry5YtrkprzZqK3W/QqoaAtiUkgheAsfnebwCOK22flghMuWVkqK5Y4a5aha+Q2dmqq1e70sK117p+qd4reYMGqqNGqT79tOumU4rsbHeYt95ydfkTJ7oLeM+erkbr668LfjM9dEj1739XbdLEHe6CC1zhZsYM1/X1mWdcd9caNfy/Z+Dll92+Ro92jb7+evFFt91jj/m3/saNrsG8X7/gf3O+9VYX++efF//5lVe6n+GiRSXv59JLXUPz+vWuWQpU33mn9OMfPer+PP79b9VbblG9556iCak0n33mEiu4rtAV2eOpqiaCj4DT8r1fCCT4WPc6IBFIbN26dcX9ZIwpSUqK+3p97bV5fVTB1ZlMmaL6xRdlu8qWYt8+1QceKFg4yf8o6zfTmTPddmPH+lclsmSJKzQNG+Z/u4Wqq6oCd/GrSImJrodX376qTzzhu+tqerrqG2+4GG680ff+0tPdr65FC5fAijN/vtvPgw+695mZeT2nNm8uuv7hwy6JDxvm1vH+rurUcUmneXP3J1RaKS4nx31pEHHVi88/7/YzZUrJ25VFyCeC/A8rEZig+eUX10o6YkRe30RvaeGhh1xbxR9/FL9tdrbfSSM72xVe9u939fW//17+bqF/+5sL8+qrS/7G/vnn7uLVsWP5jnXLLe44s2eXLYn4smiRK2m0bu3aULwX2N693Tk9+aTquHGuKsh7Z3iHDqX3CFu50lWxxcSoLl5c8LP0dHe8zp0LFhi3bHG1hb165X1Dz8lx1YQnnOCO3aOH6qRJrkD500+uYX/58rzYR4zwncj27VM97zy33qWX5p3D5Mlu2cKF5foRFlFVE4FVDZnQlZ7u+iRec03BqxG4/pWnnabarZu7snhbhevVc40Cldzn8oEH3OG7dXNVVoV98IHLa926lb+XTGamu7nOezf3lCmueaU8nbU+/NCNPNK5s2uAV3UX0SeecFVQ3h9zixYuB0+f7rbxt6fUpk0uadSqpTpnTt7yKVPcfpcuLbrN+++7z264wf0MhwzR3OqbTz/1fazsbFejGB3tEu1tt7nfx+23u31ddZVLJjVrupJF/p/XwYMuzlatyl7FVJyqmgjOKdRY/L0/+7REYKqk/ftVv/rKXegvu8w1Cowe7f7Tb77Z/fd772pLSHBfTSvRBx+4aoqICHfh9BZO5s51y/r2daWPY3HwoKsfHzUqr8DUpo3rgnrdda6GbeJE9/7GG111TuF7HubMcfEkJLh2/uLs2HHs3TpTU/PuOn/oIdfbqEYNd3H25Y473Poirj3n2Wf9z+nbtxccSaVuXbePNm3cufpqt/D2grr88rKeYVHB6jX0BrATyAKSgYnAJGCS53MBngF+Blb7Uy2klghMKMvJcd1XmzZ1V7t7763U8Q9SU90FxVuV8Ze/uIvfoEHHft9BYWlprjfuOee4023WzCWi4493JQZvIUnEDdFx333ugizivm1XdDzFycx0Dcjewtrxx7u4fTlyxHVLvfPO8n9DP3y47FVnDz6oBW7sKy+7ocyYqiQ11Q0UBK5e4JZb3FVz9epKqTZ67z13cQbXxbS89xsci+xsV3X04INuFFnv7R6jRlXu2EA5OS4BRURU3buPs7Jcia1xY1caKq+SEoFNTGNMsCxY4OZ1Xr4cDh1yy6KioEsXiIiAgwfhwAH3fPAgnHginH66ewwcCPXqlfvQqanw4YcwdizUrl1B53MM0tIgKQkSEtypV7ZDh6BOnco/rr82boQePeCqq+C558q3D5u83piq7OhRN9fzjz+6WdxWrQIRd6GPjnbPUVFu+ddfuxneatWC/v3dpM/equecHPfcsqWbIjQ+PthnZirQkiUuUZY3YVkiMKa6yMiApUtdaWLBAti50yWNGjXcswj89ptLCiNHwo03wogRULNmwf3k5LhSRv36wTkPU+lKSgRBKIQZY8qtbl0480z38CU5GV58EWbNgnPPhbZtYfRoVx+0fTv8+ivs2OFKFnFxcPLJrjrq5JPdXNJ9+0JkZKWdkgk+KxEYU11lZcG8ea5S+euv4bjjoFWrvEfjxrB5M6xZA+vWQXq6265JE7j4YrjsMjj1VFfaMCHPqoaMCXeqrtqopM+3b4fERPjvf+H9910Laps2cOmlLnFkZBR8dO4M48ZBw4aVdx6m3CwRGGPKJj3dJYP//Ac+/9w1aHtFRbnG6v37XUP2ZZfBpEnQq1fw4jWlskRgjCm/fftce0Ldui4JeBueExPh+eddsjh0CPr0gT/9ySWH2rXdulFR7nVkpHtERLhnEZdI0tLyHpmZcMUV0KlTcM+3mrJEYIwJnLQ0+Pe/XVJYu7b8+6lRwz1uvBGmTYOYmIqL0VgiMMZUkiNH3Df7w4ddKeHwYfc+Kwuys91zVpZrk2jYEBo1cs8NG8KePfDAA67HU8OG7ma7SZOK9mDKznalkpLaPEwRlgiMMaFj9Wq47TZ3n0THju6xezfs2uUeaWnQrBkMGuQegwe7rq+FezdlZrpl1hUWsERgjAk1qjB/Pjz0kLugx8W5bq1xcRAbCz//DF995Xo6gatGat3atTt4H0eOuOWPPebutA7zbrCWCIwx1dPWrS4hfPWVKy00bAgNGuQ9Pv3Ujc0wYIBrw+jSJdgRB40lAmNMeFKF2bPhzjtd76fbb3ftELVrQ0qKu8N6xw7Yu9clie7dq21VkiUCY0x4270b7roLXn3VdW89fLjgvRFedeq4brD9+7uhNlThjz/yHikpblvvQH/eR4cOMH68u5eiijZiWyIwxhiAxYvhjTdcO0OLFnD88e65YUNYuRKWLXOPFStc76T8YmOhaVN3P4V3gD8RlwhWrXJtGV27uvaIceNce0YVYonAGGPK4tAhd3GvXdv1UIqLK3mihLQ0mDsXXnkFfvjBVS/17OlKHZmZeY/oaJckJkyA5s0r73ywRGCMMZVn7VpXBfXTT24ojtq18x7btsGiRS6pjBoF110HZ5xRKT2aLBEYY0xVsXEjvPSSSxa7d7sSR4MGrvSQne2eve0X3uon7+vJk+Gee8p12KDNRyAiI4CngZrAS6r6aKHPWwOvAY0860xV1Y8DGZMxxgRVhw7w+OPw8MNuYL8PPnAX/po1XUmhZs288Zy8X9S9jdLt2wckpICVCESkJrAROANIBn4AxqrqunzrzAJ+VNXnROQk4GNVbVvSfq1EYIwxZVdSiSCQFVN9gc2q+ouqHgHmAqMLraNAA8/rhsBvAYzHGGNMMQJZNdQC2J7vfTLQr9A604HPReQmoB5wegDjMcYYU4xgD74xFpitqi2Bs4F/iUiRmETkOhFJFJHEXbt2VXqQxhhTnQUyEewAWuV739KzLL+JwFsAqvoNEAU0KbwjVZ2lqgmqmhBXxW7SMMaYUBfIRPAD0F5E4kWkFnAp8EGhdX4FhgOISGdcIrCv/MYYU4kClghUNRv4H+AzYD3wlqquFZGHRGSUZ7XbgWtF5CfgDWC8htqNDcYYE+ICeh+B556AjwsteyDf63XAgEDGYIwxpmTBbiw2xhgTZCE3xISI7AK2lXPzJsDuCgwn2Ox8qq7qdC5Qvc6nOp0L+H8+bVS12N42IZcIjoWIJPq6sy4U2flUXdXpXKB6nU91OheomPOxqiFjjAlzlgiMMSbMhVsimBXsACqYnU/VVZ3OBarX+VSnc4EKOJ+waiMwxhhTVLiVCIwxxhRiicAYY8Jc2CQCERkhIhtEZLOITA12PGUlIq+ISIqIrMm3LEZE/k9ENnmeGwczRn+JSCsR+VJE1onIWhG5xbM8VM8nSkS+F5GfPOfzoGd5vIh85/mbe9Mz5lZIEJGaIvKjiHzkeR/K57JVRFaLyEoRSfQsC9W/tUYi8raIJInIehE5tSLOJSwSgWe2tGeAkcBJwFjPjGihZDYwotCyqcBCVW0PLPS8DwXZwO2qehJwCjDZ8/sI1fPJBIapanegBzBCRE4BHgP+rqonAntxo+2GiltwY4R5hfK5AAxV1R75+tuH6t/a08CnqtoJ6I77HR37uahqtX8ApwKf5Xt/D3BPsOMqx3m0Bdbke78BOM7z+jhgQ7BjLOd5vY+b0jTkzweoC6zATcK0G4jwLC/wN1iVH7gh4xcCw4CPAAnVc/HEuxVoUmhZyP2t4WZx3IKnk09FnktYlAgofra0FkGKpSI1U9Wdnte/A82CGUx5iEhboCfwHSF8Pp6qlJVACvB/wM9AmrpReCG0/uaeAu4CcjzvYwndcwE3Je7nIrJcRK7zLAvFv7V43DD9r3qq7V4SkXpUwLmESyKo9tR9HQipvsAiEg28A9yqqvvzfxZq56OqR1W1B+7bdF+gU5BDKhcRORdIUdXlwY6lAp2mqr1wVcOTRWRQ/g9D6G8tAugFPKeqPYGDFKoGKu+5hEsi8Ge2tFD0h4gcB+B5TglyPH4TkUhcEpijqu96Fofs+XipahrwJa76pJGIeId6D5W/uQHAKBHZCszFVQ89TWieCwCqusPznAK8h0vUofi3lgwkq+p3nvdv4xLDMZ9LuCQCf2ZLC0UfAFd5Xl+Fq2uv8kREgJeB9ar6ZL6PQvV84kSkked1HVx7x3pcQrjQs1pInI+q3qOqLVW1Le7/5AtVHUcInguAiNQTkfre18CZwBpC8G9NVX8HtotIR8+i4cA6KuJcgt0AUokNLWcDG3F1t/cFO55yxP8GsBPIwn0zmIiru10IbAIWADHBjtPPczkNV3xdBaz0PM4O4fPpBvzoOZ81wAOe5e2A74HNwH+B2sGOtYznNQT4KJTPxRP3T57HWu//fgj/rfUAEj1/a/OAxhVxLjbEhDHGhLlwqRoyxhjjgyUCY4wJc5YIjDEmzFkiMMaYMGeJwBhjwpwlAmMqkYgM8Y7oaUxVYYnAGGPCnCUCY4ohIpd75hhYKSIveAaVOyAif/fMObBQROI86/YQkW9FZJWIvOcdD15EThSRBZ55ClaIyAme3UfnG1N+judOa2OCxhKBMYWISGfgEmCAuoHkjgLjgHpAoqqeDHwFTPNs8jpwt6p2A1bnWz4HeEbdPAX9cXeGgxtt9Vbc3BjtcOP7GBM0EaWvYkzYGQ70Bn7wfFmvgxvIKwd407POv4F3RaQh0EhVv/Isfw34r2d8mxaq+h6Aqh4G8Ozve1VN9rxfiZtnYmngT8uY4lkiMKYoAV5T1XsKLBT5c6H1yjs+S2a+10ex/0MTZFY1ZExRC4ELRaQp5M5v2wb3/+IdgfMyYKmq7gP2ishAz/IrgK9UNR1IFpHzPPuoLSJ1K/UsjPGTfRMxphBVXSci9+NmtaqBG/F1Mm4ikL6ez1Jw7Qjghv593nOh/wW42rP8CuAFEXnIs4+LKvE0jPGbjT5qjJ9E5ICqRgc7DmMqmlUNGWNMmLMSgTHGhDkrERhjTJizRGCMMWHOEoExxoQ5SwTGGBPmLBEYY0yY+39UjaZabQzWrgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_LxatO5J-pp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ed45ab4-4960-4f49-ff4d-5d70ca91c182"
      },
      "source": [
        "testloss = model.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "trainloss = model.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(trainloss[0]))\n",
        "print(\"Train Acc: \" + str(trainloss[1]))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 3s 25ms/step - loss: 0.9411 - accuracy: 0.6514\n",
            "Test Loss 0.9410754442214966\n",
            "Test Acc: 0.6514349579811096\n",
            "898/898 [==============================] - 23s 25ms/step - loss: 0.7796 - accuracy: 0.7091\n",
            "Train Loss 0.779575765132904\n",
            "Train Acc: 0.7091156244277954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swoRERVdKQ1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d51fd6ef-67db-496c-9ac2-e0f2b49f6eaf"
      },
      "source": [
        "testlosz = model.evaluate(x_val, y_val) \n",
        "print(\"val Loss \" + str(testlosz[0]))\n",
        "print(\"val Acc: \" + str(testlosz[1]))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 3s 25ms/step - loss: 0.9574 - accuracy: 0.6512\n",
            "val Loss 0.9574462175369263\n",
            "val Acc: 0.6511563062667847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5iaZIU6pPzk",
        "outputId": "6c215526-848d-4eed-ba22-d236885a6a0e"
      },
      "source": [
        "from keras.models import load_model\n",
        "model_load = load_model('/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50editSGD5st.h5')\n",
        "\n",
        "model_load.summary()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 46, 46, 128)  0           add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_33 (Add)                    (None, 46, 46, 128)  0           activation_101[0][0]             \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 46, 46, 128)  0           add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, 46, 46, 128)  0           activation_104[0][0]             \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 46, 46, 128)  0           add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_35 (Add)                    (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 23, 23, 256)  0           add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_36 (Add)                    (None, 23, 23, 256)  0           activation_110[0][0]             \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 23, 23, 256)  0           add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_37 (Add)                    (None, 23, 23, 256)  0           activation_113[0][0]             \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 23, 23, 256)  0           add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_38 (Add)                    (None, 23, 23, 256)  0           activation_116[0][0]             \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 23, 23, 256)  0           add_38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_39 (Add)                    (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 12, 12, 512)  0           add_39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_40 (Add)                    (None, 12, 12, 512)  0           activation_122[0][0]             \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 12, 12, 512)  0           add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_41 (Add)                    (None, 12, 12, 512)  0           activation_125[0][0]             \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 12, 12, 512)  0           add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_42 (Add)                    (None, 12, 12, 512)  0           activation_128[0][0]             \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 12, 12, 512)  0           add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_43 (Add)                    (None, 12, 12, 512)  0           activation_131[0][0]             \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 12, 12, 512)  0           add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_44 (Add)                    (None, 12, 12, 512)  0           activation_134[0][0]             \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 12, 12, 512)  0           add_44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_45 (Add)                    (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 6, 6, 1024)   0           add_45[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_46 (Add)                    (None, 6, 6, 1024)   0           activation_140[0][0]             \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 6, 6, 1024)   0           add_46[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_47 (Add)                    (None, 6, 6, 1024)   0           activation_143[0][0]             \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 6, 6, 1024)   0           add_47[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypc8clklx2p8",
        "outputId": "af408564-d325-41bd-8d69-b4271dcbf416"
      },
      "source": [
        "#loss,acc = model_load.evaluate(xtrain,ytrain)\n",
        "\"\"\"print(\"loss:\",loss)\n",
        "print(\"acc:\",acc)kjjkj\"\"\"\n",
        "\n",
        "\n",
        "testloss = model_load.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "\n",
        "testloss = model_load.evaluate(xtrain, ytrain) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 6s 25ms/step - loss: 0.9411 - accuracy: 0.6514\n",
            "Test Loss 0.9410754442214966\n",
            "Test Acc: 0.6514349579811096\n",
            "898/898 [==============================] - 23s 25ms/step - loss: 0.7796 - accuracy: 0.7091\n",
            "Test Loss 0.779575765132904\n",
            "Test Acc: 0.7091156244277954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7mSww_U2O_q",
        "outputId": "b0ea5340-5fee-4d97-baa7-1526fd58c2ae"
      },
      "source": [
        "testlosz = model_load.evaluate(x_val, y_val) \n",
        "print(\"Test Loss \" + str(testlosz[0]))\n",
        "print(\"Test Acc: \" + str(testlosz[1]))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 3s 25ms/step - loss: 0.9574 - accuracy: 0.6512\n",
            "Test Loss 0.9574462175369263\n",
            "Test Acc: 0.6511563062667847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdU7uU3PYCnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75ce0167-8f04-48b3-8a91-fc8b811801fd"
      },
      "source": [
        "print (x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3589, 48, 48, 1)\n",
            "(3589,)\n",
            "(3589, 48, 48, 1)\n",
            "(3589,)\n",
            "(28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_Tf1qg8TKnx",
        "outputId": "dbb39e20-d8a9-433e-d314-69eb863d4913"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "#y_pred = model_load.predict(xtest)\n",
        "\n",
        "test_prob = model_load.predict(xtest)\n",
        "test_pred = np.argmax(test_prob, axis=1)\n",
        "test_accuracy = np.mean(test_pred == ytest)\n",
        "\n",
        "print(test_accuracy)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6514349400947339\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpwJv9V54_1M"
      },
      "source": [
        "\n",
        "emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "KMe4WL0T5BcJ",
        "outputId": "77a7f94b-f053-48f0-a360-50ba76239510"
      },
      "source": [
        "conf_mat = confusion_matrix(ytest, test_pred)\n",
        "\n",
        "pd.DataFrame(conf_mat, columns=emotions.values(), index=emotions.values())\n",
        "\n",
        "\n",
        "\n",
        "fig, ax = plot_confusion_matrix(conf_mat=conf_mat,show_normed=True,show_absolute=False,figsize=(8, 8))\n",
        "fig.show()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW3FZjp-5DgF",
        "outputId": "50732c5d-25c6-48fc-fcb0-645a55366af2"
      },
      "source": [
        "print(classification_report(ytest, test_pred, target_names=emotions.values()))\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry       0.59      0.51      0.55       459\n",
            "     Disgust       0.50      0.32      0.39        50\n",
            "        Fear       0.55      0.37      0.44       525\n",
            "       Happy       0.81      0.89      0.85       908\n",
            "         Sad       0.57      0.54      0.56       628\n",
            "    Surprise       0.75      0.76      0.75       423\n",
            "     Neutral       0.54      0.71      0.61       596\n",
            "\n",
            "    accuracy                           0.65      3589\n",
            "   macro avg       0.62      0.59      0.59      3589\n",
            "weighted avg       0.65      0.65      0.64      3589\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}