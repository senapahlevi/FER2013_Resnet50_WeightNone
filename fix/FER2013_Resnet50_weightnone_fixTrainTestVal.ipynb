{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER2013_Resnet50_weightnone_fixTrainTestVal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-Qn1jsBTIBl0b7myLQxqa8WjCcfbamqM",
      "authorship_tag": "ABX9TyNa+dEmx2bdNjQLe8YP65KE"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b86nukQOxN7l"
      },
      "source": [
        "Resnet-50 From Scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p8gxtGy0TWP",
        "outputId": "de079ca5-af11-4662-aaf8-d90f38ba07aa"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "inputFolder = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth' \n",
        "for root, directories, filenames in os.walk(inputFolder): \n",
        "    for filename in filenames: print(os.path.join(root,filename))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Best_Model_resnet50Scracth1again.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe4.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth1again.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50ScracthSGD1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50AUGScracthadam3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD1try2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD4.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50oriScracth_sena2.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsiscWIMBDX2",
        "outputId": "f4c8a9c9-901f-4f44-d717-a645a446e1da"
      },
      "source": [
        "%cd /content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "wLMSe510xNCJ",
        "outputId": "3da9f6f5-cb75-4f61-d978-1e7de9a074fc"
      },
      "source": [
        "#Create a directory to save our generated models.dasdas\n",
        "\n",
        "#os.mkdir(\"./modelscracth\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-cf55f19f3613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#os.mkdir(\"./modelscracth\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ls' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_kluusLxM1B",
        "outputId": "27236e39-378c-4f8b-d1ef-3f51af3fa721"
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:400: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfUSF_tAxNMP"
      },
      "source": [
        "#Define the identity block helper function.\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "   \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VdYtzhn1F0I"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path \n",
        "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b',padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd-O8ZMx1GAW"
      },
      "source": [
        "def ResNet50(input_shape = (48,48,1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    #X = ZeroPadding2D((1, 1))(X_input)\n",
        "    X = X_input\n",
        "    # Stage 1\n",
        "\n",
        "    X = Conv2D(8, (3, 3), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # removed maxpool\n",
        "    #X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='c')\n",
        "\n",
        "\n",
        "    # Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [64,64,256], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL . \n",
        "    X = AveragePooling2D((2,2), name='avg_pool')(X)\n",
        "    \n",
        "    # output layerds\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(512, activation = 'relu', name='fc1024' , kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GKsSwtp-GuL"
      },
      "source": [
        "\"\"\"def ResNet50ori(input_shape = (48, 48, 1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns: dsdsf\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50ori')\n",
        "\n",
        "    return model\"\"\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3oWTDXlyBHM2",
        "outputId": "95872e23-6ed4-4acf-e3b4-46770aa8af3f"
      },
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        " \n",
        "dataset_path = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv'\n",
        "image_size=(48,48)\n",
        "#batch_size = 64\n",
        "\n",
        "def load_fer2013():\n",
        "    data = pd.read_csv(dataset_path)\n",
        "    data = (data[data['pixels'].notnull()])\n",
        "    pixels = data['pixels'].tolist()\n",
        "    width, height = 48, 48\n",
        "    faces = []\n",
        "    for pixel_sequence in pixels:\n",
        "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "        face = np.asarray(face).reshape(width, height)\n",
        "        face = cv2.resize(face.astype('uint8'),image_size)\n",
        "        faces.append(face.astype('float32'))\n",
        "    faces = np.asarray(faces)\n",
        "    faces = np.expand_dims(faces, -1)\n",
        "    emotions = (data['emotion'])#.values\n",
        "    return faces, emotions\n",
        " \n",
        "def preprocess_input(x, v2=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if v2:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x\n",
        " \n",
        "faces, emotions = load_fer2013()\n",
        "faces = preprocess_input(faces)\n",
        "#xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
        "#Data Augumentation\n",
        "data_generator = ImageDataGenerator(\n",
        "                        rotation_range=10,\n",
        "                        shear_range = 10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True)\n",
        "\"\"\"data_generator = ImageDataGenerator( )\n",
        "\"\"\""
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'data_generator = ImageDataGenerator( )\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWLhavr-rSF5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "895f7f85-9930-46ca-c552-cbb571846a4e"
      },
      "source": [
        "\"\"\"\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.1,)\n",
        "x_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1,)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nxtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.1,)\\nx_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1,)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "RGhnYFXgaqL9",
        "outputId": "0e60da2f-3a44-4d06-910b-2e0f2fa4191a"
      },
      "source": [
        "\"\"\"print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (y_train.shape)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'print (\"validasi\",x_val.shape)\\nprint (y_val.shape)\\nprint (\"test\",xtest.shape)\\nprint (ytest.shape)\\nprint (\"train\",xtrain.shape)\\nprint (y_train.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rDS3hqhDSteM",
        "outputId": "c8a7b4bd-c304-44dd-b3bd-a7ad3840c64a"
      },
      "source": [
        "train_ratio = 0.80\n",
        "validation_ratio = 0.10\n",
        "test_ratio = 0.10\n",
        "\n",
        "# train is now 75% of the entire data set\n",
        "# the _junk suffix means that we drop that variable completely # the _junk suffix means that we drop that variable completely\n",
        "#x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=1 - train_ratio)\n",
        "\n",
        "# test is now 10% of the initial data set\n",
        "# validation is now 15% of the initial data set\n",
        "#x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "x_val, xtest, y_val, ytest = train_test_split(xtest, ytest, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "\n",
        "print(xtrain, x_val, xtest)\n",
        "\n",
        "\"\"\"X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2\"\"\""
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[-0.4823529 ]\n",
            "   [-0.29411763]\n",
            "   [-0.20784312]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[-0.3333333 ]\n",
            "   [-0.30196077]\n",
            "   [-0.3333333 ]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[-0.1607843 ]\n",
            "   [-0.30196077]\n",
            "   [-0.30196077]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.64705884]\n",
            "   [ 0.6313726 ]\n",
            "   [ 0.70980394]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 0.4039216 ]\n",
            "   [ 0.48235297]\n",
            "   [ 0.69411767]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 0.18431377]\n",
            "   [ 0.32549024]\n",
            "   [ 0.34901965]\n",
            "   ...\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.9843137 ]\n",
            "   [ 1.        ]]]\n",
            "\n",
            "\n",
            " [[[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [-0.1607843 ]\n",
            "   [-0.21568626]\n",
            "   [-0.04313725]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 0.9843137 ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [-0.03529412]\n",
            "   [-0.23921567]\n",
            "   [-0.10588235]]\n",
            "\n",
            "  [[ 0.9764706 ]\n",
            "   [ 0.96862745]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 0.10588241]\n",
            "   [-0.14509803]\n",
            "   [-0.12941176]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.99215686]\n",
            "   [-0.78039217]\n",
            "   [-0.0745098 ]\n",
            "   ...\n",
            "   [-0.2862745 ]\n",
            "   [-0.25490195]\n",
            "   [-0.23921567]]\n",
            "\n",
            "  [[-0.9607843 ]\n",
            "   [-0.96862745]\n",
            "   [-0.32549018]\n",
            "   ...\n",
            "   [-0.2862745 ]\n",
            "   [-0.2862745 ]\n",
            "   [-0.26274508]]\n",
            "\n",
            "  [[-0.94509804]\n",
            "   [-1.        ]\n",
            "   [-0.6784314 ]\n",
            "   ...\n",
            "   [-0.27058822]\n",
            "   [-0.27058822]\n",
            "   [-0.27058822]]]\n",
            "\n",
            "\n",
            " [[[-0.9607843 ]\n",
            "   [-0.9529412 ]\n",
            "   [-0.9529412 ]\n",
            "   ...\n",
            "   [-0.21568626]\n",
            "   [-0.7176471 ]\n",
            "   [-0.7647059 ]]\n",
            "\n",
            "  [[-0.9607843 ]\n",
            "   [-0.9529412 ]\n",
            "   [-0.9607843 ]\n",
            "   ...\n",
            "   [-0.25490195]\n",
            "   [-0.78039217]\n",
            "   [-0.7882353 ]]\n",
            "\n",
            "  [[-0.9607843 ]\n",
            "   [-0.9607843 ]\n",
            "   [-0.9607843 ]\n",
            "   ...\n",
            "   [-0.5686275 ]\n",
            "   [-0.78039217]\n",
            "   [-0.7647059 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.85882354]\n",
            "   [-0.8352941 ]\n",
            "   [-0.18431371]\n",
            "   ...\n",
            "   [-0.8980392 ]\n",
            "   [-0.9137255 ]\n",
            "   [-0.92156863]]\n",
            "\n",
            "  [[-0.84313726]\n",
            "   [-0.654902  ]\n",
            "   [-0.00392157]\n",
            "   ...\n",
            "   [-0.90588236]\n",
            "   [-0.9137255 ]\n",
            "   [-0.92941177]]\n",
            "\n",
            "  [[-0.84313726]\n",
            "   [-0.32549018]\n",
            "   [ 0.16078436]\n",
            "   ...\n",
            "   [-0.9137255 ]\n",
            "   [-0.92156863]\n",
            "   [-0.92941177]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.27843136]\n",
            "   [-0.27058822]\n",
            "   [-0.24705881]\n",
            "   ...\n",
            "   [-0.62352943]\n",
            "   [-0.5529412 ]\n",
            "   [-0.67058825]]\n",
            "\n",
            "  [[-0.27843136]\n",
            "   [-0.26274508]\n",
            "   [-0.24705881]\n",
            "   ...\n",
            "   [-0.58431375]\n",
            "   [-0.5764706 ]\n",
            "   [-0.6392157 ]]\n",
            "\n",
            "  [[-0.24705881]\n",
            "   [-0.25490195]\n",
            "   [-0.23137254]\n",
            "   ...\n",
            "   [-0.6156863 ]\n",
            "   [-0.6392157 ]\n",
            "   [-0.6313726 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.19215685]\n",
            "   [-0.12156862]\n",
            "   [-0.06666666]\n",
            "   ...\n",
            "   [-0.8509804 ]\n",
            "   [-0.8509804 ]\n",
            "   [-0.5529412 ]]\n",
            "\n",
            "  [[-0.20784312]\n",
            "   [-0.1372549 ]\n",
            "   [-0.09019607]\n",
            "   ...\n",
            "   [-0.827451  ]\n",
            "   [-0.79607844]\n",
            "   [-0.46666664]]\n",
            "\n",
            "  [[-0.19999999]\n",
            "   [-0.1607843 ]\n",
            "   [-0.08235294]\n",
            "   ...\n",
            "   [-0.827451  ]\n",
            "   [-0.64705884]\n",
            "   [-0.40392154]]]\n",
            "\n",
            "\n",
            " [[[-0.827451  ]\n",
            "   [-0.7882353 ]\n",
            "   [-0.7254902 ]\n",
            "   ...\n",
            "   [-0.6862745 ]\n",
            "   [-0.6392157 ]\n",
            "   [-0.8117647 ]]\n",
            "\n",
            "  [[-0.827451  ]\n",
            "   [-0.78039217]\n",
            "   [-0.7647059 ]\n",
            "   ...\n",
            "   [-0.70980394]\n",
            "   [-0.5686275 ]\n",
            "   [-0.654902  ]]\n",
            "\n",
            "  [[-0.75686276]\n",
            "   [-0.67058825]\n",
            "   [-0.7254902 ]\n",
            "   ...\n",
            "   [-0.7882353 ]\n",
            "   [-0.6       ]\n",
            "   [-0.5686275 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.41176474]\n",
            "   [ 0.85882354]\n",
            "   [ 0.96862745]\n",
            "   ...\n",
            "   [ 0.3176471 ]\n",
            "   [ 0.30196083]\n",
            "   [ 0.32549024]]\n",
            "\n",
            "  [[ 0.92156863]\n",
            "   [ 0.5764706 ]\n",
            "   [ 0.7490196 ]\n",
            "   ...\n",
            "   [ 0.3176471 ]\n",
            "   [ 0.33333337]\n",
            "   [ 0.32549024]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [-0.11372548]\n",
            "   [ 0.49803925]\n",
            "   ...\n",
            "   [ 0.2941177 ]\n",
            "   [ 0.39607847]\n",
            "   [ 0.39607847]]]\n",
            "\n",
            "\n",
            " [[[ 0.9843137 ]\n",
            "   [ 1.        ]\n",
            "   [ 0.7176471 ]\n",
            "   ...\n",
            "   [ 0.05882359]\n",
            "   [ 1.        ]\n",
            "   [ 0.96862745]]\n",
            "\n",
            "  [[ 0.9843137 ]\n",
            "   [ 1.        ]\n",
            "   [ 0.8117647 ]\n",
            "   ...\n",
            "   [-0.08235294]\n",
            "   [ 1.        ]\n",
            "   [ 0.9764706 ]]\n",
            "\n",
            "  [[ 0.99215686]\n",
            "   [ 1.        ]\n",
            "   [ 0.92156863]\n",
            "   ...\n",
            "   [-0.2235294 ]\n",
            "   [ 1.        ]\n",
            "   [ 0.9843137 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 0.70980394]\n",
            "   ...\n",
            "   [-0.8980392 ]\n",
            "   [-0.8745098 ]\n",
            "   [-0.8117647 ]]\n",
            "\n",
            "  [[ 0.8901961 ]\n",
            "   [ 0.17647064]\n",
            "   [-0.62352943]\n",
            "   ...\n",
            "   [-0.8666667 ]\n",
            "   [-0.84313726]\n",
            "   [-0.8352941 ]]\n",
            "\n",
            "  [[-0.3490196 ]\n",
            "   [-0.75686276]\n",
            "   [-0.654902  ]\n",
            "   ...\n",
            "   [-0.85882354]\n",
            "   [-0.84313726]\n",
            "   [-0.827451  ]]]] [[[[ 0.56078434]\n",
            "   [ 0.58431375]\n",
            "   [ 0.56078434]\n",
            "   ...\n",
            "   [-0.6862745 ]\n",
            "   [-0.62352943]\n",
            "   [-0.7176471 ]]\n",
            "\n",
            "  [[ 0.30196083]\n",
            "   [ 0.30196083]\n",
            "   [ 0.27058828]\n",
            "   ...\n",
            "   [-0.7019608 ]\n",
            "   [-0.6313726 ]\n",
            "   [-0.6392157 ]]\n",
            "\n",
            "  [[-0.14509803]\n",
            "   [-0.1372549 ]\n",
            "   [-0.09803921]\n",
            "   ...\n",
            "   [-0.78039217]\n",
            "   [-0.7019608 ]\n",
            "   [-0.654902  ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.082353  ]\n",
            "   [-0.19215685]\n",
            "   [ 0.03529418]\n",
            "   ...\n",
            "   [-0.9529412 ]\n",
            "   [-0.9607843 ]\n",
            "   [-0.9529412 ]]\n",
            "\n",
            "  [[ 0.1686275 ]\n",
            "   [-0.27058822]\n",
            "   [-0.04313725]\n",
            "   ...\n",
            "   [-0.9607843 ]\n",
            "   [-0.9607843 ]\n",
            "   [-0.9529412 ]]\n",
            "\n",
            "  [[ 0.2313726 ]\n",
            "   [-0.1372549 ]\n",
            "   [-0.3098039 ]\n",
            "   ...\n",
            "   [-0.9607843 ]\n",
            "   [-0.9607843 ]\n",
            "   [-0.9607843 ]]]\n",
            "\n",
            "\n",
            " [[[-0.36470586]\n",
            "   [-0.31764704]\n",
            "   [-0.42745095]\n",
            "   ...\n",
            "   [-0.84313726]\n",
            "   [-0.78039217]\n",
            "   [-0.7490196 ]]\n",
            "\n",
            "  [[-0.3960784 ]\n",
            "   [-0.3098039 ]\n",
            "   [-0.41176468]\n",
            "   ...\n",
            "   [-0.79607844]\n",
            "   [-0.78039217]\n",
            "   [-0.7254902 ]]\n",
            "\n",
            "  [[-0.36470586]\n",
            "   [-0.41960782]\n",
            "   [-0.41960782]\n",
            "   ...\n",
            "   [-0.8117647 ]\n",
            "   [-0.7882353 ]\n",
            "   [-0.7490196 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.20000005]\n",
            "   [ 0.19215691]\n",
            "   [ 0.19215691]\n",
            "   ...\n",
            "   [-0.4352941 ]\n",
            "   [-0.4352941 ]\n",
            "   [-0.41960782]]\n",
            "\n",
            "  [[ 0.2313726 ]\n",
            "   [ 0.23921573]\n",
            "   [ 0.17647064]\n",
            "   ...\n",
            "   [-0.4352941 ]\n",
            "   [-0.4352941 ]\n",
            "   [-0.42745095]]\n",
            "\n",
            "  [[ 0.19215691]\n",
            "   [ 0.12941182]\n",
            "   [ 0.16078436]\n",
            "   ...\n",
            "   [-0.4352941 ]\n",
            "   [-0.4352941 ]\n",
            "   [-0.4352941 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.7882353 ]\n",
            "   [ 0.7882353 ]\n",
            "   [ 0.7882353 ]\n",
            "   ...\n",
            "   [ 0.8352941 ]\n",
            "   [ 0.81960785]\n",
            "   [ 0.8039216 ]]\n",
            "\n",
            "  [[ 0.79607844]\n",
            "   [ 0.7882353 ]\n",
            "   [ 0.8039216 ]\n",
            "   ...\n",
            "   [ 0.8352941 ]\n",
            "   [ 0.827451  ]\n",
            "   [ 0.8117647 ]]\n",
            "\n",
            "  [[ 0.7882353 ]\n",
            "   [ 0.7882353 ]\n",
            "   [ 0.8745098 ]\n",
            "   ...\n",
            "   [ 0.8352941 ]\n",
            "   [ 0.8352941 ]\n",
            "   [ 0.81960785]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.9764706 ]\n",
            "   [-1.        ]\n",
            "   [-0.8980392 ]\n",
            "   ...\n",
            "   [-0.5686275 ]\n",
            "   [-0.81960785]\n",
            "   [-0.5372549 ]]\n",
            "\n",
            "  [[-0.99215686]\n",
            "   [-0.9764706 ]\n",
            "   [-0.85882354]\n",
            "   ...\n",
            "   [-0.4588235 ]\n",
            "   [-0.79607844]\n",
            "   [-0.6784314 ]]\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-0.8666667 ]\n",
            "   [-0.8117647 ]\n",
            "   ...\n",
            "   [-0.4588235 ]\n",
            "   [-0.7176471 ]\n",
            "   [-0.8117647 ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.5764706 ]\n",
            "   [-0.64705884]\n",
            "   [-0.8745098 ]\n",
            "   ...\n",
            "   [ 0.81960785]\n",
            "   [ 0.0196079 ]\n",
            "   [-0.5294118 ]]\n",
            "\n",
            "  [[-0.5921569 ]\n",
            "   [-0.8039216 ]\n",
            "   [-0.9843137 ]\n",
            "   ...\n",
            "   [ 0.7882353 ]\n",
            "   [ 0.0196079 ]\n",
            "   [-0.6156863 ]]\n",
            "\n",
            "  [[-0.7019608 ]\n",
            "   [-0.45098037]\n",
            "   [-0.35686272]\n",
            "   ...\n",
            "   [ 0.75686276]\n",
            "   [-0.09019607]\n",
            "   [-0.7176471 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.78039217]\n",
            "   [ 0.7411765 ]\n",
            "   [ 0.6392157 ]\n",
            "   ...\n",
            "   [ 0.5058824 ]\n",
            "   [ 0.4039216 ]\n",
            "   [ 0.48235297]]\n",
            "\n",
            "  [[ 0.7647059 ]\n",
            "   [ 0.7254902 ]\n",
            "   [ 0.5921569 ]\n",
            "   ...\n",
            "   [ 0.4431373 ]\n",
            "   [ 0.3411765 ]\n",
            "   [ 0.43529415]]\n",
            "\n",
            "  [[ 0.7019608 ]\n",
            "   [ 0.6       ]\n",
            "   [ 0.4431373 ]\n",
            "   ...\n",
            "   [-0.0745098 ]\n",
            "   [ 0.37254906]\n",
            "   [ 0.32549024]]]\n",
            "\n",
            "\n",
            " [[[-0.3098039 ]\n",
            "   [-0.09019607]\n",
            "   [-0.15294117]\n",
            "   ...\n",
            "   [ 0.05882359]\n",
            "   [-0.19999999]\n",
            "   [-0.2235294 ]]\n",
            "\n",
            "  [[-0.01960784]\n",
            "   [-0.03529412]\n",
            "   [-0.46666664]\n",
            "   ...\n",
            "   [ 0.0196079 ]\n",
            "   [-0.29411763]\n",
            "   [-0.45098037]]\n",
            "\n",
            "  [[-0.19215685]\n",
            "   [-0.47450978]\n",
            "   [-0.45098037]\n",
            "   ...\n",
            "   [ 0.05882359]\n",
            "   [-0.03529412]\n",
            "   [-0.0745098 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.88235295]\n",
            "   [-0.96862745]\n",
            "   [-0.44313723]\n",
            "   ...\n",
            "   [ 0.84313726]\n",
            "   [ 0.90588236]\n",
            "   [ 0.9137255 ]]\n",
            "\n",
            "  [[-0.9529412 ]\n",
            "   [-0.92156863]\n",
            "   [-0.06666666]\n",
            "   ...\n",
            "   [ 0.90588236]\n",
            "   [ 0.92156863]\n",
            "   [ 0.92156863]]\n",
            "\n",
            "  [[-0.9607843 ]\n",
            "   [-0.8509804 ]\n",
            "   [ 0.34901965]\n",
            "   ...\n",
            "   [ 0.90588236]\n",
            "   [ 0.90588236]\n",
            "   [ 0.90588236]]]\n",
            "\n",
            "\n",
            " [[[-0.1607843 ]\n",
            "   [-0.16862744]\n",
            "   [-0.17647058]\n",
            "   ...\n",
            "   [-0.90588236]\n",
            "   [-0.94509804]\n",
            "   [-0.9529412 ]]\n",
            "\n",
            "  [[-0.23921567]\n",
            "   [-0.2235294 ]\n",
            "   [-0.23921567]\n",
            "   ...\n",
            "   [-0.8980392 ]\n",
            "   [-0.92941177]\n",
            "   [-0.94509804]]\n",
            "\n",
            "  [[-0.2235294 ]\n",
            "   [-0.19999999]\n",
            "   [-0.19999999]\n",
            "   ...\n",
            "   [-0.88235295]\n",
            "   [-0.90588236]\n",
            "   [-0.92941177]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.5058824 ]\n",
            "   [-0.41960782]\n",
            "   [-0.36470586]\n",
            "   ...\n",
            "   [-0.7490196 ]\n",
            "   [-0.7490196 ]\n",
            "   [-0.7490196 ]]\n",
            "\n",
            "  [[-0.56078434]\n",
            "   [-0.47450978]\n",
            "   [-0.41176468]\n",
            "   ...\n",
            "   [-0.75686276]\n",
            "   [-0.75686276]\n",
            "   [-0.7490196 ]]\n",
            "\n",
            "  [[-0.6156863 ]\n",
            "   [-0.5686275 ]\n",
            "   [-0.46666664]\n",
            "   ...\n",
            "   [-0.75686276]\n",
            "   [-0.7647059 ]\n",
            "   [-0.75686276]]]] [[[[-0.9137255 ]\n",
            "   [-0.9137255 ]\n",
            "   [-0.90588236]\n",
            "   ...\n",
            "   [-0.78039217]\n",
            "   [-0.7254902 ]\n",
            "   [-0.85882354]]\n",
            "\n",
            "  [[-0.90588236]\n",
            "   [-0.90588236]\n",
            "   [-0.8980392 ]\n",
            "   ...\n",
            "   [-0.8509804 ]\n",
            "   [-0.7490196 ]\n",
            "   [-0.8352941 ]]\n",
            "\n",
            "  [[-0.8980392 ]\n",
            "   [-0.8980392 ]\n",
            "   [-0.8980392 ]\n",
            "   ...\n",
            "   [-0.85882354]\n",
            "   [-0.8117647 ]\n",
            "   [-0.8352941 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.8509804 ]\n",
            "   [-0.85882354]\n",
            "   [-0.8509804 ]\n",
            "   ...\n",
            "   [-0.19999999]\n",
            "   [-0.5294118 ]\n",
            "   [-0.8352941 ]]\n",
            "\n",
            "  [[-0.8509804 ]\n",
            "   [-0.85882354]\n",
            "   [-0.8509804 ]\n",
            "   ...\n",
            "   [-0.10588235]\n",
            "   [-0.34117645]\n",
            "   [-0.67058825]]\n",
            "\n",
            "  [[-0.8509804 ]\n",
            "   [-0.85882354]\n",
            "   [-0.8509804 ]\n",
            "   ...\n",
            "   [-0.12941176]\n",
            "   [-0.23137254]\n",
            "   [-0.5686275 ]]]\n",
            "\n",
            "\n",
            " [[[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-0.9843137 ]\n",
            "   ...\n",
            "   [-1.        ]\n",
            "   [-0.4588235 ]\n",
            "   [-0.2862745 ]]\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-0.9843137 ]\n",
            "   [-0.9843137 ]\n",
            "   ...\n",
            "   [-1.        ]\n",
            "   [-0.69411767]\n",
            "   [-0.4352941 ]]\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-0.9843137 ]\n",
            "   [-0.9764706 ]\n",
            "   ...\n",
            "   [-1.        ]\n",
            "   [-0.78039217]\n",
            "   [-0.56078434]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.654902  ]\n",
            "   [ 0.22352946]\n",
            "   [ 0.6784314 ]]\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.7411765 ]\n",
            "   [-0.18431371]\n",
            "   [ 0.3411765 ]]\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.69411767]\n",
            "   [-0.25490195]\n",
            "   [ 0.09803927]]]\n",
            "\n",
            "\n",
            " [[[-0.4823529 ]\n",
            "   [-0.5529412 ]\n",
            "   [-0.30196077]\n",
            "   ...\n",
            "   [-0.5058824 ]\n",
            "   [-0.47450978]\n",
            "   [-0.46666664]]\n",
            "\n",
            "  [[-0.35686272]\n",
            "   [-0.4823529 ]\n",
            "   [-0.01176471]\n",
            "   ...\n",
            "   [-0.44313723]\n",
            "   [-0.41960782]\n",
            "   [-0.42745095]]\n",
            "\n",
            "  [[-0.24705881]\n",
            "   [-0.5058824 ]\n",
            "   [-0.41176468]\n",
            "   ...\n",
            "   [-0.372549  ]\n",
            "   [-0.35686272]\n",
            "   [-0.38823527]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.20784312]\n",
            "   [ 0.16078436]\n",
            "   [ 0.6       ]\n",
            "   ...\n",
            "   [-0.81960785]\n",
            "   [-0.78039217]\n",
            "   [-0.73333335]]\n",
            "\n",
            "  [[ 0.3411765 ]\n",
            "   [ 0.5058824 ]\n",
            "   [ 0.36470592]\n",
            "   ...\n",
            "   [-0.75686276]\n",
            "   [-0.7254902 ]\n",
            "   [-0.70980394]]\n",
            "\n",
            "  [[-0.0745098 ]\n",
            "   [-0.02745098]\n",
            "   [ 0.28627455]\n",
            "   ...\n",
            "   [-0.7490196 ]\n",
            "   [-0.70980394]\n",
            "   [-0.654902  ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.7411765 ]\n",
            "   [-0.81960785]\n",
            "   [-0.8117647 ]\n",
            "   ...\n",
            "   [-0.8352941 ]\n",
            "   [-0.85882354]\n",
            "   [-0.8509804 ]]\n",
            "\n",
            "  [[-0.75686276]\n",
            "   [-0.827451  ]\n",
            "   [-0.8117647 ]\n",
            "   ...\n",
            "   [-0.8352941 ]\n",
            "   [-0.85882354]\n",
            "   [-0.85882354]]\n",
            "\n",
            "  [[-0.77254903]\n",
            "   [-0.8352941 ]\n",
            "   [-0.827451  ]\n",
            "   ...\n",
            "   [-0.84313726]\n",
            "   [-0.85882354]\n",
            "   [-0.8509804 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.4823529 ]\n",
            "   [-0.47450978]\n",
            "   [-0.46666664]\n",
            "   ...\n",
            "   [ 0.26274514]\n",
            "   [ 0.33333337]\n",
            "   [ 0.2941177 ]]\n",
            "\n",
            "  [[-0.49019605]\n",
            "   [-0.49019605]\n",
            "   [-0.47450978]\n",
            "   ...\n",
            "   [ 0.26274514]\n",
            "   [ 0.3176471 ]\n",
            "   [ 0.2941177 ]]\n",
            "\n",
            "  [[-0.5058824 ]\n",
            "   [-0.4980392 ]\n",
            "   [-0.47450978]\n",
            "   ...\n",
            "   [ 0.26274514]\n",
            "   [ 0.3176471 ]\n",
            "   [ 0.2941177 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.09803927]\n",
            "   [ 0.06666672]\n",
            "   [ 0.04313731]\n",
            "   ...\n",
            "   [-0.5294118 ]\n",
            "   [-0.75686276]\n",
            "   [-0.81960785]]\n",
            "\n",
            "  [[ 0.07450986]\n",
            "   [ 0.04313731]\n",
            "   [ 0.01176476]\n",
            "   ...\n",
            "   [-0.372549  ]\n",
            "   [-0.6313726 ]\n",
            "   [-0.8039216 ]]\n",
            "\n",
            "  [[ 0.04313731]\n",
            "   [ 0.0196079 ]\n",
            "   [ 0.01176476]\n",
            "   ...\n",
            "   [-0.3333333 ]\n",
            "   [-0.4980392 ]\n",
            "   [-0.7490196 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.03529418]\n",
            "   [ 0.0196079 ]\n",
            "   [-0.02745098]\n",
            "   ...\n",
            "   [-0.88235295]\n",
            "   [-0.8745098 ]\n",
            "   [-0.8666667 ]]\n",
            "\n",
            "  [[-0.05098039]\n",
            "   [ 0.00392163]\n",
            "   [-0.02745098]\n",
            "   ...\n",
            "   [-0.92156863]\n",
            "   [-0.8509804 ]\n",
            "   [-0.79607844]]\n",
            "\n",
            "  [[-0.09803921]\n",
            "   [-0.01960784]\n",
            "   [ 0.0196079 ]\n",
            "   ...\n",
            "   [-0.9137255 ]\n",
            "   [-0.8117647 ]\n",
            "   [-0.8666667 ]]]\n",
            "\n",
            "\n",
            " [[[-0.4588235 ]\n",
            "   [-0.5137255 ]\n",
            "   [-0.5137255 ]\n",
            "   ...\n",
            "   [-0.25490195]\n",
            "   [-0.372549  ]\n",
            "   [-0.3960784 ]]\n",
            "\n",
            "  [[-0.49019605]\n",
            "   [-0.5058824 ]\n",
            "   [-0.5294118 ]\n",
            "   ...\n",
            "   [-0.30196077]\n",
            "   [-0.2862745 ]\n",
            "   [-0.5058824 ]]\n",
            "\n",
            "  [[-0.5058824 ]\n",
            "   [-0.5058824 ]\n",
            "   [-0.5372549 ]\n",
            "   ...\n",
            "   [-0.38823527]\n",
            "   [-0.26274508]\n",
            "   [-0.38039213]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.4352941 ]\n",
            "   [-0.40392154]\n",
            "   [-0.35686272]\n",
            "   ...\n",
            "   [ 0.54509807]\n",
            "   [ 0.48235297]\n",
            "   [ 0.2313726 ]]\n",
            "\n",
            "  [[-0.42745095]\n",
            "   [-0.372549  ]\n",
            "   [-0.32549018]\n",
            "   ...\n",
            "   [ 0.58431375]\n",
            "   [ 0.4901961 ]\n",
            "   [ 0.28627455]]\n",
            "\n",
            "  [[-0.44313723]\n",
            "   [-0.36470586]\n",
            "   [-0.30196077]\n",
            "   ...\n",
            "   [ 0.56078434]\n",
            "   [ 0.5372549 ]\n",
            "   [ 0.24705887]]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\\n\\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKvEv321Stt5",
        "outputId": "1e6bf2be-e050-494c-937f-295a836a235c"
      },
      "source": [
        "print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validasi (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "test (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "train (28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH9Q-TegBR26"
      },
      "source": [
        "#hyperparameter and callback\n",
        "batch_size = 64\n",
        "num_epochs = 60\n",
        "input_shape = (48, 48, 1)\n",
        "num_classes = 7\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGsscQRJBR-h"
      },
      "source": [
        "#Compile the model.\n",
        "\n",
        "\n",
        "from keras.optimizers import Adam, SGD\n",
        "model = ResNet50ori(input_shape = (48, 48, 1), classes = 7)\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer= optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rodttDWeT2yP"
      },
      "source": [
        "#kita mau save model callbacks\n",
        "\"\"\"import os\n",
        "try:\n",
        "  os.mkdir('scratchcheckpoint')\n",
        "except:\n",
        "  pass\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV29sTjET28U"
      },
      "source": [
        "\"\"\"file_name = 'Best_Model_resnet50Scracth_sena1.h5'\n",
        "\n",
        "checkpoint_path = os.path.join('checkpoint',file_name)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_S6wUaPT3Jx"
      },
      "source": [
        "\"\"\"call_back = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
        "                                               monitor='val_accuracy',\n",
        "                                               verbose=1,\n",
        "                                               save_freq='epoch',\n",
        "                                               save_best_only=True,\n",
        "                                               save_weights_only=False,\n",
        "                                               mode='max')\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy53DHMGB-Mr",
        "outputId": "5c4d474c-31e6-410d-bccb-43e9ce63ed31"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50ori\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 54, 54, 1)    0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 24, 24, 64)   3200        zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 24, 24, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 24, 24, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 11, 11, 64)   0           activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 11, 11, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 11, 11, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 11, 11, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 11, 11, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 11, 11, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 11, 11, 256)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 11, 11, 256)  0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 11, 11, 64)   16448       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 11, 11, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 11, 11, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 11, 11, 256)  0           activation_52[0][0]              \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 11, 11, 256)  0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 11, 11, 64)   16448       activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 11, 11, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 11, 11, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 11, 11, 256)  0           activation_55[0][0]              \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 11, 11, 256)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 6, 6, 128)    32896       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 6, 6, 128)    0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 6, 6, 128)    0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 6, 6, 512)    131584      activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 6, 6, 512)    2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 6, 6, 512)    0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 6, 6, 512)    0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 6, 6, 128)    0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 6, 6, 128)    0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 6, 6, 512)    0           activation_61[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 6, 6, 512)    0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 6, 6, 128)    0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 6, 6, 128)    0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 6, 6, 512)    0           activation_64[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 6, 6, 512)    0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 6, 6, 128)    0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 6, 6, 128)    0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 6, 6, 512)    0           activation_67[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 6, 6, 512)    0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 3, 3, 256)    131328      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 256)    0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 3, 3, 256)    0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 3, 3, 1024)   525312      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 3, 3, 1024)   4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 3, 3, 1024)   0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 3, 3, 1024)   0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 3, 3, 256)    0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 256)    0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 3, 3, 1024)   0           activation_73[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 1024)   0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 256)    0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 256)    0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 3, 3, 1024)   0           activation_76[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 1024)   0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 256)    0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 256)    0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 3, 3, 1024)   0           activation_79[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 1024)   0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 256)    0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 256)    0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 3, 3, 1024)   0           activation_82[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 1024)   0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 256)    0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 256)    0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 3, 3, 1024)   0           activation_85[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 1024)   0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 2, 2, 512)    524800      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 2, 2, 2048)   2099200     activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 2, 2, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 2, 2, 2048)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 2, 2, 2048)   0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 2, 2, 2048)   0           activation_91[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 2, 2, 2048)   0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 2, 2, 2048)   0           activation_94[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 2, 2, 2048)   0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 2048)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            14343       flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 23,595,783\n",
            "Trainable params: 23,542,663\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgxCecVwCGEr"
      },
      "source": [
        "\"\"\"history = model.fit(data_generator.flow(xtrain, ytrain,),\n",
        "                        steps_per_epoch=len(xtrain) / batch_size,\n",
        "                        epochs=num_epochs, verbose=1,callbacks=call_back,\n",
        "                        validation_data= (xtest,ytest))\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2muXWns0sJSH",
        "outputId": "ea82703d-9c8e-4c23-bc3f-a141525398b5"
      },
      "source": [
        "history = model.fit(\n",
        "    data_generator.flow(xtrain, ytrain,),\n",
        "    steps_per_epoch=len(xtrain) / batch_size,\n",
        "    epochs=num_epochs, \n",
        "    verbose=1,\n",
        "    validation_data= (x_val,y_val))\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "448/448 [==============================] - 44s 69ms/step - loss: 2.5145 - accuracy: 0.2228 - val_loss: 2.0879 - val_accuracy: 0.2653\n",
            "Epoch 2/60\n",
            "448/448 [==============================] - 27s 60ms/step - loss: 1.9293 - accuracy: 0.3119 - val_loss: 5.5767 - val_accuracy: 0.2427\n",
            "Epoch 3/60\n",
            "448/448 [==============================] - 27s 60ms/step - loss: 1.8261 - accuracy: 0.3271 - val_loss: 16.9418 - val_accuracy: 0.3291\n",
            "Epoch 4/60\n",
            "448/448 [==============================] - 26s 59ms/step - loss: 1.8168 - accuracy: 0.3191 - val_loss: 1.6861 - val_accuracy: 0.3887\n",
            "Epoch 5/60\n",
            "448/448 [==============================] - 26s 59ms/step - loss: 1.6384 - accuracy: 0.3731 - val_loss: 1.6418 - val_accuracy: 0.3480\n",
            "Epoch 6/60\n",
            "448/448 [==============================] - 27s 61ms/step - loss: 1.6237 - accuracy: 0.3682 - val_loss: 2.4104 - val_accuracy: 0.3065\n",
            "Epoch 7/60\n",
            "448/448 [==============================] - 28s 62ms/step - loss: 1.6031 - accuracy: 0.3802 - val_loss: 1.4779 - val_accuracy: 0.4283\n",
            "Epoch 8/60\n",
            "448/448 [==============================] - 28s 62ms/step - loss: 1.5922 - accuracy: 0.3821 - val_loss: 2.3208 - val_accuracy: 0.3600\n",
            "Epoch 9/60\n",
            "448/448 [==============================] - 28s 63ms/step - loss: 1.6556 - accuracy: 0.3662 - val_loss: 1.9199 - val_accuracy: 0.3511\n",
            "Epoch 10/60\n",
            "448/448 [==============================] - 27s 60ms/step - loss: 1.6987 - accuracy: 0.3519 - val_loss: 1.8174 - val_accuracy: 0.3227\n",
            "Epoch 11/60\n",
            "448/448 [==============================] - 27s 61ms/step - loss: 1.6213 - accuracy: 0.3766 - val_loss: 1.6918 - val_accuracy: 0.3678\n",
            "Epoch 12/60\n",
            "448/448 [==============================] - 28s 61ms/step - loss: 1.6498 - accuracy: 0.3709 - val_loss: 1.5486 - val_accuracy: 0.4048\n",
            "Epoch 13/60\n",
            "448/448 [==============================] - 27s 61ms/step - loss: 1.5698 - accuracy: 0.4023 - val_loss: 1.4793 - val_accuracy: 0.4285\n",
            "Epoch 14/60\n",
            "448/448 [==============================] - 28s 61ms/step - loss: 1.5569 - accuracy: 0.3965 - val_loss: 1.4482 - val_accuracy: 0.4324\n",
            "Epoch 15/60\n",
            "448/448 [==============================] - 27s 61ms/step - loss: 1.6364 - accuracy: 0.3771 - val_loss: 1.5720 - val_accuracy: 0.3959\n",
            "Epoch 16/60\n",
            "448/448 [==============================] - 28s 62ms/step - loss: 1.6291 - accuracy: 0.3800 - val_loss: 1.4943 - val_accuracy: 0.4372\n",
            "Epoch 17/60\n",
            "448/448 [==============================] - 28s 62ms/step - loss: 1.5389 - accuracy: 0.4140 - val_loss: 1.5039 - val_accuracy: 0.4533\n",
            "Epoch 18/60\n",
            "448/448 [==============================] - 27s 61ms/step - loss: 1.4828 - accuracy: 0.4261 - val_loss: 1.3811 - val_accuracy: 0.4673\n",
            "Epoch 19/60\n",
            "448/448 [==============================] - 28s 61ms/step - loss: 1.4653 - accuracy: 0.4346 - val_loss: 1.4444 - val_accuracy: 0.4430\n",
            "Epoch 20/60\n",
            "448/448 [==============================] - 27s 61ms/step - loss: 1.4740 - accuracy: 0.4392 - val_loss: 1.5628 - val_accuracy: 0.4018\n",
            "Epoch 21/60\n",
            "448/448 [==============================] - 27s 61ms/step - loss: 1.4818 - accuracy: 0.4341 - val_loss: 1.4900 - val_accuracy: 0.4246\n",
            "Epoch 22/60\n",
            "448/448 [==============================] - 27s 60ms/step - loss: 1.5319 - accuracy: 0.4192 - val_loss: 1.3981 - val_accuracy: 0.4673\n",
            "Epoch 23/60\n",
            "448/448 [==============================] - 28s 62ms/step - loss: 1.4665 - accuracy: 0.4439 - val_loss: 1.5779 - val_accuracy: 0.3990\n",
            "Epoch 24/60\n",
            "448/448 [==============================] - 28s 63ms/step - loss: 1.6620 - accuracy: 0.3702 - val_loss: 3.4639 - val_accuracy: 0.3006\n",
            "Epoch 25/60\n",
            "448/448 [==============================] - 27s 61ms/step - loss: 1.6312 - accuracy: 0.3840 - val_loss: 1.7861 - val_accuracy: 0.3909\n",
            "Epoch 26/60\n",
            "448/448 [==============================] - 27s 61ms/step - loss: 1.4578 - accuracy: 0.4510 - val_loss: 3.3582 - val_accuracy: 0.4054\n",
            "Epoch 27/60\n",
            "448/448 [==============================] - 27s 59ms/step - loss: 1.4451 - accuracy: 0.4504 - val_loss: 2.8120 - val_accuracy: 0.4026\n",
            "Epoch 28/60\n",
            "448/448 [==============================] - 27s 61ms/step - loss: 1.5316 - accuracy: 0.4208 - val_loss: 1.3458 - val_accuracy: 0.4820\n",
            "Epoch 29/60\n",
            "448/448 [==============================] - 28s 63ms/step - loss: 1.4013 - accuracy: 0.4576 - val_loss: 1.4305 - val_accuracy: 0.4678\n",
            "Epoch 30/60\n",
            "448/448 [==============================] - 28s 62ms/step - loss: 1.4505 - accuracy: 0.4519 - val_loss: 1.4362 - val_accuracy: 0.4687\n",
            "Epoch 31/60\n",
            "448/448 [==============================] - 28s 63ms/step - loss: 1.4342 - accuracy: 0.4559 - val_loss: 1.3068 - val_accuracy: 0.4837\n",
            "Epoch 32/60\n",
            "448/448 [==============================] - 28s 63ms/step - loss: 1.4174 - accuracy: 0.4630 - val_loss: 1.3394 - val_accuracy: 0.4912\n",
            "Epoch 33/60\n",
            "448/448 [==============================] - 27s 61ms/step - loss: 1.3528 - accuracy: 0.4810 - val_loss: 1.4062 - val_accuracy: 0.4745\n",
            "Epoch 34/60\n",
            "448/448 [==============================] - 27s 61ms/step - loss: 1.3855 - accuracy: 0.4678 - val_loss: 1.3960 - val_accuracy: 0.4865\n",
            "Epoch 35/60\n",
            "448/448 [==============================] - 27s 61ms/step - loss: 1.3653 - accuracy: 0.4871 - val_loss: 1.2987 - val_accuracy: 0.5102\n",
            "Epoch 36/60\n",
            "448/448 [==============================] - 28s 61ms/step - loss: 1.3716 - accuracy: 0.4913 - val_loss: 1.4658 - val_accuracy: 0.4427\n",
            "Epoch 37/60\n",
            "448/448 [==============================] - 27s 61ms/step - loss: 1.4025 - accuracy: 0.4676 - val_loss: 1.2924 - val_accuracy: 0.5113\n",
            "Epoch 38/60\n",
            "448/448 [==============================] - 27s 60ms/step - loss: 1.3330 - accuracy: 0.4986 - val_loss: 1.2823 - val_accuracy: 0.5191\n",
            "Epoch 39/60\n",
            "448/448 [==============================] - 28s 63ms/step - loss: 1.4508 - accuracy: 0.4574 - val_loss: 1.3272 - val_accuracy: 0.5060\n",
            "Epoch 40/60\n",
            "448/448 [==============================] - 37s 82ms/step - loss: 1.4180 - accuracy: 0.4682 - val_loss: 1.7890 - val_accuracy: 0.4494\n",
            "Epoch 41/60\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 1.3318 - accuracy: 0.4951 - val_loss: 1.2285 - val_accuracy: 0.5302\n",
            "Epoch 42/60\n",
            "448/448 [==============================] - 34s 76ms/step - loss: 1.2981 - accuracy: 0.5109 - val_loss: 2.8283 - val_accuracy: 0.3764\n",
            "Epoch 43/60\n",
            "448/448 [==============================] - 28s 63ms/step - loss: 1.5769 - accuracy: 0.4151 - val_loss: 3.0443 - val_accuracy: 0.4132\n",
            "Epoch 44/60\n",
            "448/448 [==============================] - 28s 63ms/step - loss: 1.4489 - accuracy: 0.4540 - val_loss: 1.2677 - val_accuracy: 0.5152\n",
            "Epoch 45/60\n",
            "448/448 [==============================] - 28s 63ms/step - loss: 1.3086 - accuracy: 0.4935 - val_loss: 1.2320 - val_accuracy: 0.5283\n",
            "Epoch 46/60\n",
            "448/448 [==============================] - 28s 63ms/step - loss: 1.2815 - accuracy: 0.5149 - val_loss: 1.2551 - val_accuracy: 0.5043\n",
            "Epoch 47/60\n",
            "448/448 [==============================] - 28s 63ms/step - loss: 1.2830 - accuracy: 0.5136 - val_loss: 1.2023 - val_accuracy: 0.5447\n",
            "Epoch 48/60\n",
            "448/448 [==============================] - 27s 60ms/step - loss: 1.2631 - accuracy: 0.5209 - val_loss: 3.1285 - val_accuracy: 0.4597\n",
            "Epoch 49/60\n",
            "448/448 [==============================] - 28s 62ms/step - loss: 1.2422 - accuracy: 0.5323 - val_loss: 1.1955 - val_accuracy: 0.5517\n",
            "Epoch 50/60\n",
            "448/448 [==============================] - 28s 63ms/step - loss: 1.2452 - accuracy: 0.5242 - val_loss: 1.1822 - val_accuracy: 0.5439\n",
            "Epoch 51/60\n",
            "448/448 [==============================] - 28s 62ms/step - loss: 1.4019 - accuracy: 0.4830 - val_loss: 1.2606 - val_accuracy: 0.5288\n",
            "Epoch 52/60\n",
            "448/448 [==============================] - 28s 62ms/step - loss: 1.3183 - accuracy: 0.5064 - val_loss: 2.3361 - val_accuracy: 0.3945\n",
            "Epoch 53/60\n",
            "448/448 [==============================] - 31s 69ms/step - loss: 1.4873 - accuracy: 0.4500 - val_loss: 1.7457 - val_accuracy: 0.4090\n",
            "Epoch 54/60\n",
            "448/448 [==============================] - 40s 89ms/step - loss: 1.4879 - accuracy: 0.4459 - val_loss: 2.5484 - val_accuracy: 0.4480\n",
            "Epoch 55/60\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 1.2991 - accuracy: 0.5081 - val_loss: 1.2601 - val_accuracy: 0.5358\n",
            "Epoch 56/60\n",
            "448/448 [==============================] - 31s 70ms/step - loss: 1.2822 - accuracy: 0.5169 - val_loss: 1.2512 - val_accuracy: 0.5417\n",
            "Epoch 57/60\n",
            "448/448 [==============================] - 39s 88ms/step - loss: 1.2468 - accuracy: 0.5292 - val_loss: 1.4069 - val_accuracy: 0.4985\n",
            "Epoch 58/60\n",
            "448/448 [==============================] - 34s 75ms/step - loss: 1.4001 - accuracy: 0.4800 - val_loss: 1.8965 - val_accuracy: 0.4879\n",
            "Epoch 59/60\n",
            "448/448 [==============================] - 28s 62ms/step - loss: 1.5489 - accuracy: 0.4216 - val_loss: 1.4769 - val_accuracy: 0.4525\n",
            "Epoch 60/60\n",
            "448/448 [==============================] - 28s 62ms/step - loss: 1.4775 - accuracy: 0.4440 - val_loss: 1.5137 - val_accuracy: 0.4882\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "GaXUP-8fDWRN",
        "outputId": "f65c3826-f1b9-47c6-e2f7-6e42f384f626"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "model.save('/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50SGD5st.h5')\n",
        "\n",
        "#gffhgffkjkjdskjjkjkjkjhjhnnn\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "num_epochs = range(len(accuracy))\n",
        "plt.plot(num_epochs, accuracy, 'r', label='Training acc')\n",
        "plt.plot(num_epochs, val_accuracy, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(num_epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(num_epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_LxatO5J-pp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9be7692-1344-4ad4-e778-3057f7225dd5"
      },
      "source": [
        "testloss = model.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "trainloss = model.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(trainloss[0]))\n",
        "print(\"Train Acc: \" + str(trainloss[1]))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 2s 16ms/step - loss: 1.5360 - accuracy: 0.4765\n",
            "Test Loss 1.5359538793563843\n",
            "Test Acc: 0.47645583748817444\n",
            "898/898 [==============================] - 13s 15ms/step - loss: 1.4770 - accuracy: 0.4952\n",
            "Train Loss 1.4770445823669434\n",
            "Train Acc: 0.49521055817604065\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swoRERVdKQ1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e7401d1-ed47-43e9-f130-9365dba50c46"
      },
      "source": [
        "testlosz = model.evaluate(x_val, y_val) \n",
        "print(\"Test Loss \" + str(testlosz[0]))\n",
        "print(\"Test Acc: \" + str(testlosz[1]))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 2s 15ms/step - loss: 1.5137 - accuracy: 0.4882\n",
            "Test Loss 1.5136774778366089\n",
            "Test Acc: 0.488158255815506\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5iaZIU6pPzk",
        "outputId": "e512e03b-98f5-4bd9-ee7a-ef640d5398c5"
      },
      "source": [
        "from keras.models import load_model\n",
        "model_load = load_model('/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50SGD5st.h5')\n",
        "\n",
        "model_load.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50ori\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 54, 54, 1)    0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 24, 24, 64)   3200        zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 24, 24, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 24, 24, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 11, 11, 64)   0           activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 11, 11, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 11, 11, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 11, 11, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 11, 11, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 11, 11, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 11, 11, 256)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 11, 11, 256)  0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 11, 11, 64)   16448       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 11, 11, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 11, 11, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 11, 11, 256)  0           activation_52[0][0]              \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 11, 11, 256)  0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 11, 11, 64)   16448       activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 11, 11, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 11, 11, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 11, 11, 64)   36928       activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 11, 11, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 11, 11, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 11, 11, 256)  16640       activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 11, 11, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 11, 11, 256)  0           activation_55[0][0]              \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 11, 11, 256)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 6, 6, 128)    32896       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 6, 6, 128)    0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 6, 6, 128)    0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 6, 6, 512)    131584      activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 6, 6, 512)    2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 6, 6, 512)    0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 6, 6, 512)    0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 6, 6, 128)    0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 6, 6, 128)    0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 6, 6, 512)    0           activation_61[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 6, 6, 512)    0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 6, 6, 128)    0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 6, 6, 128)    0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 6, 6, 512)    0           activation_64[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 6, 6, 512)    0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 6, 6, 128)    65664       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 6, 6, 128)    512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 6, 6, 128)    0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 6, 6, 128)    147584      activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 6, 6, 128)    512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 6, 6, 128)    0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 6, 6, 512)    66048       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 6, 6, 512)    2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 6, 6, 512)    0           activation_67[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 6, 6, 512)    0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 3, 3, 256)    131328      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 256)    0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 3, 3, 256)    0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 3, 3, 1024)   525312      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 3, 3, 1024)   4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 3, 3, 1024)   0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 3, 3, 1024)   0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 3, 3, 256)    0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 256)    0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 3, 3, 1024)   0           activation_73[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 1024)   0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 256)    0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 256)    0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 3, 3, 1024)   0           activation_76[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 1024)   0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 256)    0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 256)    0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 3, 3, 1024)   0           activation_79[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 1024)   0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 256)    0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 256)    0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 3, 3, 1024)   0           activation_82[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 1024)   0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 256)    0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 256)    0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 3, 3, 1024)   0           activation_85[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 1024)   0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 2, 2, 512)    524800      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 2, 2, 2048)   2099200     activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 2, 2, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 2, 2, 2048)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 2, 2, 2048)   0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 2, 2, 2048)   0           activation_91[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 2, 2, 2048)   0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 2, 2, 2048)   0           activation_94[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 2, 2, 2048)   0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 2048)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            14343       flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 23,595,783\n",
            "Trainable params: 23,542,663\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypc8clklx2p8",
        "outputId": "6df18040-8603-4500-d7f8-9f2f2665da67"
      },
      "source": [
        "#loss,acc = model_load.evaluate(xtrain,ytrain)\n",
        "\"\"\"print(\"loss:\",loss)\n",
        "print(\"acc:\",acc)kjjkj\"\"\"\n",
        "\n",
        "\n",
        "testloss = model_load.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "\n",
        "testloss = model_load.evaluate(xtrain, ytrain) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 5s 16ms/step - loss: 1.5360 - accuracy: 0.4765\n",
            "Test Loss 1.5359538793563843\n",
            "Test Acc: 0.47645583748817444\n",
            "898/898 [==============================] - 13s 15ms/step - loss: 1.4770 - accuracy: 0.4952\n",
            "Test Loss 1.4770445823669434\n",
            "Test Acc: 0.49521055817604065\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7mSww_U2O_q",
        "outputId": "edcf2287-55cc-4aec-fdca-44e02782a87f"
      },
      "source": [
        "testlosz = model_load.evaluate(x_val, y_val) \n",
        "print(\"Test Loss \" + str(testlosz[0]))\n",
        "print(\"Test Acc: \" + str(testlosz[1]))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 2s 16ms/step - loss: 1.5137 - accuracy: 0.4882\n",
            "Test Loss 1.5136774778366089\n",
            "Test Acc: 0.488158255815506\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdU7uU3PYCnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1996a0b2-82e1-41a4-8a0c-75280505e10b"
      },
      "source": [
        "print (x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3589, 48, 48, 1)\n",
            "(3589,)\n",
            "(3589, 48, 48, 1)\n",
            "(3589,)\n",
            "(28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_Tf1qg8TKnx",
        "outputId": "7e518e67-811f-48e2-8da7-e126dccaf2d0"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "#y_pred = model_load.predict(xtest)\n",
        "\n",
        "test_prob = model_load.predict(xtest)\n",
        "test_pred = np.argmax(test_prob, axis=1)\n",
        "test_accuracy = np.mean(test_pred == ytest)\n",
        "\n",
        "print(test_accuracy)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.47645583728057955\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpwJv9V54_1M"
      },
      "source": [
        "\n",
        "emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "KMe4WL0T5BcJ",
        "outputId": "35763dad-17b9-4130-a956-135b2fad807c"
      },
      "source": [
        "conf_mat = confusion_matrix(ytest, test_pred)\n",
        "\n",
        "pd.DataFrame(conf_mat, columns=emotions.values(), index=emotions.values())\n",
        "\n",
        "\n",
        "\n",
        "fig, ax = plot_confusion_matrix(conf_mat=conf_mat,show_normed=True,show_absolute=False,figsize=(8, 8))\n",
        "fig.show()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW3FZjp-5DgF",
        "outputId": "94960d44-d5a3-4127-ed26-966df75e2833"
      },
      "source": [
        "print(classification_report(ytest, test_pred, target_names=emotions.values()))\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry       0.34      0.36      0.35       482\n",
            "     Disgust       1.00      0.05      0.10        75\n",
            "        Fear       0.30      0.28      0.29       508\n",
            "       Happy       0.61      0.75      0.68       905\n",
            "         Sad       0.34      0.37      0.36       597\n",
            "    Surprise       0.69      0.68      0.68       395\n",
            "     Neutral       0.47      0.35      0.40       627\n",
            "\n",
            "    accuracy                           0.48      3589\n",
            "   macro avg       0.54      0.41      0.41      3589\n",
            "weighted avg       0.48      0.48      0.47      3589\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}