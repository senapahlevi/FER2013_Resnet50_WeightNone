{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER2013_Resnet50_weightnone_fixTrainTestVal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-Qn1jsBTIBl0b7myLQxqa8WjCcfbamqM",
      "authorship_tag": "ABX9TyMRCW4XjQMxSeS/w39KHhCH"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b86nukQOxN7l"
      },
      "source": [
        "Resnet-50 From Scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p8gxtGy0TWP",
        "outputId": "0ede5e16-741c-4cf4-fadb-e6f87dc13ec3"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "inputFolder = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth' \n",
        "for root, directories, filenames in os.walk(inputFolder): \n",
        "    for filename in filenames: print(os.path.join(root,filename))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Best_Model_resnet50Scracth1again.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe4.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth1again.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50ScracthSGD1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50AUGScracthadam3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50oriScracth_sena2.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsiscWIMBDX2",
        "outputId": "10754924-9c90-4d98-b487-a379c0dfbdc2"
      },
      "source": [
        "%cd /content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "wLMSe510xNCJ",
        "outputId": "3da9f6f5-cb75-4f61-d978-1e7de9a074fc"
      },
      "source": [
        "#Create a directory to save our generated models.dasdas\n",
        "\n",
        "#os.mkdir(\"./modelscracth\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-cf55f19f3613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#os.mkdir(\"./modelscracth\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ls' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_kluusLxM1B",
        "outputId": "e4d6c47a-fbf4-4c35-c068-a8611915b061"
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:400: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfUSF_tAxNMP"
      },
      "source": [
        "#Define the identity block helper function.\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "   \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VdYtzhn1F0I"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path \n",
        "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b',padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd-O8ZMx1GAW"
      },
      "source": [
        "def ResNet50(input_shape = (48,48,1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    #X = ZeroPadding2D((1, 1))(X_input)\n",
        "    X = X_input\n",
        "    # Stage 1\n",
        "\n",
        "    X = Conv2D(8, (3, 3), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # removed maxpool\n",
        "    #X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='c')\n",
        "\n",
        "\n",
        "    # Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [64,64,256], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL . \n",
        "    X = AveragePooling2D((2,2), name='avg_pool')(X)\n",
        "    \n",
        "    # output layerds\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(512, activation = 'relu', name='fc1024' , kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GKsSwtp-GuL"
      },
      "source": [
        "\"\"\"def ResNet50ori(input_shape = (48, 48, 1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns: dsdsf\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50ori')\n",
        "\n",
        "    return model\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3oWTDXlyBHM2",
        "outputId": "a78216e1-4860-48ae-98c2-9a9d9687b075"
      },
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        " \n",
        "dataset_path = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv'\n",
        "image_size=(48,48)\n",
        "#batch_size = 64\n",
        "\n",
        "def load_fer2013():\n",
        "    data = pd.read_csv(dataset_path)\n",
        "    data = (data[data['pixels'].notnull()])\n",
        "    pixels = data['pixels'].tolist()\n",
        "    width, height = 48, 48\n",
        "    faces = []\n",
        "    for pixel_sequence in pixels:\n",
        "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "        face = np.asarray(face).reshape(width, height)\n",
        "        face = cv2.resize(face.astype('uint8'),image_size)\n",
        "        faces.append(face.astype('float32'))\n",
        "    faces = np.asarray(faces)\n",
        "    faces = np.expand_dims(faces, -1)\n",
        "    emotions = (data['emotion'])#.values\n",
        "    return faces, emotions\n",
        " \n",
        "def preprocess_input(x, v2=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if v2:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x\n",
        " \n",
        "faces, emotions = load_fer2013()\n",
        "faces = preprocess_input(faces)\n",
        "#xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
        "#Data Augumentation\n",
        "data_generator = ImageDataGenerator(\n",
        "                        rotation_range=10,\n",
        "                        shear_range = 10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True)\n",
        "\"\"\"data_generator = ImageDataGenerator( )\n",
        "\"\"\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'data_generator = ImageDataGenerator( )\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWLhavr-rSF5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "895f7f85-9930-46ca-c552-cbb571846a4e"
      },
      "source": [
        "\"\"\"\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.1,)\n",
        "x_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1,)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nxtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.1,)\\nx_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1,)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "RGhnYFXgaqL9",
        "outputId": "0e60da2f-3a44-4d06-910b-2e0f2fa4191a"
      },
      "source": [
        "\"\"\"print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (y_train.shape)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'print (\"validasi\",x_val.shape)\\nprint (y_val.shape)\\nprint (\"test\",xtest.shape)\\nprint (ytest.shape)\\nprint (\"train\",xtrain.shape)\\nprint (y_train.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rDS3hqhDSteM",
        "outputId": "7b3b2cca-5f1e-4fe3-b8a4-4ff5a238244b"
      },
      "source": [
        "train_ratio = 0.80\n",
        "validation_ratio = 0.10\n",
        "test_ratio = 0.10\n",
        "\n",
        "# train is now 75% of the entire data set\n",
        "# the _junk suffix means that we drop that variable completely # the _junk suffix means that we drop that variable completely\n",
        "#x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=1 - train_ratio)\n",
        "\n",
        "# test is now 10% of the initial data set\n",
        "# validation is now 15% of the initial data set\n",
        "#x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "x_val, xtest, y_val, ytest = train_test_split(xtest, ytest, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "\n",
        "print(xtrain, x_val, xtest)\n",
        "\n",
        "\"\"\"X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2\"\"\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[ 0.4901961 ]\n",
            "   [ 0.3803922 ]\n",
            "   [ 0.18431377]\n",
            "   ...\n",
            "   [ 0.37254906]\n",
            "   [ 0.36470592]\n",
            "   [ 0.2941177 ]]\n",
            "\n",
            "  [[ 0.5137255 ]\n",
            "   [ 0.38823533]\n",
            "   [ 0.20000005]\n",
            "   ...\n",
            "   [ 0.38823533]\n",
            "   [ 0.36470592]\n",
            "   [ 0.2941177 ]]\n",
            "\n",
            "  [[ 0.5137255 ]\n",
            "   [ 0.39607847]\n",
            "   [ 0.2313726 ]\n",
            "   ...\n",
            "   [ 0.3803922 ]\n",
            "   [ 0.33333337]\n",
            "   [ 0.23921573]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.04313731]\n",
            "   [ 0.07450986]\n",
            "   [ 0.07450986]\n",
            "   ...\n",
            "   [-0.11372548]\n",
            "   [-0.1607843 ]\n",
            "   [-0.19215685]]\n",
            "\n",
            "  [[ 0.07450986]\n",
            "   [ 0.09803927]\n",
            "   [ 0.11372554]\n",
            "   ...\n",
            "   [-0.12156862]\n",
            "   [-0.16862744]\n",
            "   [-0.20784312]]\n",
            "\n",
            "  [[ 0.082353  ]\n",
            "   [ 0.09803927]\n",
            "   [ 0.11372554]\n",
            "   ...\n",
            "   [-0.12941176]\n",
            "   [-0.16862744]\n",
            "   [-0.2235294 ]]]\n",
            "\n",
            "\n",
            " [[[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 0.96862745]\n",
            "   [ 0.9764706 ]\n",
            "   [ 0.9764706 ]\n",
            "   ...\n",
            "   [ 0.96862745]\n",
            "   [ 0.96862745]\n",
            "   [ 0.96862745]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.19999999]\n",
            "   [-0.1607843 ]\n",
            "   [-0.14509803]\n",
            "   ...\n",
            "   [-0.16862744]\n",
            "   [-0.23137254]\n",
            "   [-0.21568626]]\n",
            "\n",
            "  [[-0.06666666]\n",
            "   [-0.06666666]\n",
            "   [-0.0745098 ]\n",
            "   ...\n",
            "   [-0.3098039 ]\n",
            "   [-0.26274508]\n",
            "   [-0.23137254]]\n",
            "\n",
            "  [[ 0.04313731]\n",
            "   [ 0.00392163]\n",
            "   [-0.05098039]\n",
            "   ...\n",
            "   [-0.12156862]\n",
            "   [-0.05882353]\n",
            "   [-0.09019607]]]\n",
            "\n",
            "\n",
            " [[[-0.7254902 ]\n",
            "   [-0.49019605]\n",
            "   [-0.3098039 ]\n",
            "   ...\n",
            "   [-0.75686276]\n",
            "   [-0.827451  ]\n",
            "   [-0.92156863]]\n",
            "\n",
            "  [[-0.654902  ]\n",
            "   [-0.4352941 ]\n",
            "   [-0.32549018]\n",
            "   ...\n",
            "   [-0.81960785]\n",
            "   [-0.88235295]\n",
            "   [-0.9137255 ]]\n",
            "\n",
            "  [[-0.6       ]\n",
            "   [-0.38039213]\n",
            "   [-0.36470586]\n",
            "   ...\n",
            "   [-0.827451  ]\n",
            "   [-0.9137255 ]\n",
            "   [-0.94509804]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.6784314 ]\n",
            "   [ 0.8039216 ]\n",
            "   [ 0.7647059 ]\n",
            "   ...\n",
            "   [ 0.7254902 ]\n",
            "   [ 0.69411767]\n",
            "   [ 0.67058825]]\n",
            "\n",
            "  [[ 0.62352943]\n",
            "   [ 0.7647059 ]\n",
            "   [ 0.8039216 ]\n",
            "   ...\n",
            "   [ 0.64705884]\n",
            "   [ 0.7411765 ]\n",
            "   [ 0.67058825]]\n",
            "\n",
            "  [[ 0.67058825]\n",
            "   [ 0.69411767]\n",
            "   [ 0.8117647 ]\n",
            "   ...\n",
            "   [ 0.64705884]\n",
            "   [ 0.70980394]\n",
            "   [ 0.7019608 ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.99215686]\n",
            "   [-0.9764706 ]\n",
            "   [-0.8509804 ]\n",
            "   ...\n",
            "   [-0.45098037]\n",
            "   [-0.01176471]\n",
            "   [ 0.06666672]]\n",
            "\n",
            "  [[-0.9764706 ]\n",
            "   [-0.9843137 ]\n",
            "   [-0.92156863]\n",
            "   ...\n",
            "   [-0.69411767]\n",
            "   [-0.3098039 ]\n",
            "   [ 0.2941177 ]]\n",
            "\n",
            "  [[-0.96862745]\n",
            "   [-0.96862745]\n",
            "   [-0.9137255 ]\n",
            "   ...\n",
            "   [-0.827451  ]\n",
            "   [-0.6862745 ]\n",
            "   [ 0.082353  ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.84313726]\n",
            "   [-0.7019608 ]\n",
            "   [-0.4980392 ]\n",
            "   ...\n",
            "   [-0.5686275 ]\n",
            "   [-0.5686275 ]\n",
            "   [-0.5764706 ]]\n",
            "\n",
            "  [[-0.7490196 ]\n",
            "   [-0.58431375]\n",
            "   [-0.47450978]\n",
            "   ...\n",
            "   [-0.5764706 ]\n",
            "   [-0.5686275 ]\n",
            "   [-0.5764706 ]]\n",
            "\n",
            "  [[-0.64705884]\n",
            "   [-0.56078434]\n",
            "   [-0.45098037]\n",
            "   ...\n",
            "   [-0.5764706 ]\n",
            "   [-0.5764706 ]\n",
            "   [-0.5764706 ]]]\n",
            "\n",
            "\n",
            " [[[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 0.9607843 ]\n",
            "   ...\n",
            "   [ 0.99215686]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 0.99215686]\n",
            "   [ 0.9529412 ]\n",
            "   ...\n",
            "   [ 0.99215686]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 0.99215686]\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.9137255 ]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.7490196 ]\n",
            "   [-0.7882353 ]\n",
            "   [-0.79607844]\n",
            "   ...\n",
            "   [-0.88235295]\n",
            "   [-0.8666667 ]\n",
            "   [-0.81960785]]\n",
            "\n",
            "  [[-0.8039216 ]\n",
            "   [-0.78039217]\n",
            "   [-0.79607844]\n",
            "   ...\n",
            "   [-0.827451  ]\n",
            "   [-0.8039216 ]\n",
            "   [-0.79607844]]\n",
            "\n",
            "  [[-0.75686276]\n",
            "   [-0.8117647 ]\n",
            "   [-0.8352941 ]\n",
            "   ...\n",
            "   [-0.827451  ]\n",
            "   [-0.81960785]\n",
            "   [-0.8509804 ]]]\n",
            "\n",
            "\n",
            " [[[-0.7019608 ]\n",
            "   [-0.654902  ]\n",
            "   [-0.6862745 ]\n",
            "   ...\n",
            "   [-0.21568626]\n",
            "   [-0.49019605]\n",
            "   [-0.8352941 ]]\n",
            "\n",
            "  [[-0.654902  ]\n",
            "   [-0.62352943]\n",
            "   [-0.60784316]\n",
            "   ...\n",
            "   [-0.32549018]\n",
            "   [-0.26274508]\n",
            "   [-0.5921569 ]]\n",
            "\n",
            "  [[-0.6627451 ]\n",
            "   [-0.60784316]\n",
            "   [-0.6       ]\n",
            "   ...\n",
            "   [-0.1607843 ]\n",
            "   [-0.32549018]\n",
            "   [-0.3490196 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.1686275 ]\n",
            "   [ 0.05098045]\n",
            "   [ 0.09019613]\n",
            "   ...\n",
            "   [-0.77254903]\n",
            "   [-0.79607844]\n",
            "   [-0.827451  ]]\n",
            "\n",
            "  [[-0.06666666]\n",
            "   [-0.09019607]\n",
            "   [-0.10588235]\n",
            "   ...\n",
            "   [-0.77254903]\n",
            "   [-0.8117647 ]\n",
            "   [-0.81960785]]\n",
            "\n",
            "  [[-0.17647058]\n",
            "   [-0.05882353]\n",
            "   [ 0.03529418]\n",
            "   ...\n",
            "   [-0.79607844]\n",
            "   [-0.8117647 ]\n",
            "   [-0.81960785]]]] [[[[-0.7019608 ]\n",
            "   [-0.7490196 ]\n",
            "   [-0.7019608 ]\n",
            "   ...\n",
            "   [-0.7490196 ]\n",
            "   [-0.7490196 ]\n",
            "   [-0.7647059 ]]\n",
            "\n",
            "  [[-0.6784314 ]\n",
            "   [-0.7254902 ]\n",
            "   [-0.64705884]\n",
            "   ...\n",
            "   [-0.7490196 ]\n",
            "   [-0.75686276]\n",
            "   [-0.7647059 ]]\n",
            "\n",
            "  [[-0.6862745 ]\n",
            "   [-0.6627451 ]\n",
            "   [-0.6392157 ]\n",
            "   ...\n",
            "   [-0.75686276]\n",
            "   [-0.7490196 ]\n",
            "   [-0.7490196 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.7647059 ]\n",
            "   [-0.8666667 ]\n",
            "   [-0.92941177]\n",
            "   ...\n",
            "   [ 0.7490196 ]\n",
            "   [ 0.85882354]\n",
            "   [ 0.8745098 ]]\n",
            "\n",
            "  [[-0.6862745 ]\n",
            "   [-0.8039216 ]\n",
            "   [-0.90588236]\n",
            "   ...\n",
            "   [ 0.79607844]\n",
            "   [ 0.77254903]\n",
            "   [ 0.8901961 ]]\n",
            "\n",
            "  [[-0.6156863 ]\n",
            "   [-0.7254902 ]\n",
            "   [-0.8509804 ]\n",
            "   ...\n",
            "   [ 0.81960785]\n",
            "   [ 0.7490196 ]\n",
            "   [ 0.8352941 ]]]\n",
            "\n",
            "\n",
            " [[[-0.25490195]\n",
            "   [-0.32549018]\n",
            "   [-0.46666664]\n",
            "   ...\n",
            "   [ 0.05882359]\n",
            "   [ 0.12156868]\n",
            "   [ 0.13725495]]\n",
            "\n",
            "  [[-0.8901961 ]\n",
            "   [-0.81960785]\n",
            "   [-0.9137255 ]\n",
            "   ...\n",
            "   [ 0.09019613]\n",
            "   [ 0.14509809]\n",
            "   [ 0.13725495]]\n",
            "\n",
            "  [[-0.96862745]\n",
            "   [-0.94509804]\n",
            "   [-0.92156863]\n",
            "   ...\n",
            "   [ 0.12941182]\n",
            "   [ 0.12941182]\n",
            "   [ 0.11372554]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.5294118 ]\n",
            "   [-0.5686275 ]\n",
            "   [-0.5372549 ]\n",
            "   ...\n",
            "   [ 0.21568632]\n",
            "   [ 0.20000005]\n",
            "   [ 0.19215691]]\n",
            "\n",
            "  [[-0.30196077]\n",
            "   [-0.38039213]\n",
            "   [-0.4823529 ]\n",
            "   ...\n",
            "   [ 0.21568632]\n",
            "   [ 0.19215691]\n",
            "   [ 0.19215691]]\n",
            "\n",
            "  [[-0.30196077]\n",
            "   [-0.2235294 ]\n",
            "   [-0.2862745 ]\n",
            "   ...\n",
            "   [ 0.20000005]\n",
            "   [ 0.17647064]\n",
            "   [ 0.17647064]]]\n",
            "\n",
            "\n",
            " [[[-0.8901961 ]\n",
            "   [-0.84313726]\n",
            "   [-0.7882353 ]\n",
            "   ...\n",
            "   [-0.5294118 ]\n",
            "   [-0.45098037]\n",
            "   [-0.41960782]]\n",
            "\n",
            "  [[-0.88235295]\n",
            "   [-0.8901961 ]\n",
            "   [-0.827451  ]\n",
            "   ...\n",
            "   [-0.18431371]\n",
            "   [-0.4352941 ]\n",
            "   [-0.3333333 ]]\n",
            "\n",
            "  [[-0.8745098 ]\n",
            "   [-0.90588236]\n",
            "   [-0.92156863]\n",
            "   ...\n",
            "   [ 0.20000005]\n",
            "   [-0.23137254]\n",
            "   [-0.52156866]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.19215691]\n",
            "   [ 0.32549024]\n",
            "   [ 0.11372554]\n",
            "   ...\n",
            "   [-0.5372549 ]\n",
            "   [-0.5372549 ]\n",
            "   [-0.56078434]]\n",
            "\n",
            "  [[ 0.41960788]\n",
            "   [ 0.34901965]\n",
            "   [ 0.254902  ]\n",
            "   ...\n",
            "   [-0.54509807]\n",
            "   [-0.5764706 ]\n",
            "   [-0.58431375]]\n",
            "\n",
            "  [[ 0.23921573]\n",
            "   [ 0.20784318]\n",
            "   [ 0.36470592]\n",
            "   ...\n",
            "   [-0.5764706 ]\n",
            "   [-0.58431375]\n",
            "   [-0.5686275 ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.4352941 ]\n",
            "   [-0.4823529 ]\n",
            "   [-0.4823529 ]\n",
            "   ...\n",
            "   [-0.24705881]\n",
            "   [-0.19999999]\n",
            "   [-0.23137254]]\n",
            "\n",
            "  [[-0.44313723]\n",
            "   [-0.44313723]\n",
            "   [-0.4352941 ]\n",
            "   ...\n",
            "   [-0.21568626]\n",
            "   [-0.17647058]\n",
            "   [-0.20784312]]\n",
            "\n",
            "  [[-0.3960784 ]\n",
            "   [-0.372549  ]\n",
            "   [-0.36470586]\n",
            "   ...\n",
            "   [-0.19999999]\n",
            "   [-0.21568626]\n",
            "   [-0.17647058]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.3960784 ]\n",
            "   [-0.38823527]\n",
            "   [-0.40392154]\n",
            "   ...\n",
            "   [-0.29411763]\n",
            "   [-0.25490195]\n",
            "   [-0.2235294 ]]\n",
            "\n",
            "  [[-0.41176468]\n",
            "   [-0.38823527]\n",
            "   [-0.38823527]\n",
            "   ...\n",
            "   [-0.29411763]\n",
            "   [-0.23921567]\n",
            "   [-0.19215685]]\n",
            "\n",
            "  [[-0.41176468]\n",
            "   [-0.41176468]\n",
            "   [-0.38039213]\n",
            "   ...\n",
            "   [-0.27843136]\n",
            "   [-0.20784312]\n",
            "   [-0.14509803]]]\n",
            "\n",
            "\n",
            " [[[ 0.5529412 ]\n",
            "   [ 0.56078434]\n",
            "   [ 0.43529415]\n",
            "   ...\n",
            "   [-0.69411767]\n",
            "   [-0.7254902 ]\n",
            "   [-0.6313726 ]]\n",
            "\n",
            "  [[ 0.5137255 ]\n",
            "   [ 0.5294118 ]\n",
            "   [ 0.43529415]\n",
            "   ...\n",
            "   [-0.6784314 ]\n",
            "   [-0.7019608 ]\n",
            "   [-0.654902  ]]\n",
            "\n",
            "  [[ 0.3803922 ]\n",
            "   [ 0.4666667 ]\n",
            "   [ 0.45098042]\n",
            "   ...\n",
            "   [-0.60784316]\n",
            "   [-0.60784316]\n",
            "   [-0.6313726 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.24705887]\n",
            "   [ 0.27843142]\n",
            "   [ 0.254902  ]\n",
            "   ...\n",
            "   [ 0.03529418]\n",
            "   [ 0.07450986]\n",
            "   [ 0.09019613]]\n",
            "\n",
            "  [[ 0.30196083]\n",
            "   [ 0.30196083]\n",
            "   [ 0.30980396]\n",
            "   ...\n",
            "   [ 0.06666672]\n",
            "   [ 0.09803927]\n",
            "   [ 0.10588241]]\n",
            "\n",
            "  [[ 0.27843142]\n",
            "   [ 0.3176471 ]\n",
            "   [ 0.41176474]\n",
            "   ...\n",
            "   [ 0.09803927]\n",
            "   [ 0.11372554]\n",
            "   [ 0.06666672]]]\n",
            "\n",
            "\n",
            " [[[ 0.20000005]\n",
            "   [ 0.09803927]\n",
            "   [ 0.26274514]\n",
            "   ...\n",
            "   [ 0.7411765 ]\n",
            "   [ 0.7254902 ]\n",
            "   [ 0.7176471 ]]\n",
            "\n",
            "  [[ 0.2313726 ]\n",
            "   [ 0.12156868]\n",
            "   [ 0.3176471 ]\n",
            "   ...\n",
            "   [ 0.64705884]\n",
            "   [ 0.6784314 ]\n",
            "   [ 0.6862745 ]]\n",
            "\n",
            "  [[ 0.2313726 ]\n",
            "   [ 0.17647064]\n",
            "   [ 0.41960788]\n",
            "   ...\n",
            "   [ 0.58431375]\n",
            "   [ 0.6627451 ]\n",
            "   [ 0.7019608 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.34901965]\n",
            "   [-0.6392157 ]\n",
            "   [-0.99215686]\n",
            "   ...\n",
            "   [-0.16862744]\n",
            "   [ 0.12941182]\n",
            "   [ 0.16078436]]\n",
            "\n",
            "  [[-0.1372549 ]\n",
            "   [-0.5529412 ]\n",
            "   [-0.9529412 ]\n",
            "   ...\n",
            "   [-0.18431371]\n",
            "   [ 0.082353  ]\n",
            "   [ 0.15294123]]\n",
            "\n",
            "  [[-0.7882353 ]\n",
            "   [-0.77254903]\n",
            "   [-0.8901961 ]\n",
            "   ...\n",
            "   [-0.19215685]\n",
            "   [ 0.07450986]\n",
            "   [ 0.14509809]]]] [[[[-0.5529412 ]\n",
            "   [-0.6627451 ]\n",
            "   [-0.8117647 ]\n",
            "   ...\n",
            "   [-0.70980394]\n",
            "   [-0.85882354]\n",
            "   [-0.88235295]]\n",
            "\n",
            "  [[-0.60784316]\n",
            "   [-0.70980394]\n",
            "   [-0.8509804 ]\n",
            "   ...\n",
            "   [-0.6627451 ]\n",
            "   [-0.7882353 ]\n",
            "   [-0.8745098 ]]\n",
            "\n",
            "  [[-0.6392157 ]\n",
            "   [-0.7254902 ]\n",
            "   [-0.827451  ]\n",
            "   ...\n",
            "   [-0.6784314 ]\n",
            "   [-0.73333335]\n",
            "   [-0.8980392 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.5764706 ]\n",
            "   [-0.6156863 ]\n",
            "   [-0.58431375]\n",
            "   ...\n",
            "   [-0.85882354]\n",
            "   [-0.7882353 ]\n",
            "   [-0.6862745 ]]\n",
            "\n",
            "  [[-0.4980392 ]\n",
            "   [-0.5529412 ]\n",
            "   [-0.56078434]\n",
            "   ...\n",
            "   [-0.8039216 ]\n",
            "   [-0.70980394]\n",
            "   [-0.67058825]]\n",
            "\n",
            "  [[-0.56078434]\n",
            "   [-0.5372549 ]\n",
            "   [-0.5764706 ]\n",
            "   ...\n",
            "   [-0.7254902 ]\n",
            "   [-0.6784314 ]\n",
            "   [-0.75686276]]]\n",
            "\n",
            "\n",
            " [[[ 0.02745104]\n",
            "   [ 0.07450986]\n",
            "   [ 0.03529418]\n",
            "   ...\n",
            "   [ 0.21568632]\n",
            "   [ 0.21568632]\n",
            "   [ 0.20784318]]\n",
            "\n",
            "  [[ 0.06666672]\n",
            "   [-0.01960784]\n",
            "   [-0.23921567]\n",
            "   ...\n",
            "   [ 0.23921573]\n",
            "   [ 0.21568632]\n",
            "   [ 0.21568632]]\n",
            "\n",
            "  [[ 0.01176476]\n",
            "   [-0.32549018]\n",
            "   [-0.29411763]\n",
            "   ...\n",
            "   [ 0.254902  ]\n",
            "   [ 0.2313726 ]\n",
            "   [ 0.22352946]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.03529412]\n",
            "   [-0.03529412]\n",
            "   [-0.01176471]\n",
            "   ...\n",
            "   [ 0.21568632]\n",
            "   [ 0.19215691]\n",
            "   [ 0.19215691]]\n",
            "\n",
            "  [[-0.03529412]\n",
            "   [-0.03529412]\n",
            "   [-0.02745098]\n",
            "   ...\n",
            "   [ 0.20000005]\n",
            "   [ 0.19215691]\n",
            "   [ 0.19215691]]\n",
            "\n",
            "  [[-0.04313725]\n",
            "   [-0.03529412]\n",
            "   [-0.02745098]\n",
            "   ...\n",
            "   [ 0.18431377]\n",
            "   [ 0.18431377]\n",
            "   [ 0.17647064]]]\n",
            "\n",
            "\n",
            " [[[ 0.3803922 ]\n",
            "   [ 0.32549024]\n",
            "   [ 0.32549024]\n",
            "   ...\n",
            "   [-0.67058825]\n",
            "   [-0.69411767]\n",
            "   [-0.67058825]]\n",
            "\n",
            "  [[ 0.7254902 ]\n",
            "   [ 0.6862745 ]\n",
            "   [ 0.69411767]\n",
            "   ...\n",
            "   [-0.69411767]\n",
            "   [-0.67058825]\n",
            "   [-0.6862745 ]]\n",
            "\n",
            "  [[ 0.70980394]\n",
            "   [ 0.7019608 ]\n",
            "   [ 0.70980394]\n",
            "   ...\n",
            "   [-0.64705884]\n",
            "   [-0.69411767]\n",
            "   [-0.6       ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.92156863]\n",
            "   [ 0.8352941 ]\n",
            "   [ 0.8117647 ]\n",
            "   ...\n",
            "   [-0.96862745]\n",
            "   [-0.96862745]\n",
            "   [-0.9529412 ]]\n",
            "\n",
            "  [[ 0.9372549 ]\n",
            "   [ 0.84313726]\n",
            "   [ 0.73333335]\n",
            "   ...\n",
            "   [-0.9607843 ]\n",
            "   [-0.9372549 ]\n",
            "   [-0.94509804]]\n",
            "\n",
            "  [[ 0.9372549 ]\n",
            "   [ 0.8352941 ]\n",
            "   [ 0.6627451 ]\n",
            "   ...\n",
            "   [-0.9137255 ]\n",
            "   [-0.92156863]\n",
            "   [-0.9372549 ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.1607843 ]\n",
            "   [-0.20784312]\n",
            "   [-0.18431371]\n",
            "   ...\n",
            "   [-0.5294118 ]\n",
            "   [-0.5372549 ]\n",
            "   [-0.54509807]]\n",
            "\n",
            "  [[-0.27058822]\n",
            "   [-0.38823527]\n",
            "   [-0.27843136]\n",
            "   ...\n",
            "   [-0.5921569 ]\n",
            "   [-0.5372549 ]\n",
            "   [-0.45098037]]\n",
            "\n",
            "  [[-0.38039213]\n",
            "   [-0.42745095]\n",
            "   [-0.372549  ]\n",
            "   ...\n",
            "   [-0.44313723]\n",
            "   [-0.4823529 ]\n",
            "   [-0.2235294 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.5921569 ]\n",
            "   [ 0.58431375]\n",
            "   [ 0.5764706 ]\n",
            "   ...\n",
            "   [ 0.7490196 ]\n",
            "   [ 0.7176471 ]\n",
            "   [ 0.79607844]]\n",
            "\n",
            "  [[ 0.60784316]\n",
            "   [ 0.6156863 ]\n",
            "   [ 0.60784316]\n",
            "   ...\n",
            "   [ 0.92156863]\n",
            "   [ 0.92941177]\n",
            "   [ 0.8666667 ]]\n",
            "\n",
            "  [[ 0.6156863 ]\n",
            "   [ 0.6313726 ]\n",
            "   [ 0.62352943]\n",
            "   ...\n",
            "   [ 0.8117647 ]\n",
            "   [ 0.92156863]\n",
            "   [ 0.8980392 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.41176474]\n",
            "   [ 0.52156866]\n",
            "   [ 0.62352943]\n",
            "   ...\n",
            "   [-0.6156863 ]\n",
            "   [ 0.20000005]\n",
            "   [ 0.06666672]]\n",
            "\n",
            "  [[ 0.5058824 ]\n",
            "   [ 0.60784316]\n",
            "   [ 0.67058825]\n",
            "   ...\n",
            "   [-0.6627451 ]\n",
            "   [-0.09803921]\n",
            "   [-0.04313725]]\n",
            "\n",
            "  [[ 0.6       ]\n",
            "   [ 0.6784314 ]\n",
            "   [ 0.6862745 ]\n",
            "   ...\n",
            "   [-0.7254902 ]\n",
            "   [-0.35686272]\n",
            "   [-0.2235294 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.9372549 ]\n",
            "   [-0.92941177]\n",
            "   [-0.9137255 ]\n",
            "   ...\n",
            "   [-0.56078434]\n",
            "   [-0.60784316]\n",
            "   [-0.6862745 ]]\n",
            "\n",
            "  [[-0.92941177]\n",
            "   [-0.92156863]\n",
            "   [-0.8980392 ]\n",
            "   ...\n",
            "   [-0.4980392 ]\n",
            "   [-0.6627451 ]\n",
            "   [-0.5921569 ]]\n",
            "\n",
            "  [[-0.9372549 ]\n",
            "   [-0.92156863]\n",
            "   [-0.8901961 ]\n",
            "   ...\n",
            "   [-0.77254903]\n",
            "   [-0.64705884]\n",
            "   [-0.62352943]]]\n",
            "\n",
            "\n",
            " [[[ 0.3176471 ]\n",
            "   [ 0.3176471 ]\n",
            "   [ 0.3176471 ]\n",
            "   ...\n",
            "   [-0.7882353 ]\n",
            "   [-0.7647059 ]\n",
            "   [-0.8039216 ]]\n",
            "\n",
            "  [[ 0.3176471 ]\n",
            "   [ 0.3176471 ]\n",
            "   [ 0.30980396]\n",
            "   ...\n",
            "   [-0.70980394]\n",
            "   [-0.77254903]\n",
            "   [-0.7490196 ]]\n",
            "\n",
            "  [[ 0.3176471 ]\n",
            "   [ 0.3176471 ]\n",
            "   [ 0.28627455]\n",
            "   ...\n",
            "   [-0.6862745 ]\n",
            "   [-0.7176471 ]\n",
            "   [-0.78039217]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.24705887]\n",
            "   [ 0.23921573]\n",
            "   [ 0.21568632]\n",
            "   ...\n",
            "   [ 0.12156868]\n",
            "   [ 0.11372554]\n",
            "   [ 0.13725495]]\n",
            "\n",
            "  [[ 0.2313726 ]\n",
            "   [ 0.254902  ]\n",
            "   [ 0.12156868]\n",
            "   ...\n",
            "   [ 0.09019613]\n",
            "   [ 0.09803927]\n",
            "   [ 0.11372554]]\n",
            "\n",
            "  [[ 0.24705887]\n",
            "   [ 0.20000005]\n",
            "   [-0.2862745 ]\n",
            "   ...\n",
            "   [ 0.00392163]\n",
            "   [ 0.082353  ]\n",
            "   [ 0.082353  ]]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\\n\\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKvEv321Stt5",
        "outputId": "aaecb81a-b227-407a-9f00-d157393cc412"
      },
      "source": [
        "print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validasi (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "test (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "train (28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH9Q-TegBR26"
      },
      "source": [
        "#hyperparameter and callback\n",
        "batch_size = 64\n",
        "num_epochs = 60\n",
        "input_shape = (48, 48, 1)\n",
        "num_classes = 7\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGsscQRJBR-h"
      },
      "source": [
        "#Compile the model.\n",
        "\n",
        "\n",
        "from keras.optimizers import Adam, SGD\n",
        "model = ResNet50(input_shape = (48, 48, 1), classes = 7)\n",
        "optimizer = SGD(learning_rate=0.005)\n",
        "model.compile(optimizer= optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rodttDWeT2yP"
      },
      "source": [
        "#kita mau save model callbacks\n",
        "\"\"\"import os\n",
        "try:\n",
        "  os.mkdir('scratchcheckpoint')\n",
        "except:\n",
        "  pass\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV29sTjET28U"
      },
      "source": [
        "\"\"\"file_name = 'Best_Model_resnet50Scracth_sena1.h5'\n",
        "\n",
        "checkpoint_path = os.path.join('checkpoint',file_name)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_S6wUaPT3Jx"
      },
      "source": [
        "\"\"\"call_back = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
        "                                               monitor='val_accuracy',\n",
        "                                               verbose=1,\n",
        "                                               save_freq='epoch',\n",
        "                                               save_best_only=True,\n",
        "                                               save_weights_only=False,\n",
        "                                               mode='max')\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy53DHMGB-Mr",
        "outputId": "0925c01f-b958-4b9f-a20f-db44796adb5c"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 46, 46, 128)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 46, 46, 128)  0           activation_3[0][0]               \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 46, 46, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 46, 46, 128)  0           activation_6[0][0]               \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 46, 46, 128)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 23, 23, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 23, 23, 256)  0           activation_12[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 23, 23, 256)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 23, 23, 256)  0           activation_15[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 23, 23, 256)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 23, 23, 256)  0           activation_18[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 23, 23, 256)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 12, 12, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 12, 12, 512)  0           activation_24[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 12, 12, 512)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 12, 12, 512)  0           activation_27[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 12, 12, 512)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 12, 12, 512)  0           activation_30[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 12, 12, 512)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 12, 12, 512)  0           activation_33[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 12, 12, 512)  0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 12, 12, 512)  0           activation_36[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 12, 12, 512)  0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 6, 6, 1024)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 6, 6, 1024)   0           activation_42[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 6, 6, 1024)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 6, 6, 1024)   0           activation_45[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 6, 6, 1024)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgxCecVwCGEr"
      },
      "source": [
        "\"\"\"history = model.fit(data_generator.flow(xtrain, ytrain,),\n",
        "                        steps_per_epoch=len(xtrain) / batch_size,\n",
        "                        epochs=num_epochs, verbose=1,callbacks=call_back,\n",
        "                        validation_data= (xtest,ytest))\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2muXWns0sJSH",
        "outputId": "c79be390-7df4-4b41-deb8-0aa139db6e0a"
      },
      "source": [
        "history = model.fit(\n",
        "    data_generator.flow(xtrain, ytrain,),\n",
        "    steps_per_epoch=len(xtrain) / batch_size,\n",
        "    epochs=num_epochs, \n",
        "    verbose=1,\n",
        "    validation_data= (x_val,y_val))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "448/448 [==============================] - 170s 250ms/step - loss: 2.2612 - accuracy: 0.2277 - val_loss: 1.7966 - val_accuracy: 0.2399\n",
            "Epoch 2/60\n",
            "448/448 [==============================] - 107s 238ms/step - loss: 1.7989 - accuracy: 0.2520 - val_loss: 1.7713 - val_accuracy: 0.2583\n",
            "Epoch 3/60\n",
            "448/448 [==============================] - 107s 237ms/step - loss: 1.7708 - accuracy: 0.2687 - val_loss: 1.7453 - val_accuracy: 0.2614\n",
            "Epoch 4/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.7685 - accuracy: 0.2702 - val_loss: 1.7278 - val_accuracy: 0.2806\n",
            "Epoch 5/60\n",
            "448/448 [==============================] - 107s 238ms/step - loss: 1.7384 - accuracy: 0.2796 - val_loss: 1.7034 - val_accuracy: 0.3045\n",
            "Epoch 6/60\n",
            "448/448 [==============================] - 107s 237ms/step - loss: 1.7368 - accuracy: 0.2859 - val_loss: 1.7146 - val_accuracy: 0.2862\n",
            "Epoch 7/60\n",
            "448/448 [==============================] - 107s 238ms/step - loss: 1.7285 - accuracy: 0.2925 - val_loss: 1.6909 - val_accuracy: 0.2973\n",
            "Epoch 8/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.6977 - accuracy: 0.3064 - val_loss: 1.6914 - val_accuracy: 0.3121\n",
            "Epoch 9/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.6991 - accuracy: 0.3167 - val_loss: 1.6504 - val_accuracy: 0.3302\n",
            "Epoch 10/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.6877 - accuracy: 0.3201 - val_loss: 1.6411 - val_accuracy: 0.3360\n",
            "Epoch 11/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.6821 - accuracy: 0.3267 - val_loss: 1.6538 - val_accuracy: 0.3282\n",
            "Epoch 12/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.6563 - accuracy: 0.3325 - val_loss: 1.6045 - val_accuracy: 0.3636\n",
            "Epoch 13/60\n",
            "448/448 [==============================] - 111s 247ms/step - loss: 1.6187 - accuracy: 0.3650 - val_loss: 1.6084 - val_accuracy: 0.3636\n",
            "Epoch 14/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.6230 - accuracy: 0.3510 - val_loss: 1.5722 - val_accuracy: 0.3767\n",
            "Epoch 15/60\n",
            "448/448 [==============================] - 107s 238ms/step - loss: 1.5947 - accuracy: 0.3742 - val_loss: 1.5429 - val_accuracy: 0.3906\n",
            "Epoch 16/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.5821 - accuracy: 0.3793 - val_loss: 1.5226 - val_accuracy: 0.4090\n",
            "Epoch 17/60\n",
            "448/448 [==============================] - 107s 238ms/step - loss: 1.5612 - accuracy: 0.3889 - val_loss: 1.4772 - val_accuracy: 0.4316\n",
            "Epoch 18/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.5292 - accuracy: 0.4099 - val_loss: 1.4761 - val_accuracy: 0.4266\n",
            "Epoch 19/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.5209 - accuracy: 0.4058 - val_loss: 1.4500 - val_accuracy: 0.4316\n",
            "Epoch 20/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.4989 - accuracy: 0.4121 - val_loss: 1.4244 - val_accuracy: 0.4455\n",
            "Epoch 21/60\n",
            "448/448 [==============================] - 111s 247ms/step - loss: 1.4861 - accuracy: 0.4266 - val_loss: 1.4185 - val_accuracy: 0.4441\n",
            "Epoch 22/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.4648 - accuracy: 0.4300 - val_loss: 1.4080 - val_accuracy: 0.4483\n",
            "Epoch 23/60\n",
            "448/448 [==============================] - 107s 238ms/step - loss: 1.4676 - accuracy: 0.4305 - val_loss: 1.3787 - val_accuracy: 0.4625\n",
            "Epoch 24/60\n",
            "448/448 [==============================] - 107s 238ms/step - loss: 1.4350 - accuracy: 0.4414 - val_loss: 1.3988 - val_accuracy: 0.4564\n",
            "Epoch 25/60\n",
            "448/448 [==============================] - 111s 247ms/step - loss: 1.4183 - accuracy: 0.4525 - val_loss: 1.3460 - val_accuracy: 0.4753\n",
            "Epoch 26/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.4014 - accuracy: 0.4482 - val_loss: 1.3464 - val_accuracy: 0.4723\n",
            "Epoch 27/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.3861 - accuracy: 0.4694 - val_loss: 1.3382 - val_accuracy: 0.4703\n",
            "Epoch 28/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.3730 - accuracy: 0.4697 - val_loss: 1.3245 - val_accuracy: 0.4801\n",
            "Epoch 29/60\n",
            "448/448 [==============================] - 111s 247ms/step - loss: 1.3738 - accuracy: 0.4654 - val_loss: 1.3190 - val_accuracy: 0.4943\n",
            "Epoch 30/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.3555 - accuracy: 0.4734 - val_loss: 1.3257 - val_accuracy: 0.4812\n",
            "Epoch 31/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.3186 - accuracy: 0.4923 - val_loss: 1.3065 - val_accuracy: 0.4865\n",
            "Epoch 32/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.3217 - accuracy: 0.4922 - val_loss: 1.2985 - val_accuracy: 0.4971\n",
            "Epoch 33/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.3095 - accuracy: 0.4874 - val_loss: 1.3212 - val_accuracy: 0.4806\n",
            "Epoch 34/60\n",
            "448/448 [==============================] - 107s 238ms/step - loss: 1.3116 - accuracy: 0.4915 - val_loss: 1.2625 - val_accuracy: 0.5169\n",
            "Epoch 35/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.2818 - accuracy: 0.5070 - val_loss: 1.2527 - val_accuracy: 0.5113\n",
            "Epoch 36/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.2856 - accuracy: 0.5063 - val_loss: 1.2624 - val_accuracy: 0.5085\n",
            "Epoch 37/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.2659 - accuracy: 0.5159 - val_loss: 1.2357 - val_accuracy: 0.5244\n",
            "Epoch 38/60\n",
            "448/448 [==============================] - 107s 238ms/step - loss: 1.2734 - accuracy: 0.5127 - val_loss: 1.2216 - val_accuracy: 0.5283\n",
            "Epoch 39/60\n",
            "448/448 [==============================] - 107s 238ms/step - loss: 1.2544 - accuracy: 0.5123 - val_loss: 1.2347 - val_accuracy: 0.5272\n",
            "Epoch 40/60\n",
            "448/448 [==============================] - 107s 238ms/step - loss: 1.2483 - accuracy: 0.5277 - val_loss: 1.2193 - val_accuracy: 0.5322\n",
            "Epoch 41/60\n",
            "448/448 [==============================] - 107s 238ms/step - loss: 1.2422 - accuracy: 0.5180 - val_loss: 1.2102 - val_accuracy: 0.5288\n",
            "Epoch 42/60\n",
            "448/448 [==============================] - 110s 246ms/step - loss: 1.2394 - accuracy: 0.5131 - val_loss: 1.2534 - val_accuracy: 0.5230\n",
            "Epoch 43/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.2324 - accuracy: 0.5250 - val_loss: 1.2113 - val_accuracy: 0.5311\n",
            "Epoch 44/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.2187 - accuracy: 0.5308 - val_loss: 1.1927 - val_accuracy: 0.5408\n",
            "Epoch 45/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.2145 - accuracy: 0.5361 - val_loss: 1.2076 - val_accuracy: 0.5403\n",
            "Epoch 46/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.1889 - accuracy: 0.5502 - val_loss: 1.1943 - val_accuracy: 0.5447\n",
            "Epoch 47/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.2012 - accuracy: 0.5407 - val_loss: 1.2275 - val_accuracy: 0.5272\n",
            "Epoch 48/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.1858 - accuracy: 0.5488 - val_loss: 1.1581 - val_accuracy: 0.5542\n",
            "Epoch 49/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.1644 - accuracy: 0.5535 - val_loss: 1.2119 - val_accuracy: 0.5341\n",
            "Epoch 50/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.1589 - accuracy: 0.5537 - val_loss: 1.1718 - val_accuracy: 0.5447\n",
            "Epoch 51/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.1527 - accuracy: 0.5619 - val_loss: 1.1847 - val_accuracy: 0.5383\n",
            "Epoch 52/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.1628 - accuracy: 0.5602 - val_loss: 1.1622 - val_accuracy: 0.5559\n",
            "Epoch 53/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.1638 - accuracy: 0.5497 - val_loss: 1.1756 - val_accuracy: 0.5442\n",
            "Epoch 54/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.1375 - accuracy: 0.5627 - val_loss: 1.1397 - val_accuracy: 0.5637\n",
            "Epoch 55/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.1369 - accuracy: 0.5648 - val_loss: 1.1400 - val_accuracy: 0.5687\n",
            "Epoch 56/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.1329 - accuracy: 0.5719 - val_loss: 1.1569 - val_accuracy: 0.5609\n",
            "Epoch 57/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.1203 - accuracy: 0.5743 - val_loss: 1.1630 - val_accuracy: 0.5511\n",
            "Epoch 58/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.1259 - accuracy: 0.5685 - val_loss: 1.1284 - val_accuracy: 0.5634\n",
            "Epoch 59/60\n",
            "448/448 [==============================] - 107s 239ms/step - loss: 1.1162 - accuracy: 0.5729 - val_loss: 1.1420 - val_accuracy: 0.5612\n",
            "Epoch 60/60\n",
            "448/448 [==============================] - 111s 247ms/step - loss: 1.1065 - accuracy: 0.5793 - val_loss: 1.1288 - val_accuracy: 0.5687\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "GaXUP-8fDWRN",
        "outputId": "dbde36ba-3fb0-49a0-bed8-8e1b01ff020c"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "model.save('/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD3.h5')\n",
        "\n",
        "#gffhgffkjkjdskjjkjkjkjhjhnnn\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "num_epochs = range(len(accuracy))\n",
        "plt.plot(num_epochs, accuracy, 'r', label='Training acc')\n",
        "plt.plot(num_epochs, val_accuracy, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(num_epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(num_epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_LxatO5J-pp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75ee4007-461f-45f9-d0d5-4201f31cd2ac"
      },
      "source": [
        "testloss = model.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "trainloss = model.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(trainloss[0]))\n",
        "print(\"Train Acc: \" + str(trainloss[1]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 7s 64ms/step - loss: 1.1504 - accuracy: 0.5620\n",
            "Test Loss 1.150363802909851\n",
            "Test Acc: 0.5619949698448181\n",
            "898/898 [==============================] - 58s 64ms/step - loss: 1.0522 - accuracy: 0.6011\n",
            "Train Loss 1.0521953105926514\n",
            "Train Acc: 0.6010658740997314\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swoRERVdKQ1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68e4da3c-15c7-4bbd-af54-e4ce2aeaea6a"
      },
      "source": [
        "testlosz = model.evaluate(x_val, y_val) \n",
        "print(\"Test Loss \" + str(testlosz[0]))\n",
        "print(\"Test Acc: \" + str(testlosz[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 3s 25ms/step - loss: 1.1345 - accuracy: 0.5751\n",
            "Test Loss 1.1344587802886963\n",
            "Test Acc: 0.5750905275344849\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5iaZIU6pPzk",
        "outputId": "16b9098d-6a24-4afa-b9fe-7f8e4f0480c4"
      },
      "source": [
        "from keras.models import load_model\n",
        "model_load = load_model('/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD3.h5')\n",
        "\n",
        "model_load.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 46, 46, 128)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 46, 46, 128)  0           activation_3[0][0]               \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 46, 46, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 46, 46, 128)  0           activation_6[0][0]               \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 46, 46, 128)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 23, 23, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 23, 23, 256)  0           activation_12[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 23, 23, 256)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 23, 23, 256)  0           activation_15[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 23, 23, 256)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 23, 23, 256)  0           activation_18[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 23, 23, 256)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 12, 12, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 12, 12, 512)  0           activation_24[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 12, 12, 512)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 12, 12, 512)  0           activation_27[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 12, 12, 512)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 12, 12, 512)  0           activation_30[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 12, 12, 512)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 12, 12, 512)  0           activation_33[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 12, 12, 512)  0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 12, 12, 512)  0           activation_36[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 12, 12, 512)  0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 6, 6, 1024)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 6, 6, 1024)   0           activation_42[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 6, 6, 1024)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 6, 6, 1024)   0           activation_45[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 6, 6, 1024)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypc8clklx2p8",
        "outputId": "9d77c29a-face-440a-c02f-986874b561f3"
      },
      "source": [
        "#loss,acc = model_load.evaluate(xtrain,ytrain)\n",
        "\"\"\"print(\"loss:\",loss)\n",
        "print(\"acc:\",acc)kjjkj\"\"\"\n",
        "\n",
        "\n",
        "testloss = model_load.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "\n",
        "testloss = model_load.evaluate(xtrain, ytrain) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 12s 65ms/step - loss: 1.1504 - accuracy: 0.5620\n",
            "Test Loss 1.150363802909851\n",
            "Test Acc: 0.5619949698448181\n",
            "898/898 [==============================] - 58s 64ms/step - loss: 1.0522 - accuracy: 0.6011\n",
            "Test Loss 1.0521953105926514\n",
            "Test Acc: 0.6010658740997314\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7mSww_U2O_q",
        "outputId": "11465a02-dbab-4ce6-f728-aaddad4ac8b5"
      },
      "source": [
        "testlosz = model_load.evaluate(xtrain, ytrain) \n",
        "print(\"Test Loss \" + str(testlosz[0]))\n",
        "print(\"Test Acc: \" + str(testlosz[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1010/1010 [==============================] - 26s 26ms/step - loss: 0.9853 - accuracy: 0.6306\n",
            "Test Loss 0.9853226542472839\n",
            "Test Acc: 0.6306272745132446\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdU7uU3PYCnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06d70af4-10f5-47c0-e492-5823d7ed040a"
      },
      "source": [
        "print (x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3589, 48, 48, 1)\n",
            "(3589,)\n",
            "(3589, 48, 48, 1)\n",
            "(3589,)\n",
            "(28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J11OOgMKYHJV"
      },
      "source": [
        "dfsfsd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvXSq92Spf6f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqXhenHGpggc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}