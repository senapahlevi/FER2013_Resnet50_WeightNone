{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER2013_Resnet50_weightnone_scratch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "18Zj-Yp1YlH0QWcuD4e7ugx8zCCcRS0jg",
      "authorship_tag": "ABX9TyPNgUXAG9ANL2mjCJ/WQehh"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eWeoD7MRFlN",
        "outputId": "0e2d5d4c-8f6c-4a8a-a287-b9e9ec1da464"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "inputFolder = '/content/drive/MyDrive/Fer2013_backup/' \n",
        "for root, directories, filenames in os.walk(inputFolder): \n",
        "    for filename in filenames: print(os.path.join(root,filename))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Fer2013_backup/backUpfer2013.csv\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/best_model_resnet50_modelB2_170false.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/best_model_resnet50_modelD2_170false.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50Scracth_tipe7.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50Scracth_tipe8.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50oriAUGScracthSGD2.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50oriAUGScracthSGD3.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50AUGScracthadam2.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/fixcheckpoint/Best_Model_resnet50oriAUGScracthSGD2.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH8iEUJiRQS7",
        "outputId": "b8dc5ae5-25e2-48a2-d113-6f008b17d0e9"
      },
      "source": [
        "%cd /content/drive/MyDrive/Fer2013_backup/\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Fer2013_backup\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqZOFwxxRQaa",
        "outputId": "d646c3e3-740a-4fe6-a3b2-ebae64fd96a3"
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:400: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUX-dSAgRQh4"
      },
      "source": [
        "#Define the identity block helper function.\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "   \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbdQH3mkRQra"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path \n",
        "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b',padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33XH76oKRQvh"
      },
      "source": [
        "def ResNet50(input_shape = (48,48,1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    #X = ZeroPadding2D((1, 1))(X_input)\n",
        "    X = X_input\n",
        "    # Stage 1\n",
        "\n",
        "    X = Conv2D(8, (3, 3), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # removed maxpool\n",
        "    #X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='c')\n",
        "\n",
        "\n",
        "    # Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [64,64,256], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL . \n",
        "    X = AveragePooling2D((2,2), name='avg_pool')(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(512, activation = 'relu', name='fc1024' , kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWuYK_f2zGJF"
      },
      "source": [
        "\"\"\"def ResNet50ori(input_shape = (48, 48, 1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50ori')\n",
        "\n",
        "    return model\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QQOxN2cRQy3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "904cc86c-2055-4cdd-e077-8ce043a6486b"
      },
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        " \n",
        "dataset_path = '/content/drive/MyDrive/Fer2013_backup/backUpfer2013.csv'\n",
        "image_size=(48,48)\n",
        "\n",
        "def load_fer2013():\n",
        "    data = pd.read_csv(dataset_path)\n",
        "    data = (data[data['pixels'].notnull()])\n",
        "    pixels = data['pixels'].tolist()\n",
        "    width, height = 48, 48\n",
        "    faces = []\n",
        "    for pixel_sequence in pixels:\n",
        "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "        face = np.asarray(face).reshape(width, height)\n",
        "        face = cv2.resize(face.astype('uint8'),image_size)\n",
        "        faces.append(face.astype('float32'))\n",
        "    faces = np.asarray(faces)\n",
        "    faces = np.expand_dims(faces, -1)\n",
        "    emotions = (data['emotion'])#.values\n",
        "    return faces, emotions\n",
        " \n",
        "def preprocess_input(x, v2=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if v2:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x\n",
        " \n",
        "faces, emotions = load_fer2013()\n",
        "faces = preprocess_input(faces)\n",
        "#xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
        "#Data Augumentationfgf\n",
        "data_generator = ImageDataGenerator(\n",
        "                        rotation_range=10,\n",
        "                        shear_range = 10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        vertical_flip=True,\n",
        "                        horizontal_flip=True)\n",
        "\"\"\"data_generator = ImageDataGenerator ()\"\"\""
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'data_generator = ImageDataGenerator ()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zCkwVdnKTm5",
        "outputId": "b9fbc1ec-4595-4ba2-8ec3-169671aa20c0"
      },
      "source": [
        "train_ratio = 0.80\n",
        "validation_ratio = 0.10\n",
        "test_ratio = 0.10\n",
        "\n",
        "# train is now 75% of the entire data set\n",
        "# the _junk suffix means that we drop that variable completely # the _junk suffix means that we drop that variable completely\n",
        "#x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=1 - train_ratio)\n",
        "\n",
        "# test is now 10% of the initial data set\n",
        "# validation is now 15% of the initial data set\n",
        "#x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "x_val, xtest, y_val, ytest = train_test_split(xtest, ytest, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "\n",
        "print(xtrain, x_val, xtest)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[ 0.52156866]\n",
            "   [ 0.69411767]\n",
            "   [ 0.70980394]\n",
            "   ...\n",
            "   [ 0.47450984]\n",
            "   [ 0.45882356]\n",
            "   [ 0.4431373 ]]\n",
            "\n",
            "  [[ 0.6313726 ]\n",
            "   [ 0.6784314 ]\n",
            "   [ 0.70980394]\n",
            "   ...\n",
            "   [ 0.49803925]\n",
            "   [ 0.47450984]\n",
            "   [ 0.45098042]]\n",
            "\n",
            "  [[ 0.6784314 ]\n",
            "   [ 0.69411767]\n",
            "   [ 0.7019608 ]\n",
            "   ...\n",
            "   [ 0.5058824 ]\n",
            "   [ 0.47450984]\n",
            "   [ 0.4666667 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.5372549 ]\n",
            "   [ 0.58431375]\n",
            "   [ 0.6156863 ]\n",
            "   ...\n",
            "   [ 0.92156863]\n",
            "   [ 0.9372549 ]\n",
            "   [ 0.94509804]]\n",
            "\n",
            "  [[ 0.41176474]\n",
            "   [ 0.4666667 ]\n",
            "   [ 0.5058824 ]\n",
            "   ...\n",
            "   [ 0.92941177]\n",
            "   [ 0.9372549 ]\n",
            "   [ 0.94509804]]\n",
            "\n",
            "  [[ 0.33333337]\n",
            "   [ 0.38823533]\n",
            "   [ 0.4431373 ]\n",
            "   ...\n",
            "   [ 0.92941177]\n",
            "   [ 0.9372549 ]\n",
            "   [ 0.94509804]]]\n",
            "\n",
            "\n",
            " [[[-0.8352941 ]\n",
            "   [-0.7882353 ]\n",
            "   [-0.75686276]\n",
            "   ...\n",
            "   [-0.78039217]\n",
            "   [-0.7490196 ]\n",
            "   [-0.73333335]]\n",
            "\n",
            "  [[-0.8352941 ]\n",
            "   [-0.7490196 ]\n",
            "   [-0.7254902 ]\n",
            "   ...\n",
            "   [-0.78039217]\n",
            "   [-0.7254902 ]\n",
            "   [-0.7254902 ]]\n",
            "\n",
            "  [[-0.7882353 ]\n",
            "   [-0.73333335]\n",
            "   [-0.7176471 ]\n",
            "   ...\n",
            "   [-0.75686276]\n",
            "   [-0.7647059 ]\n",
            "   [-0.75686276]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.4980392 ]\n",
            "   [-0.5294118 ]\n",
            "   [-0.6       ]\n",
            "   ...\n",
            "   [-0.6392157 ]\n",
            "   [-0.6156863 ]\n",
            "   [-0.6156863 ]]\n",
            "\n",
            "  [[-0.52156866]\n",
            "   [-0.5137255 ]\n",
            "   [-0.5764706 ]\n",
            "   ...\n",
            "   [-0.6313726 ]\n",
            "   [-0.60784316]\n",
            "   [-0.60784316]]\n",
            "\n",
            "  [[-0.5764706 ]\n",
            "   [-0.5764706 ]\n",
            "   [-0.5058824 ]\n",
            "   ...\n",
            "   [-0.6156863 ]\n",
            "   [-0.60784316]\n",
            "   [-0.6       ]]]\n",
            "\n",
            "\n",
            " [[[-0.01176471]\n",
            "   [-0.01176471]\n",
            "   [ 0.0196079 ]\n",
            "   ...\n",
            "   [ 0.9372549 ]\n",
            "   [ 0.92941177]\n",
            "   [ 0.92941177]]\n",
            "\n",
            "  [[ 0.00392163]\n",
            "   [ 0.01176476]\n",
            "   [ 0.04313731]\n",
            "   ...\n",
            "   [ 0.92156863]\n",
            "   [ 0.9137255 ]\n",
            "   [ 0.9137255 ]]\n",
            "\n",
            "  [[ 0.0196079 ]\n",
            "   [ 0.02745104]\n",
            "   [ 0.06666672]\n",
            "   ...\n",
            "   [ 0.8980392 ]\n",
            "   [ 0.90588236]\n",
            "   [ 0.90588236]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.81960785]\n",
            "   [-0.84313726]\n",
            "   [-0.827451  ]\n",
            "   ...\n",
            "   [ 0.75686276]\n",
            "   [ 0.75686276]\n",
            "   [ 0.75686276]]\n",
            "\n",
            "  [[-0.01960784]\n",
            "   [-0.5137255 ]\n",
            "   [-0.70980394]\n",
            "   ...\n",
            "   [ 0.75686276]\n",
            "   [ 0.75686276]\n",
            "   [ 0.75686276]]\n",
            "\n",
            "  [[ 0.34901965]\n",
            "   [ 0.24705887]\n",
            "   [ 0.05882359]\n",
            "   ...\n",
            "   [ 0.75686276]\n",
            "   [ 0.7490196 ]\n",
            "   [ 0.7490196 ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 0.96862745]\n",
            "   [ 1.        ]\n",
            "   [ 0.27843142]\n",
            "   ...\n",
            "   [-0.5921569 ]\n",
            "   [-0.6392157 ]\n",
            "   [-0.6       ]]\n",
            "\n",
            "  [[ 0.9843137 ]\n",
            "   [ 0.9764706 ]\n",
            "   [-0.17647058]\n",
            "   ...\n",
            "   [-0.60784316]\n",
            "   [-0.62352943]\n",
            "   [-0.58431375]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 0.70980394]\n",
            "   [-0.4980392 ]\n",
            "   ...\n",
            "   [-0.6       ]\n",
            "   [-0.654902  ]\n",
            "   [-0.56078434]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.19215685]\n",
            "   [-0.44313723]\n",
            "   [-0.5372549 ]\n",
            "   ...\n",
            "   [ 0.05882359]\n",
            "   [-0.1607843 ]\n",
            "   [-0.5764706 ]]\n",
            "\n",
            "  [[-0.34117645]\n",
            "   [-0.46666664]\n",
            "   [-0.5137255 ]\n",
            "   ...\n",
            "   [ 0.04313731]\n",
            "   [-0.05098039]\n",
            "   [-0.45098037]]\n",
            "\n",
            "  [[-0.47450978]\n",
            "   [-0.4352941 ]\n",
            "   [-0.5294118 ]\n",
            "   ...\n",
            "   [-0.00392157]\n",
            "   [-0.01960784]\n",
            "   [-0.42745095]]]\n",
            "\n",
            "\n",
            " [[[-0.56078434]\n",
            "   [-0.8901961 ]\n",
            "   [-0.8745098 ]\n",
            "   ...\n",
            "   [-0.85882354]\n",
            "   [-0.8509804 ]\n",
            "   [-0.62352943]]\n",
            "\n",
            "  [[-0.654902  ]\n",
            "   [-0.92941177]\n",
            "   [-0.8352941 ]\n",
            "   ...\n",
            "   [-0.8039216 ]\n",
            "   [-0.85882354]\n",
            "   [-0.67058825]]\n",
            "\n",
            "  [[-0.6784314 ]\n",
            "   [-0.9372549 ]\n",
            "   [-0.8117647 ]\n",
            "   ...\n",
            "   [-0.77254903]\n",
            "   [-0.85882354]\n",
            "   [-0.7019608 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.12156862]\n",
            "   [-0.15294117]\n",
            "   [-0.18431371]\n",
            "   ...\n",
            "   [-0.30196077]\n",
            "   [-0.32549018]\n",
            "   [-0.34117645]]\n",
            "\n",
            "  [[-0.12156862]\n",
            "   [-0.1607843 ]\n",
            "   [-0.17647058]\n",
            "   ...\n",
            "   [-0.30196077]\n",
            "   [-0.27058822]\n",
            "   [-0.27843136]]\n",
            "\n",
            "  [[-0.1372549 ]\n",
            "   [-0.16862744]\n",
            "   [-0.18431371]\n",
            "   ...\n",
            "   [-0.2862745 ]\n",
            "   [-0.24705881]\n",
            "   [-0.24705881]]]\n",
            "\n",
            "\n",
            " [[[ 0.20784318]\n",
            "   [ 0.07450986]\n",
            "   [-0.05098039]\n",
            "   ...\n",
            "   [-0.49019605]\n",
            "   [-0.5294118 ]\n",
            "   [-0.4980392 ]]\n",
            "\n",
            "  [[ 0.06666672]\n",
            "   [-0.05882353]\n",
            "   [-0.15294117]\n",
            "   ...\n",
            "   [-0.4823529 ]\n",
            "   [-0.54509807]\n",
            "   [-0.5372549 ]]\n",
            "\n",
            "  [[-0.09019607]\n",
            "   [-0.19999999]\n",
            "   [-0.29411763]\n",
            "   ...\n",
            "   [-0.49019605]\n",
            "   [-0.5372549 ]\n",
            "   [-0.5764706 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.00392163]\n",
            "   [-0.01176471]\n",
            "   [ 0.0196079 ]\n",
            "   ...\n",
            "   [-0.4352941 ]\n",
            "   [-0.44313723]\n",
            "   [-0.5686275 ]]\n",
            "\n",
            "  [[-0.01176471]\n",
            "   [-0.02745098]\n",
            "   [ 0.00392163]\n",
            "   ...\n",
            "   [-0.46666664]\n",
            "   [-0.47450978]\n",
            "   [-0.5921569 ]]\n",
            "\n",
            "  [[-0.01176471]\n",
            "   [-0.04313725]\n",
            "   [-0.01176471]\n",
            "   ...\n",
            "   [-0.42745095]\n",
            "   [-0.49019605]\n",
            "   [-0.54509807]]]] [[[[ 0.9764706 ]\n",
            "   [ 1.        ]\n",
            "   [ 0.8352941 ]\n",
            "   ...\n",
            "   [-0.77254903]\n",
            "   [-0.7411765 ]\n",
            "   [ 0.6862745 ]]\n",
            "\n",
            "  [[ 0.96862745]\n",
            "   [ 1.        ]\n",
            "   [ 0.69411767]\n",
            "   ...\n",
            "   [-0.4980392 ]\n",
            "   [-0.5058824 ]\n",
            "   [ 0.8509804 ]]\n",
            "\n",
            "  [[ 0.9607843 ]\n",
            "   [ 1.        ]\n",
            "   [ 0.27058828]\n",
            "   ...\n",
            "   [-0.41960782]\n",
            "   [-0.4823529 ]\n",
            "   [ 0.79607844]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.6392157 ]\n",
            "   [ 0.4666667 ]\n",
            "   [ 0.3411765 ]\n",
            "   ...\n",
            "   [ 0.56078434]\n",
            "   [ 0.58431375]\n",
            "   [ 0.6156863 ]]\n",
            "\n",
            "  [[ 0.6313726 ]\n",
            "   [ 0.5529412 ]\n",
            "   [ 0.48235297]\n",
            "   ...\n",
            "   [ 0.5686275 ]\n",
            "   [ 0.5921569 ]\n",
            "   [ 0.6156863 ]]\n",
            "\n",
            "  [[ 0.5294118 ]\n",
            "   [ 0.4901961 ]\n",
            "   [ 0.38823533]\n",
            "   ...\n",
            "   [ 0.5764706 ]\n",
            "   [ 0.5921569 ]\n",
            "   [ 0.60784316]]]\n",
            "\n",
            "\n",
            " [[[ 0.52156866]\n",
            "   [ 0.5294118 ]\n",
            "   [ 0.5921569 ]\n",
            "   ...\n",
            "   [ 0.90588236]\n",
            "   [ 0.90588236]\n",
            "   [ 0.90588236]]\n",
            "\n",
            "  [[ 0.5686275 ]\n",
            "   [ 0.62352943]\n",
            "   [ 0.6862745 ]\n",
            "   ...\n",
            "   [ 0.90588236]\n",
            "   [ 0.90588236]\n",
            "   [ 0.90588236]]\n",
            "\n",
            "  [[ 0.6627451 ]\n",
            "   [ 0.6784314 ]\n",
            "   [ 0.45882356]\n",
            "   ...\n",
            "   [ 0.90588236]\n",
            "   [ 0.90588236]\n",
            "   [ 0.90588236]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.41960782]\n",
            "   [-0.41960782]\n",
            "   [-0.40392154]\n",
            "   ...\n",
            "   [ 0.58431375]\n",
            "   [ 0.35686278]\n",
            "   [ 0.21568632]]\n",
            "\n",
            "  [[-0.42745095]\n",
            "   [-0.42745095]\n",
            "   [-0.3960784 ]\n",
            "   ...\n",
            "   [ 0.6       ]\n",
            "   [ 0.21568632]\n",
            "   [ 0.21568632]]\n",
            "\n",
            "  [[-0.41176468]\n",
            "   [-0.41176468]\n",
            "   [-0.40392154]\n",
            "   ...\n",
            "   [ 0.56078434]\n",
            "   [ 0.04313731]\n",
            "   [ 0.32549024]]]\n",
            "\n",
            "\n",
            " [[[ 0.92156863]\n",
            "   [ 0.92941177]\n",
            "   [ 0.9372549 ]\n",
            "   ...\n",
            "   [-0.654902  ]\n",
            "   [-0.4823529 ]\n",
            "   [-0.49019605]]\n",
            "\n",
            "  [[ 0.92156863]\n",
            "   [ 0.94509804]\n",
            "   [ 0.9607843 ]\n",
            "   ...\n",
            "   [-0.7411765 ]\n",
            "   [-0.6       ]\n",
            "   [-0.44313723]]\n",
            "\n",
            "  [[ 0.94509804]\n",
            "   [ 0.9529412 ]\n",
            "   [ 0.9607843 ]\n",
            "   ...\n",
            "   [-0.7882353 ]\n",
            "   [-0.7176471 ]\n",
            "   [-0.5686275 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.7882353 ]\n",
            "   [ 0.79607844]\n",
            "   [ 0.8117647 ]\n",
            "   ...\n",
            "   [ 0.27058828]\n",
            "   [ 0.27843142]\n",
            "   [ 0.28627455]]\n",
            "\n",
            "  [[ 0.79607844]\n",
            "   [ 0.79607844]\n",
            "   [ 0.7882353 ]\n",
            "   ...\n",
            "   [ 0.2313726 ]\n",
            "   [ 0.2941177 ]\n",
            "   [ 0.3176471 ]]\n",
            "\n",
            "  [[ 0.7882353 ]\n",
            "   [ 0.8117647 ]\n",
            "   [ 0.7882353 ]\n",
            "   ...\n",
            "   [ 0.2313726 ]\n",
            "   [ 0.30980396]\n",
            "   [ 0.33333337]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.9764706 ]\n",
            "   [-0.9764706 ]\n",
            "   [-0.8901961 ]\n",
            "   ...\n",
            "   [-0.7019608 ]\n",
            "   [-0.7647059 ]\n",
            "   [-0.88235295]]\n",
            "\n",
            "  [[-0.9764706 ]\n",
            "   [-0.96862745]\n",
            "   [-0.8666667 ]\n",
            "   ...\n",
            "   [-0.5372549 ]\n",
            "   [-0.70980394]\n",
            "   [-0.8745098 ]]\n",
            "\n",
            "  [[-0.9843137 ]\n",
            "   [-0.9529412 ]\n",
            "   [-0.9529412 ]\n",
            "   ...\n",
            "   [-0.47450978]\n",
            "   [-0.6313726 ]\n",
            "   [-0.8117647 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.90588236]\n",
            "   [ 0.90588236]\n",
            "   [ 0.8745098 ]\n",
            "   ...\n",
            "   [-0.9843137 ]\n",
            "   [-0.9843137 ]\n",
            "   [-0.9843137 ]]\n",
            "\n",
            "  [[ 0.9137255 ]\n",
            "   [ 0.8980392 ]\n",
            "   [ 0.8901961 ]\n",
            "   ...\n",
            "   [-0.9764706 ]\n",
            "   [-0.9843137 ]\n",
            "   [-0.9843137 ]]\n",
            "\n",
            "  [[ 0.92156863]\n",
            "   [ 0.90588236]\n",
            "   [ 0.88235295]\n",
            "   ...\n",
            "   [-1.        ]\n",
            "   [-0.9764706 ]\n",
            "   [-0.9843137 ]]]\n",
            "\n",
            "\n",
            " [[[-0.27058822]\n",
            "   [-0.19999999]\n",
            "   [-0.15294117]\n",
            "   ...\n",
            "   [-0.54509807]\n",
            "   [-0.5686275 ]\n",
            "   [-0.5921569 ]]\n",
            "\n",
            "  [[-0.24705881]\n",
            "   [-0.19215685]\n",
            "   [-0.10588235]\n",
            "   ...\n",
            "   [-0.5372549 ]\n",
            "   [-0.5686275 ]\n",
            "   [-0.5921569 ]]\n",
            "\n",
            "  [[-0.23921567]\n",
            "   [-0.18431371]\n",
            "   [-0.12156862]\n",
            "   ...\n",
            "   [-0.5294118 ]\n",
            "   [-0.5764706 ]\n",
            "   [-0.5764706 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.5058824 ]\n",
            "   [-0.6       ]\n",
            "   [-0.5764706 ]\n",
            "   ...\n",
            "   [-0.6784314 ]\n",
            "   [-0.2862745 ]\n",
            "   [-0.18431371]]\n",
            "\n",
            "  [[-0.47450978]\n",
            "   [-0.56078434]\n",
            "   [-0.6862745 ]\n",
            "   ...\n",
            "   [-0.41176468]\n",
            "   [-0.12941176]\n",
            "   [-0.20784312]]\n",
            "\n",
            "  [[-0.46666664]\n",
            "   [-0.5058824 ]\n",
            "   [-0.6627451 ]\n",
            "   ...\n",
            "   [-0.34117645]\n",
            "   [-0.1607843 ]\n",
            "   [-0.23137254]]]\n",
            "\n",
            "\n",
            " [[[-0.34117645]\n",
            "   [ 0.05882359]\n",
            "   [-0.17647058]\n",
            "   ...\n",
            "   [-0.40392154]\n",
            "   [-0.8509804 ]\n",
            "   [-0.9372549 ]]\n",
            "\n",
            "  [[-0.5764706 ]\n",
            "   [-0.5137255 ]\n",
            "   [ 0.07450986]\n",
            "   ...\n",
            "   [-0.40392154]\n",
            "   [-0.7411765 ]\n",
            "   [-0.9137255 ]]\n",
            "\n",
            "  [[-0.6156863 ]\n",
            "   [-0.41960782]\n",
            "   [ 0.52156866]\n",
            "   ...\n",
            "   [-0.5137255 ]\n",
            "   [-0.75686276]\n",
            "   [-0.92941177]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.6627451 ]\n",
            "   [ 0.5686275 ]\n",
            "   [ 0.49803925]\n",
            "   ...\n",
            "   [-0.12156862]\n",
            "   [-0.1607843 ]\n",
            "   [-0.15294117]]\n",
            "\n",
            "  [[ 0.7882353 ]\n",
            "   [ 0.69411767]\n",
            "   [ 0.5137255 ]\n",
            "   ...\n",
            "   [ 0.01176476]\n",
            "   [-0.0745098 ]\n",
            "   [-0.14509803]]\n",
            "\n",
            "  [[ 0.6784314 ]\n",
            "   [ 0.69411767]\n",
            "   [ 0.7647059 ]\n",
            "   ...\n",
            "   [ 0.05882359]\n",
            "   [ 0.02745104]\n",
            "   [-0.05882353]]]] [[[[ 0.99215686]\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.96862745]\n",
            "   ...\n",
            "   [ 0.05882359]\n",
            "   [ 0.20000005]\n",
            "   [ 0.254902  ]]\n",
            "\n",
            "  [[ 0.99215686]\n",
            "   [ 0.99215686]\n",
            "   [ 0.92156863]\n",
            "   ...\n",
            "   [ 0.082353  ]\n",
            "   [-0.00392157]\n",
            "   [ 0.21568632]]\n",
            "\n",
            "  [[ 0.9843137 ]\n",
            "   [ 0.99215686]\n",
            "   [ 0.7647059 ]\n",
            "   ...\n",
            "   [ 0.05098045]\n",
            "   [-0.00392157]\n",
            "   [ 0.02745104]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.01176476]\n",
            "   [-0.04313725]\n",
            "   [-0.1607843 ]\n",
            "   ...\n",
            "   [-0.31764704]\n",
            "   [ 0.23921573]\n",
            "   [ 0.41176474]]\n",
            "\n",
            "  [[-0.04313725]\n",
            "   [-0.01960784]\n",
            "   [-0.09803921]\n",
            "   ...\n",
            "   [-0.27843136]\n",
            "   [ 0.1686275 ]\n",
            "   [ 0.39607847]]\n",
            "\n",
            "  [[-0.02745098]\n",
            "   [ 0.01176476]\n",
            "   [-0.19215685]\n",
            "   ...\n",
            "   [-0.3490196 ]\n",
            "   [ 0.04313731]\n",
            "   [ 0.35686278]]]\n",
            "\n",
            "\n",
            " [[[-0.40392154]\n",
            "   [-0.4352941 ]\n",
            "   [-0.34117645]\n",
            "   ...\n",
            "   [ 1.        ]\n",
            "   [ 0.99215686]\n",
            "   [ 0.9843137 ]]\n",
            "\n",
            "  [[-0.46666664]\n",
            "   [-0.4352941 ]\n",
            "   [-0.32549018]\n",
            "   ...\n",
            "   [ 0.9764706 ]\n",
            "   [ 0.99215686]\n",
            "   [ 0.99215686]]\n",
            "\n",
            "  [[-0.46666664]\n",
            "   [-0.42745095]\n",
            "   [-0.40392154]\n",
            "   ...\n",
            "   [ 0.9529412 ]\n",
            "   [ 0.99215686]\n",
            "   [ 0.99215686]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.79607844]\n",
            "   [-0.75686276]\n",
            "   [-0.77254903]\n",
            "   ...\n",
            "   [-0.18431371]\n",
            "   [-0.24705881]\n",
            "   [ 0.082353  ]]\n",
            "\n",
            "  [[-0.79607844]\n",
            "   [-0.75686276]\n",
            "   [-0.78039217]\n",
            "   ...\n",
            "   [-0.4352941 ]\n",
            "   [-0.41960782]\n",
            "   [-0.04313725]]\n",
            "\n",
            "  [[-0.81960785]\n",
            "   [-0.77254903]\n",
            "   [-0.77254903]\n",
            "   ...\n",
            "   [-0.7176471 ]\n",
            "   [-0.49019605]\n",
            "   [-0.10588235]]]\n",
            "\n",
            "\n",
            " [[[-0.9529412 ]\n",
            "   [-0.96862745]\n",
            "   [-0.9529412 ]\n",
            "   ...\n",
            "   [ 0.06666672]\n",
            "   [-0.00392157]\n",
            "   [ 0.16078436]]\n",
            "\n",
            "  [[-0.9607843 ]\n",
            "   [-0.9607843 ]\n",
            "   [-0.9607843 ]\n",
            "   ...\n",
            "   [-0.03529412]\n",
            "   [ 0.09019613]\n",
            "   [ 0.082353  ]]\n",
            "\n",
            "  [[-0.9607843 ]\n",
            "   [-0.9607843 ]\n",
            "   [-0.9607843 ]\n",
            "   ...\n",
            "   [-0.18431371]\n",
            "   [-0.09019607]\n",
            "   [ 0.04313731]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.9843137 ]\n",
            "   [-0.9843137 ]\n",
            "   [-0.9764706 ]\n",
            "   ...\n",
            "   [-0.96862745]\n",
            "   [-0.94509804]\n",
            "   [-0.8901961 ]]\n",
            "\n",
            "  [[-0.9843137 ]\n",
            "   [-0.9607843 ]\n",
            "   [-0.96862745]\n",
            "   ...\n",
            "   [-0.9607843 ]\n",
            "   [-0.94509804]\n",
            "   [-0.92156863]]\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-0.9764706 ]\n",
            "   [-0.96862745]\n",
            "   ...\n",
            "   [-0.9607843 ]\n",
            "   [-0.9529412 ]\n",
            "   [-0.9372549 ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 0.49803925]\n",
            "   [ 0.4039216 ]\n",
            "   [ 0.16078436]\n",
            "   ...\n",
            "   [ 0.5764706 ]\n",
            "   [ 0.5686275 ]\n",
            "   [ 0.5686275 ]]\n",
            "\n",
            "  [[ 0.45098042]\n",
            "   [ 0.20784318]\n",
            "   [-0.11372548]\n",
            "   ...\n",
            "   [ 0.5686275 ]\n",
            "   [ 0.5686275 ]\n",
            "   [ 0.5764706 ]]\n",
            "\n",
            "  [[ 0.24705887]\n",
            "   [-0.10588235]\n",
            "   [-0.35686272]\n",
            "   ...\n",
            "   [ 0.5686275 ]\n",
            "   [ 0.5686275 ]\n",
            "   [ 0.5764706 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.02745098]\n",
            "   [-0.01176471]\n",
            "   [ 0.04313731]\n",
            "   ...\n",
            "   [-0.99215686]\n",
            "   [-0.99215686]\n",
            "   [-0.99215686]]\n",
            "\n",
            "  [[-0.03529412]\n",
            "   [-0.03529412]\n",
            "   [-0.00392157]\n",
            "   ...\n",
            "   [-0.99215686]\n",
            "   [-0.99215686]\n",
            "   [-0.99215686]]\n",
            "\n",
            "  [[-0.09803921]\n",
            "   [-0.08235294]\n",
            "   [-0.09019607]\n",
            "   ...\n",
            "   [-1.        ]\n",
            "   [-0.99215686]\n",
            "   [-0.99215686]]]\n",
            "\n",
            "\n",
            " [[[-0.6392157 ]\n",
            "   [-0.654902  ]\n",
            "   [-0.6784314 ]\n",
            "   ...\n",
            "   [ 0.38823533]\n",
            "   [ 0.36470592]\n",
            "   [ 0.33333337]]\n",
            "\n",
            "  [[-0.62352943]\n",
            "   [-0.6       ]\n",
            "   [-0.6313726 ]\n",
            "   ...\n",
            "   [ 0.37254906]\n",
            "   [ 0.38823533]\n",
            "   [ 0.36470592]]\n",
            "\n",
            "  [[-0.64705884]\n",
            "   [-0.64705884]\n",
            "   [-0.64705884]\n",
            "   ...\n",
            "   [ 0.35686278]\n",
            "   [ 0.37254906]\n",
            "   [ 0.39607847]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.28627455]\n",
            "   [ 0.28627455]\n",
            "   [ 0.27843142]\n",
            "   ...\n",
            "   [ 0.13725495]\n",
            "   [-0.10588235]\n",
            "   [-0.08235294]]\n",
            "\n",
            "  [[ 0.27058828]\n",
            "   [ 0.27058828]\n",
            "   [ 0.27843142]\n",
            "   ...\n",
            "   [-0.12941176]\n",
            "   [-0.1372549 ]\n",
            "   [ 0.09803927]]\n",
            "\n",
            "  [[ 0.254902  ]\n",
            "   [ 0.26274514]\n",
            "   [ 0.254902  ]\n",
            "   ...\n",
            "   [-0.36470586]\n",
            "   [-0.02745098]\n",
            "   [ 0.1686275 ]]]\n",
            "\n",
            "\n",
            " [[[-0.73333335]\n",
            "   [-0.7254902 ]\n",
            "   [-0.7254902 ]\n",
            "   ...\n",
            "   [-0.67058825]\n",
            "   [-0.6627451 ]\n",
            "   [-0.6313726 ]]\n",
            "\n",
            "  [[-0.73333335]\n",
            "   [-0.7254902 ]\n",
            "   [-0.7254902 ]\n",
            "   ...\n",
            "   [-0.64705884]\n",
            "   [-0.654902  ]\n",
            "   [-0.62352943]]\n",
            "\n",
            "  [[-0.73333335]\n",
            "   [-0.7411765 ]\n",
            "   [-0.7411765 ]\n",
            "   ...\n",
            "   [-0.62352943]\n",
            "   [-0.6392157 ]\n",
            "   [-0.5921569 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.75686276]\n",
            "   [-0.77254903]\n",
            "   [-0.75686276]\n",
            "   ...\n",
            "   [-0.4352941 ]\n",
            "   [-0.47450978]\n",
            "   [-0.3490196 ]]\n",
            "\n",
            "  [[-0.7490196 ]\n",
            "   [-0.7647059 ]\n",
            "   [-0.7490196 ]\n",
            "   ...\n",
            "   [-0.42745095]\n",
            "   [-0.34117645]\n",
            "   [-0.3098039 ]]\n",
            "\n",
            "  [[-0.75686276]\n",
            "   [-0.7647059 ]\n",
            "   [-0.75686276]\n",
            "   ...\n",
            "   [-0.26274508]\n",
            "   [-0.30196077]\n",
            "   [-0.41176468]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t--o7TREKTu2",
        "outputId": "a36a867f-9989-4ebb-b325-752d3818306e"
      },
      "source": [
        "print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validasi (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "test (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "train (28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ofOj3-fRREN"
      },
      "source": [
        "#hyperparameter and callback\n",
        "batch_size = 64\n",
        "num_epochs = 60\n",
        "input_shape = (48, 48, 1)\n",
        "num_classes = 7\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXikieAnRbYs"
      },
      "source": [
        "#Compile the model.\n",
        "\n",
        "\n",
        "from keras.optimizers import Adam, SGD\n",
        "model = ResNet50(input_shape = (48, 48, 1), classes = 7)\n",
        "optimizer = SGD(learning_rate=0.02)\n",
        "model.compile(optimizer= optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5JTFulCRbiX"
      },
      "source": [
        "\"\"\"#kita mau save model callbacks\n",
        "import os\n",
        "try:\n",
        "  os.mkdir('/content/drive/MyDrive/Fer2013_backup/scratchcheckpoint')\n",
        "except:\n",
        "  pass\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkceBySwRgFO"
      },
      "source": [
        "\"\"\"file_name = 'Best_Model_resnet50oriScracth_aug_tipe2.h5'\n",
        "\n",
        "checkpoint_path = os.path.join('checkpoint',file_name)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an3sDjjGRgO1"
      },
      "source": [
        "\"\"\"call_back = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
        "                                               monitor='val_accuracy',\n",
        "                                               verbose=1,\n",
        "                                               save_freq='epoch',\n",
        "                                               save_best_only=True,\n",
        "                                               save_weights_only=False,\n",
        "                                               mode='max')\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nefC0ZE8RgX5",
        "outputId": "1882a717-ce95-4117-bf9e-abbb140cc475"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 46, 46, 128)  0           add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_33 (Add)                    (None, 46, 46, 128)  0           activation_101[0][0]             \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 46, 46, 128)  0           add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, 46, 46, 128)  0           activation_104[0][0]             \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 46, 46, 128)  0           add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_35 (Add)                    (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 23, 23, 256)  0           add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_36 (Add)                    (None, 23, 23, 256)  0           activation_110[0][0]             \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 23, 23, 256)  0           add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_37 (Add)                    (None, 23, 23, 256)  0           activation_113[0][0]             \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 23, 23, 256)  0           add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_38 (Add)                    (None, 23, 23, 256)  0           activation_116[0][0]             \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 23, 23, 256)  0           add_38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_39 (Add)                    (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 12, 12, 512)  0           add_39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_40 (Add)                    (None, 12, 12, 512)  0           activation_122[0][0]             \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 12, 12, 512)  0           add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_41 (Add)                    (None, 12, 12, 512)  0           activation_125[0][0]             \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 12, 12, 512)  0           add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_42 (Add)                    (None, 12, 12, 512)  0           activation_128[0][0]             \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 12, 12, 512)  0           add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_43 (Add)                    (None, 12, 12, 512)  0           activation_131[0][0]             \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 12, 12, 512)  0           add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_44 (Add)                    (None, 12, 12, 512)  0           activation_134[0][0]             \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 12, 12, 512)  0           add_44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_45 (Add)                    (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 6, 6, 1024)   0           add_45[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_46 (Add)                    (None, 6, 6, 1024)   0           activation_140[0][0]             \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 6, 6, 1024)   0           add_46[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_47 (Add)                    (None, 6, 6, 1024)   0           activation_143[0][0]             \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 6, 6, 1024)   0           add_47[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVvpTr7-RkdR"
      },
      "source": [
        "\"\"\"history = model.fit(data_generator.flow(xtrain, ytrain,),\n",
        "                        steps_per_epoch=len(xtrain) / batch_size,\n",
        "                        epochs=num_epochs, verbose=1,callbacks=call_back,\n",
        "                        validation_data= (xtest,ytest))hu\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_tXyjuSz_IP",
        "outputId": "4455ab13-c640-4ffe-dd5b-e6a28dcd9c4f"
      },
      "source": [
        "history = model.fit(\n",
        "    data_generator.flow(xtrain, ytrain,),\n",
        "    steps_per_epoch=len(xtrain) / batch_size,\n",
        "    epochs=num_epochs, \n",
        "    verbose=1,\n",
        "    validation_data= (x_val,y_val))\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "448/448 [==============================] - 61s 113ms/step - loss: 2.9964 - accuracy: 0.2355 - val_loss: 1.7859 - val_accuracy: 0.2444\n",
            "Epoch 2/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.8013 - accuracy: 0.2590 - val_loss: 1.7857 - val_accuracy: 0.2463\n",
            "Epoch 3/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7999 - accuracy: 0.2503 - val_loss: 1.7761 - val_accuracy: 0.2449\n",
            "Epoch 4/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7946 - accuracy: 0.2598 - val_loss: 1.7755 - val_accuracy: 0.2460\n",
            "Epoch 5/60\n",
            "448/448 [==============================] - 49s 109ms/step - loss: 1.7874 - accuracy: 0.2643 - val_loss: 1.7647 - val_accuracy: 0.2552\n",
            "Epoch 6/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.7796 - accuracy: 0.2659 - val_loss: 1.7729 - val_accuracy: 0.2566\n",
            "Epoch 7/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7761 - accuracy: 0.2714 - val_loss: 1.7469 - val_accuracy: 0.2803\n",
            "Epoch 8/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7532 - accuracy: 0.2890 - val_loss: 1.7237 - val_accuracy: 0.2928\n",
            "Epoch 9/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7455 - accuracy: 0.2913 - val_loss: 1.6956 - val_accuracy: 0.3048\n",
            "Epoch 10/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7232 - accuracy: 0.3017 - val_loss: 1.6921 - val_accuracy: 0.3193\n",
            "Epoch 11/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7107 - accuracy: 0.3167 - val_loss: 1.6733 - val_accuracy: 0.3302\n",
            "Epoch 12/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.6738 - accuracy: 0.3302 - val_loss: 1.6366 - val_accuracy: 0.3338\n",
            "Epoch 13/60\n",
            "448/448 [==============================] - 49s 110ms/step - loss: 1.6463 - accuracy: 0.3403 - val_loss: 1.6019 - val_accuracy: 0.3650\n",
            "Epoch 14/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.6240 - accuracy: 0.3623 - val_loss: 1.5577 - val_accuracy: 0.3692\n",
            "Epoch 15/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.5978 - accuracy: 0.3702 - val_loss: 1.5610 - val_accuracy: 0.3753\n",
            "Epoch 16/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.5720 - accuracy: 0.3814 - val_loss: 1.5192 - val_accuracy: 0.3979\n",
            "Epoch 17/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.5492 - accuracy: 0.3881 - val_loss: 1.5226 - val_accuracy: 0.3904\n",
            "Epoch 18/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.5362 - accuracy: 0.4024 - val_loss: 1.6750 - val_accuracy: 0.3611\n",
            "Epoch 19/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.5146 - accuracy: 0.4072 - val_loss: 1.5105 - val_accuracy: 0.4082\n",
            "Epoch 20/60\n",
            "448/448 [==============================] - 49s 110ms/step - loss: 1.4880 - accuracy: 0.4147 - val_loss: 1.4619 - val_accuracy: 0.4076\n",
            "Epoch 21/60\n",
            "448/448 [==============================] - 50s 110ms/step - loss: 1.4833 - accuracy: 0.4157 - val_loss: 1.4523 - val_accuracy: 0.4174\n",
            "Epoch 22/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.4785 - accuracy: 0.4293 - val_loss: 1.4564 - val_accuracy: 0.4374\n",
            "Epoch 23/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.4643 - accuracy: 0.4287 - val_loss: 1.4712 - val_accuracy: 0.4163\n",
            "Epoch 24/60\n",
            "448/448 [==============================] - 50s 110ms/step - loss: 1.4469 - accuracy: 0.4472 - val_loss: 1.4197 - val_accuracy: 0.4322\n",
            "Epoch 25/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.4505 - accuracy: 0.4335 - val_loss: 1.3814 - val_accuracy: 0.4572\n",
            "Epoch 26/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.4234 - accuracy: 0.4503 - val_loss: 1.4508 - val_accuracy: 0.4285\n",
            "Epoch 27/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.4016 - accuracy: 0.4548 - val_loss: 1.3732 - val_accuracy: 0.4703\n",
            "Epoch 28/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.3704 - accuracy: 0.4722 - val_loss: 1.3560 - val_accuracy: 0.4673\n",
            "Epoch 29/60\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.3832 - accuracy: 0.4625 - val_loss: 1.3830 - val_accuracy: 0.4519\n",
            "Epoch 30/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.3483 - accuracy: 0.4788 - val_loss: 1.4618 - val_accuracy: 0.4528\n",
            "Epoch 31/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.3566 - accuracy: 0.4771 - val_loss: 1.3237 - val_accuracy: 0.4857\n",
            "Epoch 32/60\n",
            "448/448 [==============================] - 49s 110ms/step - loss: 1.3194 - accuracy: 0.4943 - val_loss: 1.4515 - val_accuracy: 0.4285\n",
            "Epoch 33/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 1.3135 - accuracy: 0.5011 - val_loss: 1.3034 - val_accuracy: 0.4923\n",
            "Epoch 34/60\n",
            "448/448 [==============================] - 50s 110ms/step - loss: 1.3128 - accuracy: 0.4985 - val_loss: 1.3294 - val_accuracy: 0.4843\n",
            "Epoch 35/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.3114 - accuracy: 0.4866 - val_loss: 1.2739 - val_accuracy: 0.5057\n",
            "Epoch 36/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.2818 - accuracy: 0.5070 - val_loss: 1.2766 - val_accuracy: 0.5091\n",
            "Epoch 37/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.2743 - accuracy: 0.5103 - val_loss: 1.2670 - val_accuracy: 0.5177\n",
            "Epoch 38/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.2390 - accuracy: 0.5254 - val_loss: 1.2876 - val_accuracy: 0.5004\n",
            "Epoch 39/60\n",
            "448/448 [==============================] - 49s 109ms/step - loss: 1.2632 - accuracy: 0.5130 - val_loss: 1.3046 - val_accuracy: 0.4776\n",
            "Epoch 40/60\n",
            "448/448 [==============================] - 49s 110ms/step - loss: 1.2300 - accuracy: 0.5271 - val_loss: 1.3232 - val_accuracy: 0.4887\n",
            "Epoch 41/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.2330 - accuracy: 0.5277 - val_loss: 1.2851 - val_accuracy: 0.4993\n",
            "Epoch 42/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.2329 - accuracy: 0.5249 - val_loss: 1.2865 - val_accuracy: 0.4968\n",
            "Epoch 43/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.2272 - accuracy: 0.5259 - val_loss: 1.2319 - val_accuracy: 0.5222\n",
            "Epoch 44/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.2112 - accuracy: 0.5315 - val_loss: 1.2261 - val_accuracy: 0.5233\n",
            "Epoch 45/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 1.2218 - accuracy: 0.5317 - val_loss: 1.2433 - val_accuracy: 0.5166\n",
            "Epoch 46/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.2126 - accuracy: 0.5338 - val_loss: 1.2139 - val_accuracy: 0.5277\n",
            "Epoch 47/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.2185 - accuracy: 0.5313 - val_loss: 1.2119 - val_accuracy: 0.5274\n",
            "Epoch 48/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.2061 - accuracy: 0.5413 - val_loss: 1.2153 - val_accuracy: 0.5305\n",
            "Epoch 49/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.1760 - accuracy: 0.5556 - val_loss: 1.1959 - val_accuracy: 0.5383\n",
            "Epoch 50/60\n",
            "448/448 [==============================] - 49s 110ms/step - loss: 1.1813 - accuracy: 0.5408 - val_loss: 1.2659 - val_accuracy: 0.5160\n",
            "Epoch 51/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.1674 - accuracy: 0.5484 - val_loss: 1.1935 - val_accuracy: 0.5444\n",
            "Epoch 52/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.1615 - accuracy: 0.5542 - val_loss: 1.2521 - val_accuracy: 0.5188\n",
            "Epoch 53/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.1717 - accuracy: 0.5554 - val_loss: 1.2200 - val_accuracy: 0.5383\n",
            "Epoch 54/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.1708 - accuracy: 0.5517 - val_loss: 1.2350 - val_accuracy: 0.5202\n",
            "Epoch 55/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 1.1376 - accuracy: 0.5673 - val_loss: 1.2268 - val_accuracy: 0.5311\n",
            "Epoch 56/60\n",
            "448/448 [==============================] - 49s 110ms/step - loss: 1.1656 - accuracy: 0.5504 - val_loss: 1.2622 - val_accuracy: 0.5222\n",
            "Epoch 57/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 1.2204 - accuracy: 0.5338 - val_loss: 1.2083 - val_accuracy: 0.5316\n",
            "Epoch 58/60\n",
            "448/448 [==============================] - 49s 110ms/step - loss: 1.1809 - accuracy: 0.5488 - val_loss: 1.2353 - val_accuracy: 0.5288\n",
            "Epoch 59/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 1.1457 - accuracy: 0.5571 - val_loss: 1.2147 - val_accuracy: 0.5330\n",
            "Epoch 60/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 1.1767 - accuracy: 0.5519 - val_loss: 1.2492 - val_accuracy: 0.5347\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZvluWhSRkq4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "outputId": "95c31141-b0ee-4f11-d666-d7610329702b"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "model.save('/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50AUGScracthSGD5.h5')\n",
        "\n",
        "#gffhgffkjkjdshufdfh\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "num_epochs = range(len(accuracy))\n",
        "plt.plot(num_epochs, accuracy, 'r', label='Training acc')\n",
        "plt.plot(num_epochs, val_accuracy, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(num_epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(num_epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Pzozx-30LSe",
        "outputId": "f70fc3cd-b79f-443e-bc5e-a7201ebd284d"
      },
      "source": [
        "testloss = model.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "trainloss = model.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(trainloss[0]))\n",
        "print(\"Train Acc: \" + str(trainloss[1]))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 3s 27ms/step - loss: 1.2021 - accuracy: 0.5350\n",
            "Test Loss 1.2020732164382935\n",
            "Test Acc: 0.5349679589271545\n",
            "898/898 [==============================] - 24s 27ms/step - loss: 1.1378 - accuracy: 0.5673\n",
            "Train Loss 1.1378016471862793\n",
            "Train Acc: 0.5673133730888367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ6YCHax59vt",
        "outputId": "bc9fea72-0e61-4f80-c910-a3450213ea82"
      },
      "source": [
        "from keras.models import load_model\n",
        "model_load = load_model('/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50AUGScracthSGD5.h5')\n",
        "\n",
        "model_load.summary()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 46, 46, 128)  0           add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_33 (Add)                    (None, 46, 46, 128)  0           activation_101[0][0]             \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 46, 46, 128)  0           add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, 46, 46, 128)  0           activation_104[0][0]             \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 46, 46, 128)  0           add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_35 (Add)                    (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 23, 23, 256)  0           add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_36 (Add)                    (None, 23, 23, 256)  0           activation_110[0][0]             \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 23, 23, 256)  0           add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_37 (Add)                    (None, 23, 23, 256)  0           activation_113[0][0]             \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 23, 23, 256)  0           add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_38 (Add)                    (None, 23, 23, 256)  0           activation_116[0][0]             \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 23, 23, 256)  0           add_38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_39 (Add)                    (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 12, 12, 512)  0           add_39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_40 (Add)                    (None, 12, 12, 512)  0           activation_122[0][0]             \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 12, 12, 512)  0           add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_41 (Add)                    (None, 12, 12, 512)  0           activation_125[0][0]             \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 12, 12, 512)  0           add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_42 (Add)                    (None, 12, 12, 512)  0           activation_128[0][0]             \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 12, 12, 512)  0           add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_43 (Add)                    (None, 12, 12, 512)  0           activation_131[0][0]             \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 12, 12, 512)  0           add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_44 (Add)                    (None, 12, 12, 512)  0           activation_134[0][0]             \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 12, 12, 512)  0           add_44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_45 (Add)                    (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 6, 6, 1024)   0           add_45[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_46 (Add)                    (None, 6, 6, 1024)   0           activation_140[0][0]             \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 6, 6, 1024)   0           add_46[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_47 (Add)                    (None, 6, 6, 1024)   0           activation_143[0][0]             \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 6, 6, 1024)   0           add_47[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fpz7ehkO6Cat",
        "outputId": "c56d9d70-f3ac-4e7c-cee7-18806de84f36"
      },
      "source": [
        "\n",
        "testloss = model_load.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "\n",
        "testloss = model_load.evaluate(xtrain, ytrain) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 7s 26ms/step - loss: 1.2021 - accuracy: 0.5350\n",
            "Test Loss 1.2020732164382935\n",
            "Test Acc: 0.5349679589271545\n",
            "898/898 [==============================] - 23s 26ms/step - loss: 1.1378 - accuracy: 0.5673\n",
            "Test Loss 1.1378016471862793\n",
            "Test Acc: 0.5673133730888367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrQ63iiV6F-W",
        "outputId": "1536bbca-419e-47ba-e72b-d57f8bc6fcd3"
      },
      "source": [
        "testlosz = model_load.evaluate(xtrain, ytrain) \n",
        "print(\"Test Loss \" + str(testlosz[0]))\n",
        "print(\"Test Acc: \" + str(testlosz[1]))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "898/898 [==============================] - 23s 26ms/step - loss: 1.3753 - accuracy: 0.4682\n",
            "Test Loss 1.3752880096435547\n",
            "Test Acc: 0.46818071603775024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDwmru9p0gyj",
        "outputId": "268e437e-9dd1-466c-8a93-b1187fb2e855"
      },
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "y_pred1 = model_load.predict(xtest)\n",
        "y_pred = np.argmax(y_pred1, axis=1)\n",
        "\n",
        "# Print f1, precision, and recall scores s\n",
        "print(precision_score(ytest, y_pred , average=\"macro\"))\n",
        "print(recall_score(ytest, y_pred , average=\"macro\"))\n",
        "print(f1_score(ytest, y_pred , average=\"macro\"))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4942733665224318\n",
            "0.4665306634077046\n",
            "0.4517686224169304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9L61nPWxpn1",
        "outputId": "c658c3a1-5b45-44a6-a382-1c3ab7a1567e"
      },
      "source": [
        "!pip install mlxtend\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (3.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from mlxtend) (57.0.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.1.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.10.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->mlxtend) (1.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.1->mlxtend) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=1.5.1->mlxtend) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COc9HoDyhWQ2"
      },
      "source": [
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "ypred = model_load.predict(xtest)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "or0mwBSoaa6U",
        "outputId": "e2fa8e6d-730a-43d1-ada8-9010d956ea3b"
      },
      "source": [
        "mat = confusion_matrix(ytest,ypred)\n",
        "plot_confusion_matrix(conf_mat = mat)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-dc1d28471ea1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mypred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 90\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICOVlE12cOpZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}