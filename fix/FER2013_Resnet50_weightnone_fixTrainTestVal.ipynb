{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER2013_Resnet50_weightnone_scratch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "18Zj-Yp1YlH0QWcuD4e7ugx8zCCcRS0jg",
      "authorship_tag": "ABX9TyO/tzz8apVFipiu24dseVuv"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eWeoD7MRFlN",
        "outputId": "0e2d5d4c-8f6c-4a8a-a287-b9e9ec1da464"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "inputFolder = '/content/drive/MyDrive/Fer2013_backup/' \n",
        "for root, directories, filenames in os.walk(inputFolder): \n",
        "    for filename in filenames: print(os.path.join(root,filename))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Fer2013_backup/backUpfer2013.csv\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/best_model_resnet50_modelB2_170false.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/best_model_resnet50_modelD2_170false.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50Scracth_tipe7.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50Scracth_tipe8.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50Scracth_tipe9.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50oriAUGScracthSGD2.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50oriAUGScracthSGD3.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/Best_Model_resnet50AUGScracthadam2.h5\n",
            "/content/drive/MyDrive/Fer2013_backup/checkpoint/fixcheckpoint/Best_Model_resnet50oriAUGScracthSGD2.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH8iEUJiRQS7",
        "outputId": "b8dc5ae5-25e2-48a2-d113-6f008b17d0e9"
      },
      "source": [
        "%cd /content/drive/MyDrive/Fer2013_backup/\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Fer2013_backup\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqZOFwxxRQaa",
        "outputId": "d646c3e3-740a-4fe6-a3b2-ebae64fd96a3"
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:400: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUX-dSAgRQh4"
      },
      "source": [
        "#Define the identity block helper function.\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "   \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbdQH3mkRQra"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path \n",
        "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b',padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33XH76oKRQvh"
      },
      "source": [
        "def ResNet50(input_shape = (48,48,1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    #X = ZeroPadding2D((1, 1))(X_input)\n",
        "    X = X_input\n",
        "    # Stage 1\n",
        "\n",
        "    X = Conv2D(8, (3, 3), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # removed maxpool\n",
        "    #X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='c')\n",
        "\n",
        "\n",
        "    # Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [64,64,256], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL . \n",
        "    X = AveragePooling2D((2,2), name='avg_pool')(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(512, activation = 'relu', name='fc1024' , kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWuYK_f2zGJF"
      },
      "source": [
        "\"\"\"def ResNet50ori(input_shape = (48, 48, 1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50ori')\n",
        "\n",
        "    return model\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QQOxN2cRQy3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6f581ee6-a766-43d9-95d8-18490fdd5ed5"
      },
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        " \n",
        "dataset_path = '/content/drive/MyDrive/Fer2013_backup/backUpfer2013.csv'\n",
        "image_size=(48,48)\n",
        "\n",
        "def load_fer2013():\n",
        "    data = pd.read_csv(dataset_path)\n",
        "    data = (data[data['pixels'].notnull()])\n",
        "    pixels = data['pixels'].tolist()\n",
        "    width, height = 48, 48\n",
        "    faces = []\n",
        "    for pixel_sequence in pixels:\n",
        "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "        face = np.asarray(face).reshape(width, height)\n",
        "        face = cv2.resize(face.astype('uint8'),image_size)\n",
        "        faces.append(face.astype('float32'))\n",
        "    faces = np.asarray(faces)\n",
        "    faces = np.expand_dims(faces, -1)\n",
        "    emotions = (data['emotion'])#.values\n",
        "    return faces, emotions\n",
        " \n",
        "def preprocess_input(x, v2=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if v2:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x\n",
        " \n",
        "faces, emotions = load_fer2013()\n",
        "faces = preprocess_input(faces)\n",
        "#xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
        "#Data Augumentationfgf\n",
        "data_generator = ImageDataGenerator(\n",
        "                        rotation_range=10,\n",
        "                        shear_range = 10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        vertical_flip=True,\n",
        "                        horizontal_flip=True)\n",
        "\"\"\"data_generator = ImageDataGenerator ()\"\"\""
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'data_generator = ImageDataGenerator ()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zCkwVdnKTm5",
        "outputId": "bacb1d47-7186-46b9-bb01-febf82016d1b"
      },
      "source": [
        "train_ratio = 0.80\n",
        "validation_ratio = 0.10\n",
        "test_ratio = 0.10\n",
        "\n",
        "# train is now 75% of the entire data set\n",
        "# the _junk suffix means that we drop that variable completely # the _junk suffix means that we drop that variable completely\n",
        "#x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=1 - train_ratio)\n",
        "\n",
        "# test is now 10% of the initial data set\n",
        "# validation is now 15% of the initial data set\n",
        "#x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "x_val, xtest, y_val, ytest = train_test_split(xtest, ytest, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "\n",
        "print(xtrain, x_val, xtest)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[ 0.3411765 ]\n",
            "   [ 0.27843142]\n",
            "   [ 0.38823533]\n",
            "   ...\n",
            "   [ 0.36470592]\n",
            "   [ 0.35686278]\n",
            "   [ 0.35686278]]\n",
            "\n",
            "  [[ 0.3411765 ]\n",
            "   [ 0.28627455]\n",
            "   [ 0.38823533]\n",
            "   ...\n",
            "   [ 0.30980396]\n",
            "   [ 0.37254906]\n",
            "   [ 0.36470592]]\n",
            "\n",
            "  [[ 0.34901965]\n",
            "   [ 0.2941177 ]\n",
            "   [ 0.37254906]\n",
            "   ...\n",
            "   [ 0.15294123]\n",
            "   [ 0.34901965]\n",
            "   [ 0.38823533]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.10588235]\n",
            "   [-0.41176468]\n",
            "   [-0.73333335]\n",
            "   ...\n",
            "   [-0.46666664]\n",
            "   [-0.64705884]\n",
            "   [-0.6156863 ]]\n",
            "\n",
            "  [[-0.15294117]\n",
            "   [-0.49019605]\n",
            "   [-0.6784314 ]\n",
            "   ...\n",
            "   [-0.58431375]\n",
            "   [-0.7254902 ]\n",
            "   [-0.58431375]]\n",
            "\n",
            "  [[-0.26274508]\n",
            "   [-0.47450978]\n",
            "   [-0.70980394]\n",
            "   ...\n",
            "   [-0.54509807]\n",
            "   [-0.73333335]\n",
            "   [-0.64705884]]]\n",
            "\n",
            "\n",
            " [[[-0.5764706 ]\n",
            "   [-0.17647058]\n",
            "   [-0.27843136]\n",
            "   ...\n",
            "   [-0.3490196 ]\n",
            "   [-0.372549  ]\n",
            "   [-0.38039213]]\n",
            "\n",
            "  [[-0.4823529 ]\n",
            "   [-0.12941176]\n",
            "   [-0.3490196 ]\n",
            "   ...\n",
            "   [-0.3490196 ]\n",
            "   [-0.36470586]\n",
            "   [-0.36470586]]\n",
            "\n",
            "  [[-0.29411763]\n",
            "   [-0.1372549 ]\n",
            "   [-0.41960782]\n",
            "   ...\n",
            "   [-0.36470586]\n",
            "   [-0.36470586]\n",
            "   [-0.36470586]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.1372549 ]\n",
            "   [-0.08235294]\n",
            "   [-0.05882353]\n",
            "   ...\n",
            "   [-0.26274508]\n",
            "   [-0.26274508]\n",
            "   [-0.27058822]]\n",
            "\n",
            "  [[-0.21568626]\n",
            "   [-0.1607843 ]\n",
            "   [-0.09019607]\n",
            "   ...\n",
            "   [-0.27058822]\n",
            "   [-0.27058822]\n",
            "   [-0.26274508]]\n",
            "\n",
            "  [[-0.23137254]\n",
            "   [-0.21568626]\n",
            "   [-0.15294117]\n",
            "   ...\n",
            "   [-0.25490195]\n",
            "   [-0.27058822]\n",
            "   [-0.27843136]]]\n",
            "\n",
            "\n",
            " [[[ 0.96862745]\n",
            "   [ 1.        ]\n",
            "   [ 0.5372549 ]\n",
            "   ...\n",
            "   [-0.7176471 ]\n",
            "   [-0.6       ]\n",
            "   [-0.654902  ]]\n",
            "\n",
            "  [[ 0.9529412 ]\n",
            "   [ 1.        ]\n",
            "   [ 0.15294123]\n",
            "   ...\n",
            "   [-0.7176471 ]\n",
            "   [-0.56078434]\n",
            "   [-0.5921569 ]]\n",
            "\n",
            "  [[ 0.9529412 ]\n",
            "   [ 1.        ]\n",
            "   [-0.14509803]\n",
            "   ...\n",
            "   [-0.7176471 ]\n",
            "   [-0.654902  ]\n",
            "   [-0.5058824 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.5294118 ]\n",
            "   [-0.23921567]\n",
            "   [ 0.56078434]\n",
            "   ...\n",
            "   [-0.5294118 ]\n",
            "   [-0.6392157 ]\n",
            "   [-0.77254903]]\n",
            "\n",
            "  [[-0.5372549 ]\n",
            "   [-0.02745098]\n",
            "   [ 0.75686276]\n",
            "   ...\n",
            "   [-0.54509807]\n",
            "   [-0.64705884]\n",
            "   [-0.7490196 ]]\n",
            "\n",
            "  [[-0.30196077]\n",
            "   [ 0.16078436]\n",
            "   [ 0.81960785]\n",
            "   ...\n",
            "   [-0.5921569 ]\n",
            "   [-0.6392157 ]\n",
            "   [-0.7647059 ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 0.84313726]\n",
            "   [ 0.7647059 ]\n",
            "   [ 0.6313726 ]\n",
            "   ...\n",
            "   [ 0.5764706 ]\n",
            "   [ 0.8509804 ]\n",
            "   [ 0.9372549 ]]\n",
            "\n",
            "  [[ 0.827451  ]\n",
            "   [ 0.6156863 ]\n",
            "   [ 0.1686275 ]\n",
            "   ...\n",
            "   [ 0.05098045]\n",
            "   [ 0.64705884]\n",
            "   [ 0.88235295]]\n",
            "\n",
            "  [[ 0.7490196 ]\n",
            "   [ 0.20000005]\n",
            "   [-0.31764704]\n",
            "   ...\n",
            "   [-0.36470586]\n",
            "   [ 0.11372554]\n",
            "   [ 0.70980394]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.05882353]\n",
            "   [-0.38039213]\n",
            "   [-0.38039213]\n",
            "   ...\n",
            "   [-0.6313726 ]\n",
            "   [-0.77254903]\n",
            "   [-0.6313726 ]]\n",
            "\n",
            "  [[ 0.30196083]\n",
            "   [-0.02745098]\n",
            "   [-0.3960784 ]\n",
            "   ...\n",
            "   [-0.7254902 ]\n",
            "   [-0.78039217]\n",
            "   [-0.42745095]]\n",
            "\n",
            "  [[ 0.45098042]\n",
            "   [ 0.254902  ]\n",
            "   [-0.23921567]\n",
            "   ...\n",
            "   [-0.75686276]\n",
            "   [-0.6784314 ]\n",
            "   [-0.12156862]]]\n",
            "\n",
            "\n",
            " [[[-0.2862745 ]\n",
            "   [-0.27058822]\n",
            "   [-0.29411763]\n",
            "   ...\n",
            "   [-0.30196077]\n",
            "   [-0.29411763]\n",
            "   [-0.26274508]]\n",
            "\n",
            "  [[-0.27058822]\n",
            "   [-0.27058822]\n",
            "   [-0.29411763]\n",
            "   ...\n",
            "   [-0.3098039 ]\n",
            "   [-0.32549018]\n",
            "   [-0.31764704]]\n",
            "\n",
            "  [[-0.2235294 ]\n",
            "   [-0.25490195]\n",
            "   [-0.30196077]\n",
            "   ...\n",
            "   [-0.27843136]\n",
            "   [-0.27058822]\n",
            "   [-0.2862745 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.77254903]\n",
            "   [-0.92941177]\n",
            "   [-0.94509804]\n",
            "   ...\n",
            "   [-0.90588236]\n",
            "   [-0.92941177]\n",
            "   [-0.9843137 ]]\n",
            "\n",
            "  [[-0.5921569 ]\n",
            "   [-0.84313726]\n",
            "   [-0.9529412 ]\n",
            "   ...\n",
            "   [-0.9607843 ]\n",
            "   [-0.9529412 ]\n",
            "   [-0.9764706 ]]\n",
            "\n",
            "  [[-0.47450978]\n",
            "   [-0.6862745 ]\n",
            "   [-0.9843137 ]\n",
            "   ...\n",
            "   [-0.9764706 ]\n",
            "   [-0.9764706 ]\n",
            "   [-0.9764706 ]]]\n",
            "\n",
            "\n",
            " [[[-0.8352941 ]\n",
            "   [-0.96862745]\n",
            "   [-0.9607843 ]\n",
            "   ...\n",
            "   [-0.9607843 ]\n",
            "   [-0.96862745]\n",
            "   [-0.96862745]]\n",
            "\n",
            "  [[-0.92941177]\n",
            "   [-0.96862745]\n",
            "   [-0.9372549 ]\n",
            "   ...\n",
            "   [-0.9372549 ]\n",
            "   [-0.9607843 ]\n",
            "   [-0.9764706 ]]\n",
            "\n",
            "  [[-0.94509804]\n",
            "   [-0.9607843 ]\n",
            "   [-0.8980392 ]\n",
            "   ...\n",
            "   [-0.88235295]\n",
            "   [-0.9529412 ]\n",
            "   [-0.96862745]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.27058822]\n",
            "   [-0.6       ]\n",
            "   [-0.6862745 ]\n",
            "   ...\n",
            "   [-0.56078434]\n",
            "   [-0.52156866]\n",
            "   [-0.60784316]]\n",
            "\n",
            "  [[-0.30196077]\n",
            "   [-0.5372549 ]\n",
            "   [-0.29411763]\n",
            "   ...\n",
            "   [-0.5764706 ]\n",
            "   [-0.5372549 ]\n",
            "   [-0.5921569 ]]\n",
            "\n",
            "  [[-0.05098039]\n",
            "   [ 0.05098045]\n",
            "   [ 0.24705887]\n",
            "   ...\n",
            "   [-0.40392154]\n",
            "   [-0.4980392 ]\n",
            "   [-0.6       ]]]] [[[[-0.38039213]\n",
            "   [-0.24705881]\n",
            "   [-0.32549018]\n",
            "   ...\n",
            "   [-0.18431371]\n",
            "   [-0.17647058]\n",
            "   [-0.23137254]]\n",
            "\n",
            "  [[-0.34117645]\n",
            "   [-0.24705881]\n",
            "   [-0.3960784 ]\n",
            "   ...\n",
            "   [-0.17647058]\n",
            "   [-0.1607843 ]\n",
            "   [-0.19999999]]\n",
            "\n",
            "  [[-0.30196077]\n",
            "   [-0.35686272]\n",
            "   [-0.5058824 ]\n",
            "   ...\n",
            "   [-0.19999999]\n",
            "   [-0.19215685]\n",
            "   [-0.20784312]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.6784314 ]\n",
            "   [-0.7254902 ]\n",
            "   [-0.7411765 ]\n",
            "   ...\n",
            "   [-0.5058824 ]\n",
            "   [-0.6156863 ]\n",
            "   [-0.67058825]]\n",
            "\n",
            "  [[-0.6313726 ]\n",
            "   [-0.67058825]\n",
            "   [-0.73333335]\n",
            "   ...\n",
            "   [-0.54509807]\n",
            "   [-0.6392157 ]\n",
            "   [-0.69411767]]\n",
            "\n",
            "  [[-0.6       ]\n",
            "   [-0.60784316]\n",
            "   [-0.7019608 ]\n",
            "   ...\n",
            "   [-0.5921569 ]\n",
            "   [-0.67058825]\n",
            "   [-0.70980394]]]\n",
            "\n",
            "\n",
            " [[[-0.38039213]\n",
            "   [-0.34117645]\n",
            "   [-0.31764704]\n",
            "   ...\n",
            "   [ 0.18431377]\n",
            "   [ 0.36470592]\n",
            "   [ 0.3411765 ]]\n",
            "\n",
            "  [[-0.49019605]\n",
            "   [-0.40392154]\n",
            "   [-0.31764704]\n",
            "   ...\n",
            "   [-0.03529412]\n",
            "   [ 0.32549024]\n",
            "   [ 0.37254906]]\n",
            "\n",
            "  [[-0.6313726 ]\n",
            "   [-0.5372549 ]\n",
            "   [-0.40392154]\n",
            "   ...\n",
            "   [-0.06666666]\n",
            "   [ 0.24705887]\n",
            "   [ 0.30196083]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.41176468]\n",
            "   [-0.32549018]\n",
            "   [-0.29411763]\n",
            "   ...\n",
            "   [ 0.45098042]\n",
            "   [ 0.45098042]\n",
            "   [ 0.4431373 ]]\n",
            "\n",
            "  [[-0.4352941 ]\n",
            "   [-0.31764704]\n",
            "   [-0.27843136]\n",
            "   ...\n",
            "   [ 0.45098042]\n",
            "   [ 0.45882356]\n",
            "   [ 0.45098042]]\n",
            "\n",
            "  [[-0.4588235 ]\n",
            "   [-0.3490196 ]\n",
            "   [-0.23137254]\n",
            "   ...\n",
            "   [ 0.45098042]\n",
            "   [ 0.45098042]\n",
            "   [ 0.45098042]]]\n",
            "\n",
            "\n",
            " [[[ 0.03529418]\n",
            "   [ 0.04313731]\n",
            "   [ 0.05098045]\n",
            "   ...\n",
            "   [ 0.3176471 ]\n",
            "   [ 0.32549024]\n",
            "   [ 0.3176471 ]]\n",
            "\n",
            "  [[ 0.04313731]\n",
            "   [ 0.05098045]\n",
            "   [ 0.05882359]\n",
            "   ...\n",
            "   [ 0.32549024]\n",
            "   [ 0.3411765 ]\n",
            "   [ 0.33333337]]\n",
            "\n",
            "  [[ 0.06666672]\n",
            "   [ 0.07450986]\n",
            "   [ 0.07450986]\n",
            "   ...\n",
            "   [ 0.3411765 ]\n",
            "   [ 0.34901965]\n",
            "   [ 0.3411765 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.6862745 ]\n",
            "   [-0.7882353 ]\n",
            "   [-0.79607844]\n",
            "   ...\n",
            "   [ 0.0196079 ]\n",
            "   [-0.08235294]\n",
            "   [-0.12156862]]\n",
            "\n",
            "  [[-0.70980394]\n",
            "   [-0.8117647 ]\n",
            "   [-0.8117647 ]\n",
            "   ...\n",
            "   [-0.19999999]\n",
            "   [-0.11372548]\n",
            "   [-0.29411763]]\n",
            "\n",
            "  [[-0.7254902 ]\n",
            "   [-0.827451  ]\n",
            "   [-0.81960785]\n",
            "   ...\n",
            "   [-0.15294117]\n",
            "   [-0.00392157]\n",
            "   [-0.26274508]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.75686276]\n",
            "   [-0.8745098 ]\n",
            "   [-0.8039216 ]\n",
            "   ...\n",
            "   [-0.78039217]\n",
            "   [-0.90588236]\n",
            "   [-0.8509804 ]]\n",
            "\n",
            "  [[-0.75686276]\n",
            "   [-0.7019608 ]\n",
            "   [-0.47450978]\n",
            "   ...\n",
            "   [-0.7411765 ]\n",
            "   [-0.7882353 ]\n",
            "   [-0.90588236]]\n",
            "\n",
            "  [[-0.54509807]\n",
            "   [-0.40392154]\n",
            "   [-0.23137254]\n",
            "   ...\n",
            "   [-0.77254903]\n",
            "   [-0.69411767]\n",
            "   [-0.75686276]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.6627451 ]\n",
            "   [-0.67058825]\n",
            "   [-0.6784314 ]\n",
            "   ...\n",
            "   [-0.27058822]\n",
            "   [-0.79607844]\n",
            "   [-0.78039217]]\n",
            "\n",
            "  [[-0.6784314 ]\n",
            "   [-0.6784314 ]\n",
            "   [-0.6862745 ]\n",
            "   ...\n",
            "   [-0.4980392 ]\n",
            "   [-0.8745098 ]\n",
            "   [-0.75686276]]\n",
            "\n",
            "  [[-0.6862745 ]\n",
            "   [-0.69411767]\n",
            "   [-0.70980394]\n",
            "   ...\n",
            "   [-0.7490196 ]\n",
            "   [-0.8352941 ]\n",
            "   [-0.75686276]]]\n",
            "\n",
            "\n",
            " [[[ 0.26274514]\n",
            "   [ 0.26274514]\n",
            "   [ 0.24705887]\n",
            "   ...\n",
            "   [ 0.18431377]\n",
            "   [ 0.17647064]\n",
            "   [ 0.1686275 ]]\n",
            "\n",
            "  [[ 0.27843142]\n",
            "   [ 0.27058828]\n",
            "   [ 0.254902  ]\n",
            "   ...\n",
            "   [ 0.18431377]\n",
            "   [ 0.18431377]\n",
            "   [ 0.1686275 ]]\n",
            "\n",
            "  [[ 0.28627455]\n",
            "   [ 0.27843142]\n",
            "   [ 0.27058828]\n",
            "   ...\n",
            "   [ 0.19215691]\n",
            "   [ 0.18431377]\n",
            "   [ 0.17647064]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.05098039]\n",
            "   [-0.18431371]\n",
            "   [-0.19999999]\n",
            "   ...\n",
            "   [-0.27058822]\n",
            "   [-0.1607843 ]\n",
            "   [-0.00392157]]\n",
            "\n",
            "  [[-0.16862744]\n",
            "   [-0.08235294]\n",
            "   [ 0.13725495]\n",
            "   ...\n",
            "   [-0.23921567]\n",
            "   [-0.27058822]\n",
            "   [-0.27058822]]\n",
            "\n",
            "  [[-0.00392157]\n",
            "   [ 0.20784318]\n",
            "   [ 0.30980396]\n",
            "   ...\n",
            "   [-0.23137254]\n",
            "   [-0.2235294 ]\n",
            "   [-0.23137254]]]\n",
            "\n",
            "\n",
            " [[[ 0.3176471 ]\n",
            "   [ 0.3411765 ]\n",
            "   [ 0.41176474]\n",
            "   ...\n",
            "   [ 0.09803927]\n",
            "   [ 0.11372554]\n",
            "   [ 0.11372554]]\n",
            "\n",
            "  [[ 0.3411765 ]\n",
            "   [ 0.36470592]\n",
            "   [ 0.4039216 ]\n",
            "   ...\n",
            "   [ 0.05098045]\n",
            "   [ 0.14509809]\n",
            "   [ 0.09019613]]\n",
            "\n",
            "  [[ 0.36470592]\n",
            "   [ 0.4039216 ]\n",
            "   [ 0.34901965]\n",
            "   ...\n",
            "   [-0.05098039]\n",
            "   [ 0.16078436]\n",
            "   [ 0.09019613]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.45098042]\n",
            "   [ 0.45098042]\n",
            "   [ 0.43529415]\n",
            "   ...\n",
            "   [ 0.082353  ]\n",
            "   [-0.00392157]\n",
            "   [-0.02745098]]\n",
            "\n",
            "  [[ 0.4431373 ]\n",
            "   [ 0.43529415]\n",
            "   [ 0.43529415]\n",
            "   ...\n",
            "   [ 0.06666672]\n",
            "   [-0.03529412]\n",
            "   [-0.09803921]]\n",
            "\n",
            "  [[ 0.43529415]\n",
            "   [ 0.427451  ]\n",
            "   [ 0.427451  ]\n",
            "   ...\n",
            "   [ 0.04313731]\n",
            "   [-0.14509803]\n",
            "   [-0.05098039]]]] [[[[-0.69411767]\n",
            "   [-0.654902  ]\n",
            "   [-0.62352943]\n",
            "   ...\n",
            "   [-0.56078434]\n",
            "   [-0.6156863 ]\n",
            "   [-0.58431375]]\n",
            "\n",
            "  [[-0.73333335]\n",
            "   [-0.6156863 ]\n",
            "   [-0.5372549 ]\n",
            "   ...\n",
            "   [-0.6       ]\n",
            "   [-0.6       ]\n",
            "   [-0.5764706 ]]\n",
            "\n",
            "  [[-0.69411767]\n",
            "   [-0.62352943]\n",
            "   [-0.4823529 ]\n",
            "   ...\n",
            "   [-0.2862745 ]\n",
            "   [-0.54509807]\n",
            "   [-0.4823529 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.31764704]\n",
            "   [-0.19215685]\n",
            "   [-0.19215685]\n",
            "   ...\n",
            "   [ 0.20784318]\n",
            "   [ 0.27058828]\n",
            "   [ 0.33333337]]\n",
            "\n",
            "  [[-0.34117645]\n",
            "   [-0.27843136]\n",
            "   [-0.29411763]\n",
            "   ...\n",
            "   [ 0.20784318]\n",
            "   [ 0.28627455]\n",
            "   [ 0.34901965]]\n",
            "\n",
            "  [[-0.38823527]\n",
            "   [-0.38823527]\n",
            "   [-0.40392154]\n",
            "   ...\n",
            "   [ 0.21568632]\n",
            "   [ 0.254902  ]\n",
            "   [ 0.36470592]]]\n",
            "\n",
            "\n",
            " [[[ 0.15294123]\n",
            "   [ 0.16078436]\n",
            "   [ 0.14509809]\n",
            "   ...\n",
            "   [ 0.33333337]\n",
            "   [ 0.32549024]\n",
            "   [ 0.39607847]]\n",
            "\n",
            "  [[ 0.04313731]\n",
            "   [ 0.04313731]\n",
            "   [ 0.0196079 ]\n",
            "   ...\n",
            "   [ 0.3176471 ]\n",
            "   [ 0.34901965]\n",
            "   [ 0.35686278]]\n",
            "\n",
            "  [[ 0.0196079 ]\n",
            "   [-0.04313725]\n",
            "   [-0.2235294 ]\n",
            "   ...\n",
            "   [ 0.3411765 ]\n",
            "   [ 0.2941177 ]\n",
            "   [ 0.3411765 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.0196079 ]\n",
            "   [ 0.05098045]\n",
            "   [ 0.06666672]\n",
            "   ...\n",
            "   [ 0.07450986]\n",
            "   [ 0.05882359]\n",
            "   [ 0.10588241]]\n",
            "\n",
            "  [[-0.01176471]\n",
            "   [ 0.00392163]\n",
            "   [ 0.05098045]\n",
            "   ...\n",
            "   [ 0.06666672]\n",
            "   [ 0.01176476]\n",
            "   [ 0.02745104]]\n",
            "\n",
            "  [[-0.03529412]\n",
            "   [-0.02745098]\n",
            "   [ 0.09803927]\n",
            "   ...\n",
            "   [ 0.05098045]\n",
            "   [ 0.0196079 ]\n",
            "   [ 0.01176476]]]\n",
            "\n",
            "\n",
            " [[[-0.8039216 ]\n",
            "   [-0.8039216 ]\n",
            "   [-0.8117647 ]\n",
            "   ...\n",
            "   [-0.18431371]\n",
            "   [-0.15294117]\n",
            "   [ 0.20000005]]\n",
            "\n",
            "  [[-0.8039216 ]\n",
            "   [-0.8039216 ]\n",
            "   [-0.8039216 ]\n",
            "   ...\n",
            "   [-0.15294117]\n",
            "   [-0.23137254]\n",
            "   [ 0.0196079 ]]\n",
            "\n",
            "  [[-0.8039216 ]\n",
            "   [-0.8039216 ]\n",
            "   [-0.8039216 ]\n",
            "   ...\n",
            "   [-0.08235294]\n",
            "   [-0.15294117]\n",
            "   [-0.0745098 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.8039216 ]\n",
            "   [-0.79607844]\n",
            "   [-0.8039216 ]\n",
            "   ...\n",
            "   [-0.5137255 ]\n",
            "   [-0.4980392 ]\n",
            "   [-0.46666664]]\n",
            "\n",
            "  [[-0.8039216 ]\n",
            "   [-0.79607844]\n",
            "   [-0.79607844]\n",
            "   ...\n",
            "   [-0.52156866]\n",
            "   [-0.47450978]\n",
            "   [-0.47450978]]\n",
            "\n",
            "  [[-0.8039216 ]\n",
            "   [-0.8039216 ]\n",
            "   [-0.8039216 ]\n",
            "   ...\n",
            "   [-0.52156866]\n",
            "   [-0.5058824 ]\n",
            "   [-0.54509807]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.38823527]\n",
            "   [-0.372549  ]\n",
            "   [-0.3333333 ]\n",
            "   ...\n",
            "   [-0.56078434]\n",
            "   [-0.41960782]\n",
            "   [ 0.45882356]]\n",
            "\n",
            "  [[-0.40392154]\n",
            "   [-0.3960784 ]\n",
            "   [-0.32549018]\n",
            "   ...\n",
            "   [-0.5137255 ]\n",
            "   [-0.49019605]\n",
            "   [ 0.2313726 ]]\n",
            "\n",
            "  [[-0.4823529 ]\n",
            "   [-0.42745095]\n",
            "   [-0.31764704]\n",
            "   ...\n",
            "   [-0.4352941 ]\n",
            "   [-0.5058824 ]\n",
            "   [-0.09803921]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.12941176]\n",
            "   [-0.52156866]\n",
            "   [-0.12941176]\n",
            "   ...\n",
            "   [ 0.254902  ]\n",
            "   [ 0.28627455]\n",
            "   [ 0.5529412 ]]\n",
            "\n",
            "  [[-0.3490196 ]\n",
            "   [-0.44313723]\n",
            "   [ 0.04313731]\n",
            "   ...\n",
            "   [ 0.22352946]\n",
            "   [ 0.45882356]\n",
            "   [ 0.6       ]]\n",
            "\n",
            "  [[ 0.15294123]\n",
            "   [-0.25490195]\n",
            "   [ 0.10588241]\n",
            "   ...\n",
            "   [ 0.27058828]\n",
            "   [ 0.5372549 ]\n",
            "   [ 0.6       ]]]\n",
            "\n",
            "\n",
            " [[[ 0.3411765 ]\n",
            "   [ 0.3176471 ]\n",
            "   [ 0.41960788]\n",
            "   ...\n",
            "   [-0.4352941 ]\n",
            "   [-0.46666664]\n",
            "   [-0.5137255 ]]\n",
            "\n",
            "  [[ 0.21568632]\n",
            "   [ 0.34901965]\n",
            "   [ 0.4901961 ]\n",
            "   ...\n",
            "   [-0.4352941 ]\n",
            "   [-0.47450978]\n",
            "   [-0.5058824 ]]\n",
            "\n",
            "  [[ 0.3411765 ]\n",
            "   [ 0.5529412 ]\n",
            "   [ 0.47450984]\n",
            "   ...\n",
            "   [-0.41176468]\n",
            "   [-0.4588235 ]\n",
            "   [-0.4980392 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.04313725]\n",
            "   [ 0.22352946]\n",
            "   [ 0.45882356]\n",
            "   ...\n",
            "   [-0.4823529 ]\n",
            "   [-0.44313723]\n",
            "   [-0.5058824 ]]\n",
            "\n",
            "  [[-0.02745098]\n",
            "   [ 0.05098045]\n",
            "   [ 0.41176474]\n",
            "   ...\n",
            "   [-0.5058824 ]\n",
            "   [-0.5372549 ]\n",
            "   [-0.5764706 ]]\n",
            "\n",
            "  [[ 0.07450986]\n",
            "   [ 0.19215691]\n",
            "   [ 0.3411765 ]\n",
            "   ...\n",
            "   [-0.4588235 ]\n",
            "   [-0.5921569 ]\n",
            "   [-0.62352943]]]\n",
            "\n",
            "\n",
            " [[[-0.2235294 ]\n",
            "   [-0.26274508]\n",
            "   [-0.32549018]\n",
            "   ...\n",
            "   [-0.24705881]\n",
            "   [-0.30196077]\n",
            "   [-0.31764704]]\n",
            "\n",
            "  [[-0.21568626]\n",
            "   [-0.24705881]\n",
            "   [-0.29411763]\n",
            "   ...\n",
            "   [-0.2862745 ]\n",
            "   [-0.2235294 ]\n",
            "   [-0.372549  ]]\n",
            "\n",
            "  [[-0.19215685]\n",
            "   [-0.2235294 ]\n",
            "   [-0.27843136]\n",
            "   ...\n",
            "   [-0.27058822]\n",
            "   [-0.3490196 ]\n",
            "   [-0.40392154]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.01960784]\n",
            "   [-0.06666666]\n",
            "   [-0.12156862]\n",
            "   ...\n",
            "   [-0.11372548]\n",
            "   [-0.24705881]\n",
            "   [-0.19999999]]\n",
            "\n",
            "  [[-0.09019607]\n",
            "   [-0.11372548]\n",
            "   [-0.15294117]\n",
            "   ...\n",
            "   [-0.32549018]\n",
            "   [-0.34117645]\n",
            "   [-0.19999999]]\n",
            "\n",
            "  [[-0.14509803]\n",
            "   [-0.16862744]\n",
            "   [-0.1372549 ]\n",
            "   ...\n",
            "   [-0.5137255 ]\n",
            "   [-0.35686272]\n",
            "   [-0.19999999]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t--o7TREKTu2",
        "outputId": "b297023c-5692-4516-9eae-5284b1a49efc"
      },
      "source": [
        "print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validasi (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "test (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "train (28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ofOj3-fRREN"
      },
      "source": [
        "#hyperparameter and callback\n",
        "batch_size = 64\n",
        "num_epochs = 60\n",
        "input_shape = (48, 48, 1)\n",
        "num_classes = 7\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXikieAnRbYs"
      },
      "source": [
        "#Compile the model.\n",
        "\n",
        "\n",
        "from keras.optimizers import Adam, SGD\n",
        "model = ResNet50(input_shape = (48, 48, 1), classes = 7)\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "model.compile(optimizer= optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5JTFulCRbiX"
      },
      "source": [
        "\"\"\"#kita mau save model callbacks\n",
        "import os\n",
        "try:\n",
        "  os.mkdir('/content/drive/MyDrive/Fer2013_backup/scratchcheckpoint')\n",
        "except:\n",
        "  pass\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkceBySwRgFO"
      },
      "source": [
        "\"\"\"file_name = 'Best_Model_resnet50oriScracth_aug_tipe2.h5'\n",
        "\n",
        "checkpoint_path = os.path.join('checkpoint',file_name)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an3sDjjGRgO1"
      },
      "source": [
        "\"\"\"call_back = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
        "                                               monitor='val_accuracy',\n",
        "                                               verbose=1,\n",
        "                                               save_freq='epoch',\n",
        "                                               save_best_only=True,\n",
        "                                               save_weights_only=False,\n",
        "                                               mode='max')\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nefC0ZE8RgX5",
        "outputId": "e82cdfb5-becc-4d1a-d01b-d3af1bfb0321"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 46, 46, 128)  0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 46, 46, 128)  0           activation_52[0][0]              \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 46, 46, 128)  0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 46, 46, 128)  0           activation_55[0][0]              \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 46, 46, 128)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 23, 23, 256)  0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 23, 23, 256)  0           activation_61[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 23, 23, 256)  0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 23, 23, 256)  0           activation_64[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 23, 23, 256)  0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 23, 23, 256)  0           activation_67[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 23, 23, 256)  0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 12, 12, 512)  0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 12, 12, 512)  0           activation_73[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 12, 12, 512)  0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 12, 12, 512)  0           activation_76[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 12, 12, 512)  0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 12, 12, 512)  0           activation_79[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 12, 12, 512)  0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 12, 12, 512)  0           activation_82[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 12, 12, 512)  0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 12, 12, 512)  0           activation_85[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 12, 12, 512)  0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 6, 6, 1024)   0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 6, 6, 1024)   0           activation_91[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 6, 6, 1024)   0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 6, 6, 1024)   0           activation_94[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 6, 6, 1024)   0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVvpTr7-RkdR"
      },
      "source": [
        "\"\"\"history = model.fit(data_generator.flow(xtrain, ytrain,),\n",
        "                        steps_per_epoch=len(xtrain) / batch_size,\n",
        "                        epochs=num_epochs, verbose=1,callbacks=call_back,\n",
        "                        validation_data= (xtest,ytest))\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_tXyjuSz_IP",
        "outputId": "f6f811a3-cf4a-45af-c52d-ad8f0b6abe64"
      },
      "source": [
        "history = model.fit(\n",
        "    data_generator.flow(xtrain, ytrain,),\n",
        "    steps_per_epoch=len(xtrain) / batch_size,\n",
        "    epochs=num_epochs, \n",
        "    verbose=1,\n",
        "    validation_data= (x_val,y_val))\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "448/448 [==============================] - 62s 115ms/step - loss: 17.7915 - accuracy: 0.2209 - val_loss: 1.7739 - val_accuracy: 0.2575\n",
            "Epoch 2/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.7853 - accuracy: 0.2582 - val_loss: 1.7696 - val_accuracy: 0.2619\n",
            "Epoch 3/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.7864 - accuracy: 0.2601 - val_loss: 1.7565 - val_accuracy: 0.2711\n",
            "Epoch 4/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.7765 - accuracy: 0.2674 - val_loss: 1.7862 - val_accuracy: 0.2516\n",
            "Epoch 5/60\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.7801 - accuracy: 0.2606 - val_loss: 1.7481 - val_accuracy: 0.2839\n",
            "Epoch 6/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.7690 - accuracy: 0.2654 - val_loss: 1.7459 - val_accuracy: 0.2845\n",
            "Epoch 7/60\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.7612 - accuracy: 0.2662 - val_loss: 1.7887 - val_accuracy: 0.2817\n",
            "Epoch 8/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.7585 - accuracy: 0.2762 - val_loss: 1.7818 - val_accuracy: 0.2658\n",
            "Epoch 9/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.7623 - accuracy: 0.2810 - val_loss: 1.7452 - val_accuracy: 0.2692\n",
            "Epoch 10/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 1.7753 - accuracy: 0.2646 - val_loss: 1.7661 - val_accuracy: 0.2639\n",
            "Epoch 11/60\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.7905 - accuracy: 0.2556 - val_loss: 2.2911 - val_accuracy: 0.2009\n",
            "Epoch 12/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.7602 - accuracy: 0.2758 - val_loss: 1.8569 - val_accuracy: 0.2650\n",
            "Epoch 13/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 1.7671 - accuracy: 0.2767 - val_loss: 1.7391 - val_accuracy: 0.2848\n",
            "Epoch 14/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.7639 - accuracy: 0.2739 - val_loss: 1.8455 - val_accuracy: 0.2385\n",
            "Epoch 15/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.7812 - accuracy: 0.2674 - val_loss: 1.7570 - val_accuracy: 0.2728\n",
            "Epoch 16/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 1.7656 - accuracy: 0.2685 - val_loss: 1.7387 - val_accuracy: 0.2884\n",
            "Epoch 17/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.7558 - accuracy: 0.2790 - val_loss: 1.7922 - val_accuracy: 0.2884\n",
            "Epoch 18/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.7421 - accuracy: 0.2917 - val_loss: 2.8658 - val_accuracy: 0.1750\n",
            "Epoch 19/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.7318 - accuracy: 0.2873 - val_loss: 2.1884 - val_accuracy: 0.2377\n",
            "Epoch 20/60\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.7186 - accuracy: 0.2949 - val_loss: 1.7176 - val_accuracy: 0.2995\n",
            "Epoch 21/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.7241 - accuracy: 0.2915 - val_loss: 1.7120 - val_accuracy: 0.2990\n",
            "Epoch 22/60\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.7098 - accuracy: 0.3056 - val_loss: 2.2362 - val_accuracy: 0.2343\n",
            "Epoch 23/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.7039 - accuracy: 0.3032 - val_loss: 1.6533 - val_accuracy: 0.3293\n",
            "Epoch 24/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.7139 - accuracy: 0.2956 - val_loss: 1.7064 - val_accuracy: 0.3043\n",
            "Epoch 25/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.6907 - accuracy: 0.3104 - val_loss: 1.7625 - val_accuracy: 0.2942\n",
            "Epoch 26/60\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.6659 - accuracy: 0.3247 - val_loss: 1.8786 - val_accuracy: 0.2597\n",
            "Epoch 27/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.7041 - accuracy: 0.3164 - val_loss: 2.4633 - val_accuracy: 0.2313\n",
            "Epoch 28/60\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 1.6261 - accuracy: 0.3554 - val_loss: 2.7685 - val_accuracy: 0.2524\n",
            "Epoch 29/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.5996 - accuracy: 0.3690 - val_loss: 1.5866 - val_accuracy: 0.3714\n",
            "Epoch 30/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.5843 - accuracy: 0.3734 - val_loss: 1.9078 - val_accuracy: 0.3215\n",
            "Epoch 31/60\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.5566 - accuracy: 0.3812 - val_loss: 1.7256 - val_accuracy: 0.3419\n",
            "Epoch 32/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.5776 - accuracy: 0.3725 - val_loss: 1.7105 - val_accuracy: 0.3761\n",
            "Epoch 33/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.5469 - accuracy: 0.3946 - val_loss: 1.4756 - val_accuracy: 0.4210\n",
            "Epoch 34/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.5401 - accuracy: 0.3990 - val_loss: 1.4874 - val_accuracy: 0.4218\n",
            "Epoch 35/60\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.5356 - accuracy: 0.4065 - val_loss: 3.2413 - val_accuracy: 0.2898\n",
            "Epoch 36/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.5428 - accuracy: 0.3952 - val_loss: 2.0816 - val_accuracy: 0.3444\n",
            "Epoch 37/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.5349 - accuracy: 0.4013 - val_loss: 2.4780 - val_accuracy: 0.3653\n",
            "Epoch 38/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.5076 - accuracy: 0.4137 - val_loss: 1.7143 - val_accuracy: 0.3703\n",
            "Epoch 39/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.4999 - accuracy: 0.4104 - val_loss: 1.4810 - val_accuracy: 0.4277\n",
            "Epoch 40/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.5027 - accuracy: 0.4130 - val_loss: 1.9240 - val_accuracy: 0.3455\n",
            "Epoch 41/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.4795 - accuracy: 0.4266 - val_loss: 1.6767 - val_accuracy: 0.4096\n",
            "Epoch 42/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.4832 - accuracy: 0.4266 - val_loss: 1.5710 - val_accuracy: 0.4037\n",
            "Epoch 43/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.4695 - accuracy: 0.4356 - val_loss: 1.6101 - val_accuracy: 0.4029\n",
            "Epoch 44/60\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.4662 - accuracy: 0.4317 - val_loss: 1.4560 - val_accuracy: 0.4380\n",
            "Epoch 45/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.4721 - accuracy: 0.4317 - val_loss: 1.5698 - val_accuracy: 0.4288\n",
            "Epoch 46/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.4425 - accuracy: 0.4463 - val_loss: 1.4794 - val_accuracy: 0.4305\n",
            "Epoch 47/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 1.4409 - accuracy: 0.4342 - val_loss: 1.4285 - val_accuracy: 0.4430\n",
            "Epoch 48/60\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.4673 - accuracy: 0.4312 - val_loss: 1.4750 - val_accuracy: 0.4461\n",
            "Epoch 49/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.4342 - accuracy: 0.4438 - val_loss: 1.6585 - val_accuracy: 0.4009\n",
            "Epoch 50/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.4516 - accuracy: 0.4354 - val_loss: 1.4900 - val_accuracy: 0.4152\n",
            "Epoch 51/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.4279 - accuracy: 0.4472 - val_loss: 1.4891 - val_accuracy: 0.4469\n",
            "Epoch 52/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.4183 - accuracy: 0.4510 - val_loss: 1.4886 - val_accuracy: 0.4341\n",
            "Epoch 53/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.4355 - accuracy: 0.4475 - val_loss: 1.5091 - val_accuracy: 0.4177\n",
            "Epoch 54/60\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 1.4121 - accuracy: 0.4538 - val_loss: 1.3675 - val_accuracy: 0.4675\n",
            "Epoch 55/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.4054 - accuracy: 0.4527 - val_loss: 1.4100 - val_accuracy: 0.4413\n",
            "Epoch 56/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.4060 - accuracy: 0.4547 - val_loss: 1.4078 - val_accuracy: 0.4531\n",
            "Epoch 57/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.3756 - accuracy: 0.4680 - val_loss: 1.3705 - val_accuracy: 0.4709\n",
            "Epoch 58/60\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.3877 - accuracy: 0.4648 - val_loss: 1.3625 - val_accuracy: 0.4670\n",
            "Epoch 59/60\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.3767 - accuracy: 0.4700 - val_loss: 1.3905 - val_accuracy: 0.4706\n",
            "Epoch 60/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.3684 - accuracy: 0.4664 - val_loss: 1.3727 - val_accuracy: 0.4556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZvluWhSRkq4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "outputId": "6e67c1e0-1f37-4f23-89fc-5a1f58255f04"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "model.save('/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50AUGScracthAdam1.h5')\n",
        "\n",
        "#gffhgffkjkjdshufdfh\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "num_epochs = range(len(accuracy))\n",
        "plt.plot(num_epochs, accuracy, 'r', label='Training acc')\n",
        "plt.plot(num_epochs, val_accuracy, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(num_epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(num_epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Pzozx-30LSe",
        "outputId": "2645017c-3bea-4bb6-9ad2-aecd116fb624"
      },
      "source": [
        "testloss = model.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "trainloss = model.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(trainloss[0]))\n",
        "print(\"Train Acc: \" + str(trainloss[1]))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 3s 26ms/step - loss: 1.3776 - accuracy: 0.4720\n",
            "Test Loss 1.3775609731674194\n",
            "Test Acc: 0.47199776768684387\n",
            "898/898 [==============================] - 23s 26ms/step - loss: 1.3753 - accuracy: 0.4682\n",
            "Train Loss 1.3752880096435547\n",
            "Train Acc: 0.46818071603775024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ6YCHax59vt",
        "outputId": "646e455a-6d33-48c9-c5a4-7ae970ea3acb"
      },
      "source": [
        "from keras.models import load_model\n",
        "model_load = load_model('/content/drive/MyDrive/Fer2013_backup/checkpoint/Fix_Model_resnet50AUGScracthAdam1.h5')\n",
        "\n",
        "model_load.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 46, 46, 128)  0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 46, 46, 128)  0           activation_52[0][0]              \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 46, 46, 128)  0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 46, 46, 128)  0           activation_55[0][0]              \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 46, 46, 128)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 23, 23, 256)  0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 23, 23, 256)  0           activation_61[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 23, 23, 256)  0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 23, 23, 256)  0           activation_64[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 23, 23, 256)  0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 23, 23, 256)  0           activation_67[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 23, 23, 256)  0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 12, 12, 512)  0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 12, 12, 512)  0           activation_73[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 12, 12, 512)  0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 12, 12, 512)  0           activation_76[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 12, 12, 512)  0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 12, 12, 512)  0           activation_79[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 12, 12, 512)  0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 12, 12, 512)  0           activation_82[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 12, 12, 512)  0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 12, 12, 512)  0           activation_85[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 12, 12, 512)  0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 6, 6, 1024)   0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 6, 6, 1024)   0           activation_91[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 6, 6, 1024)   0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 6, 6, 1024)   0           activation_94[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 6, 6, 1024)   0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fpz7ehkO6Cat",
        "outputId": "2162a9da-aad7-4c60-83f5-1c0dbe0a46b6"
      },
      "source": [
        "\n",
        "testloss = model_load.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "\n",
        "testloss = model_load.evaluate(xtrain, ytrain) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 7s 26ms/step - loss: 1.3776 - accuracy: 0.4720\n",
            "Test Loss 1.3775609731674194\n",
            "Test Acc: 0.47199776768684387\n",
            "898/898 [==============================] - 23s 26ms/step - loss: 1.3753 - accuracy: 0.4682\n",
            "Test Loss 1.3752880096435547\n",
            "Test Acc: 0.46818071603775024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrQ63iiV6F-W",
        "outputId": "1536bbca-419e-47ba-e72b-d57f8bc6fcd3"
      },
      "source": [
        "testlosz = model_load.evaluate(xtrain, ytrain) \n",
        "print(\"Test Loss \" + str(testlosz[0]))\n",
        "print(\"Test Acc: \" + str(testlosz[1]))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "898/898 [==============================] - 23s 26ms/step - loss: 1.3753 - accuracy: 0.4682\n",
            "Test Loss 1.3752880096435547\n",
            "Test Acc: 0.46818071603775024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDwmru9p0gyj",
        "outputId": "a4aacdfb-6964-4111-bf98-0a2412086d18"
      },
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "y_pred1 = model_load.predict(xtest)\n",
        "y_pred = np.argmax(y_pred1, axis=1)\n",
        "\n",
        "# Print f1, precision, and recall scores s\n",
        "print(precision_score(ytest, y_pred , average=\"macro\"))\n",
        "print(recall_score(ytest, y_pred , average=\"macro\"))\n",
        "print(f1_score(ytest, y_pred , average=\"macro\"))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.39403146636744485\n",
            "0.39716089244829306\n",
            "0.392185746266939\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9L61nPWxpn1",
        "outputId": "c658c3a1-5b45-44a6-a382-1c3ab7a1567e"
      },
      "source": [
        "!pip install mlxtend\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (3.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from mlxtend) (57.0.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.1.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.10.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->mlxtend) (1.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.1->mlxtend) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=1.5.1->mlxtend) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COc9HoDyhWQ2"
      },
      "source": [
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "ypred = model_load.predict(xtest)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "or0mwBSoaa6U",
        "outputId": "e2fa8e6d-730a-43d1-ada8-9010d956ea3b"
      },
      "source": [
        "mat = confusion_matrix(ytest,ypred)\n",
        "plot_confusion_matrix(conf_mat = mat)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-dc1d28471ea1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mypred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 90\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICOVlE12cOpZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}