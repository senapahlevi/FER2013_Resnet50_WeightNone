{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER2013_Resnet50_weightnone_fixTrainTestVal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-Qn1jsBTIBl0b7myLQxqa8WjCcfbamqM",
      "authorship_tag": "ABX9TyNdDhoNzsyas/S3yXgiHAgO"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b86nukQOxN7l"
      },
      "source": [
        "Resnet-50 From Scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p8gxtGy0TWP",
        "outputId": "15abfdb9-c475-4a60-e327-93b5607c6c25"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "inputFolder = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth' \n",
        "for root, directories, filenames in os.walk(inputFolder): \n",
        "    for filename in filenames: print(os.path.join(root,filename))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Best_Model_resnet50Scracth1again.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe4.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth1again.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50ScracthSGD1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50AUGScracthadam3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50oriScracth_sena2.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsiscWIMBDX2",
        "outputId": "0769099c-5753-47cd-e59c-02dab2b3290c"
      },
      "source": [
        "%cd /content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "wLMSe510xNCJ",
        "outputId": "3da9f6f5-cb75-4f61-d978-1e7de9a074fc"
      },
      "source": [
        "#Create a directory to save our generated models.dasdas\n",
        "\n",
        "#os.mkdir(\"./modelscracth\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-cf55f19f3613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#os.mkdir(\"./modelscracth\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ls' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_kluusLxM1B",
        "outputId": "a2d22553-ce99-44ea-bd9f-8f405eec674f"
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:400: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfUSF_tAxNMP"
      },
      "source": [
        "#Define the identity block helper function.\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "   \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VdYtzhn1F0I"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path \n",
        "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b',padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd-O8ZMx1GAW"
      },
      "source": [
        "def ResNet50(input_shape = (48,48,1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    #X = ZeroPadding2D((1, 1))(X_input)\n",
        "    X = X_input\n",
        "    # Stage 1\n",
        "\n",
        "    X = Conv2D(8, (3, 3), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # removed maxpool\n",
        "    #X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='c')\n",
        "\n",
        "\n",
        "    # Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [64,64,256], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL . \n",
        "    X = AveragePooling2D((2,2), name='avg_pool')(X)\n",
        "    \n",
        "    # output layerds\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(512, activation = 'relu', name='fc1024' , kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GKsSwtp-GuL"
      },
      "source": [
        "\"\"\"def ResNet50ori(input_shape = (48, 48, 1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns: dsdsf\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50ori')\n",
        "\n",
        "    return model\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3oWTDXlyBHM2",
        "outputId": "50a6ed5a-2f85-4f9d-f8a0-763d83b94afc"
      },
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        " \n",
        "dataset_path = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv'\n",
        "image_size=(48,48)\n",
        "#batch_size = 64\n",
        "\n",
        "def load_fer2013():\n",
        "    data = pd.read_csv(dataset_path)\n",
        "    data = (data[data['pixels'].notnull()])\n",
        "    pixels = data['pixels'].tolist()\n",
        "    width, height = 48, 48\n",
        "    faces = []\n",
        "    for pixel_sequence in pixels:\n",
        "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "        face = np.asarray(face).reshape(width, height)\n",
        "        face = cv2.resize(face.astype('uint8'),image_size)\n",
        "        faces.append(face.astype('float32'))\n",
        "    faces = np.asarray(faces)\n",
        "    faces = np.expand_dims(faces, -1)\n",
        "    emotions = (data['emotion'])#.values\n",
        "    return faces, emotions\n",
        " \n",
        "def preprocess_input(x, v2=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if v2:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x\n",
        " \n",
        "faces, emotions = load_fer2013()\n",
        "faces = preprocess_input(faces)\n",
        "#xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
        "#Data Augumentation\n",
        "data_generator = ImageDataGenerator(\n",
        "                        rotation_range=10,\n",
        "                        shear_range = 10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True)\n",
        "\"\"\"data_generator = ImageDataGenerator( )\n",
        "\"\"\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'data_generator = ImageDataGenerator( )\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWLhavr-rSF5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "895f7f85-9930-46ca-c552-cbb571846a4e"
      },
      "source": [
        "\"\"\"\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.1,)\n",
        "x_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1,)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nxtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.1,)\\nx_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1,)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "RGhnYFXgaqL9",
        "outputId": "0e60da2f-3a44-4d06-910b-2e0f2fa4191a"
      },
      "source": [
        "\"\"\"print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (y_train.shape)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'print (\"validasi\",x_val.shape)\\nprint (y_val.shape)\\nprint (\"test\",xtest.shape)\\nprint (ytest.shape)\\nprint (\"train\",xtrain.shape)\\nprint (y_train.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rDS3hqhDSteM",
        "outputId": "4e681bae-fe49-498e-bbaa-6a4714c27eb0"
      },
      "source": [
        "train_ratio = 0.80\n",
        "validation_ratio = 0.10\n",
        "test_ratio = 0.10\n",
        "\n",
        "# train is now 75% of the entire data set\n",
        "# the _junk suffix means that we drop that variable completely # the _junk suffix means that we drop that variable completely\n",
        "#x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=1 - train_ratio)\n",
        "\n",
        "# test is now 10% of the initial data set\n",
        "# validation is now 15% of the initial data set\n",
        "#x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "x_val, xtest, y_val, ytest = train_test_split(xtest, ytest, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "\n",
        "print(xtrain, x_val, xtest)\n",
        "\n",
        "\"\"\"X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2\"\"\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[-0.6862745 ]\n",
            "   [-0.7019608 ]\n",
            "   [-0.75686276]\n",
            "   ...\n",
            "   [-0.8666667 ]\n",
            "   [-0.8666667 ]\n",
            "   [-0.88235295]]\n",
            "\n",
            "  [[-0.64705884]\n",
            "   [-0.7019608 ]\n",
            "   [-0.70980394]\n",
            "   ...\n",
            "   [-0.8666667 ]\n",
            "   [-0.8745098 ]\n",
            "   [-0.88235295]]\n",
            "\n",
            "  [[-0.6392157 ]\n",
            "   [-0.69411767]\n",
            "   [-0.64705884]\n",
            "   ...\n",
            "   [-0.8509804 ]\n",
            "   [-0.85882354]\n",
            "   [-0.8666667 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.38823527]\n",
            "   [-0.41960782]\n",
            "   [-0.47450978]\n",
            "   ...\n",
            "   [-0.84313726]\n",
            "   [-0.85882354]\n",
            "   [-0.8745098 ]]\n",
            "\n",
            "  [[-0.4823529 ]\n",
            "   [-0.47450978]\n",
            "   [-0.41960782]\n",
            "   ...\n",
            "   [-0.8666667 ]\n",
            "   [-0.8509804 ]\n",
            "   [-0.85882354]]\n",
            "\n",
            "  [[-0.47450978]\n",
            "   [-0.45098037]\n",
            "   [-0.44313723]\n",
            "   ...\n",
            "   [-0.84313726]\n",
            "   [-0.8352941 ]\n",
            "   [-0.8509804 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.20000005]\n",
            "   [ 0.03529418]\n",
            "   [-0.23921567]\n",
            "   ...\n",
            "   [ 0.38823533]\n",
            "   [ 0.38823533]\n",
            "   [ 0.37254906]]\n",
            "\n",
            "  [[ 0.19215691]\n",
            "   [-0.11372548]\n",
            "   [-0.2235294 ]\n",
            "   ...\n",
            "   [ 0.39607847]\n",
            "   [ 0.38823533]\n",
            "   [ 0.3803922 ]]\n",
            "\n",
            "  [[ 0.11372554]\n",
            "   [-0.21568626]\n",
            "   [-0.16862744]\n",
            "   ...\n",
            "   [ 0.39607847]\n",
            "   [ 0.39607847]\n",
            "   [ 0.39607847]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.29411763]\n",
            "   [-0.3333333 ]\n",
            "   [-0.02745098]\n",
            "   ...\n",
            "   [-0.5137255 ]\n",
            "   [-0.42745095]\n",
            "   [ 0.06666672]]\n",
            "\n",
            "  [[-0.27843136]\n",
            "   [-0.49019605]\n",
            "   [-0.12156862]\n",
            "   ...\n",
            "   [-0.16862744]\n",
            "   [-0.3490196 ]\n",
            "   [-0.36470586]]\n",
            "\n",
            "  [[-0.30196077]\n",
            "   [-0.30196077]\n",
            "   [-0.19215685]\n",
            "   ...\n",
            "   [-0.12156862]\n",
            "   [ 0.04313731]\n",
            "   [-0.24705881]]]\n",
            "\n",
            "\n",
            " [[[-0.42745095]\n",
            "   [-0.44313723]\n",
            "   [-0.372549  ]\n",
            "   ...\n",
            "   [ 0.75686276]\n",
            "   [ 0.7254902 ]\n",
            "   [ 0.3803922 ]]\n",
            "\n",
            "  [[-0.46666664]\n",
            "   [-0.42745095]\n",
            "   [-0.4588235 ]\n",
            "   ...\n",
            "   [ 0.49803925]\n",
            "   [ 0.70980394]\n",
            "   [ 0.62352943]]\n",
            "\n",
            "  [[-0.47450978]\n",
            "   [-0.4980392 ]\n",
            "   [-0.5686275 ]\n",
            "   ...\n",
            "   [-0.29411763]\n",
            "   [ 0.05098045]\n",
            "   [ 0.3411765 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.78039217]\n",
            "   [-0.7411765 ]\n",
            "   [-0.7176471 ]\n",
            "   ...\n",
            "   [-0.3960784 ]\n",
            "   [-0.4823529 ]\n",
            "   [-0.4588235 ]]\n",
            "\n",
            "  [[-0.7411765 ]\n",
            "   [-0.7647059 ]\n",
            "   [-0.7019608 ]\n",
            "   ...\n",
            "   [-0.372549  ]\n",
            "   [-0.49019605]\n",
            "   [-0.4588235 ]]\n",
            "\n",
            "  [[-0.7254902 ]\n",
            "   [-0.75686276]\n",
            "   [-0.7411765 ]\n",
            "   ...\n",
            "   [-0.3490196 ]\n",
            "   [-0.44313723]\n",
            "   [-0.47450978]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 0.62352943]\n",
            "   [ 0.654902  ]\n",
            "   [ 0.6392157 ]\n",
            "   ...\n",
            "   [-0.21568626]\n",
            "   [-0.2235294 ]\n",
            "   [-0.09803921]]\n",
            "\n",
            "  [[ 0.654902  ]\n",
            "   [ 0.654902  ]\n",
            "   [ 0.6784314 ]\n",
            "   ...\n",
            "   [-0.23137254]\n",
            "   [-0.23137254]\n",
            "   [-0.12156862]]\n",
            "\n",
            "  [[ 0.6862745 ]\n",
            "   [ 0.67058825]\n",
            "   [ 0.69411767]\n",
            "   ...\n",
            "   [-0.2235294 ]\n",
            "   [-0.24705881]\n",
            "   [-0.15294117]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.54509807]\n",
            "   [ 0.6156863 ]\n",
            "   [ 0.6       ]\n",
            "   ...\n",
            "   [-0.0745098 ]\n",
            "   [-0.10588235]\n",
            "   [-0.12156862]]\n",
            "\n",
            "  [[ 0.54509807]\n",
            "   [ 0.58431375]\n",
            "   [ 0.5921569 ]\n",
            "   ...\n",
            "   [-0.0745098 ]\n",
            "   [-0.10588235]\n",
            "   [-0.15294117]]\n",
            "\n",
            "  [[ 0.5372549 ]\n",
            "   [ 0.56078434]\n",
            "   [ 0.5921569 ]\n",
            "   ...\n",
            "   [-0.11372548]\n",
            "   [-0.10588235]\n",
            "   [-0.09803921]]]\n",
            "\n",
            "\n",
            " [[[-0.9529412 ]\n",
            "   [-0.8901961 ]\n",
            "   [-0.827451  ]\n",
            "   ...\n",
            "   [-0.12156862]\n",
            "   [-0.31764704]\n",
            "   [-0.5058824 ]]\n",
            "\n",
            "  [[-0.9372549 ]\n",
            "   [-0.8745098 ]\n",
            "   [-0.81960785]\n",
            "   ...\n",
            "   [-0.0745098 ]\n",
            "   [-0.2862745 ]\n",
            "   [-0.52156866]]\n",
            "\n",
            "  [[-0.92941177]\n",
            "   [-0.8745098 ]\n",
            "   [-0.827451  ]\n",
            "   ...\n",
            "   [-0.01176471]\n",
            "   [-0.2235294 ]\n",
            "   [-0.52156866]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.41176468]\n",
            "   [-0.6784314 ]\n",
            "   [-0.58431375]\n",
            "   ...\n",
            "   [ 0.23921573]\n",
            "   [ 0.19215691]\n",
            "   [ 0.05882359]]\n",
            "\n",
            "  [[-0.6313726 ]\n",
            "   [-0.69411767]\n",
            "   [-0.5921569 ]\n",
            "   ...\n",
            "   [ 0.21568632]\n",
            "   [ 0.12941182]\n",
            "   [-0.01960784]]\n",
            "\n",
            "  [[-0.69411767]\n",
            "   [-0.7019608 ]\n",
            "   [-0.64705884]\n",
            "   ...\n",
            "   [ 0.15294123]\n",
            "   [ 0.03529418]\n",
            "   [-0.08235294]]]\n",
            "\n",
            "\n",
            " [[[ 0.39607847]\n",
            "   [-0.23137254]\n",
            "   [ 0.06666672]\n",
            "   ...\n",
            "   [-0.62352943]\n",
            "   [-0.5529412 ]\n",
            "   [ 0.5686275 ]]\n",
            "\n",
            "  [[ 0.5058824 ]\n",
            "   [-0.3098039 ]\n",
            "   [-0.26274508]\n",
            "   ...\n",
            "   [-0.6392157 ]\n",
            "   [-0.44313723]\n",
            "   [ 0.427451  ]]\n",
            "\n",
            "  [[ 0.5372549 ]\n",
            "   [-0.19215685]\n",
            "   [ 0.12941182]\n",
            "   ...\n",
            "   [-0.67058825]\n",
            "   [-0.6313726 ]\n",
            "   [ 0.082353  ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.05098045]\n",
            "   [ 0.17647064]\n",
            "   [-0.36470586]\n",
            "   ...\n",
            "   [-0.16862744]\n",
            "   [-0.1607843 ]\n",
            "   [-0.20784312]]\n",
            "\n",
            "  [[-0.06666666]\n",
            "   [ 0.02745104]\n",
            "   [-0.0745098 ]\n",
            "   ...\n",
            "   [-0.23137254]\n",
            "   [-0.21568626]\n",
            "   [-0.5294118 ]]\n",
            "\n",
            "  [[-0.01960784]\n",
            "   [-0.1372549 ]\n",
            "   [ 0.06666672]\n",
            "   ...\n",
            "   [ 0.41960788]\n",
            "   [-0.45098037]\n",
            "   [-0.31764704]]]] [[[[-0.35686272]\n",
            "   [-0.30196077]\n",
            "   [-0.19215685]\n",
            "   ...\n",
            "   [-0.41960782]\n",
            "   [-0.2235294 ]\n",
            "   [-0.1372549 ]]\n",
            "\n",
            "  [[-0.41176468]\n",
            "   [-0.34117645]\n",
            "   [-0.25490195]\n",
            "   ...\n",
            "   [-0.5529412 ]\n",
            "   [-0.3333333 ]\n",
            "   [-0.23921567]]\n",
            "\n",
            "  [[-0.45098037]\n",
            "   [-0.36470586]\n",
            "   [-0.4352941 ]\n",
            "   ...\n",
            "   [-0.6       ]\n",
            "   [-0.38823527]\n",
            "   [-0.26274508]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.5529412 ]\n",
            "   [ 0.54509807]\n",
            "   [ 0.58431375]\n",
            "   ...\n",
            "   [ 0.5137255 ]\n",
            "   [ 0.18431377]\n",
            "   [ 0.56078434]]\n",
            "\n",
            "  [[ 0.2313726 ]\n",
            "   [ 0.27058828]\n",
            "   [ 0.39607847]\n",
            "   ...\n",
            "   [ 0.5372549 ]\n",
            "   [ 0.20784318]\n",
            "   [ 0.45882356]]\n",
            "\n",
            "  [[ 0.09803927]\n",
            "   [ 0.22352946]\n",
            "   [ 0.34901965]\n",
            "   ...\n",
            "   [ 0.39607847]\n",
            "   [ 0.23921573]\n",
            "   [ 0.4431373 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.54509807]\n",
            "   [ 0.6392157 ]\n",
            "   [ 0.60784316]\n",
            "   ...\n",
            "   [-0.44313723]\n",
            "   [-0.21568626]\n",
            "   [-0.2235294 ]]\n",
            "\n",
            "  [[ 0.62352943]\n",
            "   [ 0.73333335]\n",
            "   [ 0.5686275 ]\n",
            "   ...\n",
            "   [-0.7176471 ]\n",
            "   [-0.34117645]\n",
            "   [-0.19999999]]\n",
            "\n",
            "  [[ 0.81960785]\n",
            "   [ 0.62352943]\n",
            "   [ 0.34901965]\n",
            "   ...\n",
            "   [-0.78039217]\n",
            "   [-0.58431375]\n",
            "   [-0.41176468]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.8117647 ]\n",
            "   [ 0.7647059 ]\n",
            "   [ 0.7490196 ]\n",
            "   ...\n",
            "   [ 0.79607844]\n",
            "   [ 0.8352941 ]\n",
            "   [ 0.8745098 ]]\n",
            "\n",
            "  [[ 0.8039216 ]\n",
            "   [ 0.70980394]\n",
            "   [ 0.5686275 ]\n",
            "   ...\n",
            "   [ 0.79607844]\n",
            "   [ 0.827451  ]\n",
            "   [ 0.8666667 ]]\n",
            "\n",
            "  [[ 0.84313726]\n",
            "   [ 0.70980394]\n",
            "   [ 0.48235297]\n",
            "   ...\n",
            "   [ 0.8666667 ]\n",
            "   [ 0.827451  ]\n",
            "   [ 0.73333335]]]\n",
            "\n",
            "\n",
            " [[[-0.34117645]\n",
            "   [-0.54509807]\n",
            "   [-0.372549  ]\n",
            "   ...\n",
            "   [-0.5058824 ]\n",
            "   [-0.70980394]\n",
            "   [-0.6392157 ]]\n",
            "\n",
            "  [[-0.4588235 ]\n",
            "   [-0.54509807]\n",
            "   [-0.20784312]\n",
            "   ...\n",
            "   [-0.5294118 ]\n",
            "   [-0.5686275 ]\n",
            "   [-0.7176471 ]]\n",
            "\n",
            "  [[-0.5921569 ]\n",
            "   [-0.32549018]\n",
            "   [-0.19215685]\n",
            "   ...\n",
            "   [-0.6862745 ]\n",
            "   [-0.56078434]\n",
            "   [-0.6627451 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.49019605]\n",
            "   [-0.5294118 ]\n",
            "   [-0.40392154]\n",
            "   ...\n",
            "   [-0.8666667 ]\n",
            "   [-0.81960785]\n",
            "   [-0.81960785]]\n",
            "\n",
            "  [[-0.4352941 ]\n",
            "   [-0.40392154]\n",
            "   [-0.45098037]\n",
            "   ...\n",
            "   [-0.85882354]\n",
            "   [-0.81960785]\n",
            "   [-0.8117647 ]]\n",
            "\n",
            "  [[-0.47450978]\n",
            "   [-0.25490195]\n",
            "   [-0.41176468]\n",
            "   ...\n",
            "   [-0.827451  ]\n",
            "   [-0.8666667 ]\n",
            "   [-0.85882354]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 0.03529418]\n",
            "   [ 0.22352946]\n",
            "   [-0.10588235]\n",
            "   ...\n",
            "   [-0.30196077]\n",
            "   [-0.3098039 ]\n",
            "   [-0.41960782]]\n",
            "\n",
            "  [[ 0.0196079 ]\n",
            "   [ 0.2313726 ]\n",
            "   [-0.05098039]\n",
            "   ...\n",
            "   [-0.38823527]\n",
            "   [-0.34117645]\n",
            "   [-0.654902  ]]\n",
            "\n",
            "  [[ 0.01176476]\n",
            "   [ 0.21568632]\n",
            "   [-0.0745098 ]\n",
            "   ...\n",
            "   [-0.36470586]\n",
            "   [-0.34117645]\n",
            "   [-0.52156866]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.17647058]\n",
            "   [-0.49019605]\n",
            "   [-0.7490196 ]\n",
            "   ...\n",
            "   [ 0.18431377]\n",
            "   [-0.21568626]\n",
            "   [-0.5372549 ]]\n",
            "\n",
            "  [[-0.09803921]\n",
            "   [-0.7254902 ]\n",
            "   [-0.6392157 ]\n",
            "   ...\n",
            "   [ 0.06666672]\n",
            "   [ 0.07450986]\n",
            "   [-0.38039213]]\n",
            "\n",
            "  [[-0.2862745 ]\n",
            "   [-0.8901961 ]\n",
            "   [-0.5921569 ]\n",
            "   ...\n",
            "   [-0.23137254]\n",
            "   [ 0.10588241]\n",
            "   [-0.04313725]]]\n",
            "\n",
            "\n",
            " [[[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 0.99215686]\n",
            "   ...\n",
            "   [-0.24705881]\n",
            "   [-0.20784312]\n",
            "   [-0.16862744]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [-0.18431371]\n",
            "   [-0.20784312]\n",
            "   [-0.23921567]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 0.99215686]\n",
            "   [ 1.        ]\n",
            "   ...\n",
            "   [-0.06666666]\n",
            "   [-0.15294117]\n",
            "   [-0.1372549 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.62352943]\n",
            "   [ 0.6862745 ]\n",
            "   [ 0.64705884]\n",
            "   ...\n",
            "   [ 0.5137255 ]\n",
            "   [ 0.30196083]\n",
            "   [-0.5137255 ]]\n",
            "\n",
            "  [[ 0.5921569 ]\n",
            "   [ 0.7019608 ]\n",
            "   [ 0.69411767]\n",
            "   ...\n",
            "   [ 0.5058824 ]\n",
            "   [ 0.09803927]\n",
            "   [-0.58431375]]\n",
            "\n",
            "  [[ 0.5764706 ]\n",
            "   [ 0.7019608 ]\n",
            "   [ 0.7176471 ]\n",
            "   ...\n",
            "   [ 0.5058824 ]\n",
            "   [-0.18431371]\n",
            "   [-0.5529412 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.3411765 ]\n",
            "   [ 0.19215691]\n",
            "   [-0.1607843 ]\n",
            "   ...\n",
            "   [ 0.56078434]\n",
            "   [ 0.6392157 ]\n",
            "   [ 0.7411765 ]]\n",
            "\n",
            "  [[ 0.22352946]\n",
            "   [-0.12156862]\n",
            "   [-0.58431375]\n",
            "   ...\n",
            "   [ 0.5686275 ]\n",
            "   [ 0.70980394]\n",
            "   [ 0.7411765 ]]\n",
            "\n",
            "  [[-0.19999999]\n",
            "   [-0.6156863 ]\n",
            "   [-0.8666667 ]\n",
            "   ...\n",
            "   [ 0.47450984]\n",
            "   [ 0.67058825]\n",
            "   [ 0.7176471 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.94509804]\n",
            "   [-0.94509804]\n",
            "   [-0.96862745]\n",
            "   ...\n",
            "   [-0.4980392 ]\n",
            "   [-0.11372548]\n",
            "   [-0.29411763]]\n",
            "\n",
            "  [[-0.94509804]\n",
            "   [-0.94509804]\n",
            "   [-0.96862745]\n",
            "   ...\n",
            "   [-0.6313726 ]\n",
            "   [-0.1372549 ]\n",
            "   [-0.29411763]]\n",
            "\n",
            "  [[-0.94509804]\n",
            "   [-0.9529412 ]\n",
            "   [-0.96862745]\n",
            "   ...\n",
            "   [-0.6313726 ]\n",
            "   [-0.03529412]\n",
            "   [-0.27058822]]]] [[[[-0.3490196 ]\n",
            "   [-0.372549  ]\n",
            "   [-0.372549  ]\n",
            "   ...\n",
            "   [-0.02745098]\n",
            "   [ 0.13725495]\n",
            "   [ 0.20000005]]\n",
            "\n",
            "  [[-0.35686272]\n",
            "   [-0.38039213]\n",
            "   [-0.38823527]\n",
            "   ...\n",
            "   [-0.03529412]\n",
            "   [ 0.15294123]\n",
            "   [ 0.24705887]]\n",
            "\n",
            "  [[-0.372549  ]\n",
            "   [-0.372549  ]\n",
            "   [-0.38039213]\n",
            "   ...\n",
            "   [-0.10588235]\n",
            "   [ 0.06666672]\n",
            "   [ 0.19215691]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.08235294]\n",
            "   [-0.18431371]\n",
            "   [-0.40392154]\n",
            "   ...\n",
            "   [-0.41960782]\n",
            "   [-0.38039213]\n",
            "   [-0.35686272]]\n",
            "\n",
            "  [[-0.41176468]\n",
            "   [-0.42745095]\n",
            "   [-0.3098039 ]\n",
            "   ...\n",
            "   [-0.27843136]\n",
            "   [-0.26274508]\n",
            "   [-0.27058822]]\n",
            "\n",
            "  [[-0.20784312]\n",
            "   [-0.21568626]\n",
            "   [-0.24705881]\n",
            "   ...\n",
            "   [-0.0745098 ]\n",
            "   [-0.1607843 ]\n",
            "   [-0.2235294 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.07450986]\n",
            "   [ 0.06666672]\n",
            "   [ 0.05882359]\n",
            "   ...\n",
            "   [ 0.09803927]\n",
            "   [ 0.07450986]\n",
            "   [ 0.07450986]]\n",
            "\n",
            "  [[ 0.03529418]\n",
            "   [ 0.05882359]\n",
            "   [ 0.05098045]\n",
            "   ...\n",
            "   [ 0.06666672]\n",
            "   [ 0.06666672]\n",
            "   [ 0.05098045]]\n",
            "\n",
            "  [[ 0.04313731]\n",
            "   [ 0.07450986]\n",
            "   [ 0.07450986]\n",
            "   ...\n",
            "   [ 0.06666672]\n",
            "   [ 0.082353  ]\n",
            "   [ 0.02745104]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.5921569 ]\n",
            "   [-0.5921569 ]\n",
            "   [-0.5764706 ]\n",
            "   ...\n",
            "   [-0.05882353]\n",
            "   [-0.10588235]\n",
            "   [-0.0745098 ]]\n",
            "\n",
            "  [[-0.5529412 ]\n",
            "   [-0.5529412 ]\n",
            "   [-0.5686275 ]\n",
            "   ...\n",
            "   [-0.01960784]\n",
            "   [-0.0745098 ]\n",
            "   [-0.12941176]]\n",
            "\n",
            "  [[-0.54509807]\n",
            "   [-0.56078434]\n",
            "   [-0.58431375]\n",
            "   ...\n",
            "   [ 0.02745104]\n",
            "   [-0.01176471]\n",
            "   [-0.15294117]]]\n",
            "\n",
            "\n",
            " [[[-0.09803921]\n",
            "   [-0.08235294]\n",
            "   [-0.10588235]\n",
            "   ...\n",
            "   [-0.85882354]\n",
            "   [-0.85882354]\n",
            "   [-0.85882354]]\n",
            "\n",
            "  [[-0.1372549 ]\n",
            "   [-0.08235294]\n",
            "   [-0.06666666]\n",
            "   ...\n",
            "   [-0.84313726]\n",
            "   [-0.8509804 ]\n",
            "   [-0.85882354]]\n",
            "\n",
            "  [[-0.19215685]\n",
            "   [-0.09019607]\n",
            "   [-0.06666666]\n",
            "   ...\n",
            "   [-0.8509804 ]\n",
            "   [-0.8509804 ]\n",
            "   [-0.8509804 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.8039216 ]\n",
            "   [-0.81960785]\n",
            "   [-0.81960785]\n",
            "   ...\n",
            "   [ 0.48235297]\n",
            "   [ 0.3803922 ]\n",
            "   [ 0.2941177 ]]\n",
            "\n",
            "  [[-0.84313726]\n",
            "   [-0.827451  ]\n",
            "   [-0.8352941 ]\n",
            "   ...\n",
            "   [ 0.49803925]\n",
            "   [ 0.427451  ]\n",
            "   [ 0.3411765 ]]\n",
            "\n",
            "  [[-0.8352941 ]\n",
            "   [-0.827451  ]\n",
            "   [-0.8352941 ]\n",
            "   ...\n",
            "   [ 0.47450984]\n",
            "   [ 0.45098042]\n",
            "   [ 0.35686278]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 0.36470592]\n",
            "   [ 0.28627455]\n",
            "   [ 0.00392163]\n",
            "   ...\n",
            "   [ 0.99215686]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 0.32549024]\n",
            "   [ 0.13725495]\n",
            "   [-0.05882353]\n",
            "   ...\n",
            "   [ 0.99215686]\n",
            "   [ 0.99215686]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[ 0.254902  ]\n",
            "   [ 0.0196079 ]\n",
            "   [-0.30196077]\n",
            "   ...\n",
            "   [ 0.99215686]\n",
            "   [ 1.        ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.372549  ]\n",
            "   [ 0.36470592]\n",
            "   [ 0.5137255 ]\n",
            "   ...\n",
            "   [-0.2235294 ]\n",
            "   [ 0.8901961 ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[-0.41176468]\n",
            "   [ 0.14509809]\n",
            "   [ 0.58431375]\n",
            "   ...\n",
            "   [ 0.02745104]\n",
            "   [ 0.6       ]\n",
            "   [ 1.        ]]\n",
            "\n",
            "  [[-0.38039213]\n",
            "   [-0.01960784]\n",
            "   [ 0.62352943]\n",
            "   ...\n",
            "   [ 0.3176471 ]\n",
            "   [ 0.5294118 ]\n",
            "   [ 1.        ]]]\n",
            "\n",
            "\n",
            " [[[-0.6392157 ]\n",
            "   [-0.4980392 ]\n",
            "   [-0.5137255 ]\n",
            "   ...\n",
            "   [-0.5058824 ]\n",
            "   [-0.9137255 ]\n",
            "   [-0.96862745]]\n",
            "\n",
            "  [[-0.58431375]\n",
            "   [-0.52156866]\n",
            "   [-0.45098037]\n",
            "   ...\n",
            "   [-0.5764706 ]\n",
            "   [-0.92941177]\n",
            "   [-0.9843137 ]]\n",
            "\n",
            "  [[-0.6627451 ]\n",
            "   [-0.54509807]\n",
            "   [-0.49019605]\n",
            "   ...\n",
            "   [-0.60784316]\n",
            "   [-0.9372549 ]\n",
            "   [-0.99215686]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.06666666]\n",
            "   [ 0.3411765 ]\n",
            "   [ 0.48235297]\n",
            "   ...\n",
            "   [ 0.27058828]\n",
            "   [ 0.21568632]\n",
            "   [ 0.07450986]]\n",
            "\n",
            "  [[-0.12941176]\n",
            "   [ 0.10588241]\n",
            "   [ 0.19215691]\n",
            "   ...\n",
            "   [ 0.18431377]\n",
            "   [ 0.04313731]\n",
            "   [-0.3098039 ]]\n",
            "\n",
            "  [[-0.27843136]\n",
            "   [-0.23921567]\n",
            "   [-0.19215685]\n",
            "   ...\n",
            "   [-0.00392157]\n",
            "   [-0.3490196 ]\n",
            "   [-0.16862744]]]\n",
            "\n",
            "\n",
            " [[[-0.84313726]\n",
            "   [-0.7411765 ]\n",
            "   [-0.60784316]\n",
            "   ...\n",
            "   [ 0.77254903]\n",
            "   [ 0.77254903]\n",
            "   [ 0.77254903]]\n",
            "\n",
            "  [[-0.8039216 ]\n",
            "   [-0.67058825]\n",
            "   [-0.4823529 ]\n",
            "   ...\n",
            "   [ 0.75686276]\n",
            "   [ 0.7647059 ]\n",
            "   [ 0.77254903]]\n",
            "\n",
            "  [[-0.7176471 ]\n",
            "   [-0.5529412 ]\n",
            "   [-0.36470586]\n",
            "   ...\n",
            "   [ 0.7411765 ]\n",
            "   [ 0.75686276]\n",
            "   [ 0.7647059 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.4666667 ]\n",
            "   [ 0.2941177 ]\n",
            "   [-0.19999999]\n",
            "   ...\n",
            "   [-0.44313723]\n",
            "   [-0.41960782]\n",
            "   [-0.41176468]]\n",
            "\n",
            "  [[ 0.54509807]\n",
            "   [ 0.45098042]\n",
            "   [-0.01176471]\n",
            "   ...\n",
            "   [-0.4352941 ]\n",
            "   [-0.41960782]\n",
            "   [-0.38039213]]\n",
            "\n",
            "  [[ 0.6       ]\n",
            "   [ 0.5529412 ]\n",
            "   [ 0.1686275 ]\n",
            "   ...\n",
            "   [-0.30196077]\n",
            "   [-0.3960784 ]\n",
            "   [-0.372549  ]]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\\n\\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKvEv321Stt5",
        "outputId": "95e29b31-85e5-42b6-edde-773340618e5c"
      },
      "source": [
        "print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validasi (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "test (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "train (28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH9Q-TegBR26"
      },
      "source": [
        "#hyperparameter and callback\n",
        "batch_size = 64\n",
        "num_epochs = 60\n",
        "input_shape = (48, 48, 1)\n",
        "num_classes = 7\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGsscQRJBR-h"
      },
      "source": [
        "#Compile the model.\n",
        "\n",
        "\n",
        "from keras.optimizers import Adam, SGD\n",
        "model = ResNet50(input_shape = (48, 48, 1), classes = 7)\n",
        "optimizer = SGD(learning_rate=0.01)\n",
        "model.compile(optimizer= optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rodttDWeT2yP"
      },
      "source": [
        "#kita mau save model callbacks\n",
        "\"\"\"import os\n",
        "try:\n",
        "  os.mkdir('scratchcheckpoint')\n",
        "except:\n",
        "  pass\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV29sTjET28U"
      },
      "source": [
        "\"\"\"file_name = 'Best_Model_resnet50Scracth_sena1.h5'\n",
        "\n",
        "checkpoint_path = os.path.join('checkpoint',file_name)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_S6wUaPT3Jx"
      },
      "source": [
        "\"\"\"call_back = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
        "                                               monitor='val_accuracy',\n",
        "                                               verbose=1,\n",
        "                                               save_freq='epoch',\n",
        "                                               save_best_only=True,\n",
        "                                               save_weights_only=False,\n",
        "                                               mode='max')\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy53DHMGB-Mr",
        "outputId": "761a26df-8563-4210-e668-a9b5210f93b5"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 46, 46, 128)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 46, 46, 128)  0           activation_3[0][0]               \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 46, 46, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 46, 46, 128)  0           activation_6[0][0]               \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 46, 46, 128)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 23, 23, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 23, 23, 256)  0           activation_12[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 23, 23, 256)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 23, 23, 256)  0           activation_15[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 23, 23, 256)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 23, 23, 256)  0           activation_18[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 23, 23, 256)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 12, 12, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 12, 12, 512)  0           activation_24[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 12, 12, 512)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 12, 12, 512)  0           activation_27[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 12, 12, 512)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 12, 12, 512)  0           activation_30[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 12, 12, 512)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 12, 12, 512)  0           activation_33[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 12, 12, 512)  0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 12, 12, 512)  0           activation_36[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 12, 12, 512)  0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 6, 6, 1024)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 6, 6, 1024)   0           activation_42[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 6, 6, 1024)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 6, 6, 1024)   0           activation_45[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 6, 6, 1024)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgxCecVwCGEr"
      },
      "source": [
        "\"\"\"history = model.fit(data_generator.flow(xtrain, ytrain,),\n",
        "                        steps_per_epoch=len(xtrain) / batch_size,\n",
        "                        epochs=num_epochs, verbose=1,callbacks=call_back,\n",
        "                        validation_data= (xtest,ytest))\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2muXWns0sJSH",
        "outputId": "def33c5e-4e95-498f-c339-85c8661cc46f"
      },
      "source": [
        "history = model.fit(\n",
        "    data_generator.flow(xtrain, ytrain,),\n",
        "    steps_per_epoch=len(xtrain) / batch_size,\n",
        "    epochs=num_epochs, \n",
        "    verbose=1,\n",
        "    validation_data= (x_val,y_val))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "448/448 [==============================] - 105s 111ms/step - loss: 2.4220 - accuracy: 0.2389 - val_loss: 1.8187 - val_accuracy: 0.2310\n",
            "Epoch 2/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 1.8042 - accuracy: 0.2385 - val_loss: 1.8308 - val_accuracy: 0.2435\n",
            "Epoch 3/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7841 - accuracy: 0.2517 - val_loss: 1.7723 - val_accuracy: 0.2516\n",
            "Epoch 4/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7674 - accuracy: 0.2666 - val_loss: 1.7701 - val_accuracy: 0.2664\n",
            "Epoch 5/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.7344 - accuracy: 0.2840 - val_loss: 1.7061 - val_accuracy: 0.3034\n",
            "Epoch 6/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.7059 - accuracy: 0.3036 - val_loss: 1.8933 - val_accuracy: 0.3199\n",
            "Epoch 7/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.6615 - accuracy: 0.3229 - val_loss: 1.6399 - val_accuracy: 0.3455\n",
            "Epoch 8/60\n",
            "448/448 [==============================] - 49s 109ms/step - loss: 1.6455 - accuracy: 0.3363 - val_loss: 1.7089 - val_accuracy: 0.3157\n",
            "Epoch 9/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.6068 - accuracy: 0.3549 - val_loss: 1.5855 - val_accuracy: 0.3753\n",
            "Epoch 10/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.5737 - accuracy: 0.3707 - val_loss: 1.5710 - val_accuracy: 0.3898\n",
            "Epoch 11/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.5419 - accuracy: 0.3888 - val_loss: 1.5225 - val_accuracy: 0.3965\n",
            "Epoch 12/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.5129 - accuracy: 0.3988 - val_loss: 1.5133 - val_accuracy: 0.4185\n",
            "Epoch 13/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.4898 - accuracy: 0.4066 - val_loss: 1.4357 - val_accuracy: 0.4366\n",
            "Epoch 14/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.4590 - accuracy: 0.4248 - val_loss: 1.3882 - val_accuracy: 0.4547\n",
            "Epoch 15/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.4243 - accuracy: 0.4443 - val_loss: 1.3959 - val_accuracy: 0.4567\n",
            "Epoch 16/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.3865 - accuracy: 0.4580 - val_loss: 1.3426 - val_accuracy: 0.4806\n",
            "Epoch 17/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.3812 - accuracy: 0.4613 - val_loss: 1.3507 - val_accuracy: 0.4726\n",
            "Epoch 18/60\n",
            "448/448 [==============================] - 47s 104ms/step - loss: 1.3523 - accuracy: 0.4784 - val_loss: 1.3087 - val_accuracy: 0.4943\n",
            "Epoch 19/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 1.3467 - accuracy: 0.4900 - val_loss: 1.2795 - val_accuracy: 0.5040\n",
            "Epoch 20/60\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.3228 - accuracy: 0.4854 - val_loss: 1.4024 - val_accuracy: 0.4700\n",
            "Epoch 21/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.2942 - accuracy: 0.5039 - val_loss: 1.3098 - val_accuracy: 0.4951\n",
            "Epoch 22/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.2850 - accuracy: 0.5132 - val_loss: 1.2958 - val_accuracy: 0.5057\n",
            "Epoch 23/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.2662 - accuracy: 0.5140 - val_loss: 1.2359 - val_accuracy: 0.5188\n",
            "Epoch 24/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.2472 - accuracy: 0.5228 - val_loss: 1.4264 - val_accuracy: 0.4391\n",
            "Epoch 25/60\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.2474 - accuracy: 0.5189 - val_loss: 1.2859 - val_accuracy: 0.5099\n",
            "Epoch 26/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.2268 - accuracy: 0.5257 - val_loss: 1.2137 - val_accuracy: 0.5350\n",
            "Epoch 27/60\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 1.2269 - accuracy: 0.5309 - val_loss: 1.1916 - val_accuracy: 0.5425\n",
            "Epoch 28/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.2029 - accuracy: 0.5386 - val_loss: 1.3543 - val_accuracy: 0.4918\n",
            "Epoch 29/60\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 1.1900 - accuracy: 0.5463 - val_loss: 1.2105 - val_accuracy: 0.5327\n",
            "Epoch 30/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.1866 - accuracy: 0.5494 - val_loss: 1.2270 - val_accuracy: 0.5288\n",
            "Epoch 31/60\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.1689 - accuracy: 0.5521 - val_loss: 1.4006 - val_accuracy: 0.4921\n",
            "Epoch 32/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 1.1442 - accuracy: 0.5579 - val_loss: 1.1633 - val_accuracy: 0.5489\n",
            "Epoch 33/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.1425 - accuracy: 0.5669 - val_loss: 1.1569 - val_accuracy: 0.5598\n",
            "Epoch 34/60\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.1659 - accuracy: 0.5537 - val_loss: 1.1668 - val_accuracy: 0.5536\n",
            "Epoch 35/60\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.1668 - accuracy: 0.5573 - val_loss: 1.1680 - val_accuracy: 0.5592\n",
            "Epoch 36/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.1339 - accuracy: 0.5709 - val_loss: 1.2074 - val_accuracy: 0.5358\n",
            "Epoch 37/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.1254 - accuracy: 0.5712 - val_loss: 1.1909 - val_accuracy: 0.5456\n",
            "Epoch 38/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.1042 - accuracy: 0.5827 - val_loss: 1.1541 - val_accuracy: 0.5617\n",
            "Epoch 39/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.0946 - accuracy: 0.5847 - val_loss: 1.2310 - val_accuracy: 0.5400\n",
            "Epoch 40/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.1139 - accuracy: 0.5752 - val_loss: 1.1675 - val_accuracy: 0.5581\n",
            "Epoch 41/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.1065 - accuracy: 0.5764 - val_loss: 1.1918 - val_accuracy: 0.5444\n",
            "Epoch 42/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 1.1089 - accuracy: 0.5733 - val_loss: 1.2197 - val_accuracy: 0.5469\n",
            "Epoch 43/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.0810 - accuracy: 0.5892 - val_loss: 1.1139 - val_accuracy: 0.5896\n",
            "Epoch 44/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.0841 - accuracy: 0.5906 - val_loss: 1.1995 - val_accuracy: 0.5645\n",
            "Epoch 45/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.0758 - accuracy: 0.5893 - val_loss: 1.1185 - val_accuracy: 0.5676\n",
            "Epoch 46/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.0695 - accuracy: 0.5989 - val_loss: 1.1648 - val_accuracy: 0.5584\n",
            "Epoch 47/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 1.0562 - accuracy: 0.5971 - val_loss: 1.1845 - val_accuracy: 0.5506\n",
            "Epoch 48/60\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.0472 - accuracy: 0.6068 - val_loss: 1.1110 - val_accuracy: 0.5798\n",
            "Epoch 49/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.0623 - accuracy: 0.5949 - val_loss: 1.2107 - val_accuracy: 0.5472\n",
            "Epoch 50/60\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.0361 - accuracy: 0.6045 - val_loss: 1.1494 - val_accuracy: 0.5704\n",
            "Epoch 51/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 1.0468 - accuracy: 0.6050 - val_loss: 1.1079 - val_accuracy: 0.5754\n",
            "Epoch 52/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.0146 - accuracy: 0.6130 - val_loss: 1.1139 - val_accuracy: 0.5754\n",
            "Epoch 53/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.0439 - accuracy: 0.6033 - val_loss: 1.0645 - val_accuracy: 0.6004\n",
            "Epoch 54/60\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.0212 - accuracy: 0.6144 - val_loss: 1.0614 - val_accuracy: 0.6038\n",
            "Epoch 55/60\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.0138 - accuracy: 0.6147 - val_loss: 1.1011 - val_accuracy: 0.5904\n",
            "Epoch 56/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.0323 - accuracy: 0.6116 - val_loss: 1.2340 - val_accuracy: 0.5428\n",
            "Epoch 57/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.0143 - accuracy: 0.6162 - val_loss: 1.0907 - val_accuracy: 0.5885\n",
            "Epoch 58/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.0129 - accuracy: 0.6207 - val_loss: 1.1232 - val_accuracy: 0.5860\n",
            "Epoch 59/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 0.9935 - accuracy: 0.6212 - val_loss: 1.1012 - val_accuracy: 0.5848\n",
            "Epoch 60/60\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.0065 - accuracy: 0.6201 - val_loss: 1.1078 - val_accuracy: 0.5988\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "GaXUP-8fDWRN",
        "outputId": "4802fee0-7d24-4008-b2c3-488a224d6c9c"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "model.save('/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD1try2.h5')\n",
        "\n",
        "#gffhgffkjkjdskjjkjkjkjhjhnnn\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "num_epochs = range(len(accuracy))\n",
        "plt.plot(num_epochs, accuracy, 'r', label='Training acc')\n",
        "plt.plot(num_epochs, val_accuracy, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(num_epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(num_epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeZzN9f7A8dfb2JfsWihGWZKsU4oWomhB3BZLt7RTtC8qLT/VjZJu3SsuLbRaStIiIRJajDVLmFCIsi9ZZpj374/3mXGMMzNnluPMjPfz8TiPc853O+9zhvM+n11UFeeccy6tQtEOwDnnXN7kCcI551xIniCcc86F5AnCOedcSJ4gnHPOheQJwjnnXEieIFzYRGSSiNyU28dGk4isFZE2EbiuisgZgcfDROTJcI7Nxut0F5GvsxuncxkRHwdRsInInqCnJYEDwKHA8ztV9f1jH1XeISJrgdtUdWouX1eBWqqakFvHikgNYA1QRFUP5kaczmWkcLQDcJGlqqVTHmf0ZSgihf1Lx+UV/u8xb/AqpuOUiLQUkfUi8qiIbALeFpHyIvK5iGwWke2Bx9WCzpkhIrcFHvcQkVkiMihw7BoRuTybx8aKyEwR2S0iU0VkiIi8l07c4cT4rIjMDlzvaxGpFLT/nyLym4hsFZEnMvh8monIJhGJCdrWSUQWBx6fKyLfi8gOEdkoIv8VkaLpXGukiDwX9PzhwDl/iMgtaY69UkQWiMguEVknIs8E7Z4ZuN8hIntE5PyUzzbo/OYiMldEdgbum4f72WTxc64gIm8H3sN2EZkQtK+jiCwMvIdfRaRdYPsR1Xki8kzK31lEagSq2m4Vkd+BbwLbxwX+DjsD/0bOCjq/hIi8HPh77gz8GyshIl+ISJ8072exiHQK9V5d+jxBHN9OAioA1YE7sH8PbweenwbsA/6bwfnNgBVAJeBF4E0RkWwc+wHwE1AReAb4ZwavGU6M3YCbgSpAUeAhABGpBwwNXP+UwOtVIwRV/RH4G7gkzXU/CDw+BNwfeD/nA62BuzKIm0AM7QLxXArUAtK2f/wN3AiUA64EeonI1YF9FwXuy6lqaVX9Ps21KwBfAK8F3ttg4AsRqZjmPRz12YSQ2ef8LlZleVbgWq8EYjgXeAd4OPAeLgLWpvd5hHAxcCbQNvB8EvY5VQHmA8FVooOApkBz7N/xI0AyMAq4IeUgEWkIVMU+G5cVquq34+SG/UdtE3jcEkgEimdwfCNge9DzGVgVFUAPICFoX0lAgZOyciz25XMQKBm0/z3gvTDfU6gY+wU9vwv4KvD4KWB00L5Sgc+gTTrXfg54K/C4DPblXT2dY+8DPgl6rsAZgccjgecCj98CBgQdVzv42BDX/TfwSuBxjcCxhYP29wBmBR7/E/gpzfnfAz0y+2yy8jkDJ2NfxOVDHPe/lHgz+vcXeP5Myt856L3VzCCGcoFjymIJbB/QMMRxxYHtWLsOWCJ5/Vj/fysINy9BHN82q+r+lCciUlJE/hcosu/CqjTKBVezpLEp5YGq7g08LJ3FY08BtgVtA1iXXsBhxrgp6PHeoJhOCb62qv4NbE3vtbDSQmcRKQZ0Buar6m+BOGoHql02BeL4F1aayMwRMQC/pXl/zURkeqBqZyfQM8zrplz7tzTbfsN+PadI77M5Qiaf86nY32x7iFNPBX4NM95QUj8bEYkRkQGBaqpdHC6JVArciod6rcC/6THADSJSCOiKlXhcFnmCOL6l7cL2IFAHaKaqJ3C4SiO9aqPcsBGoICIlg7admsHxOYlxY/C1A69ZMb2DVXUZ9gV7OUdWL4FVVf2C/Uo9AXg8OzFgJahgHwATgVNVtSwwLOi6mXU5/AOrEgp2GrAhjLjSyuhzXof9zcqFOG8dcHo61/wbKz2mOCnEMcHvsRvQEauGK4uVMlJi2ALsz+C1RgHdsaq/vZqmOs6FxxOEC1YGK7bvCNRnPx3pFwz8Io8HnhGRoiJyPtA+QjF+BFwlIhcEGpT7k/n/gQ+Ae7EvyHFp4tgF7BGRukCvMGMYC/QQkXqBBJU2/jLYr/P9gfr8bkH7NmNVOzXTufaXQG0R6SYihUXkeqAe8HmYsaWNI+TnrKobsbaB1wON2UVEJCWBvAncLCKtRaSQiFQNfD4AC4EugePjgGvCiOEAVsoriZXSUmJIxqrrBovIKYHSxvmB0h6BhJAMvIyXHrLNE4QL9m+gBPbr7Afgq2P0ut2xht6tWL3/GOyLIZRsx6iqS4G7sS/9jVg99fpMTvsQazj9RlW3BG1/CPvy3g2MCMQcTgyTAu/hGyAhcB/sLqC/iOzG2kzGBp27F3gemC3We+q8NNfeClyF/frfijXaXpUm7nBl9jn/E0jCSlF/YW0wqOpPWCP4K8BO4FsOl2qexH7xbwf+jyNLZKG8g5XgNgDLAnEEewj4GZgLbAMGcuR32jvA2ViblssGHyjn8hwRGQP8oqoRL8G4gktEbgTuUNULoh1LfuUlCBd1InKOiJweqJJoh9U7T8jsPOfSE6i+uwsYHu1Y8jNPEC4vOAnrgrkH68PfS1UXRDUil2+JSFusveZPMq/GchnwKibnnHMheQnCOedcSAVmsr5KlSppjRo1oh2Gc87lK/PmzduiqpVD7SswCaJGjRrEx8dHOwznnMtXRCTt6PtUXsXknHMuJE8QzjnnQvIE4ZxzLqQC0wYRSlJSEuvXr2f//v2ZH+yionjx4lSrVo0iRYpEOxTnXBoFOkGsX7+eMmXKUKNGDdJfx8ZFi6qydetW1q9fT2xsbLTDcc6lUaCrmPbv30/FihU9OeRRIkLFihW9hOdcHlWgEwTgySGP87+Pc3lXgU8QzjmX7xw6BG+9Bb+GsTjfnj2wLt1FGHPEE0QEbd26lUaNGtGoUSNOOukkqlatmvo8MTExw3Pj4+O55557Mn2N5s2b51a4zrm8IDERuneHW2+Fc86B6dPTP3bZMjj3XOjYEZKTcz2UAt1IHW0VK1Zk4cKFADzzzDOULl2ahx56KHX/wYMHKVw49J8gLi6OuLi4TF9jzpw5uROscy769uyBzp1hyhR4/HGYMAEuuwyGDoXbbjvy2A8+gNtvh9Kl7XGh3P+97yWIY6xHjx707NmTZs2a8cgjj/DTTz9x/vnn07hxY5o3b86KFSsAmDFjBldddRVgyeWWW26hZcuW1KxZk9deey31eqVLl049vmXLllxzzTXUrVuX7t27kzJT75dffkndunVp2rQp99xzT+p1g61du5YLL7yQJk2a0KRJkyMSz8CBAzn77LNp2LAhffv2BSAhIYE2bdrQsGFDmjRpwq/hFIWdc+nbsgUuuQS++caql55/HubMsW233w4PP2xVT/v3Q69eVspo0gQWLIDWrSMS0vFTgrjvPgj8ms81jRrBv/+d5dPWr1/PnDlziImJYdeuXXz33XcULlyYqVOn8vjjj/Pxxx8fdc4vv/zC9OnT2b17N3Xq1KFXr15HjR1YsGABS5cu5ZRTTqFFixbMnj2buLg47rzzTmbOnElsbCxdu3YNGVOVKlWYMmUKxYsXZ9WqVXTt2pX4+HgmTZrEp59+yo8//kjJkiXZtm0bAN27d6dv37506tSJ/fv3kxyB4q1zx43ff7eSwm+/wfjx0KGDbS9bFr74wr6/Bg2CX36BjRth3jxLGM8/DxEcQ3T8JIg85NprryUmJgaAnTt3ctNNN7Fq1SpEhKSkpJDnXHnllRQrVoxixYpRpUoV/vzzT6pVq3bEMeeee27qtkaNGrF27VpKly5NzZo1U8cZdO3aleHDj15kKykpid69e7Nw4UJiYmJYuXIlAFOnTuXmm2+mZMmSAFSoUIHdu3ezYcMGOnXqBNhgN+dcGgsWWAmgSBEoWhSKFbObCPz1F2zaZF/2mzbB999byWDyZLjooiOvU7gw/Pe/ULcu3HsvnHACfPrp4SQSQcdPgsjGL/1IKVWqVOrjJ598klatWvHJJ5+wdu1aWrZsGfKcYsWKpT6OiYnh4MGD2TomPa+88gonnngiixYtIjk52b/0ncuOfftg7FhrM/jxx8yPr1QJTj7ZGqOffx4aNkz/2N694YIL7Jw0Pw4jxdsgomznzp1UrVoVgJEjR+b69evUqcPq1atZu3YtAGPGjEk3jpNPPplChQrx7rvvcujQIQAuvfRS3n77bfbu3QvAtm3bKFOmDNWqVWPCBFs2+sCBA6n7nTsurV4NDz1kX9w9esCOHfajdN06WL/e9i9fbtXc8+fb9sRE2LwZFi+Gzz/PODmkaNTomCUH8AQRdY888giPPfYYjRs3ztIv/nCVKFGC119/nXbt2tG0aVPKlClD2bJljzrurrvuYtSoUTRs2JBffvkltZTTrl07OnToQFxcHI0aNWLQoEEAvPvuu7z22ms0aNCA5s2bs2nTplyP3bk8b8EC6NIFatWCV1893Mi8fLlVB1WrBlWrQmysVRE1bAiNG9v2fDD/WIFZkzouLk7TLhi0fPlyzjzzzChFlHfs2bOH0qVLo6rcfffd1KpVi/vvvz/aYaXyv5M7phYvtl5Cp58OcXH2q7xEiSOP2b3bvuRXrrT2g5NOstvJJ1u30m++gYEDrTtqmTLWq+ieeywZ5DMiMk9VQ/apj2gbhIi0A14FYoA3VHVAiGOuA54BFFikqt0C228C+gUOe05VR0Uy1oJsxIgRjBo1isTERBo3bsydd94Z7ZCcy32JiTaOoEKF0PsPHIDnnoMBga+hlBJ7TAzUrw9nnw1//mmJYf369F+nWDG71kknwYABbLm2FxNnnECFuXB1/ssPGYpYCUJEYoCVwKXAemAu0FVVlwUdUwsYC1yiqttFpIqq/iUiFYB4IA5LHPOApqq6Pb3X8xJE/uV/J5djc+bAP/8Ja9bYmIAbb7QBZykdQmbPtoFmv/xi+wYPtl5D8fEwd67dL1liJYQzzzx8q1PHxh4E9zjatIk/qzbhkyLX8dGnRZgxww4pVAimToVWraL6SWRZtEoQ5wIJqro6EMRooCOwLOiY24EhKV/8qvpXYHtbYIqqbgucOwVoB3wYwXidc/lNUhL07w//+hecdpqNDRg3zpJAr15wzTVWffS//9n+r76Ctm0Pn1+1qk1TkZn69VMf9u4Nrz8EqlC7Njz6KFx5peWfLl2sWeKUUyLwXtOxbRuULAmR6HgYyUbqqkDwDFLrA9uC1QZqi8hsEfkhUCUV7rmIyB0iEi8i8Zs3b87F0J1zed6KFdC8uVUb3XgjLFpk7QK//grffQfdusEnn1hy6NPHSgjBySEbVq2CIUPg+uvh55+tQPL88xbGRx9ZDVeXLpa3joXkZOjaFVq2jMhUTFEfB1EYqAW0BKoBM0Xk7HBPVtXhwHCwKqZIBOici5ING2xMwccf2zfvCSccvhUvDqNHW+ngo4/gH/84fJ6IjRe44ALrWbRjh1Ud5YL//c/GrQ0efPQl69WDESNsBownnoAXX8yVl8zQoEHw9dc27CICUzFFNEFsAE4Nel4tsC3YeuBHVU0C1ojISixhbMCSRvC5MyIWqXMub9i61b7wP/wQZs60epzGjaFGDdi1y9oAVq6EnTuhTRsYNizj+pwSJY7uoZRN+/fD22/D1Venn2+6dYNZs+Cll6xUcfXVufLSIf3wgyWia66BiPU7UdWI3LDksxqIBYoCi4Cz0hzTDhgVeFwJq1aqCFQA1gDlA7c1QIWMXq9p06aa1rJly47adiy1bNlSv/rqqyO2vfLKK9qzZ890z7n44ot17ty5qqp6+eWX6/bt24865umnn9aXXnopw9f+5JNPdOnSpanPn3zySZ0yZUpWwj9mov13clGQnKy6erXq+PGqzzyj2qmTas2aqpYSVOvUse0rVkQ70lTvvGOhTZuW8XH796vGxamWLauakBCZWLZvV61RQ7V6dXucE0C8pvO9GrEShKoeFJHewGSsm+tbqrpURPoHApoY2HeZiCwDDgEPq+pWABF5Fuv5BNBfAw3W+UnXrl0ZPXo0bYPqPUePHs2LYZY9v/zyy2y/9oQJE7jqqquoV68eAP3798/2tZzLib17Ye5PysWnrbG1DaZPhxkzrAoJrEqoVi1o2hRuucVafBs2tO15yNCh1iidWS+lYsWsnbxJE2uP+Omn3H0rqja56/r11tRSrlzuXTvEi0WmBHGsb3mxBLF161atXLmyHjhwQFVV16xZo6eeeqomJydrz549tWnTplqvXj196qmnUs8JLkFUr15dN2/erKqqzz33nNaqVUtbtGihXbp0SS1BDB8+XOPi4rRBgwbauXNn/fvvv3X27Nlavnx5rVGjhjZs2FATEhL0pptu0nHjxqmq6tSpU7VRo0Zav359vfnmm3X//v2pr/fUU09p48aNtX79+rp8+fKj3tOaNWv0ggsu0MaNG2vjxo119uzZqfsGDBig9evX1wYNGuijjz6qqqqrVq3S1q1ba4MGDbRx48aaEOInVbT/Ti5CkpNV58zRgc0nKKjOo7H9BK9SRfW661SHDFH94QfVPXuiHWmmFi600AcPDv+cf//bzlmzJuPjtm5VbdNG9ZZbVEeNUl27NuPjhw2z6w4cGH4sGSEaJYi8JhqzfVeoUIFzzz2XSZMm0bFjR0aPHs11112HiPD8889ToUIFDh06ROvWrVm8eDENGjQIeZ158+YxevRoFi5cyMGDB2nSpAlNmzYFoHPnztx+++0A9OvXjzfffJM+ffrQoUMHrrrqKq655pojrrV//3569OjBtGnTqF27NjfeeCNDhw7lvvvuA6BSpUrMnz+f119/nUGDBvHGG28ccb5PC+4ypGojlT/80BqRf/uNGYUmATC0+XuMGIGNL8hjpYPMDBtm7eI33RT+ORdcYPc//mhNKOn5+msbP1G6tA3wBuuRe9FF9lFVq3b4tnOnfZe1bWtTP0Waz8UUYSnVTGDVSynrMYwdO5YmTZrQuHFjli5dyrJly9K9xnfffUenTp0oWbIkJ5xwAh2CpvldsmQJF154IWeffTbvv/8+S5cuzTCeFStWEBsbS+3atQG46aabmDlzZur+zp07A9C0adPUCf6CJSUlcfvtt3P22Wdz7bXXpsYd7rTgKftdHqRq/Tg/+shGFGfVpk1w1VX2y2nQIDjzTA69/Q6zS7elUCH4YGE9dlatl++Sw+7d8N571rU1vUHaoTRoYEkls0ldv//exjFs3Wo9dV97zVYRnTrVGqFvusnG/tWpY9vLlYN33olMr6W0jpsSRLRm++7YsSP3338/8+fPZ+/evTRt2pQ1a9YwaNAg5s6dS/ny5enRowf79+/P1vV79OjBhAkTaNiwISNHjmTGjBk5ijdlyvD0pgv3acELmHnzrE1g9mwbjfxXYKxqhQr2TdWtW3hf6J99Zu0He/bYWISbb4bKlVm8wDofPfCAdQ19910baJafvP++va1evbJ2XpEi1g6RWYKYM8dm+y5a1JJKgwY2bAOs/eaPP6y9Yf16G8x91VVQpUr23ktWeQkiwkqXLk2rVq245ZZbUksPu3btolSpUpQtW5Y///yTSZMmZXiNiy66iAkTJrBv3z52797NZ599lrpv9+7dnHzyySQlJfH++++nbi9Tpgy7d+8+6lp16tRh7dq1JCQkADYr68UXXxz2+/FpwQuI5GQbdRwXZ/c//wzt2llH/2nT7OfqDTfYKOM//kj/On//DT172uI11apZwnnkEahcGbCeqmDVInFx1tAbqflBV660tu/cpGoxN2pkv96zqlkzm907vYFz+/ZZ1Xfz5qH3lywJZ5xhA+FuuMH+VMdyVhpPEMdA165dWbRoUWqCaNiwIY0bN6Zu3bp069aNFi1aZHh+kyZNuP7662nYsCGXX34555xzTuq+Z599lmbNmtGiRQvq1q2bur1Lly689NJLNG7c+Ij1oosXL87bb7/Ntddey9lnn02hQoXo2bNn2O/FpwUvAPbvt+41gwbBXXfZz9KEBBg1Cu64w6as/u47ePllm630rLNs3969to7BwoWWRN5/33oeDR9u31w//GCjxYJ8953Vv596qv0CX7bMxglEwh132K/rffty75rff29NKr16Za9mrFkz+7gXLw69Pz7e5gw8//ycxRkx6bVe57dbXuzF5MLjf6djaMsW1RYtrBvMoEHW0ygjK1eqXnDB4fEJaW9Vq6Y7MCA5WbVyZdV//tOe79ljYwO6ds3l96Sq69apilhIn32W9fOTk1UXL1adPfvI29VXq5Ypo7p7d/biWrPGYhoyJPT+AQNsf6CzYlTgvZicc6xeDVdcAWvXwpgxcN11mZ9TqxZ8+6210m7YYMtdVqx4+Hb66emOVF650hZMS1liuVQpa3AdOtTaBHOzHn3MGMtYxYvDhAlWkgiHqs3f9+yzVloI5e67rYdRdlSvbu/zxx+tsJbW99/bR1ypUvauH2meIJwraJKTYelSa9XcsOHw7dNPrT5j6tTDfTDDUaiQTYaXRSntDxdeeHjbnXda2/fbb9ssqLnlgw+sjaNWLZg40abfjolJ/3hVO+6556ya57TT4D//sYFwwQoVyln1j4hVM4VqqFa1BNGu3dH78ooCnyBUFcln3eqOJxqpFsvj1Y4dNjnPtGlHbq9SxZa8HD7cGqCPgZkz7WWDv3Tr1YOLL7a28Icfzp2umitWWEPwyy9bO/mHH1rPoODEFGz9emjf3ppSataEN96wpSSKFs15LKE0a2advLZvh/LlD29fvdo6jaXXQJ0XFOhG6uLFi7N161b/EsqjVJWtW7d6V9nc8vvvVjL49ltrgJ41y6qTDhywcQ3ffnvMkgNYA/WFFx7duNuzp63r8/XXR25PWb/nwIGsvc6HH9prXH89XH65fdF/8kn6xw8YYI3lI0dacrn11sglB7AEATblRrCUKq0820BNAS9BVKtWjfXr1+NrReRdxYsXp1q1atEOI/9bsMDmMPr7b6tUb906quH8/jv89puNf0irc2crWQwdalMuffGF/cKeOtU6SrVoYdU/4QxKU7UE0bLl4eWg27SxdoiXXz46OW3bZtVb3bplbVR0TpxzjsXx449HLkcxZ44tZ33WWccmjuwo0AmiSJEixMbGRjsM57ImIQEuvdS+WV59NfO1DL780hqcK1SwAW9Bq59Fy3ff2X2oap6iRe1X+wsvWCIAawPo0cO6xPbrZ+d99ZV1j83I/PnWGB487USnTvaRLF5sCSjYiBGWhAIzyxwTZcta7V7adojvv7fSRUZtJdFWoKuYnMt3Nm2Cyy6ztoSJE21U1LBhoZcLW7sWnnzSBqnVrm3jELKQHFRtOeZI1MDOnGnr+qQzvRh9+lhTyfPP2/QSa9faSm0PP2yJYf16q3rJZOYYPvjARiwHrxfUvr39Yg+Mz0yVlGQN0a1bH504Ii2loTrls96zxxJYXq5eAgr2OAjn8pUdO1QbNlQtWVJnDluqG2f/qnrJJdZRvnlz1SVLVHfuVH3zTdWLL1YFTQZN6nSt6q5dWX65IUMy7qOfE2eeqXr55dk/f9Ei1ZNPVi1XTnXmzNDHHDyoesopqh06HL3vggvsowz2/vv2fj//PPtxZdfQofbaKZMZT5tmzydNOvaxpEUG4yCi/sWeWzdPEC5f27dPtWVL1cKFdWifJQo2QOvlQcma+MYo1QoVVIsUUS1eXBX0UK06+uF147XmaYnavHnm493SWrfOrg+26ExiYsbHf/qp6s8/h3ftv/6y677wQtZiSmvtWls3qFgx1Q8/PHr/9On2OqNHH71v0CDbt3q1PU9OtkV86tRRPXQoZ3Flx4IFFs/779vz556z59u2HftY0vIE4VxedvCgaufOqqDv3zVLRVTbtlW94gr7H3rWWarTP9mu2qeP6t1367T/LtOmTZMVVE880Y6ZMSNrL3n11ZZrXnnFzn/33fSPXbRItVAhe62NGzO/9vjxds1Zs7IWUyhbthweyN27t63WluL221VLlVL9+++jz0tIsHNeecWef/edPR86NOcxZUdSkmrJkqr33GPPr7hCtV696MSSVtQSBLak6AogAegbYn8PYDOwMHC7LWjfoaDtEzN7LU8QLl9KSlK9805V0Am3fKoxMVaQ2LvXfvV++qktLQmqXbpYtQ2onnaaLYG5Z49qxYr2hR+ulC/wAQPs13T9+paEQv2yTk5Wbd3aqnpKlFBt1cryWUbuu8+ST/CXeU4kJqo+8IDFfM45VrI4cEC1fHnV7t3TP+/ss1Uvusged+pkhbBQyeRYufBC1WbN7DOtUEH11lujF0uwqCQIbJnRX4GaHF6Tul6aY3oA/03n/D1ZeT1PEC5PSU62NoX0JCZaW0JgHeap1w/XokVVzz336OaEvXtVn37aqlrKl1d96SWrkUrxxBM2D1E46x/v2GF1+w0bHq5Wevdd+yaYOPHo4z/7zPa9+qrq22/b46AFEENq0sSaSHLb+PE2l1P58paEQPWLL9I//sknreTzww/2+Tz+eO7HlBUPPaRatKiVyMD+/HlBtBLE+cDkoOePAY+lOcYThCt4/vrL1pAE1bp1rW7k00/t2zkxUXXECNXYWNvftKnOefE7LVUqWevXt+Un07NtW+hJ4zZsUC1cWPXeezMPrVcv+9L86afD25KSrJRy/vlHtmUkJlqdfZ06h5NJjx72ZTtlSujr79xp13/yycxjyY6EBNXGgZVLK1bMuO1k/nxNbWMpUsQ+p2gaN87i6dXL7vPKHJXRShDXAG8EPf9n2mQQSBAbgcXAR8CpQfsOAvHAD8DV6bzGHYFj4k877bTIfYLOheuHH1SrVbOf+w88oNqundXNgGpMjGqlSvY4Lk718891y+ZkLVdO9YwzwqvfT0/37tbovHNn+sfMmmUvfd99R+9L6dH07beHt736qh41O+qePVZ3XqWK6h9/HH2dSZPsnPQSSG7Yt0+1b1/VN97I+LjkZEsOcHhG2Wj6/XeLpWRJq7KLRmN5KHk5QVQEigUe3wl8E7SvauC+JrAWOD2j1/MShIuq5GT7li1SxH6Oz5t3eN/+/daK3K+f6rXXWr1I4Kf655/b/8Lp03P28nPn6hGNsmnt329f7KedFroUsnevfem3a2fPt261qpzWrY/uIbV0qX3JtWxp7RE7d6p++aXqo49agX57XwQAACAASURBVCkmJvvTY+e2e++1zyX4zxEtyclWvQc56wKc2/JsFVOa42OAnensGwlck9HreYJwUbNnj+oNN9h/pyuuyLieKI1//ctOy6i5IlwtWljNVdpG5MRE1euvP7o0kF4s8+fbF2uhQlZfHsrIkXZszZp2HFhubN5c9b//zfl7yS2bN0dn3EN6rr7aPqv+/aMdyWHRShCFgdVAbFAj9Vlpjjk56HEn4IfA4/JBJYtKwKq0Ddxpb54gXG7atct+8M+dm8FBCQmqDz9s1UYi9r8+i/UGXbpYgSM3pNRxf/LJ4W379qm2b2/bX3wx4/N37FA94QTrVlq4sHUjzcjDD1sp4qmnbOBXNHsI5RcvvGB/i6lTox3JYdHs5noFsDLQm+mJwLb+QIfA4xeApYHkMR2oG9jeHPg5sP1n4NbMXssThMst8fHWJgCq3bql2ZmUZN/AbdtqartC587Z7vRfr55qx445jzkltOrVD/cg2rPHqohA9fXXw7vGo49q6iC9TZtyJy532Lp1VjrLrS7AuSFqCeJY3jxBuJxKTrY6/CJFrJ25YUPV2rWDDli82L7RU5ba/L//U12/Ptuvt2+f5Zfc7PGTMoJ4+nSrcipUSHXUqPDP37jRGlBffjn3YnJ5W0YJwifrcw7YssXmvLv/fltTYOFCm0xu5UrYuUNtwrxzzrH5oseNs9nlnnrq8BzT2bB8ua18lt6Edtlx6622tOell9r6A2PHZm0xuJNOsvkCQ03T7Y4/niDccW/7dmjSxBawee01mwW0YkVbwhJgQcdnoFcvW3Rg0SLLHIVzPlP+okV2n5sJolw5W9azcGF7H8GznIarWLHci8flb54g3HFv1ChYt84SRJ8+gUVmVGmaaEt+xc/aBy++aIsMVKly1PnjxtmSlZMmWYkgXIsXQ4kScPrpufRGAl580ZagvuKK3L2uO/6IVUHlf3FxcRofHx/tMFw+o2pLLpQvD9/PUfj5Z6uXGTcOVq6kRsw6zmtVgtFTKqZ7jXPOsaUyAU45xap0br75yLWYQ2nTBnbtOnopSueOJRGZp6pxofZ5CcId12bMsHWJe574iS371bChLXVWrRoMG0bTK05k3tr0k8POnbaqWd++8PHHVlX14ou29HPHjqHX+QFLTIsW5W71knO5zROEK7h27bKK+F27Qu9PSmLoA6soL9u57tPuqUmBjRth2jS4807izi9CQoK1U4Qya5Ylgcsus7WWP/vMVkO7+25bEG7BgtDn/fmnNYx7gnB5mScIVzCpWsNAp07WbvCPf8BHH8G+fbbviy/YVO8SPllYgx7VplFi4fepSSG4nSGloXr+/NAvM2OGrbF83nmHt518snVwAls+M5TFi+3+WC996VxWeIJwBdPbb9tP+AcegDvugNmz4dpr7cs/Lg6uuoo3t3fiIEXoOeUf6X5TN2li9+k1b82YYcmhRIkjt1epAo0bw+TJoc9LSRBnn531t+bcseIJwhU8q1fDvfdCq1bw0kvWd3XDBpg6Fbp0gaQkDg1+leGl7qd1a6hdR9K9VMWKEBsL8+YdvS+l/aFly9DntmsH339vx6W1aJHVaFWokL236Nyx4AnCFQhjx0K/flg/0xtvhEKFYORIuweIiYHWrWHECFi8mEm17uH334WePTO/dlxc6BJESvtDegmibVs4eBC++ebofYsXe/uDy/s8Qbh878cf4YYbrLCQPPAlq04aMgROOy3dc4YOtVHDHTtmfv24OFizBrZuPXJ7qPaHYOefD6VLH13NlJhoo6g9Qbi8zhOEy9f++ssGNicl2RfvxqeHWVtD9+7pnrNmjQ1qu+02KFIk89do2tTu0zZUp9f+kKJoUSu0TJ5s7eIpVqyweD1BuLzOE4TLtw4etCaFLVvgX/2TAFhTtpEVDyT9doURI2z3HXeE9zqhGqoza39I0batTdu0cuXhbSkN1J4gXF7nCcLlP4mJ8PPP9Ou8jOnTYeiZr9F5WFsA1tzc31qWMzj1zTfhqqvg1FPDe7ny5eGMM45MEJm1P6Roa2EdUc20eLGVLjIbae1ctOV8xjHnImn3bpg716ZXXbTI7pcvZ3zSVQxkPD1lGD32D2N/s0bwCawpk/HP8hkzrFrqttuyFkZcHMyZc+R1ihWzdoaM1KwJtWpZgrjnHtu2aBGcdVZ41VvORZMnCJd37dhh9TDr1tnzk0+GRo34pdlN9HivD+eevpd/z74ZTuhJceCUqta+kJFffrH7c8/NWihNm8Lo0bB5M1SufLj9oXjxzM9t29ZKLfv32/GLF9vIa+fyuohWMYlIOxFZISIJItI3xP4eIrJZRBYGbrcF7btJRFYFbjdFMk53bCUn26/oTOeJ7NfPxi+MHm1zU/zxB3+88SXtpz9A8dJF+OjLkhQ74fDc1LGxmSeIVaugTJmQk7JmKGVE9bx54bc/pGjXzgZwz5plCWbjRm9/cPlDxEoQIhIDDAEuBdYDc0VkoqouS3PoGFXtnebcCsDTQBygwLzAuenMiOPyi4MH4fbbbYjChAkZdDONj4fXX7dJja6/HrCqodatbUGbKVOObkOIjYWZMzN+/VWrrMongzbskIIbqg8dCq/9IUXLltbmMHny4WEZniBcfhDJEsS5QIKqrlbVRGA0EEavcwDaAlNUdVsgKUwB2kUoTneMJCZCt26WHAoXhk8+SefAQ4egZ0848UR47jnAxiC0aQO//QZffBF67EFsrE2Ul5SUfgwrV1qCyKoTTrBG5XnzDrc/pDf+Ia1SpeCCC2xeJu/B5PKTSCaIqsC6oOfrA9vS+oeILBaRj0Qk5TdhWOeKyB0iEi8i8Zs3b86tuF0E7Ntns52OGweDBlmh4Isv0llgZ+hQ+yYePBjKlmXHDqvHX7nSple66KLQrxEba7/sf/899P7EREsw2UkQcHhEdVbaH1K0awdLltj4ixNPzHoVl3PREO1urp8BNVS1AVZKGJWVk1V1uKrGqWpc5cqVIxKgy7k9e+DKK21BtmHD4MEHbf3nLVvghx/SHLxxIzzxhBUXunRh925bGW3xYhg/3janJzbW7tNrh1i92hJIThLE+vWWu8KtXkqR0t3166+99ODyj0gmiA1AcC1xtcC2VKq6VVUPBJ6+ATQN91yXP+zcaT12Zs6Ed96x2bTBvjALF7b1E47w4IPW3WfIEBDh2mttxbUxYzJfQjOzBLFqld3nJEGANa5nNUGcfbZ1wgJPEC7/iGSCmAvUEpFYESkKdAEmBh8gIicHPe0ALA88ngxcJiLlRaQ8cFlgm8tnnn/e5koaO9bmS0pRtixcfHGaBDF1Knz4oS3PVrs28fHWsDtwoC3rkJlq1SzpRCpBNG5sjdtZaX9IIXK4FOFrQLj8ImIJQlUPAr2xL/blwFhVXSoi/UWkQ+Cwe0RkqYgsAu4BegTO3QY8iyWZuUD/wDaXj2zfbs0J111n7Q9ptW8Py5bB6pUHrXHhjjvg9NPhsccAO7dUKev1FI6YGJufL6MEUa5chgOtM1S6NNSvD82bZ639IUXHjpYosjoGw7loiehAOVX9Evgyzbangh4/BjyWzrlvAW9FMj4XWa+/bu0PfY8aAWPan7OJ+ziJz859lnt39rc6mDFjoHhxtm+3wsQ//2k9iMJVo0bGCaJ27ax3cQ02fryVILKjY0drJA93ig/noi3ajdSugNq7F/79b2s3OKpKZeNGuOYaal5UjXosZWLM1fbN+9tvcOGFALz7rvV8Cme9hmCxsTY5XigpYyBy4owzsv8FL+LJweUvPtWGi4g337ReSkeVHhISrNX6zz/hwQdpv+MUXn6rPDsvaUzZwNxEqtbbqVkzq/fPithYu/TevVCy5OHt+/fbjB05TRDOHU+8BOFyXVKSjXVo0SK1QGAWLLCNu3bB9OkwcCDtbyzPwYM2iCzFt9/agjpZLT3A4Z5MaUsRv/5qiccThHPh8wThsuXHH61dOZQPP7TBao8Fty5Nn27dlooXt0mJAi21550HlSod2Ztp2DBrTA7MsJEl6XV1zWkPJueOR54gXJYdPGg9kzp2hF69bIRyiuRkGDDA+v2njlv4+GMbSnzqqbYcaN26qcfHxBweRHfwoFUPjR8PPXqkv1JbRjxBOJd7PEG4LPvsMyshtGtnv/YvvtgmXQUrVSxfbm0PIlhXpmuvtfmyv/vOBiuk0b69dYmdM8faLpKSsle9BDaNRYkSoRNEpUpWMnHOhccThMuy//wHqle3RDFuHPz8s812OnMmvPCC/Yq/7ppkePhhm431yittEFyFCiGvd9llNtvphAkwfDi0agV16mQvNpHQXV1zoweTc8cbTxAuS37+2ZoT7rrLRi1fc41NhVGunH2x//QTPHxvIoW7X28t1Xffbd/8wV2K0ihTxqaueP116+naq1fOYgy1LoQnCOeyzhOEy5L//teqcIKX7KxXzxJDp05Qt9ZBenzYFj76yBLEf/5jDQ2ZaN8eDhyAk06Cq6/OWYxpE8TevVYF5gnCuazxBOHCtm2bDWDr3v3o2qKyZeGjgb+yLPlMSiz83uqeHnww7GHL7dvbYjq3357ztZpjY22SwO2B5aUSEuzeE4RzWeMD5VzY3nrLRjf36RNi59q10KoV8vff8M03NmFRFlSvbsMkgjo4ZVtwT6by5b0Hk3PZFVYJQkTGi8iVIuIljuPUoUM2A/fFF4eYrnrDBlsLdPdumDYty8khRYMG1lidUzVq2H1KNZMnCOeyJ9wv/NeBbsAqERkgItnsY+Lyq88/t0LCUaWHv/6yVXz++suGQzdqFI3wjpB2LMSqVdb9tUyZ6MXkXH4UVoJQ1amq2h1oAqwFporIHBG5WURyWGPs8oP//MfGuXUMXlV82zbro5qyUHSzZlGLL1j58tYmEpwgvPTgXNaFXWUkIhWx9RpuAxYAr2IJY0pEInN5xtKlVnOU0rUVsPmULr/cRsVNmJD+QtFREjyr68qVniCcy45w2yA+Ab4DSgLtVbWDqo5R1T5A6UgG6KJn716bc6lfP5tC6bbbsBnvUkoL8+dbb6XLLot2qEdJ6eq6a5dN3+EJwrmsC7cE8Zqq1lPVF1R1Y/AOVY1L7yQRaSciK0QkQUTSWTYGROQfIqIiEhd4XkNE9onIwsBtWJhxuhx67z3rxlqvntXZn3eeFRB694ZK6xZYe8NVV1mr9eefQ4cOmV80ClJKEN5A7Vz2hdvNtZ6ILFDVHQCBdaK7qurr6Z0gIjHAEOBSYD0wV0QmquqyNMeVAe4FfkxziV9VNfotnseRqVNtBbdTTrGpk6691tqcG5+8iepD+0LTd2wAxH/+A3femfMBCxEUG2tdcmfPtue1a0c3Hufyo3ATxO2qOiTliapuF5Hbsd5N6TkXSFDV1QAiMhroCCxLc9yzwEDg4bCjdrnu0CF44AHrIrp8edCay3v3Qt1zrZfSww/bHN75YMa7lJ5MX39t92ecEb1YnMuvwq1iihE5PCQ2UDrIrMd6VWBd0PP1gW2pRKQJcKqqfhHi/FgRWSAi34rIhSH2u1z05ps2z9KLLwYlB4DBg20ptsmTYeDAfJEc4HCCmDEDqlbNcCoo51w6wi1BfAWMEZH/BZ7fGdiWbYFBd4OxnlFpbQROU9WtItIUmCAiZ6nqrjTXuAO4A+C0007LSTjHtV274Mkn4YILbPK9VJs22eIOnTvbCLl8JGWw3N9/wznnRDUU5/KtcEsQjwLTgV6B2zTgkUzO2QAEL9FeLbAtRRmgPjBDRNYC5wETRSROVQ+o6lYAVZ0H/AocVYusqsNVNU5V4ypXrhzmW3Fp/etfVoM0eHCaqZOeecZm0BswIFqhZVvJkjY4DryB2rnsCqsEoarJwNDALVxzgVoiEoslhi7YaOyUa+4EKqU8F5EZwEOqGi8ilYFtqnpIRGoCtYDVWXhtF6Y1a+CVV+CGG9L80l62DEaMsO5L+fQbNjbWu7g6lxPhjoOoJSIficgyEVmdcsvoHFU9CPQGJgPLgbGqulRE+otIZn0jLwIWi8hC4COgp6puCydWlzV9+9ps3C+8kGbHI49YP9cnn4xKXLkhpZrJE4Rz2RNuG8TbwNPAK0Ar4GbCSC6q+iXwZZptT6VzbMugxx8DH4cZm8um2bNh7Fh46qk0K4FOm2aD4V580dbpzKdSGqo9QTiXPeG2QZRQ1WmAqOpvqvoMcGXkwnKRlpwM999vYx4eCW5NOnTI1nGoXj2deb3zjyuvtNlAPEE4lz3hliAOBHodrRKR3libgk+xkY998AHMnQsjR0KpUkE73nsPFi2yA47o75r/tGgBX36Z+XHOudBEVTM/SOQcrB2hHDaw7QTgJVX9IbLhhS8uLk7j4+OjHUa+sHcv1KkDVapYkiiUUo78+2/bUbUq/PBD2KvBOefyLxGZl96USZmWIAKD4q5X1YeAPVj7g8vHBg2C9evh/feDkgNYm8OGDTB6tCcH51xYDc2HgAuOQSzuGPjjDxsQ3blzmhm6f/vNEkSXLjZizjl33Au3DWKBiEwExgF/p2xU1fERicpFzBNPwMGDlguO8MgjVmoYODAqcTnn8p5wE0RxYCtwSdA2BTxB5CPz58OoUdZJ6fTTg3bMnGn9XZ95BnzKEudcQFiN1PmBN1JnTBVatrQB0gkJtiQnYN1a4+Jg61b45Ref1c6540yOGqkDF3gbKzEcQVVvyWFs7hj55BMrKLz+elByAHjrLVi40BqmPTk454KE2831H0FPiwOdgD9U9Z5IBZZVXoJI34EDcNZZNqxh4cKgdaV37rRRZHXqWPbwnkvOHXdyXIIITH0RfMEPgVm5EJs7Bt58E379FSZNCkoOAM8+C1u2wFdfeXJwzh0l3Kk20qoFVMnNQFxkHDwIL71ka0u3bRu0Y/58ePVVuPVWaNIkavE55/KucNsgdnNkG8QmbI0Il8eNGwdr19qU3qmFhD//hI4d4eSTbTEI55wLIdwqpjKRDsTlPlUb1lC3LnRImWA9MdGWjdu6FWbNAl9oyTmXjnDXg+gkImWDnpcTkasjF5bLDV9/bfPuPfJI0JQa99xjieHNN71qyTmXoXDbIJ4OrAAHgKruwNaHcHnYwIE271737oENw4bB//4Hjz4KXbtGNTbnXN4XboIIdVy4o7BdFPz0E0yfbms+FC0KfPedre9w+eXw/PPRDs85lw+EmyDiRWSwiJweuA0G5mV2koi0E5EVIpIgIn0zOO4fIqIiEhe07bHAeStEpG1657rQBg6EcuXgjjuAdevgH/+AmjVtnYeYmGiH55zLB8JNEH2ARGAMMBrYD9yd0QmBacKHAJcD9YCuIlIvxHFlgHuBH4O21QO6AGcB7YDXA9dzYVixwkZO33UXlCmVDDfdZItAfPqpZQ3nnAtDuL2Y/gbSLQGk41wgQVVXA4jIaKAjsCzNcc8CA4GHg7Z1BEar6gFgjYgkBK73fRZjOC4NGgTFill7NK++anVNI0ZYdybnnAtTuL2YpohIuaDn5UVkcianVQXWBT1fH9gWfN0mwKmq+kVWzw2cf4eIxItI/ObNm8N4JwXfxo3wzjtw881w4pal8Nhj0L69DYhzzrksCLeKqVKg5xIAqrqdHI6kDqxxPRh4MLvXUNXhqhqnqnGVvT8/CxfClVfa6OkH+yTCDTfACSdY6cGn0nDOZVG4CSJZRFIXChCRGoSY3TWNDcCpQc+rBbalKAPUB2aIyFrgPGBioKE6s3NdkAMHoF8/OOccWzFu/Hg4/d1nLGOMGAEnnhjtEJ1z+VC4XVWfAGaJyLeAABcCd2RyzlyglojEYl/uXYBuKTsD4yoqpTwXkRnAQ6oaLyL7gA8CvaVOweZ++inMWI8rP/xgtUfLlllb9ODBUGHZLOvGdOutNqWGc85lQ1glCFX9CogDVgAfYtVC+zI55yDQG5gMLAfGqupSEekvIh0yOXcpMBZr0P4KuDuwNrYL8sor0Lw57N5tM7WOHAkViuyGG2+E6tXtAOecy6Zw14O4DeuKWg1YiFUHfa+ql2R44jF0vK0HMWcOXHihzbE0apQ1NQDQsycMH27rO1xwQVRjdM7lfRmtBxFuG8S9wDnAb6raCmgM7Mj4FBcpu3bZ9BnVq6dJDtOn21QaDzzgycE5l2PhtkHsV9X9IoKIFFPVX0SkTkQjc+nq0wd+/90KCanJ4e+/4bbb4IwzoH//qMbnnCsYwk0Q6wPjICYAU0RkO/Bb5MJy6Rk71sY5PPkktGgRtKNfP1i9Gr791teWds7lirDaII44QeRioCzwlaomRiSqbDge2iDWrYMGDaB2bZuxu0iRwI7vv7ds0asXDBkS1Ridc/lLjtekDqaq3+Y8JJdVyYEplZKS4P33g5LD/v1wyy1w6qkwYEBUY3TOFSw+ZXc+8cor1gb9xhvWzJDq2Wfhl19g8mQo4wv/OedyT7i9mFyUDRkCrVtbYSHV/Pk2IO7mm+Gyy6IWm3OuYPIEkQ/s2QNr1kCrVkFTKu3YYavCVakCL78c1ficcwWTVzHlA8sCE6TXrx/YcOgQdOliWeObb6B8+ajF5pwruDxB5ANLlth9aoJ49FFrcxgxwgfEOecixquY8oElS6BECYiNxQZBvPwy9O5tA+Occy5CPEHkA0uWQL16UGjuj7bIdKtWNm2rc85FkCeIfGDJEqhfcy906gSnnALjxgUNhHDOucjwNog8butWW0a0fvxIm6Vv8mSoWDHaYTnnjgOeIPK4pUvtvv6aiTDi33D22dENyDl33PAqpjxuyXyb7qr+WdiAOOecO0YimiBEpJ2IrBCRBBHpG2J/TxH5WUQWisgsEakX2F5DRPYFti8UkWGRjDMvW/LhYsqyg6r/fQxiYqIdjnPuOBKxKiYRiQGGAJcC64G5IjJRVZcFHfaBqg4LHN8BGAy0C+z7VVUbRSq+fOGPP1gSv5/6FTciLS+OdjTOueNMJEsQ5wIJqro6MC34aKBj8AGquivoaSkga3OPF3D6+BMsSa5H/ctOiXYozrnjUCQTRFVgXdDz9YFtRxCRu0XkV+BF4J6gXbEiskBEvhWRC0O9gIjcISLxIhK/efPm3Iw9+ubNY+OoyWynAvWbl412NM6541DUG6lVdYiqng48CvQLbN4InKaqjYEHgA9E5IQQ5w5X1ThVjatcufKxCzqXJCfbmtI7d6bZoQr33ceSsjaNRuoUG845dwxFMkFsAE4Nel4tsC09o4GrAVT1gKpuDTyeB/wK1I5QnFEzeTL06AH//neaHR9/DLNmseTS+wE466xjHppzzkU0QcwFaolIrIgUBboAE4MPEJFaQU+vBFYFtlcONHIjIjWBWsDqCMYaFcOH2/3o0VZoAGDzZnjwQWjQgCWlm3HiiZAPC0fOuQIgYr2YVPWgiPQGJgMxwFuqulRE+gPxqjoR6C0ibYAkYDtwU+D0i4D+IpIEJAM9VXVbpGKNhj/+gM8+g+rVbUG4n3+GBmfshQ4d4K+/YOxYlvQp5NVLzrmoiehIalX9Evgyzbangh7fm855HwMfRzK2aHvrLVvWYfRom7F79AfJNFjRHX78ET76iORzmrF0Kdx+e7Qjdc4dr6LeSH08OnTI1pZu0wbOOw/atFFGD92GTphgDRKdO7N2Lezd6w3Uzrno8QQRBV9/Db/9ZjN3A3QpN5k1uyoxt+srcI/19D1qkSDnnDvGPEFEwfDhtpR0x47AmDFcPaYLRQslMfrEwzVuKQmiXr3oxOicc54gjrGUxumbb4aivyfAjTdS7sIGXH5FIcaMFZKT7bglS6wB+4SjRn8459yx4QniGEtpnL7tNuD//s8m4Bs7li7dY/jjD5g1y45bssSrl5xz0eUJ4hgKbpw+I2k5fPCBrS190km0bw8lS1qvpqQk6/rqCcI5F02eII6hIxqn/+//oEQJePhhAEqVgvbtbTXR5cstSXiCcM5FkyeIYyi1cfr0JTBmDNx77xHDpLt0gS1b4LXX7LknCOdcNHmCOEY2bAhqnH7+aWt9fvDBI45p1842jxwJhQpB3brRidU558ATxDHTt6996d/RYimMHw/33w8VKhxxTPHi0KmTtVXUqmXPnXMuWjxBHAPTpsF778Gjj0LN4X2hXDlLECF06WL3Xr3knIs2TxARtn8/9OoFp58Oj186Fz7/HB56CMqGXgSodWtLDpdddowDdc65NCI6WZ+DF16AVausB1OJfz0JFSumTqcRSpEiNrOrc85FmyeICPrlFxgwALp3h0tLzLIVgl58EcqUiXZozjmXKU8QEaIKPXva4LeXByl0ehhOPhnuuivaoTnnXFg8QUTIO+/At9/a2IcTZ4+HH36wYdSlSkU7NOecC0tEG6lFpJ2IrBCRBBHpG2J/TxH5WUQWisgsEakXtO+xwHkrRKRtJOPMbVu22BCHFi3g1n8mWh/Xs86yBaidcy6fiFgJIrCm9BDgUmA9MFdEJqrqsqDDPlDVYYHjOwCDgXaBRNEFOAs4BZgqIrVV9VCk4s1NQ4fCtm0wbBgUemM4JCTAF1/YxHzOOZdPRLIEcS6QoKqrVTURGA10DD5AVXcFPS0FaOBxR2C0qh5Q1TVAQuB6+cJXX0FcHNQ/bZfNudSqFVx+ebTDcs65LIlkgqgKrAt6vj6w7QgicreI/Aq8CNyTxXPvEJF4EYnfvHlzrgWeEzt22LLSbdsCAwdafdNLL4FItENzzrksifpAOVUdoqqnA48C/bJ47nBVjVPVuMpBk95F0zff2FQZbRv/BYMHQ7du0LRptMNyzrksi2SC2ACcGvS8WmBbekYDV2fz3Dxj8mSbcK/ZZ/0gORmefz7aITnnXLZEMkHMBWqJSKyIFMUanScGHyAitYKeXgmsCjyeCHQRkWIiEgvUAn6KYKy5QtUSROtzdlLknTehTx+oUSPaYTnnXLZErBeTqh4Ukd7AZCAGeEtVl4pIfyBeVScCvUWkDZAEbAduCpy7VETGAsuAg8Dd+aEH08qVtiBQ3wpjoHRpePzxTYteUQAACoZJREFUaIfknHPZFtGBcqr6JfBlmm1PBT2+N4NznwfyVf3M5Ml233bBAOh3z1HTeTvnXH7iI6lz0ddfQ60yG4k99KetFuecc/lY1HsxFRQHDsD0b5Jpu/tjm9+7UqVoh+ScczniJYhcMns27N1XiMsKfwMPDol2OM45l2Negsglk8ftogiJtLq5hs3a6pxz+ZyXIHLJ5I920ULmU/oJb3twzhUMXoLIBZsW/8WiLdVo22QLVK8e7XCccy5XeILIBVMe+waAy/rlm/kEnXMuU54gcmrrViZPhsrFdtKow2nRjsY553KNJ4gcSn7lVb4+dAmXtVEK+afpnCtA/CstJ/74g0UvT2UzVWh7fbloR+Occ7nKE0ROPPUUXya2AeDSS6Mci3PO5TLv5ppdP//Murem8FKRX2jVAk46KdoBOedc7vISRDYlP/woPWLe4WCR4owYEe1onHMu93kJIjumTOE/k2vxDRczYiicfnq0A3LOudznCSKrDh1iWZ+hPMqHtL/yELfeGhPtiJxzLiK8iimLEkd+wA0r+nHCCcqIN2MQiXZEzjkXGRFNECLSTkRWiEiCiPQNsf8BEVkmIotFZJqIVA/ad0hEFgZuE9OeGxV799L//m0soAnDRxbjxBOjHZBzzkVOxKqYRCQGGAJcCqwH5orIRFVdFnTYAiBOVfeKSC/gReD6wL59qtooUvFlx5z7xvLC7t7ccsUmru7k3ZaccwVbJEsQ5wIJqrpaVROB0UDH4ANUdbqq7g08/QGoFsF4cmTqC3PpMOIqTiu5lVc+9OTgnCv4IpkgqgLrgp6vD2xLz63ApKDnxUUkXkR+EJGrQ50gIncEjonfvHlzziMOQRVevHcDbR9vwknFd/D1rJKccEJEXso55/KUPNGLSURuAOKAi4M2V1fVDSJSE/hGRH5W1V+Dz1PV4cBwgLi4OM3tuHbvhpuv38vHk6pyXYnPeHNRHKVrlc7tl3HOuTwpkiWIDcCpQc+rBbYdQUTaAE8AHVT1QMp2Vd0QuF8NzAAaRyzSxMSjNq1YAc3OOcSESUUZVLwfo3+MpXQtXynOOXf8iGQJYi5QS0RiscTQBegWfICINAb+B7RT1b+CtpcH9qrqARGpBLTAGrBz3+7dtkRo06bQsiW0asWvVc6n+YVFidm9iykx19Hqi8fg7PoReXnnnMurIlaCUNWDQG9gMrAcGKuqS0Wkv4h0CBz2ElAaGJemO+uZQLyILAKmAwPS9H7KPQcOwF13wd698Nxz7G7Vno71E9AdO5mTdA6tRt4El1wSkZd2zrm8TFRzveo+KuLi4jQ+Pj5H10jevpPOl+/j858qM7nOvbS+vSY88EAuReicc3mPiMxT1bhQ+/JEI3Ve8fTgsnz6Y1leew1a9/lvtMNxzrmo8qk2AsaNg+eeg1tvhd69ox2Nc85FnycIYOFC6NEDmjeHIUPw+ZWccw5PEPz1F3TsCBUqwPjxUKxYtCNyzrm84bhPEIULQ4MGMGECPvmec84FOe4bqStUgM8+i3YUzjmX9xz3JQjnnHOheYJwzjkXkicI55xzIXmCcM45F5InCOeccyF5gnDOOReSJwjnnHMheYJwzjkXUoGZ7ltENgO/5eASlYAtuRROtBWk9wIF6/0UpPcC/n7ysnDfS3VVrRxqR4FJEDklIvHpzYme3xSk9wIF6/0UpPcC/n7ystx4L17F5JxzLiRPEM4550LyBHHY8GgHkIsK0nuBgvV+CtJ7AX8/eVmO34u3QTjnnAvJSxDOOedC8gThnHMupOM+QYhIOxFZISIJItI32vFklYi8JSJ/iciSoG0VRGSKiKwK3JePZozhEpFTRWS6iCwTkaUicm9ge359P8VF5CcRWRR4P/8X2B4rIj8G/s2NEZGi0Y41XCISIyILROTzwPP8/F7WisjPIrJQROID2/LlvzUAESknIh+JyC8islxEzs/p+zmuE4SIxABDgMuBekBXEakX3aiybCTQLs22vsA0Va0FTAs8zw8OAg+qaj3gPODuwN8jv76fA8AlqtoQaAS0E5HzgIHAK6p6BrAduDWKMWbVvcDyoOf5+b0AtFLVRkHjBfLrvzWAV4GvVLUu0BD7O+Xs/ajqcXsDzof/b+/uXqyqwjiOf38xJb6E04uJaGRWVASiBgZpIUldSEQXRpGJRNCNN14VQ2/QH9DLRZRQhJFUWFriTaXFgBf52qSm2KvgiDZdZGVQlD5drOfEUXZ0PDO5Zzu/D2zO3mvv2awH1p5n77XPWYsP27b7gL6669VFHDOBfW3bB4FpuT4NOFh3HbuM6wPgzvMhHmACsBu4hfLr1p4sP60NjuYFmJH/ZO4ANgFqaixZ30PA5WeUNbKtAZOB78kvHo1UPGP6CQKYDhxu2x7MsqabGhFHc/0YMLXOynRD0kxgLrCNBseTXTIDwBDwMfAtcDwi/spDmtTmXgAeA07l9mU0NxaAAD6StEvSo1nW1LZ2NfAj8Hp2Ab4qaSLDjGesJ4jzXpRbh0Z9l1nSJOA9YFVE/NK+r2nxRMTJiJhDufueD9xQc5W6IuluYCgidtVdlxG0MCLmUbqYV0q6vX1nw9paDzAPeDki5gK/cUZ3UjfxjPUEcQS4sm17RpY13Q+SpgHk51DN9emYpAspyWFtRKzP4sbG0xIRx4FPKd0wvZJ6cldT2twC4B5Jh4C3Kd1ML9LMWACIiCP5OQRsoCTwpra1QWAwIrbl9ruUhDGseMZ6gtgBXJffxLgIeADYWHOdRsJGYEWur6D05Y96kgS8BhyIiOfadjU1nimSenN9POV9ygFKoliahzUinojoi4gZETGTcp18EhHLaGAsAJImSrq4tQ7cBeyjoW0tIo4BhyVdn0WLgf0MN566X67UvQBLgK8ofcNP1F2fLur/FnAU+JNyF/EIpW94C/A1sBm4tO56dhjLQsoj8B5gIJclDY5nNvB5xrMPeDrLZwHbgW+AdcC4uut6lnEtAjY1OZas9xe5fNm69pva1rLuc4Cd2d7eBy4ZbjweasPMzCqN9S4mMzP7F04QZmZWyQnCzMwqOUGYmVklJwgzM6vkBGE2Ckha1Boh1Wy0cIIwM7NKThBmZ0HSQznHw4Ck1TkY3wlJz+ecD1skTclj50j6TNIeSRtaY/FLulbS5pwnYreka/L0k9rG81+bvyw3q40ThFmHJN0I3A8siDIA30lgGTAR2BkRNwH9wDP5J28Aj0fEbGBvW/la4KUo80TcSvklPJTRa1dR5iaZRRn/yKw2Pf99iJmlxcDNwI68uR9PGfzsFPBOHvMmsF7SZKA3IvqzfA2wLsf/mR4RGwAi4neAPN/2iBjM7QHKPB9b//+wzKo5QZh1TsCaiOg7rVB66ozjuh2/5o+29ZP4+rSauYvJrHNbgKWSroB/5i++inIdtUY0fRDYGhE/Az9Jui3LlwP9EfErMCjp3jzHOEkTzmkUZh3yHYpZhyJiv6QnKbOQXUAZQXclZXKW+blviPKeAsrwyq9kAvgOeDjLlwOrJT2b57jvHIZh1jGP5mo2TJJORMSkuuthNtLcxWRmZpX8BGFmZpX8BGFmZpWcIMzMrJIThJmZVXKCMDOzSk4QZmZW6W9zpAawLwMJrAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_LxatO5J-pp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee6c2558-7f05-4178-93f9-9e6c833132b9"
      },
      "source": [
        "testloss = model.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "trainloss = model.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(trainloss[0]))\n",
        "print(\"Train Acc: \" + str(trainloss[1]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 3s 27ms/step - loss: 1.0993 - accuracy: 0.5971\n",
            "Test Loss 1.0993008613586426\n",
            "Test Acc: 0.5971022844314575\n",
            "898/898 [==============================] - 24s 26ms/step - loss: 0.9563 - accuracy: 0.6381\n",
            "Train Loss 0.9562753438949585\n",
            "Train Acc: 0.6381274461746216\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swoRERVdKQ1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85e666a0-63ca-4b08-e319-42188c610866"
      },
      "source": [
        "testlosz = model.evaluate(x_val, y_val) \n",
        "print(\"Test Loss \" + str(testlosz[0]))\n",
        "print(\"Test Acc: \" + str(testlosz[1]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 3s 26ms/step - loss: 1.1078 - accuracy: 0.5988\n",
            "Test Loss 1.1078197956085205\n",
            "Test Acc: 0.5987740159034729\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5iaZIU6pPzk",
        "outputId": "03fe7cb1-7470-4f3a-c46c-73940f42a127"
      },
      "source": [
        "from keras.models import load_model\n",
        "model_load = load_model('/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD1try2.h5')\n",
        "\n",
        "model_load.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 46, 46, 128)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 46, 46, 128)  0           activation_3[0][0]               \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 46, 46, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 46, 46, 128)  0           activation_6[0][0]               \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 46, 46, 128)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 23, 23, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 23, 23, 256)  0           activation_12[0][0]              \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 23, 23, 256)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 23, 23, 256)  0           activation_15[0][0]              \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 23, 23, 256)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 23, 23, 256)  0           activation_18[0][0]              \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 23, 23, 256)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 12, 12, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 12, 12, 512)  0           activation_24[0][0]              \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 12, 12, 512)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 12, 12, 512)  0           activation_27[0][0]              \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 12, 12, 512)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 12, 12, 512)  0           activation_30[0][0]              \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 12, 12, 512)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 12, 12, 512)  0           activation_33[0][0]              \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 12, 12, 512)  0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 12, 12, 512)  0           activation_36[0][0]              \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 12, 12, 512)  0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 6, 6, 1024)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 6, 6, 1024)   0           activation_42[0][0]              \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 6, 6, 1024)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 6, 6, 1024)   0           activation_45[0][0]              \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 6, 6, 1024)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypc8clklx2p8",
        "outputId": "65bf2bbf-e105-4ae9-82c4-aa30e669ce76"
      },
      "source": [
        "#loss,acc = model_load.evaluate(xtrain,ytrain)\n",
        "\"\"\"print(\"loss:\",loss)\n",
        "print(\"acc:\",acc)kjjkj\"\"\"\n",
        "\n",
        "\n",
        "testloss = model_load.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "\n",
        "testloss = model_load.evaluate(xtrain, ytrain) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 6s 27ms/step - loss: 1.0993 - accuracy: 0.5971\n",
            "Test Loss 1.0993008613586426\n",
            "Test Acc: 0.5971022844314575\n",
            "898/898 [==============================] - 24s 27ms/step - loss: 0.9563 - accuracy: 0.6381\n",
            "Test Loss 0.9562753438949585\n",
            "Test Acc: 0.6381274461746216\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7mSww_U2O_q",
        "outputId": "11465a02-dbab-4ce6-f728-aaddad4ac8b5"
      },
      "source": [
        "testlosz = model_load.evaluate(xtrain, ytrain) \n",
        "print(\"Test Loss \" + str(testlosz[0]))\n",
        "print(\"Test Acc: \" + str(testlosz[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1010/1010 [==============================] - 26s 26ms/step - loss: 0.9853 - accuracy: 0.6306\n",
            "Test Loss 0.9853226542472839\n",
            "Test Acc: 0.6306272745132446\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdU7uU3PYCnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd7742a5-f919-4a3d-9ddb-d64a0f100143"
      },
      "source": [
        "print (x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3589, 48, 48, 1)\n",
            "(3589,)\n",
            "(3589, 48, 48, 1)\n",
            "(3589,)\n",
            "(28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "P_Tf1qg8TKnx",
        "outputId": "85df0abf-8909-4cc9-f958-65a326f9b432"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "#y_pred = model_load.predict(xtest)\n",
        "y_pred = np.argmax(model_load.predict(xtest))\n",
        "\n",
        "confusion = confusion_matrix(ytest,y_pred)\n",
        "\n",
        "print('Confusion Matrix\\n')\n",
        "print(confusion)\n",
        "\n",
        "#importing accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(ytest, y_pred)))\n",
        "\n",
        "print('Micro Precision: {:.2f}'.format(precision_score(ytest, y_pred, average='micro')))\n",
        "print('Micro Recall: {:.2f}'.format(recall_score(ytest, y_pred, average='micro')))\n",
        "print('Micro F1-score: {:.2f}\\n'.format(f1_score(ytest, y_pred, average='micro')))\n",
        "\n",
        "print('Macro Precision: {:.2f}'.format(precision_score(ytest, y_pred, average='macro')))\n",
        "print('Macro Recall: {:.2f}'.format(recall_score(ytest, y_pred, average='macro')))\n",
        "print('Macro F1-score: {:.2f}\\n'.format(f1_score(ytest, y_pred, average='macro')))\n",
        "\n",
        "print('Weighted Precision: {:.2f}'.format(precision_score(ytest, y_pred, average='weighted')))\n",
        "print('Weighted Recall: {:.2f}'.format(recall_score(ytest, y_pred, average='weighted')))\n",
        "print('Weighted F1-score: {:.2f}'.format(f1_score(ytest, y_pred, average='weighted')))\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-da4c1a32eaea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mconfusion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Confusion Matrix\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: confusion_matrix() missing 1 required positional argument: 'y_pred'"
          ]
        }
      ]
    }
  ]
}