{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER2013_Resnet50_weightnone_fixTrainTestVal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-Qn1jsBTIBl0b7myLQxqa8WjCcfbamqM",
      "authorship_tag": "ABX9TyNy2yAe6R3qnjsthtGW4Kae"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b86nukQOxN7l"
      },
      "source": [
        "Resnet-50 From Scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p8gxtGy0TWP",
        "outputId": "af841b6c-0169-4a76-b390-e95bbac0f214"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "inputFolder = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth' \n",
        "for root, directories, filenames in os.walk(inputFolder): \n",
        "    for filename in filenames: print(os.path.join(root,filename))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Best_Model_resnet50Scracth1again.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe4.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth1again.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50ScracthSGD1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50AUGScracthadam3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan2.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_oriyijungan3.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/checkpoint/Best_Model_resnet50oriScracth_sena2.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsiscWIMBDX2",
        "outputId": "4ebe6187-ba79-4275-d4a9-538b8054e375"
      },
      "source": [
        "%cd /content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "wLMSe510xNCJ",
        "outputId": "3da9f6f5-cb75-4f61-d978-1e7de9a074fc"
      },
      "source": [
        "#Create a directory to save our generated models.dasdas\n",
        "\n",
        "#os.mkdir(\"./modelscracth\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-cf55f19f3613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#os.mkdir(\"./modelscracth\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ls' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_kluusLxM1B",
        "outputId": "b0c7232c-ba70-4847-ecb6-2a0e3ba5e91b"
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:400: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfUSF_tAxNMP"
      },
      "source": [
        "#Define the identity block helper function.\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "   \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VdYtzhn1F0I"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path \n",
        "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b',padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd-O8ZMx1GAW"
      },
      "source": [
        "def ResNet50(input_shape = (48,48,1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    #X = ZeroPadding2D((1, 1))(X_input)\n",
        "    X = X_input\n",
        "    # Stage 1\n",
        "\n",
        "    X = Conv2D(8, (3, 3), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # removed maxpool\n",
        "    #X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='c')\n",
        "\n",
        "\n",
        "    # Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [64,64,256], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL . \n",
        "    X = AveragePooling2D((2,2), name='avg_pool')(X)\n",
        "    \n",
        "    # output layerds\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(512, activation = 'relu', name='fc1024' , kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GKsSwtp-GuL"
      },
      "source": [
        "\"\"\"def ResNet50ori(input_shape = (48, 48, 1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns: dsdsf\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50ori')\n",
        "\n",
        "    return model\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3oWTDXlyBHM2",
        "outputId": "1356ca8e-b52c-41e0-8703-37c51a7d88e8"
      },
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        " \n",
        "dataset_path = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv'\n",
        "image_size=(48,48)\n",
        "#batch_size = 64\n",
        "\n",
        "def load_fer2013():\n",
        "    data = pd.read_csv(dataset_path)\n",
        "    data = (data[data['pixels'].notnull()])\n",
        "    pixels = data['pixels'].tolist()\n",
        "    width, height = 48, 48\n",
        "    faces = []\n",
        "    for pixel_sequence in pixels:\n",
        "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "        face = np.asarray(face).reshape(width, height)\n",
        "        face = cv2.resize(face.astype('uint8'),image_size)\n",
        "        faces.append(face.astype('float32'))\n",
        "    faces = np.asarray(faces)\n",
        "    faces = np.expand_dims(faces, -1)\n",
        "    emotions = (data['emotion'])#.values\n",
        "    return faces, emotions\n",
        " \n",
        "def preprocess_input(x, v2=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if v2:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x\n",
        " \n",
        "faces, emotions = load_fer2013()\n",
        "faces = preprocess_input(faces)\n",
        "#xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
        "#Data Augumentation\n",
        "data_generator = ImageDataGenerator(\n",
        "                        rotation_range=10,\n",
        "                        shear_range = 10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True)\n",
        "\"\"\"data_generator = ImageDataGenerator( )\n",
        "\"\"\""
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'data_generator = ImageDataGenerator( )\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWLhavr-rSF5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "895f7f85-9930-46ca-c552-cbb571846a4e"
      },
      "source": [
        "\"\"\"\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.1,)\n",
        "x_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1,)\"\"\""
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nxtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.1,)\\nx_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1,)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "RGhnYFXgaqL9",
        "outputId": "0e60da2f-3a44-4d06-910b-2e0f2fa4191a"
      },
      "source": [
        "\"\"\"print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (y_train.shape)\"\"\""
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'print (\"validasi\",x_val.shape)\\nprint (y_val.shape)\\nprint (\"test\",xtest.shape)\\nprint (ytest.shape)\\nprint (\"train\",xtrain.shape)\\nprint (y_train.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rDS3hqhDSteM",
        "outputId": "82f42a21-0dfe-4993-c68d-5058e114e647"
      },
      "source": [
        "train_ratio = 0.80\n",
        "validation_ratio = 0.10\n",
        "test_ratio = 0.10\n",
        "\n",
        "# train is now 75% of the entire data set\n",
        "# the _junk suffix means that we drop that variable completely # the _junk suffix means that we drop that variable completely\n",
        "#x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=1 - train_ratio)\n",
        "\n",
        "# test is now 10% of the initial data set\n",
        "# validation is now 15% of the initial data set\n",
        "#x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "x_val, xtest, y_val, ytest = train_test_split(xtest, ytest, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
        "\n",
        "print(xtrain, x_val, xtest)\n",
        "\n",
        "\"\"\"X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2\"\"\""
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[ 0.09019613]\n",
            "   [-0.01176471]\n",
            "   [-0.49019605]\n",
            "   ...\n",
            "   [ 0.45098042]\n",
            "   [ 0.48235297]\n",
            "   [ 0.35686278]]\n",
            "\n",
            "  [[ 0.082353  ]\n",
            "   [-0.02745098]\n",
            "   [-0.6156863 ]\n",
            "   ...\n",
            "   [ 0.4431373 ]\n",
            "   [ 0.4666667 ]\n",
            "   [ 0.36470592]]\n",
            "\n",
            "  [[ 0.06666672]\n",
            "   [-0.10588235]\n",
            "   [-0.77254903]\n",
            "   ...\n",
            "   [ 0.4666667 ]\n",
            "   [ 0.4666667 ]\n",
            "   [ 0.36470592]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.8666667 ]\n",
            "   [ 0.654902  ]\n",
            "   [-0.00392157]\n",
            "   ...\n",
            "   [ 0.10588241]\n",
            "   [ 0.05882359]\n",
            "   [-0.00392157]]\n",
            "\n",
            "  [[ 0.8666667 ]\n",
            "   [ 0.6156863 ]\n",
            "   [-0.03529412]\n",
            "   ...\n",
            "   [ 0.05098045]\n",
            "   [ 0.00392163]\n",
            "   [-0.01960784]]\n",
            "\n",
            "  [[ 0.85882354]\n",
            "   [ 0.5764706 ]\n",
            "   [-0.05098039]\n",
            "   ...\n",
            "   [-0.01176471]\n",
            "   [-0.03529412]\n",
            "   [-0.05882353]]]\n",
            "\n",
            "\n",
            " [[[ 0.7490196 ]\n",
            "   [ 0.84313726]\n",
            "   [ 0.84313726]\n",
            "   ...\n",
            "   [-0.6392157 ]\n",
            "   [-0.6313726 ]\n",
            "   [-0.01176471]]\n",
            "\n",
            "  [[ 0.84313726]\n",
            "   [ 0.9607843 ]\n",
            "   [ 0.94509804]\n",
            "   ...\n",
            "   [-0.45098037]\n",
            "   [-0.7019608 ]\n",
            "   [-0.06666666]]\n",
            "\n",
            "  [[ 0.6784314 ]\n",
            "   [ 0.6862745 ]\n",
            "   [ 0.85882354]\n",
            "   ...\n",
            "   [-0.36470586]\n",
            "   [-0.73333335]\n",
            "   [-0.23921567]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.38039213]\n",
            "   [-0.23137254]\n",
            "   [-0.3098039 ]\n",
            "   ...\n",
            "   [-0.36470586]\n",
            "   [-0.38823527]\n",
            "   [-0.75686276]]\n",
            "\n",
            "  [[-0.25490195]\n",
            "   [-0.23137254]\n",
            "   [-0.36470586]\n",
            "   ...\n",
            "   [-0.49019605]\n",
            "   [-0.5294118 ]\n",
            "   [-0.5764706 ]]\n",
            "\n",
            "  [[-0.09803921]\n",
            "   [-0.19215685]\n",
            "   [-0.36470586]\n",
            "   ...\n",
            "   [-0.6784314 ]\n",
            "   [-0.6313726 ]\n",
            "   [-0.52156866]]]\n",
            "\n",
            "\n",
            " [[[-0.4352941 ]\n",
            "   [-0.30196077]\n",
            "   [-0.19215685]\n",
            "   ...\n",
            "   [-0.8745098 ]\n",
            "   [-0.8352941 ]\n",
            "   [-0.8745098 ]]\n",
            "\n",
            "  [[-0.3490196 ]\n",
            "   [-0.21568626]\n",
            "   [-0.19999999]\n",
            "   ...\n",
            "   [-0.8509804 ]\n",
            "   [-0.8745098 ]\n",
            "   [-0.8901961 ]]\n",
            "\n",
            "  [[-0.20784312]\n",
            "   [-0.12156862]\n",
            "   [-0.3098039 ]\n",
            "   ...\n",
            "   [-0.8039216 ]\n",
            "   [-0.8117647 ]\n",
            "   [-0.84313726]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 0.99215686]\n",
            "   [ 0.96862745]\n",
            "   ...\n",
            "   [-0.84313726]\n",
            "   [-0.8039216 ]\n",
            "   [-0.73333335]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 0.99215686]\n",
            "   [ 0.85882354]\n",
            "   ...\n",
            "   [-0.81960785]\n",
            "   [-0.8039216 ]\n",
            "   [-0.7647059 ]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 0.96862745]\n",
            "   [ 0.827451  ]\n",
            "   ...\n",
            "   [-0.79607844]\n",
            "   [-0.77254903]\n",
            "   [-0.7490196 ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.62352943]\n",
            "   [-0.62352943]\n",
            "   [-0.62352943]\n",
            "   ...\n",
            "   [ 0.52156866]\n",
            "   [ 0.3803922 ]\n",
            "   [ 0.36470592]]\n",
            "\n",
            "  [[-0.62352943]\n",
            "   [-0.62352943]\n",
            "   [-0.62352943]\n",
            "   ...\n",
            "   [ 0.5529412 ]\n",
            "   [ 0.4431373 ]\n",
            "   [ 0.41176474]]\n",
            "\n",
            "  [[-0.6156863 ]\n",
            "   [-0.6156863 ]\n",
            "   [-0.60784316]\n",
            "   ...\n",
            "   [ 0.5764706 ]\n",
            "   [ 0.49803925]\n",
            "   [ 0.5058824 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.654902  ]\n",
            "   [-0.654902  ]\n",
            "   [-0.62352943]\n",
            "   ...\n",
            "   [ 0.56078434]\n",
            "   [-0.09019607]\n",
            "   [ 0.20000005]]\n",
            "\n",
            "  [[-0.6156863 ]\n",
            "   [-0.5921569 ]\n",
            "   [-0.5921569 ]\n",
            "   ...\n",
            "   [ 0.33333337]\n",
            "   [-0.15294117]\n",
            "   [ 0.43529415]]\n",
            "\n",
            "  [[-0.5294118 ]\n",
            "   [-0.4980392 ]\n",
            "   [-0.52156866]\n",
            "   ...\n",
            "   [ 0.05882359]\n",
            "   [-0.11372548]\n",
            "   [ 0.6       ]]]\n",
            "\n",
            "\n",
            " [[[-0.372549  ]\n",
            "   [-0.36470586]\n",
            "   [-0.3960784 ]\n",
            "   ...\n",
            "   [-0.7019608 ]\n",
            "   [-0.54509807]\n",
            "   [-0.49019605]]\n",
            "\n",
            "  [[-0.4352941 ]\n",
            "   [-0.46666664]\n",
            "   [-0.5137255 ]\n",
            "   ...\n",
            "   [-0.7254902 ]\n",
            "   [-0.5764706 ]\n",
            "   [-0.49019605]]\n",
            "\n",
            "  [[-0.4588235 ]\n",
            "   [-0.5294118 ]\n",
            "   [-0.60784316]\n",
            "   ...\n",
            "   [-0.7490196 ]\n",
            "   [-0.6       ]\n",
            "   [-0.4980392 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.4980392 ]\n",
            "   [-0.4980392 ]\n",
            "   [-0.45098037]\n",
            "   ...\n",
            "   [-0.372549  ]\n",
            "   [-0.38039213]\n",
            "   [-0.4352941 ]]\n",
            "\n",
            "  [[-0.5058824 ]\n",
            "   [-0.47450978]\n",
            "   [-0.41960782]\n",
            "   ...\n",
            "   [-0.34117645]\n",
            "   [-0.38039213]\n",
            "   [-0.45098037]]\n",
            "\n",
            "  [[-0.47450978]\n",
            "   [-0.44313723]\n",
            "   [-0.47450978]\n",
            "   ...\n",
            "   [-0.34117645]\n",
            "   [-0.41176468]\n",
            "   [-0.45098037]]]\n",
            "\n",
            "\n",
            " [[[-0.7176471 ]\n",
            "   [-0.5686275 ]\n",
            "   [-0.4980392 ]\n",
            "   ...\n",
            "   [ 0.5529412 ]\n",
            "   [ 0.58431375]\n",
            "   [ 0.6862745 ]]\n",
            "\n",
            "  [[-0.67058825]\n",
            "   [-0.62352943]\n",
            "   [-0.5137255 ]\n",
            "   ...\n",
            "   [ 0.41176474]\n",
            "   [ 0.5294118 ]\n",
            "   [ 0.60784316]]\n",
            "\n",
            "  [[-0.6       ]\n",
            "   [-0.58431375]\n",
            "   [-0.5137255 ]\n",
            "   ...\n",
            "   [ 0.79607844]\n",
            "   [ 0.81960785]\n",
            "   [ 0.67058825]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.69411767]\n",
            "   [-0.7490196 ]\n",
            "   [-0.70980394]]\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.827451  ]\n",
            "   [-0.78039217]\n",
            "   [-0.6784314 ]]\n",
            "\n",
            "  [[-1.        ]\n",
            "   [-1.        ]\n",
            "   [-1.        ]\n",
            "   ...\n",
            "   [-0.78039217]\n",
            "   [-0.7254902 ]\n",
            "   [-0.70980394]]]] [[[[-0.2862745 ]\n",
            "   [-0.2862745 ]\n",
            "   [-0.3960784 ]\n",
            "   ...\n",
            "   [-0.38039213]\n",
            "   [-0.5058824 ]\n",
            "   [-0.54509807]]\n",
            "\n",
            "  [[-0.26274508]\n",
            "   [-0.27843136]\n",
            "   [-0.44313723]\n",
            "   ...\n",
            "   [-0.42745095]\n",
            "   [-0.372549  ]\n",
            "   [-0.58431375]]\n",
            "\n",
            "  [[-0.25490195]\n",
            "   [-0.3098039 ]\n",
            "   [-0.5058824 ]\n",
            "   ...\n",
            "   [-0.46666664]\n",
            "   [-0.3490196 ]\n",
            "   [-0.6627451 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.6862745 ]\n",
            "   [-0.73333335]\n",
            "   [-0.7176471 ]\n",
            "   ...\n",
            "   [-0.77254903]\n",
            "   [-0.75686276]\n",
            "   [-0.5921569 ]]\n",
            "\n",
            "  [[-0.64705884]\n",
            "   [-0.7411765 ]\n",
            "   [-0.7490196 ]\n",
            "   ...\n",
            "   [-0.7647059 ]\n",
            "   [-0.7176471 ]\n",
            "   [-0.6862745 ]]\n",
            "\n",
            "  [[-0.60784316]\n",
            "   [-0.70980394]\n",
            "   [-0.77254903]\n",
            "   ...\n",
            "   [-0.75686276]\n",
            "   [-0.6627451 ]\n",
            "   [-0.6784314 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.9607843 ]\n",
            "   [ 0.9607843 ]\n",
            "   [ 0.96862745]\n",
            "   ...\n",
            "   [ 0.6313726 ]\n",
            "   [ 0.54509807]\n",
            "   [ 0.4901961 ]]\n",
            "\n",
            "  [[ 0.9607843 ]\n",
            "   [ 0.96862745]\n",
            "   [ 0.9607843 ]\n",
            "   ...\n",
            "   [ 0.64705884]\n",
            "   [ 0.6313726 ]\n",
            "   [ 0.5372549 ]]\n",
            "\n",
            "  [[ 0.9607843 ]\n",
            "   [ 0.96862745]\n",
            "   [ 0.96862745]\n",
            "   ...\n",
            "   [ 0.6313726 ]\n",
            "   [ 0.58431375]\n",
            "   [ 0.5372549 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.9764706 ]\n",
            "   [ 0.9764706 ]\n",
            "   [ 0.9764706 ]\n",
            "   ...\n",
            "   [ 0.84313726]\n",
            "   [ 0.254902  ]\n",
            "   [-0.20784312]]\n",
            "\n",
            "  [[ 0.9843137 ]\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.9843137 ]\n",
            "   ...\n",
            "   [ 0.7882353 ]\n",
            "   [ 0.7882353 ]\n",
            "   [ 0.11372554]]\n",
            "\n",
            "  [[ 0.9843137 ]\n",
            "   [ 0.9764706 ]\n",
            "   [ 0.9843137 ]\n",
            "   ...\n",
            "   [ 0.78039217]\n",
            "   [ 0.8039216 ]\n",
            "   [ 0.7176471 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.20784318]\n",
            "   [ 0.18431377]\n",
            "   [ 0.2313726 ]\n",
            "   ...\n",
            "   [-0.27058822]\n",
            "   [ 0.2313726 ]\n",
            "   [ 0.14509809]]\n",
            "\n",
            "  [[ 0.18431377]\n",
            "   [ 0.1686275 ]\n",
            "   [ 0.254902  ]\n",
            "   ...\n",
            "   [-0.32549018]\n",
            "   [ 0.15294123]\n",
            "   [ 0.14509809]]\n",
            "\n",
            "  [[ 0.18431377]\n",
            "   [ 0.17647064]\n",
            "   [ 0.20784318]\n",
            "   ...\n",
            "   [-0.31764704]\n",
            "   [ 0.11372554]\n",
            "   [ 0.17647064]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 0.94509804]\n",
            "   [ 0.33333337]\n",
            "   ...\n",
            "   [-0.38039213]\n",
            "   [-0.20784312]\n",
            "   [-0.01176471]]\n",
            "\n",
            "  [[ 0.99215686]\n",
            "   [ 0.8039216 ]\n",
            "   [ 0.24705887]\n",
            "   ...\n",
            "   [-0.31764704]\n",
            "   [-0.1372549 ]\n",
            "   [ 0.04313731]]\n",
            "\n",
            "  [[ 1.        ]\n",
            "   [ 0.6784314 ]\n",
            "   [ 0.27058828]\n",
            "   ...\n",
            "   [-0.24705881]\n",
            "   [-0.05882353]\n",
            "   [ 0.10588241]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-0.7254902 ]\n",
            "   [-0.7490196 ]\n",
            "   [-0.77254903]\n",
            "   ...\n",
            "   [ 0.33333337]\n",
            "   [ 0.24705887]\n",
            "   [ 0.21568632]]\n",
            "\n",
            "  [[-0.7490196 ]\n",
            "   [-0.78039217]\n",
            "   [-0.75686276]\n",
            "   ...\n",
            "   [ 0.254902  ]\n",
            "   [ 0.2941177 ]\n",
            "   [ 0.15294123]]\n",
            "\n",
            "  [[-0.7647059 ]\n",
            "   [-0.7882353 ]\n",
            "   [-0.6627451 ]\n",
            "   ...\n",
            "   [ 0.27058828]\n",
            "   [ 0.20000005]\n",
            "   [ 0.15294123]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.01960784]\n",
            "   [ 0.18431377]\n",
            "   [ 0.28627455]\n",
            "   ...\n",
            "   [ 0.082353  ]\n",
            "   [ 0.27843142]\n",
            "   [ 0.3411765 ]]\n",
            "\n",
            "  [[ 0.00392163]\n",
            "   [ 0.16078436]\n",
            "   [ 0.26274514]\n",
            "   ...\n",
            "   [ 0.15294123]\n",
            "   [ 0.2941177 ]\n",
            "   [ 0.32549024]]\n",
            "\n",
            "  [[-0.02745098]\n",
            "   [ 0.12156868]\n",
            "   [ 0.2313726 ]\n",
            "   ...\n",
            "   [ 0.16078436]\n",
            "   [ 0.27843142]\n",
            "   [ 0.28627455]]]\n",
            "\n",
            "\n",
            " [[[-0.09019607]\n",
            "   [-0.15294117]\n",
            "   [-0.11372548]\n",
            "   ...\n",
            "   [ 0.99215686]\n",
            "   [ 0.99215686]\n",
            "   [ 0.99215686]]\n",
            "\n",
            "  [[ 0.17647064]\n",
            "   [ 0.05882359]\n",
            "   [ 0.04313731]\n",
            "   ...\n",
            "   [ 0.99215686]\n",
            "   [ 0.99215686]\n",
            "   [ 0.99215686]]\n",
            "\n",
            "  [[ 0.05098045]\n",
            "   [-0.00392157]\n",
            "   [ 0.04313731]\n",
            "   ...\n",
            "   [ 0.99215686]\n",
            "   [ 0.99215686]\n",
            "   [ 0.99215686]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.99215686]\n",
            "   [ 0.99215686]\n",
            "   [ 0.99215686]\n",
            "   ...\n",
            "   [-0.827451  ]\n",
            "   [-0.827451  ]\n",
            "   [-0.8117647 ]]\n",
            "\n",
            "  [[ 0.9843137 ]\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.99215686]\n",
            "   ...\n",
            "   [-0.77254903]\n",
            "   [-0.79607844]\n",
            "   [-0.8117647 ]]\n",
            "\n",
            "  [[ 0.99215686]\n",
            "   [ 0.9843137 ]\n",
            "   [ 0.96862745]\n",
            "   ...\n",
            "   [-0.6784314 ]\n",
            "   [-0.7647059 ]\n",
            "   [-0.79607844]]]\n",
            "\n",
            "\n",
            " [[[ 0.85882354]\n",
            "   [ 0.85882354]\n",
            "   [ 0.8509804 ]\n",
            "   ...\n",
            "   [-0.4823529 ]\n",
            "   [-0.44313723]\n",
            "   [-0.372549  ]]\n",
            "\n",
            "  [[ 0.8745098 ]\n",
            "   [ 0.8745098 ]\n",
            "   [ 0.85882354]\n",
            "   ...\n",
            "   [-0.21568626]\n",
            "   [-0.09019607]\n",
            "   [-0.00392157]]\n",
            "\n",
            "  [[ 0.85882354]\n",
            "   [ 0.85882354]\n",
            "   [ 0.85882354]\n",
            "   ...\n",
            "   [ 0.20784318]\n",
            "   [ 0.22352946]\n",
            "   [ 0.22352946]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.34901965]\n",
            "   [ 0.5058824 ]\n",
            "   [ 0.41176474]\n",
            "   ...\n",
            "   [-0.3333333 ]\n",
            "   [-0.372549  ]\n",
            "   [ 0.05098045]]\n",
            "\n",
            "  [[ 0.5137255 ]\n",
            "   [ 0.47450984]\n",
            "   [ 0.4039216 ]\n",
            "   ...\n",
            "   [-0.36470586]\n",
            "   [ 0.05098045]\n",
            "   [-0.12941176]]\n",
            "\n",
            "  [[ 0.5137255 ]\n",
            "   [ 0.427451  ]\n",
            "   [ 0.427451  ]\n",
            "   ...\n",
            "   [-0.01176471]\n",
            "   [ 0.06666672]\n",
            "   [-0.2862745 ]]]] [[[[ 0.6156863 ]\n",
            "   [ 0.60784316]\n",
            "   [ 0.654902  ]\n",
            "   ...\n",
            "   [-0.3490196 ]\n",
            "   [-0.4352941 ]\n",
            "   [-0.49019605]]\n",
            "\n",
            "  [[ 0.6156863 ]\n",
            "   [ 0.60784316]\n",
            "   [ 0.654902  ]\n",
            "   ...\n",
            "   [-0.31764704]\n",
            "   [-0.38039213]\n",
            "   [-0.4588235 ]]\n",
            "\n",
            "  [[ 0.6156863 ]\n",
            "   [ 0.60784316]\n",
            "   [ 0.6627451 ]\n",
            "   ...\n",
            "   [-0.34117645]\n",
            "   [-0.4352941 ]\n",
            "   [-0.5058824 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.3176471 ]\n",
            "   [ 0.10588241]\n",
            "   [ 0.254902  ]\n",
            "   ...\n",
            "   [-0.4823529 ]\n",
            "   [-0.47450978]\n",
            "   [-0.46666664]]\n",
            "\n",
            "  [[ 0.45882356]\n",
            "   [ 0.1686275 ]\n",
            "   [ 0.12156868]\n",
            "   ...\n",
            "   [-0.4823529 ]\n",
            "   [-0.47450978]\n",
            "   [-0.46666664]]\n",
            "\n",
            "  [[ 0.47450984]\n",
            "   [ 0.32549024]\n",
            "   [ 0.03529418]\n",
            "   ...\n",
            "   [-0.49019605]\n",
            "   [-0.49019605]\n",
            "   [-0.49019605]]]\n",
            "\n",
            "\n",
            " [[[-0.56078434]\n",
            "   [-0.5764706 ]\n",
            "   [-0.5921569 ]\n",
            "   ...\n",
            "   [-0.5686275 ]\n",
            "   [-0.5764706 ]\n",
            "   [-0.56078434]]\n",
            "\n",
            "  [[-0.5686275 ]\n",
            "   [-0.58431375]\n",
            "   [-0.58431375]\n",
            "   ...\n",
            "   [-0.5294118 ]\n",
            "   [-0.5764706 ]\n",
            "   [-0.56078434]]\n",
            "\n",
            "  [[-0.5764706 ]\n",
            "   [-0.56078434]\n",
            "   [-0.56078434]\n",
            "   ...\n",
            "   [-0.5058824 ]\n",
            "   [-0.5294118 ]\n",
            "   [-0.5372549 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.62352943]\n",
            "   [-0.64705884]\n",
            "   [-0.6313726 ]\n",
            "   ...\n",
            "   [-0.6156863 ]\n",
            "   [-0.6627451 ]\n",
            "   [-0.6392157 ]]\n",
            "\n",
            "  [[-0.6156863 ]\n",
            "   [-0.60784316]\n",
            "   [-0.5921569 ]\n",
            "   ...\n",
            "   [-0.60784316]\n",
            "   [-0.654902  ]\n",
            "   [-0.654902  ]]\n",
            "\n",
            "  [[-0.5921569 ]\n",
            "   [-0.6       ]\n",
            "   [-0.6313726 ]\n",
            "   ...\n",
            "   [-0.6313726 ]\n",
            "   [-0.6392157 ]\n",
            "   [-0.64705884]]]\n",
            "\n",
            "\n",
            " [[[-0.49019605]\n",
            "   [ 0.3176471 ]\n",
            "   [ 0.654902  ]\n",
            "   ...\n",
            "   [-0.09803921]\n",
            "   [-0.5764706 ]\n",
            "   [-0.45098037]]\n",
            "\n",
            "  [[-0.5137255 ]\n",
            "   [ 0.24705887]\n",
            "   [ 0.6392157 ]\n",
            "   ...\n",
            "   [-0.01176471]\n",
            "   [-0.52156866]\n",
            "   [-0.49019605]]\n",
            "\n",
            "  [[-0.5294118 ]\n",
            "   [ 0.17647064]\n",
            "   [ 0.60784316]\n",
            "   ...\n",
            "   [-0.27058822]\n",
            "   [-0.3098039 ]\n",
            "   [-0.36470586]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.09019613]\n",
            "   [ 0.10588241]\n",
            "   [ 0.19215691]\n",
            "   ...\n",
            "   [ 0.8117647 ]\n",
            "   [ 0.7647059 ]\n",
            "   [ 0.8039216 ]]\n",
            "\n",
            "  [[ 0.09803927]\n",
            "   [ 0.12156868]\n",
            "   [ 0.17647064]\n",
            "   ...\n",
            "   [ 0.8745098 ]\n",
            "   [ 0.77254903]\n",
            "   [ 0.79607844]]\n",
            "\n",
            "  [[ 0.30196083]\n",
            "   [ 0.39607847]\n",
            "   [ 0.45882356]\n",
            "   ...\n",
            "   [ 0.8901961 ]\n",
            "   [ 0.85882354]\n",
            "   [ 0.75686276]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 0.41176474]\n",
            "   [ 0.6392157 ]\n",
            "   [ 0.75686276]\n",
            "   ...\n",
            "   [ 0.8352941 ]\n",
            "   [ 0.84313726]\n",
            "   [ 0.8117647 ]]\n",
            "\n",
            "  [[ 0.4901961 ]\n",
            "   [ 0.69411767]\n",
            "   [ 0.7882353 ]\n",
            "   ...\n",
            "   [ 0.84313726]\n",
            "   [ 0.8509804 ]\n",
            "   [ 0.81960785]]\n",
            "\n",
            "  [[ 0.5764706 ]\n",
            "   [ 0.73333335]\n",
            "   [ 0.8039216 ]\n",
            "   ...\n",
            "   [ 0.827451  ]\n",
            "   [ 0.8509804 ]\n",
            "   [ 0.827451  ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.17647064]\n",
            "   [ 0.34901965]\n",
            "   [ 0.4666667 ]\n",
            "   ...\n",
            "   [ 0.81960785]\n",
            "   [ 0.5058824 ]\n",
            "   [ 0.11372554]]\n",
            "\n",
            "  [[ 0.37254906]\n",
            "   [ 0.35686278]\n",
            "   [ 0.47450984]\n",
            "   ...\n",
            "   [ 0.8901961 ]\n",
            "   [ 0.3176471 ]\n",
            "   [ 0.082353  ]]\n",
            "\n",
            "  [[ 0.7254902 ]\n",
            "   [ 0.5686275 ]\n",
            "   [ 0.5294118 ]\n",
            "   ...\n",
            "   [ 0.9764706 ]\n",
            "   [-0.02745098]\n",
            "   [ 0.30980396]]]\n",
            "\n",
            "\n",
            " [[[-0.06666666]\n",
            "   [-0.1372549 ]\n",
            "   [-0.2862745 ]\n",
            "   ...\n",
            "   [ 0.09019613]\n",
            "   [-0.77254903]\n",
            "   [-0.49019605]]\n",
            "\n",
            "  [[-0.1607843 ]\n",
            "   [-0.24705881]\n",
            "   [-0.29411763]\n",
            "   ...\n",
            "   [ 0.27058828]\n",
            "   [-0.03529412]\n",
            "   [ 0.30196083]]\n",
            "\n",
            "  [[-0.30196077]\n",
            "   [-0.3333333 ]\n",
            "   [-0.35686272]\n",
            "   ...\n",
            "   [ 0.45098042]\n",
            "   [ 0.5137255 ]\n",
            "   [ 0.5058824 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.4588235 ]\n",
            "   [-0.4588235 ]\n",
            "   [-0.4588235 ]\n",
            "   ...\n",
            "   [-0.4352941 ]\n",
            "   [-0.58431375]\n",
            "   [-0.827451  ]]\n",
            "\n",
            "  [[-0.4588235 ]\n",
            "   [-0.4588235 ]\n",
            "   [-0.4588235 ]\n",
            "   ...\n",
            "   [-0.47450978]\n",
            "   [-0.45098037]\n",
            "   [-0.69411767]]\n",
            "\n",
            "  [[-0.45098037]\n",
            "   [-0.46666664]\n",
            "   [-0.4588235 ]\n",
            "   ...\n",
            "   [-0.46666664]\n",
            "   [-0.45098037]\n",
            "   [-0.5137255 ]]]\n",
            "\n",
            "\n",
            " [[[-0.1607843 ]\n",
            "   [-0.14509803]\n",
            "   [-0.1372549 ]\n",
            "   ...\n",
            "   [ 0.9372549 ]\n",
            "   [ 0.9372549 ]\n",
            "   [ 0.9372549 ]]\n",
            "\n",
            "  [[-0.17647058]\n",
            "   [-0.16862744]\n",
            "   [-0.1607843 ]\n",
            "   ...\n",
            "   [ 0.9372549 ]\n",
            "   [ 0.9372549 ]\n",
            "   [ 0.94509804]]\n",
            "\n",
            "  [[-0.14509803]\n",
            "   [-0.14509803]\n",
            "   [-0.12941176]\n",
            "   ...\n",
            "   [ 0.9372549 ]\n",
            "   [ 0.94509804]\n",
            "   [ 0.94509804]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.4823529 ]\n",
            "   [-0.4823529 ]\n",
            "   [-0.45098037]\n",
            "   ...\n",
            "   [ 0.21568632]\n",
            "   [ 0.17647064]\n",
            "   [ 0.11372554]]\n",
            "\n",
            "  [[-0.46666664]\n",
            "   [-0.4588235 ]\n",
            "   [-0.4588235 ]\n",
            "   ...\n",
            "   [ 0.16078436]\n",
            "   [ 0.13725495]\n",
            "   [ 0.09019613]]\n",
            "\n",
            "  [[-0.5058824 ]\n",
            "   [-0.5058824 ]\n",
            "   [-0.4980392 ]\n",
            "   ...\n",
            "   [ 0.28627455]\n",
            "   [ 0.254902  ]\n",
            "   [ 0.19215691]]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=1)\\n\\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1) # 0.25 x 0.8 = 0.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKvEv321Stt5",
        "outputId": "fa8812de-b06e-4278-d0fd-7fcbd72df185"
      },
      "source": [
        "print (\"validasi\",x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (\"test\",xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (\"train\",xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validasi (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "test (3589, 48, 48, 1)\n",
            "(3589,)\n",
            "train (28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH9Q-TegBR26"
      },
      "source": [
        "#hyperparameter and callback\n",
        "batch_size = 64\n",
        "num_epochs = 60\n",
        "input_shape = (48, 48, 1)\n",
        "num_classes = 7\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGsscQRJBR-h"
      },
      "source": [
        "#Compile the model.\n",
        "\n",
        "\n",
        "from keras.optimizers import Adam, SGD\n",
        "model = ResNet50(input_shape = (48, 48, 1), classes = 7)\n",
        "optimizer = SGD(learning_rate=0.009)\n",
        "model.compile(optimizer= optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rodttDWeT2yP"
      },
      "source": [
        "#kita mau save model callbacks\n",
        "\"\"\"import os\n",
        "try:\n",
        "  os.mkdir('scratchcheckpoint')\n",
        "except:\n",
        "  pass\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV29sTjET28U"
      },
      "source": [
        "\"\"\"file_name = 'Best_Model_resnet50Scracth_sena1.h5'\n",
        "\n",
        "checkpoint_path = os.path.join('checkpoint',file_name)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_S6wUaPT3Jx"
      },
      "source": [
        "call_back = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
        "                                               monitor='val_accuracy',\n",
        "                                               verbose=1,\n",
        "                                               save_freq='epoch',\n",
        "                                               save_best_only=True,\n",
        "                                               save_weights_only=False,\n",
        "                                               mode='max')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy53DHMGB-Mr",
        "outputId": "38ef9877-a2c3-45a3-81a5-5e6c35728817"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_294 (Activation)     (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation_294[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_295 (Activation)     (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_295[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_296 (Activation)     (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation_294[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_296[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_96 (Add)                    (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_297 (Activation)     (None, 46, 46, 128)  0           add_96[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_298 (Activation)     (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_298[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_299 (Activation)     (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_299[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_97 (Add)                    (None, 46, 46, 128)  0           activation_297[0][0]             \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_300 (Activation)     (None, 46, 46, 128)  0           add_97[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_300[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_301 (Activation)     (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_301[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_302 (Activation)     (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_302[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_98 (Add)                    (None, 46, 46, 128)  0           activation_300[0][0]             \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_303 (Activation)     (None, 46, 46, 128)  0           add_98[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_303[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_304 (Activation)     (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_304[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_305 (Activation)     (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_303[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_305[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_99 (Add)                    (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_306 (Activation)     (None, 23, 23, 256)  0           add_99[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_306[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_307 (Activation)     (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_307[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_308 (Activation)     (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_308[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_100 (Add)                   (None, 23, 23, 256)  0           activation_306[0][0]             \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_309 (Activation)     (None, 23, 23, 256)  0           add_100[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_309[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_310 (Activation)     (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_310[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_311 (Activation)     (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_311[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_101 (Add)                   (None, 23, 23, 256)  0           activation_309[0][0]             \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_312 (Activation)     (None, 23, 23, 256)  0           add_101[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_312[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_313 (Activation)     (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_313[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_314 (Activation)     (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_314[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_102 (Add)                   (None, 23, 23, 256)  0           activation_312[0][0]             \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_315 (Activation)     (None, 23, 23, 256)  0           add_102[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_315[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_316 (Activation)     (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_316[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_317 (Activation)     (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_315[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_317[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_103 (Add)                   (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_318 (Activation)     (None, 12, 12, 512)  0           add_103[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_318[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_319 (Activation)     (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_319[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_320 (Activation)     (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_320[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_104 (Add)                   (None, 12, 12, 512)  0           activation_318[0][0]             \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_321 (Activation)     (None, 12, 12, 512)  0           add_104[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_321[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_322 (Activation)     (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_322[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_323 (Activation)     (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_323[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_105 (Add)                   (None, 12, 12, 512)  0           activation_321[0][0]             \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_324 (Activation)     (None, 12, 12, 512)  0           add_105[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_324[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_325 (Activation)     (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_325[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_326 (Activation)     (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_326[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_106 (Add)                   (None, 12, 12, 512)  0           activation_324[0][0]             \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_327 (Activation)     (None, 12, 12, 512)  0           add_106[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_327[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_328 (Activation)     (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_328[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_329 (Activation)     (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_329[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_107 (Add)                   (None, 12, 12, 512)  0           activation_327[0][0]             \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_330 (Activation)     (None, 12, 12, 512)  0           add_107[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_330[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_331 (Activation)     (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_331[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_332 (Activation)     (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_332[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_108 (Add)                   (None, 12, 12, 512)  0           activation_330[0][0]             \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_333 (Activation)     (None, 12, 12, 512)  0           add_108[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_333[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_334 (Activation)     (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_334[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_335 (Activation)     (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_333[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_335[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_109 (Add)                   (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_336 (Activation)     (None, 6, 6, 1024)   0           add_109[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_336[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_337 (Activation)     (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_337[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_338 (Activation)     (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_338[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_110 (Add)                   (None, 6, 6, 1024)   0           activation_336[0][0]             \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_339 (Activation)     (None, 6, 6, 1024)   0           add_110[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_339[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_340 (Activation)     (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_340[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_341 (Activation)     (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_341[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_111 (Add)                   (None, 6, 6, 1024)   0           activation_339[0][0]             \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_342 (Activation)     (None, 6, 6, 1024)   0           add_111[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_342[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_6 (Flatten)             (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgxCecVwCGEr"
      },
      "source": [
        "\"\"\"history = model.fit(data_generator.flow(xtrain, ytrain,),\n",
        "                        steps_per_epoch=len(xtrain) / batch_size,\n",
        "                        epochs=num_epochs, verbose=1,callbacks=call_back,\n",
        "                        validation_data= (xtest,ytest))\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2muXWns0sJSH",
        "outputId": "fd66642d-4f60-4aa7-b7da-41e82b3bfe24"
      },
      "source": [
        "history = model.fit(\n",
        "    data_generator.flow(xtrain, ytrain,),\n",
        "    steps_per_epoch=len(xtrain) / batch_size,\n",
        "    epochs=num_epochs, \n",
        "    verbose=1,\n",
        "    validation_data= (x_val,y_val))\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "448/448 [==============================] - 62s 116ms/step - loss: 2.3005 - accuracy: 0.2353 - val_loss: 1.8132 - val_accuracy: 0.2427\n",
            "Epoch 2/60\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 1.8010 - accuracy: 0.2422 - val_loss: 1.7878 - val_accuracy: 0.2516\n",
            "Epoch 3/60\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.7908 - accuracy: 0.2505 - val_loss: 1.7602 - val_accuracy: 0.2756\n",
            "Epoch 4/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.7600 - accuracy: 0.2629 - val_loss: 1.7448 - val_accuracy: 0.2839\n",
            "Epoch 5/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.7534 - accuracy: 0.2824 - val_loss: 1.7081 - val_accuracy: 0.3023\n",
            "Epoch 6/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.7313 - accuracy: 0.2866 - val_loss: 1.6895 - val_accuracy: 0.3165\n",
            "Epoch 7/60\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.6883 - accuracy: 0.3150 - val_loss: 1.6959 - val_accuracy: 0.3210\n",
            "Epoch 8/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.6665 - accuracy: 0.3234 - val_loss: 1.7899 - val_accuracy: 0.3285\n",
            "Epoch 9/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.6308 - accuracy: 0.3425 - val_loss: 1.6287 - val_accuracy: 0.3449\n",
            "Epoch 10/60\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 1.6176 - accuracy: 0.3461 - val_loss: 1.6712 - val_accuracy: 0.3614\n",
            "Epoch 11/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.5882 - accuracy: 0.3727 - val_loss: 1.5684 - val_accuracy: 0.3692\n",
            "Epoch 12/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.5705 - accuracy: 0.3778 - val_loss: 1.5056 - val_accuracy: 0.3873\n",
            "Epoch 13/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.5212 - accuracy: 0.3945 - val_loss: 1.4730 - val_accuracy: 0.4152\n",
            "Epoch 14/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.5068 - accuracy: 0.4029 - val_loss: 1.5544 - val_accuracy: 0.3904\n",
            "Epoch 15/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.4764 - accuracy: 0.4194 - val_loss: 1.4950 - val_accuracy: 0.3990\n",
            "Epoch 16/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.4405 - accuracy: 0.4327 - val_loss: 1.4622 - val_accuracy: 0.4458\n",
            "Epoch 17/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.4059 - accuracy: 0.4520 - val_loss: 1.3918 - val_accuracy: 0.4494\n",
            "Epoch 18/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.3830 - accuracy: 0.4581 - val_loss: 1.4050 - val_accuracy: 0.4611\n",
            "Epoch 19/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.3808 - accuracy: 0.4603 - val_loss: 1.3929 - val_accuracy: 0.4625\n",
            "Epoch 20/60\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 1.3416 - accuracy: 0.4854 - val_loss: 1.3774 - val_accuracy: 0.4689\n",
            "Epoch 21/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.3265 - accuracy: 0.4869 - val_loss: 1.4206 - val_accuracy: 0.4636\n",
            "Epoch 22/60\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.3024 - accuracy: 0.4984 - val_loss: 1.3062 - val_accuracy: 0.4823\n",
            "Epoch 23/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.3056 - accuracy: 0.4947 - val_loss: 1.3895 - val_accuracy: 0.4767\n",
            "Epoch 24/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.2857 - accuracy: 0.4998 - val_loss: 1.3578 - val_accuracy: 0.4915\n",
            "Epoch 25/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.2716 - accuracy: 0.5098 - val_loss: 1.3375 - val_accuracy: 0.4918\n",
            "Epoch 26/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.2578 - accuracy: 0.5108 - val_loss: 1.2665 - val_accuracy: 0.5160\n",
            "Epoch 27/60\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 1.2399 - accuracy: 0.5210 - val_loss: 1.2904 - val_accuracy: 0.5082\n",
            "Epoch 28/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.2486 - accuracy: 0.5213 - val_loss: 1.2757 - val_accuracy: 0.5060\n",
            "Epoch 29/60\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 1.2275 - accuracy: 0.5268 - val_loss: 1.2327 - val_accuracy: 0.5263\n",
            "Epoch 30/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.2042 - accuracy: 0.5375 - val_loss: 1.2567 - val_accuracy: 0.5082\n",
            "Epoch 31/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.2033 - accuracy: 0.5338 - val_loss: 1.2890 - val_accuracy: 0.5074\n",
            "Epoch 32/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.1905 - accuracy: 0.5361 - val_loss: 1.2926 - val_accuracy: 0.5063\n",
            "Epoch 33/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.1673 - accuracy: 0.5541 - val_loss: 1.1810 - val_accuracy: 0.5422\n",
            "Epoch 34/60\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.1515 - accuracy: 0.5588 - val_loss: 1.2314 - val_accuracy: 0.5386\n",
            "Epoch 35/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.1574 - accuracy: 0.5562 - val_loss: 1.3637 - val_accuracy: 0.4937\n",
            "Epoch 36/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.1381 - accuracy: 0.5655 - val_loss: 1.1691 - val_accuracy: 0.5539\n",
            "Epoch 37/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.1494 - accuracy: 0.5593 - val_loss: 1.2218 - val_accuracy: 0.5210\n",
            "Epoch 38/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.1419 - accuracy: 0.5633 - val_loss: 1.3148 - val_accuracy: 0.4826\n",
            "Epoch 39/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.1136 - accuracy: 0.5684 - val_loss: 1.2025 - val_accuracy: 0.5439\n",
            "Epoch 40/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.1200 - accuracy: 0.5794 - val_loss: 1.1590 - val_accuracy: 0.5439\n",
            "Epoch 41/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.1066 - accuracy: 0.5705 - val_loss: 1.2379 - val_accuracy: 0.5288\n",
            "Epoch 42/60\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 1.1076 - accuracy: 0.5808 - val_loss: 1.1506 - val_accuracy: 0.5617\n",
            "Epoch 43/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.1096 - accuracy: 0.5746 - val_loss: 1.1281 - val_accuracy: 0.5765\n",
            "Epoch 44/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.0964 - accuracy: 0.5830 - val_loss: 1.1460 - val_accuracy: 0.5522\n",
            "Epoch 45/60\n",
            "448/448 [==============================] - 48s 108ms/step - loss: 1.0909 - accuracy: 0.5885 - val_loss: 1.1346 - val_accuracy: 0.5795\n",
            "Epoch 46/60\n",
            "448/448 [==============================] - 50s 112ms/step - loss: 1.0945 - accuracy: 0.5833 - val_loss: 1.2030 - val_accuracy: 0.5397\n",
            "Epoch 47/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.0903 - accuracy: 0.5826 - val_loss: 1.1714 - val_accuracy: 0.5559\n",
            "Epoch 48/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.0941 - accuracy: 0.5834 - val_loss: 1.0833 - val_accuracy: 0.5991\n",
            "Epoch 49/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.0646 - accuracy: 0.5893 - val_loss: 1.1089 - val_accuracy: 0.5840\n",
            "Epoch 50/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.0491 - accuracy: 0.5979 - val_loss: 1.1550 - val_accuracy: 0.5589\n",
            "Epoch 51/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.0521 - accuracy: 0.5916 - val_loss: 1.1148 - val_accuracy: 0.5787\n",
            "Epoch 52/60\n",
            "448/448 [==============================] - 50s 110ms/step - loss: 1.0344 - accuracy: 0.6034 - val_loss: 1.2473 - val_accuracy: 0.5355\n",
            "Epoch 53/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.0487 - accuracy: 0.5988 - val_loss: 1.1123 - val_accuracy: 0.5915\n",
            "Epoch 54/60\n",
            "448/448 [==============================] - 48s 106ms/step - loss: 1.0466 - accuracy: 0.5952 - val_loss: 1.1073 - val_accuracy: 0.5787\n",
            "Epoch 55/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.0301 - accuracy: 0.6046 - val_loss: 1.1058 - val_accuracy: 0.5826\n",
            "Epoch 56/60\n",
            "448/448 [==============================] - 47s 106ms/step - loss: 1.0427 - accuracy: 0.6084 - val_loss: 1.1128 - val_accuracy: 0.5846\n",
            "Epoch 57/60\n",
            "448/448 [==============================] - 47s 105ms/step - loss: 1.0376 - accuracy: 0.6101 - val_loss: 1.1425 - val_accuracy: 0.5678\n",
            "Epoch 58/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.0255 - accuracy: 0.6072 - val_loss: 1.1556 - val_accuracy: 0.5648\n",
            "Epoch 59/60\n",
            "448/448 [==============================] - 48s 107ms/step - loss: 1.0278 - accuracy: 0.6059 - val_loss: 1.2309 - val_accuracy: 0.5653\n",
            "Epoch 60/60\n",
            "448/448 [==============================] - 50s 111ms/step - loss: 1.0148 - accuracy: 0.6147 - val_loss: 1.1345 - val_accuracy: 0.5751\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "GaXUP-8fDWRN",
        "outputId": "76407f6f-74a3-406d-bab5-1f4ec40f25bb"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "model.save('/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD2.h5')\n",
        "\n",
        "#gffhgffkjkjdskjjkjkjkjhjhnnn\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "num_epochs = range(len(accuracy))\n",
        "plt.plot(num_epochs, accuracy, 'r', label='Training acc')\n",
        "plt.plot(num_epochs, val_accuracy, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(num_epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(num_epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeZyOZffAv8e+Zokie4VSYRgkZSlKy0vSQiuVrbRv2uSlRYXKGxXK0lsRSkJZftGCmBGVfX9DkhCyjzm/P84zPMYzM88wj2eW8/18ns/c931d132f+5mZ+9zXOec6R1QVx3Ecx0lOrmgL4DiO42ROXEE4juM4IXEF4TiO44TEFYTjOI4TElcQjuM4TkhcQTiO4zghcQXhhI2IfCUid2V032giIutFpHkEzqsicm5g+10ReT6cvidwndtEZNqJyuk4qSG+DiJ7IyL/BO0WAg4AhwP7XVT1o1MvVeZBRNYD96rqjAw+rwJVVXV1RvUVkcrAOiCvqiZkhJyOkxp5oi2AE1lUtUjSdmoPQxHJ4w8dJ7Pgf4+ZAzcx5VBEpKmIbBSRp0TkD2C4iJQQkUkislVEdgS2yweNmSUi9wa2O4jIDyLSL9B3nYhcfYJ9q4jIdyKyW0RmiMggEflvCnKHI2MfEZkdON80ESkV1H6HiPxPRLaJyLOpfD8NROQPEckddKyNiPwS2K4vInNF5G8R2Swib4tIvhTONUJEXgzafyIw5ncRuTtZ32tFZKGI7BKRDSLSK6j5u8DPv0XkHxFpmPTdBo2/RETiRGRn4Ocl4X436fyeS4rI8MA97BCRCUFtrUVkUeAe1ohIy8DxY8x5ItIr6fcsIpUDprZ7ROQ34JvA8bGB38POwN/IBUHjC4pI/8Dvc2fgb6ygiEwWkQeS3c8vItIm1L06KeMKImdTBigJVAI6Y38PwwP7FYF9wNupjG8ArABKAa8B74uInEDfj4H5wOlAL+COVK4Zjoy3Ah2BM4B8wOMAIlIDeCdw/rMC1ytPCFR1HrAHuDzZeT8ObB8GHgncT0PgCuC+VOQmIEPLgDwtgKpAcv/HHuBOoDhwLdBNRK4PtDUO/CyuqkVUdW6yc5cEJgMDA/c2AJgsIqcnu4fjvpsQpPU9f4iZLC8InOuNgAz1gVHAE4F7aAysT+n7CEET4HzgqsD+V9j3dAbwExBsEu0H1AUuwf6OnwQSgZHA7UmdRKQWUA77bpz0oKr+ySEf7B+1eWC7KXAQKJBK/9rAjqD9WZiJCqADsDqorRCgQJn09MUePglAoaD2/wL/DfOeQsn4XND+fcDXge2ewOigtsKB76B5Cud+EfggsF0Ue3hXSqHvw8DnQfsKnBvYHgG8GNj+AOgb1K9acN8Q530TeCOwXTnQN09Qewfgh8D2HcD8ZOPnAh3S+m7S8z0DZbEHcYkQ/d5Lkje1v7/Afq+k33PQvZ2digzFA32KYQpsH1ArRL8CwA7MrwOmSAaf6v+37PDxGUTOZquq7k/aEZFCIvJeYMq+CzNpFA82syTjj6QNVd0b2CySzr5nAduDjgFsSEngMGX8I2h7b5BMZwWfW1X3ANtSuhY2W7hBRPIDNwA/qer/AnJUC5hd/gjI8TI2m0iLY2QA/pfs/hqIyMyAaWcn0DXM8yad+3/Jjv0Pe3tOIqXv5hjS+J4rYL+zHSGGVgDWhClvKI58NyKSW0T6BsxUuzg6EykV+BQIda3A3/QY4HYRyQW0x2Y8TjpxBZGzSR7C9hhQHWigqqdx1KSRktkoI9gMlBSRQkHHKqTS/2Rk3Bx87sA1T0+ps6ouxR6wV3OseQnMVLUce0s9DXjmRGTAZlDBfAxMBCqoajHg3aDzphVy+DtmEgqmIrApDLmSk9r3vAH7nRUPMW4DcE4K59yDzR6TKBOiT/A93gq0xsxwxbBZRpIMfwH7U7nWSOA2zPS3V5OZ45zwcAXhBFMUm7b/HbBnvxDpCwbeyOOBXiKST0QaAv+KkIzjgOtE5NKAQ7k3af8PfAw8hD0gxyaTYxfwj4icB3QLU4ZPgQ4iUiOgoJLLXxR7O98fsOffGtS2FTPtnJ3CuacA1UTkVhHJIyK3ADWASWHKllyOkN+zqm7GfAODA87svCKSpEDeBzqKyBUikktEygW+H4BFQLtA/1jgxjBkOIDN8gphs7QkGRIxc90AETkrMNtoGJjtEVAIiUB/fPZwwriCcIJ5EyiIvZ39CHx9iq57G+bo3YbZ/cdgD4ZQnLCMqroEuB976G/G7NQb0xj2CeY4/UZV/wo6/jj28N4NDA3IHI4MXwXu4RtgdeBnMPcBvUVkN+Yz+TRo7F7gJWC2WPTUxcnOvQ24Dnv734Y5ba9LJne4pPU93wEcwmZRf2I+GFR1PuYEfwPYCXzL0VnN89gb/w7g3xw7IwvFKGwGtwlYGpAjmMeBX4E4YDvwKsc+00YBF2E+LecE8IVyTqZDRMYAy1U14jMYJ/siIncCnVX10mjLklXxGYQTdUSknoicEzBJtMTszhPSGuc4KREw390HDIm2LFkZVxBOZqAMFoL5DxbD301VF0ZVIifLIiJXYf6aLaRtxnJSwU1MjuM4Tkh8BuE4juOEJNsk6ytVqpRWrlw52mI4juNkKRYsWPCXqpYO1ZZtFETlypWJj4+PthiO4zhZChFJvvr+CG5ichzHcULiCsJxHMcJiSsIx3EcJyTZxgcRikOHDrFx40b279+fdmcnKhQoUIDy5cuTN2/eaIviOE4ysrWC2LhxI0WLFqVy5cqkXMfGiRaqyrZt29i4cSNVqlSJtjiO4yQjW5uY9u/fz+mnn+7KIZMiIpx++uk+w3OcTEq2VhCAK4dMjv9+HCfzku0VhOM4Trbmiy/ggw8icmpXEBFk27Zt1K5dm9q1a1OmTBnKlSt3ZP/gwYOpjo2Pj+fBBx9M8xqXXHJJRonrOE5WYutWaN8err8ehg2DxMQMv0S2dlJHm9NPP51FixYB0KtXL4oUKcLjjz9+pD0hIYE8eUL/CmJjY4mNjU3zGnPmzMkYYR3HyRqowpgx8MADsHMn9O4NTz0FuTL+fd9nEKeYDh060LVrVxo0aMCTTz7J/PnzadiwITExMVxyySWsWLECgFmzZnHdddcBplzuvvtumjZtytlnn83AgQOPnK9IkSJH+jdt2pQbb7yR8847j9tuu42kTL1TpkzhvPPOo27dujz44INHzhvM+vXrueyyy6hTpw516tQ5RvG8+uqrXHTRRdSqVYsePXoAsHr1apo3b06tWrWoU6cOa9acTJ16x8nBbN0KM2bA7NmwbBls2QKHDh1tV4V9+2DbNli+HNq0sZlDlSrw00/w/POQL19ERMs5M4iHH4bA23yGUbs2vPlmuodt3LiROXPmkDt3bnbt2sX3339Pnjx5mDFjBs888wzjx48/bszy5cuZOXMmu3fvpnr16nTr1u24tQMLFy5kyZIlnHXWWTRq1IjZs2cTGxtLly5d+O6776hSpQrt27cPKdMZZ5zB9OnTKVCgAKtWraJ9+/bEx8fz1Vdf8cUXXzBv3jwKFSrE9u3bAbjtttvo0aMHbdq0Yf/+/SRGYHrrOJkOVfjmGyhTBi64IPW+CxbA+PFQvDiUKnX0kycPxMXBjz/C3LmQ0stVkSJmNtq799jjBQrA66/bMy0FC0RGkXMURCbipptuInfu3ADs3LmTu+66i1WrViEiHAp+cwji2muvJX/+/OTPn58zzjiDLVu2UL58+WP61K9f/8ix2rVrs379eooUKcLZZ599ZJ1B+/btGTLk+CJbhw4donv37ixatIjcuXOzcuVKAGbMmEHHjh0pVKgQACVLlmT37t1s2rSJNm3aALbYzXGyNarw1VfQq5c93PPlg/794f77IXkkniq88449wBMSbD8UZcpAw4bQpQvUrWt9t22D7duPfvLkgUKFjn4KFoRmzeCccyJ+yxBhBREoH/kWkBsYpqp9Q/S5GegFKPCzqt4aOH4X8Fyg24uqOvKkhDmBN/1IUbhw4SPbzz//PM2aNePzzz9n/fr1NG3aNOSY/PnzH9nOnTs3CQkJJ9QnJd544w3OPPNMfv75ZxITE/2h7zhgD/cpU0wxxMdD5cr28J80yXwAM2fC++/bLAFgzx7o3Bk+/hiuuQY+/BDy54e//jJT0l9/wf79EBMDFSser1wyGRHzQYhIbmAQcDVQA2gvIjWS9akKPA00UtULgIcDx0sCLwANgPrACyJSIlKyRpOdO3dSrlw5AEaMGJHh569evTpr165l/fr1AIwZMyZFOcqWLUuuXLn48MMPOXz4MAAtWrRg+PDh7A1Mc7dv307RokUpX748EyZY2egDBw4caXecbMP8+XDxxXDddfZgHzYMVq6Erl1h4kTo189+xsTAvHnmH6hfHz75BF58Eb78EkqWhMKFoVIliI2Fli0t6qhSpUyvHCCyTur6wGpVXauqB4HRWDH6YDoBg1R1B4Cq/hk4fhUwXVW3B9qmAy0jKGvUePLJJ3n66aeJiYlJ1xt/uBQsWJDBgwfTsmVL6tatS9GiRSlWrNhx/e677z5GjhxJrVq1WL58+ZFZTsuWLWnVqhWxsbHUrl2bfv36AfDhhx8ycOBAatasySWXXMIff/yR4bI7TnqYPx/++98MONG2bTYLuPhi2LABhg41xXDPPZDk98uVCx57DH74wWYZl15qCuDPP2HaNHj22YhEFZ1yVDUiH+BGzKyUtH8H8HayPhOA14DZwI9Ay8Dxx4Hngvo9Dzwe4hqdgXggvmLFipqcpUuXHncsJ7J7925VVU1MTNRu3brpgAEDoizRsfjvyckIrrpKFVS/+y6Njr/9pvrkk6r9+6tOnaq6aZNqYqLq4cOqQ4aoliypmju36qOPqu7cmfaFt29XbddO9Yor7NxZDCBeU3iOR9tJnQeoCjQFygPfichF4Q5W1SHAEIDY2NgUPEHO0KFDGTlyJAcPHiQmJoYuXbpEWyTHyVASEy0oCODee+Hnny3Y5zg2boSmTWHdumOdxyVK2GftWmjcGAYNggsvDO/iJUqYWSkbEkkFsQmoELRfPnAsmI3APFU9BKwTkZWYwtiEKY3gsbMiJmk255FHHuGRRx6JthiOEzGWLbM1Y7ffbmam3r3h5ZeTdfr9d7j8cvMn/PijrSNYsgQWL7bPunXw73/DbbdlCf/AqSCSCiIOqCoiVbAHfjvg1mR9JgDtgeEiUgqoBqwF1gAvBzmmr8Sc2Y7jOMeRtK6zZ0+LDH3tNbj5ZluqBMAff5hy2LzZfAT169vxpk3tkw7GjbNJwxVXZJT0mZeIeVFUNQHoDkwFlgGfquoSEektIq0C3aYC20RkKTATeEJVt6nqdqAPpmTigN6BY47jOMcxZ46tQTv3XFueUKqU+ZQTEjDH8RVXmMN5yhRbe3ASPPggtGoFS5dmjOyZmYj6IFR1CjAl2bGeQdsKPBr4JB/7ARCZFIWO42Qr5s5VGpb9H3LjY5QsVoy36zXhpkl3MeDGOTy5tquZj6ZMgcsuO6nrbNtmkxCAG2+0NXNBy5qyHdkgDstxnJzMX4v/YMUK4ZJf37XcRNOm0fb/7qMNn/HCFzGsWqm2JiGdpqRQLF5sP594wpY9dOuW8kLp7IAriAjSrFkzpk6desyxN998k27duqU4pmnTpsTHxwNwzTXX8Pfffx/Xp1evXkfWI6TEhAkTWBo0B+7ZsyczZsxIj/iOc+pQtUVnLVtCo0bQpImZha66Cq691tYVxMUd/zQeN44fG1oAxiWPNrQopI0bkb17eHvddeQ/LT+dYheil2eMw+DXX+3nww/DCy/YQun330/9ttavN7/F00/DlVdCnTqwKXm4TibFFUQEad++PaNHjz7m2OjRo1NMmJecKVOmUDxpCX86Sa4gevfuTfPmzU/oXI4TMQ4fhrFjzZvcujWsWGE5h3LlggMHLDRp0yZ49VVzLFeoAN27w9Sp0LEj3HQTc4u0IE8eJbZP62Oij86qnI+XXs7Ft7PzHAmBPVkWL7bF0WXLwnPPQYsWJk5wHlBVC5K6+24oXdqCpW66yXwjf/1lvounnsoYeSJOSgskstqnbt26xy0AifYCrG3btmnp0qX1wIEDqqq6bt06rVChgiYmJmrXrl21bt26WqNGDe3Zs+eRMU2aNNG4uDhVVa1UqZJu3bpVVVVffPFFrVq1qjZq1EjbtWunr7/+uqqqDhkyRGNjY7VmzZp6ww036J49e3T27NlaokQJrVy5staqVUtXr16td911l44dO1ZVVWfMmKG1a9fWCy+8UDt27Kj79+8/cr2ePXtqTEyMXnjhhbps2bLj7mndunV66aWXakxMjMbExOjs2bOPtPXt21cvvPBCrVmzpj711FOqqrpq1Sq94oortGbNmhoTE6OrV68+7pzR/j05USAhQfXDD1XPO89Wt1WvrjpqlK5ffUgTEkL0/+sv1ZEjVdu0US1Y0MbkyqX6/PPatMlhjY0NfZldu1QLF1a9556MEfuSS1QbNz66v2WL6llnqZ57rq2Re/tt1Zo1TbwiRVTvvFP1nXdU4+JUA/9m+swz1h70rxNVSGWhXNQf7Bn1SUtBPPSQapMmGft56KG0vnrVa6+9VidMmKCqqq+88oo+9thjqmrKQ1U1ISFBmzRpoj///LOqhlYQ8fHxeuGFF+qePXt0586des455xxREH/99deRaz377LM6cOBAVdVjFELw/r59+7R8+fK6YsUKVVW944479I033jhyvaTxgwYN0ntC/Fft2bNH9+3bp6qqK1eu1KTvfcqUKdqwYUPds2fPMfdXv359/eyzz1RVdd++fUfag3EFkYNITFT94gvVCy6wx89FF6mOGaOakKCrVqnmyaM6bFga59izR3XSJNVFi/TQIdVChVQffDDl7nffbUpi166U++zYodq2rery5amLftppqvfff+zx776zhdc2d1CtU0f1vfdSvt7u3aZU6ta1xdvRJjUF4SamCBNsZgo2L3366afUqVOHmJgYlixZcow5KDnff/89bdq0oVChQpx22mm0atXqSNvixYu57LLLuOiii/joo49YsmRJqvKsWLGCKlWqUK1aNQDuuusuvvvuuyPtN9xwAwB169Y9kuAvmEOHDtGpUycuuugibrrppiNyh5sWPKndyWYkJlp66tWrLW/RgQNHmtautdx1h7/9waKIWre2gjhjx5pt5uabIXduPvrIwlKnTUvjWoUKmV+iVi1++cXKJaQWuXrPPZZk9dNPU+7z5ptWuiGFXJaARcnu2nX8AuvLLjM/xH33mZtkwQJL5VS0aOjzFCli6zQWLICMyM95+DCkUcH4hIl2qo1TRrSyfbdu3ZpHHnmEn376ib1791K3bl3WrVtHv379iIuLo0SJEnTo0IH9+/ef0Pk7dOjAhAkTqFWrFiNGjGDWrFknJW9SyvCU0oV7WnCHAwdg8mT46CP45RdTDDt2HOtAFoFy5UioUpV2y4YR99fZ1OUlri67Ft57z/wHQQWvVO10AN9+a/vhLGZOWiCXWmn2hg3h/PMtGes99xzfvnPn0edDahV8kyKYLgqRDOiuu+wTLrfeCoMHm+O6bVsIkT8zLA4fhg4dYPduU3CBMjMZhs8gIkyRIkVo1qwZd99995HZw65duyhcuDDFihVjy5YtfPXVV6meo3HjxkyYMIF9+/axe/duvvzyyyNtu3fvpmzZshw6dIiPkv7DgKJFi7J79+7jzlW9enXWr1/P6tWrAcvK2qRJk7Dvx9OC51ASE+3J3amTFbpp29ZKZNata+Uvn3sO3ngDRo601+IXXoDLL2fAhpuI++ts8rOfITXetBlG587HKAewN+9Vq+xhvmWLbYfDnDlQrpz5rlNCxBTDjz+GXtz29tumJBo2tD4pFUdMimBKq5BcOIjAwIFWIqJPnxM7R5Jy+O9/oV69jFcOkINmENGkffv2tGnT5oipqVatWsTExHDeeedRoUIFGjVqlOr4OnXqcMstt1CrVi3OOOMM6tWrd6StT58+NGjQgNKlS9OgQYMjSqFdu3Z06tSJgQMHMm7cuCP9CxQowPDhw7nppptISEigXr16dO3aNex7ue+++2jbti2jRo2iZcuWx6QFX7RoEbGxseTLl49rrrmGl19+mQ8//JAuXbrQs2dP8ubNy9ixYzn77LPDvp5zitm61Uw/a9bYirDNmy1NxaZN9ppauDDccIMlPbr88lRLXq5YAT3HWAnlqlUL0L9/dX7/G84KYWX86COrq/Pmm9CggemigBU0VebOtQd7WrONO+6AHj3MFNS//9Hju3fDgAFW8uHGG+2Bu2xZaCWweDGUL3+0NtDJUreuTaTeesv0bvXq4Y89fNjG/ve/Zr579tmMkek4UnJOZLVPZoxicsLDf09RJjFR9ZtvVG+5RTVvXvO0Fiqkes45qpdeqnrjjardu6t+/LHqP/+EdcqEBIv4KVFCdfNm1VWr7LS9ex/f99Ah1TPOMCdxYqLqmWeq3n572tfYtMnOGW72+rZtVUuVUg0EFaqqat++do5581RXrrTtIUNCj69dW/Xqq8O7Vrj88Yc5vtNz3oQE1TvuMFn79Dl5GfAoJicz47+nKLF7t+rrr6tWrWqPguLFLTRv8eKTPvUbb9gpR406eqx5c9WKFfW4MNavv7a+gWA3vekm1QoVTFmkxrhxNm7u3PBkmjLF+icF9/3zjymMli1tPzHR9jt2PH7soUOq+fOrPvFEeNdKD/36mVyNGtn2mjUp901IsNDZjFIOqqkrCDcxOU5OIyEBhg+H5583g/+ll1oa1LZtoWDBkz79mjXwzDMWaHT77UePd+liC8amTrVyzUl89JGZbZKONW5sVq7//c9KQKfE3LlmloqJCU+uK680E9H775s56d13beFaz0B2OBEzV4VyVK9ebb75UA7qk+XBBy2oa8wYePxx+1x0kVUmLV7c/CM7d1oE1cqV5vrp3dvcPhEnJc2R1T4pzSAS03oNcaJKYmKizyBOFYmJqpMnq9aoYa+gl1yiOmdOhl7i8GFbI3TaaaobNhzbdvCgmY9atTp67J9/bI3CvfcePfbLLybeiBGpX6thQ3vrTg/PP68qYusdzjzTZjXBvPKKXTtoeZGqqn76qR3/6af0XS+9rF1rJrPGjW0dYNLaitNOUy1f3paP9O+fsdckp66DKFCgANu2bTNbmpPpUFW2bdvmobKRZu9e+Pxzywtx7bUWND9+vNVTPsnU18kZPtwczAMG2Nt6MHnzmmN10qSjuYgmTrQ1CsEzjQsusHQWQctzjuPAAVtHkF7xO3a0R26rVjZ56tnz2PakcNnkqTkWL7bsH+efn77rpZcqVeCRR+w73LED/v7bHNI7d9o6jMWL4dHjcl9HjmxtYipfvjwbN25k69at0RbFSYECBQpQPvmTxDl5du2yJ/Fnn8FXX5mSKF3aQma6doV8+SJy2REjoGZNy0MUik6doG9fM/P07GnmpQoVjs3CnSuX7X/7bcrX+ekn03OprX8IRZUqlgPw//7Pkrsmz/4dG2uBWXPmmC5N4tdfoWrVFMqYRojTTjt110qJbK0g8ubNS5UqVaIthuOcGn7/3V7Jv/gCvvnGnqBly1rsZtu2ZtxPJSz1ZNm2zR6szz2Xctjp2WebL2DYMPNJTJ1qb8S5ktkyGje229i0ydY5JCfJT3AiE6Bu3UxBvPDC8W2FClnewOR+iMWLoVat9F8rq5OtFYTjZCtULXA/yWOZ5L1csMCepoE08ZxzjqUYbdsWLr74+KdvhPj6a1tkFvzmHYrOnc1JnFTx7bbbju+TtHbz+++hXbvj23/4wWYDZcqkX862bc1ck9LEtWFDm+EkJJg+3bvXnNSh5MzuRPQvR0RaisgKEVktIj1CtHcQka0isijwuTeo7XDQ8YmRlNNxMj0rV1poS7FiULGiJQRq1MhCf55/3pbRvvwyLFnCL+NX8VbF/mZ/OUXKASz7xhlnmJkmNVq1sgf75Ml2GzVrHt+nVi3LZRTKzPTzzzZR+te/TlzW1Kyal1xiSuGXX2x/2TLTzZGIYMrsRGwGISK5gUFAC2AjECciE1U1+WL3MaraPcQp9qlq7RDHHSdnMW2aJbTLm9cM+CVLmqIoVswM1clepd/uDEOHWphkpUqnRsSEBHN1tGmTtk7Km9d8FC+/nPJbeZ48Fn2b3FGtCvffDyVKhDYRZQRJfo05c6y4T1KKjeRJ+nICkTQx1QdWq+paABEZDbQGckCpb8fJAFTNqfzYY/Z0mjgxrCf+smX2c/JkyzB6KpgzxyJurrsuvP4PPGBZXlNyZoP5IZ5+2rJ/lC5txz780NYBDBtmejISVKgAZ51l6yy6dzf/Q4ECZrnLaURy/lkO2BC0vzFwLDltReQXERknIsEptwqISLyI/Cgi14e6gIh0DvSJ90glJ1tx4IAZ6R95xNJjz54dlnJQPZqQbvLkCMsYxKRJNjNo0SK8/mXKwCefmEkqJYL9EGAK6IknLFdTx44nJ29qiNgsIslR/euvUKNGZJLhZXaivQ7iS6CyqtYEpgMjg9oqqWoscCvwpogcp79VdYiqxqpqbOmkVwzHyer89ZfFYg4fbrGg48ZZEYEw2LrVsm+fdppF6uzZE2FZA0yebA/0lGognAh169rC7iQ/RM+edn+DB0fetXLJJVZLevNmm0HkRPMSRNbEtAkInhGUDxw7gqpuC9odBrwW1LYp8HOtiMwCYoA1kRLWcTIFq1aZ43njRsu9cPPN6RqeZF7q0gVef92iXdPrzJ0/3yJmgxGBZs1Cx+avXWuzls6d03edtMiXzx7U331ndYUGDbIQ1Tp1MvY6oUgKn5082b6LnOighsgqiDigqohUwRRDO2w2cAQRKauqmwO7rYBlgeMlgL2qekBESgGNCFIejpOlULVZwaZN8M8/ZiNJVg8BMDNS69YgwoxXF1DinBrUCbNwThJJ5qUuXeCdd8z0kx4FsX27PZQDZT6OoUEDEzG5qSXJlBWu/yE9NG4MvXqZta1kSUttfSqIibE8T0OH2n5OnUFEbKKmqglAd2Aq9uD/VFWXiEhvEUmqmfmgiCwRkZ+BB4EOgePnA/GB4zOBviGinxwn8/L997ZU9+yzzU5yxhn21LnsMvOCPvmkFbODDQkAACAASURBVExIYuxYMyuVLMmfk+Zz5cM1iI21ENB+/czUEQ7Llpk1KmlB2uTJxxZ6S4ulS005DB4MCxce/QwcCPPmwX/+c/yYyZOtlkEknLhNmpj8P/1kZTpLlMj4a4Qif34L150/3/Zz6gwi6kn2MuoTKlmf40SFP/+0THDly6vedpvqk0+qDhyoOn685ai+/nrVPHn0SI7n++8/ur11q370ke326GEJ6cASt11zjSWyS43mzVXr1bPtDz6wsQsXhi/60KE2Zu3aY48nJtr1CxU6tm33btV8+VQfeyz8a6SHfftUCxSw7+Hw4chcIyUef1yPZEHPzjk/yan1IBznlJOYaAogX77Un+abN6u++qpqtWr2b3jTTfY0VNUOHazQTlLdhOXLVZ9+2h5ULVqkfvmzzrJ6AapWjCa9dQMefdQeyMlrNqiq/vabapEipoSSHpiff27XmDkz/Guklx9+sK/rVPPZZ3Zvl1126q99KklNQUQ7islxshcffAATJtgqsNTsEmXKmJlp+XJbJT16NBQogCpMnw7Nmx+19Vevbqe75RYzeaRUM3nnTnOo1qhh+2eeabWKJ00KX/xly+x6oUI6K1QwM8+MGVZ6GuzcxYrZou5I0ajRiaXUOFmSHNU51f8A0Q9zdZzsw5o18NBDFu7zyCPhjRGxNKGBuM1ly8yXHWo9QYMGpgSCXRfBLF9uP4NTUl93nSmVP/8MT5zly+G881Ju79LF3CiPPGJ+kSlT4KqrQvvcszplypjPpXuoPA85BFcQjpMRJCRYUYO8ee31+gQD9adPt5+hFMTFF9vPefNCj02KYEqaQYApCFVLg5EW+/ZZ7H9qNQ9y5bLInn37LBp38+bIRC9lFrp3P/b7zGm4gnCcjOCVV6zKzODBZos5QaZPtwlFqFKb1aubOSd5MZskli2z6JvgDPcxMZY2Ihwz08qVpkzSKopTvbrlQVq0yCZAV1+d9rmdrImn+3ac1FC15cjbttkigW3bLNVnQoLFgyYk2PF//xtuvRXatz/hSx08CLNmwV13hW7PlQvq1099BlGt2rH+AxF70x8zxs6fWp2gpEV2qZmYknj8cStKV6wYlCqVdn8na+IKwnFCsWOHrTCLi7Mnayo8wWvMKzCHmQOrcTLpeubONV2UWj6jBg3MYb1nDxQufGzbsmXmlE7OdddZcrsffoDLL0/53MuWmUKpVi1tWfPmTb0kqJM9cAXhOMk5dMgq2syfb2lHzzwTTj/dlvKefro9mfPkgTx52Lg1P29deQ6H9gsfTYY77zzxy06fbm//zZql3Ofiiy2KacECW2WcxL59sG5d6OtfcYWZniZNSl1BLF9u5qlwy2oWKhRePyfr4grCcYLRQMGBb74xZ3MaT/x+D9sD+7zzrG7PzTefeN3iadNshlCsWMp9GjSwnz/+eKyCWLEiZf9BkSK2qHvSJBgwIOVzL1uWtv/ByVm4k9pxghkwwMJ0nnkmTeWwdSsMGWJFb/7zH/jtN8t/dCJs324VQ9NKl12qlKW0SO6HSPIfpBRxc+21lgdw9erQ7YcPm5PaFYQTjCsIx0li4kQrOHDjjdCnT5rd33oL9u+HHj1sYVuLFvDSS7ZWIb18843NAMKpp3Dxxeav0KAcS0uXmhO7atXQY5o3t58zZ4ZuX7/eSlCE46B2cg6uIJwcT2IiDOv5G+vb9bAMbWGsY9i5E95+G2644ehbd9++FuT0+uvpl2H6dEulXb9+2n0bNLD1Bxs3Hj22bBmce675GkJx3nm28CslBZE0A/EZhBOMKwgnZ/PPP3z94BQ69alI3QOzmfHYV2F5XwcPNiXxzDNHj9WpA+3awRtvhJ99FWwmMG2aOafDWZEcasFcWv4DEfNDzJoVOrtr0ipsn0E4wbiCcHImK1fCww9DuXIMGXSQ0nm2c9bZBbnq1tPp3z/1FNl795oSaNny+OI1ffpYVGzv3uGLsmaNmXjCLddZq5bNFJIWzB06FJ7/oFkzU1wrVx7ftmyZZSSPVJ1nJ2viCsLJWSxaZEt/q1eHwYPZdMWdTMrdmnseK8HchQVo08YWgd1+uymCUAwbZg7qZ589vu3cc62y2tCh5hQOh9TSa4QiXz5TTEkziDVrbL1eWikhmja1n6HMTB7B5ITCFYSTM9i9Gx591AodL1hgr/i//cb7tf/D4cNCp85CkSJWt+ell+CTTyyLaPK6zgcPmo/hssvg0ktDX+r55y3U9YEHLLR0/nybIaSkcKZNg0qVUnYwh6JBA4t6OnQofP9B1aqWdiO5glBNO0mfkzPxdRBO9kYVPv8cHnzQcmF36WJLkUuU4PBhmw20aGEV2MBs9c88A7VrW/hqUtrt2rWtFKeIOYeHDUv5kmXKmJLo0QOmTj22rUgRKF8eKla0lE0VK1oE0803p6+06MUXw5tvwq+/Hk3Sl9YDPqmu9PTp9rUkXe/PP23huM8gnOS4gnCyJ/v3W26JN9+0mpi1asG4cUc9vMDXX8OGDeZPSM4119hb/5w5Vod59mxTCvv2WaDTlVemfvmnnrK0TH/8YQ/gpM8ff5iC+e03+OUX2wcrRZ0eghfMLVtmiqZIkbTHNWsGH31kY5JMUqHShDsORFhBiEhL4C0gNzBMVfsma+8AvA5sChx6W1WHBdruAp4LHH9RVUdGUlYni6MKixebvWbaNEsUtH+/PTUHDDB7T55j/9zfe8/e9lu1Cn3KYsXMXZGUrfTQIXtjL18+vLf9ihXtkxoHDsDff5uDOD1UqmQZQObNsxlEuA/3pDQeM2ceVRDpSdLn5CwipiBEJDcwCGgBbATiRGSiqi5N1nWMqnZPNrYk8AIQCyiwIDB2R6TkdbIwa9dCx45Hs8edf76Zkq680vJRhHi13rDBJhY9eoRf7CZv3uOjlk6W/PntQZ9eRGwWMXeuzUiaNAlvXJUqZtqaNcsyioApiMKFTfE5TjCRnEHUB1ar6loAERkNtAaSK4hQXAVMV9XtgbHTgZbAJxGS1cmKqFq40KOPmqPgrbds5VoYT7oPPrDh9957CuSMEBdfbIu/IfyiNkl+iClTbIFgrlxmYqpe/YRrHDnZmEj+SZQDNgTtbwwcS05bEflFRMaJSFKllbDGikhnEYkXkfitW7dmlNxOVuD33y3BUJcu9qT89VdzRIehHBISzJ9w5ZXHFtfJaiT5ISB9/oNmzeCvv2DJEtv3EFcnJaL9zvAlUFlVawLTgXT5GVR1iKrGqmps6dKlIyKgkwkZO9Yqyc+aZVnypk1L29gfxFdfmVmmS5fIiXgqqFfvqC8kPQ/44PUQ//xj5jZXEE4oIqkgNgHBtRfLc9QZDYCqblPVA4HdYUDdcMc6OZADB8xwfvPNVtVm0SIrGpxO28h770HZslm/lnLRonDBBebgPv308MdVrmyfWbMsTTi4g9oJTSR9EHFAVRGpgj3c2wG3BncQkbKqmpS1phUQiKdgKvCyiJQI7F8JPB1BWZ3Mztq1phgWLLCMqy+9lKZ3+fffLf32rl2mWw4csMCmr76ytQ7hOqczM48+auGz6aVZM/jiC7j+etv3GYQTiogpCFVNEJHu2MM+N/CBqi4Rkd5AvKpOBB4UkVZAArAd6BAYu11E+mBKBqB3ksPayYFMmAAdOpg95YsvUo5LDSIxEW65xdYxFC1q0UL589sK53r1oGvXyIt9KujY8cTGNWsGw4fDp5+af//cczNWLid7IJpaVrIsRGxsrMbHx0dbDCcjOXzY4lD79bPVaWPHmm0kDP7zH/NZDx9uusU5lg0bzG0jYik4kkxNTs5DRBaoamyotmg7qR0nNPv2mUmpXz+47z5bFR2mcli3zvRKy5Zw112RFTOrUqGCVaZLqUyp44ArCCczsn27xaB+/rnlwRg0KOVKOMlIWtuQO7eVA01PfqOcRtKqandQOynhCsLJXPz2m6VJnT8fRo+2mg3JGD0a+ve3SUZyhg615Hf9+tlbspMySQrCZxBOSriCcDIPP/8MDRta+NG0aWZiSsbmzXD33Vaz4fzzzcma5Eb77Tc7fsUV0KnTKZY9C/Kvf0G3brbe0HFC4QrCyRzMnWt5k3LlMn9DCsmFXnrJkuaNHAnFi1ukUpMmFv3apYtFLw0d6qalcCha1EqnlioVbUmczIorCCf6zJ5tPoczz7S41AsvDNlt/XrzK9xzD9x5pymF996zXEKxsZa+u2/frJ0+w3EyE14Pwoku339v+bTLlbPcD2edlWLX3r1tgvFcIAl87txW3vOWW6wG0PbtFvDkOE7G4ArCiR7ffmsG8AoVzLNctmyKXZcvN7PSww8fn4+vWDF49dUIy+o4ORA3MTnRYeZMK9tWqZJtp6IcAF54AQoVsvUNjuOcGlxBOKee776zmUOVKqYcypRh9254+20roZmchQstWunhh8GT9jrOqcMVhHNq+ekni6+sVMnMSmecwbRp5pd+4AGLcm3bFlauPDrk+eehRAl47LHoie04ORFXEM6pY8UKy39RvDhMn87f+c7gnnvgqqvMfPR//wf//rctgahRwxzOEyZYadAnn7RhjuOcOsJK1icinwHvA1+pamLEpToBPFlfJmfDBmjUCA4cYP+MH5i6tir3328L35580nwMBQpY1y1boE8fC2FNSLDo1zVrrG6y4zgZS0Yk6xuM1XJYJSJ9RaR6hknnZGt27YK3XvqHbhf9QPPfR1Ep1wYK1arK9deb2WjePHjllaPKAUwhvP02LF1qax7eeceVg+NEg3Sl+xaRYkB74FmsZvRQ4L+qeigy4oWPzyAyH4cOQcsrDvLN9/koyTaq1sjLuTGnUbWqJYhr0wby5Yu2lI6Ts0ltBhH2OggROR24HbgDWAh8BFwK3AU0PXkxnWzFgQM81GwZ38ytzfDc99BhYlsLa3UcJ8sQloIQkc+B6sCHwL+CyoSOERF/bXeOogrjxjG426+8s603T1QZR4cvH7XiyY7jZCnCnUEMVNWZoRpSmpoAiEhL4C2s5OgwVe2bQr+2wDignqrGi0hlrD51Up2rH1U1mxSJzMYsXw733MOMOQV5kK+5rsFWXpl9o/32HcfJcoSrIGqIyEJV/RtAREoA7VV1cEoDRCQ3MAhoAWwE4kRkoqouTdavKPAQMC/ZKdaoau0w5XOizb59cP31rNxSjJsKTeb8s3Pz8fTS5Hbl4DhZlnCjmDolKQcAVd0BpJVxvz6wWlXXqupBYDTQOkS/PsCrwP4wZXEyI08/zfYVf/KvIt+Qp1B+Jk4UihaNtlCO45wM4SqI3CJHM+wHZgdpxZ+UwyKdktgYOHYEEakDVFDVySHGVxGRhSLyrYhcFuoCItJZROJFJH7r1q1h3YiTsSQmwjf9F3LXWzFUzLuZdVsKM368p9x2nOxAuCamrzGH9HuB/S6BYyeMiOQCBgAdQjRvBiqq6jYRqQtMEJELVHVXcCdVHQIMAQtzPRl5nPSxZYutVRg1IpHfNsZwWq5zufX23HS5H+rWjbZ0juNkBOEqiKcwpdAtsD8dGJbGmE1AcFXg8oFjSRQFLgRmBSYnZYCJItJKVeOBAwCqukBE1gDVAI+YyiTcey9MmQItyiyhr/Tl+pkPU7BxvWiL5ThOBhKWggik13gn8AmXOKCqiFTBFEM7bDV20jl3AkeKHYrILODxQBRTaWC7qh4WkbOBqsDadFzbiSCqVhX0nivWMWR6Tcum58rBcbId4a6DqAq8AtQAjiRFUNWzUxqjqgki0h2YigU6fqCqS0SkNxCvqhNTuWRjoLeIHAISga6quj0cWZ3Is3o1/P031J87EOrUOVrizXGcbEW4JqbhwAvAG0AzoCNhOLhVdQowJdmxnin0bRq0PR4YH6Zszilm/nz7We/ADzBqlOfLcJxsSrhRTAVV9f+w3E3/U9VewLWRE8vJzMSNXU9B9nLB8zf4CmnHycaEO4M4EIg6WhUwG20CikROLCfTsn8/cVO3EVNgO3mefDTa0jiOE0HCnUE8BBQCHgTqYkn77oqUUE7mJeHl11i4/3zqX1MK8uePtjiO40SQNBVEYFHcLar6j6puVNWOqtpWVUNUD3ayNWvWsKTvl+yjEPXaVoy2NI7jRJhwHM2HsbTeTk5GFbp3Jy5XAwDqeVSr42R7wvVBLBSRicBYYE/SQVX9LCJSOZmPzz+Hr79m/sW/UHw5nHtutAVyHCfShKsgCgDbgMuDjingCiIn8M8/8PDDULMmcfsuJDYWjmbmchwnuxLuSuqOkRbEycT06QMbNrBvxBh+vVJ46qloC+Q4zqkg3JXUw7EZwzGo6t0ZLpGTuVi/Ht58Ezp0YFHBhhw+7P4Hx8kphGtimhS0XQBoA/ye8eI4mY5evcye1KcPcQGDoisIx8kZhGtiOibthYh8AvwQEYmczMPixZZK47HHoHx54uKgbFkoVy7toY7jZH3CXSiXnKrAGRkpiJMJee45KFoUevQALAeTzx4cJ+cQloIQkd0isivpA3yJ1Yhwsihr10KpUjBrVgod5s6FL76AJ5+E00/n779h5UqoX/9USuk4TjQJ18Tk1YWzGaNGwbZt8NZb0LRpskZVmzWceSY89BAACxZYk88gHCfnEO4Moo2IFAvaLy4i10dOLCeSqMInn9j2l1/CH38k6zB1Knz3nRUCKmI5GePirCk29tTJ6ThOdAnXB/FCoAIcAKr6N1YfwsmC/PSTmYsefxwOH4YRI4IaExPh6aehShXo1OnI4bg4OOccKFnylIvrOE6UCFdBhOoXboisk8n45BPIm9f0QOPGMGyYzSoA+PRTWLTIFscFFQKKi3PzkuPkNMJVEPEiMkBEzgl8BgALIimYExkSE2H0aGjZ0mYDnTrBmjXw7beYremZZ6BmTWjf/siYP/6ADRtcQThOTiNcBfEAcBAYA4wG9gP3pzVIRFqKyAoRWS0iPVLp11ZEVERig449HRi3QkSuClNOJw2+/x42bTr6/G/bFooVg6Gv/w0NGsCWLfD225Dr6J9Gkv/BI5gcJ2cRbhTTHiDFB3woAnUkBgEtgI1AnIhMVNWlyfoVxQoSzQs6VgNoB1wAnAXMEJFqgdTjzknwySdQqBC0amX7BQvC7Y1/Y9iXZ/CfMkUo+f3nUKfOMWPi4kxfxMREQWDHcaJGuFFM00WkeNB+CRGZmsaw+sBqVV2rqgexmUfrEP36AK9is5IkWgOjVfWAqq4DVgfO55wEhw7BuHHQujUULhw4OGQInSZfzwEK8NF9PxynHMAWyF1wQdAYx3FyBOGamEoFIpcAUNUdpL2SuhywIWh/Y+DYEUSkDlBBVSend2xgfGcRiReR+K1bt6Z9Fzmc6dNt7UP79phX+sknoUsXarUsS2zMYYaOLXHUWR3o8tJLFvXaokXUxHYcJ0qEqyASReRIjUkRqUyI7K7pQURyAQOAx070HKo6RFVjVTW2dOnSJyNOjuDjj6FECbjqKuDdd+H11+G+++CLL+jUNTe//nrU35CQAN26WbaNO+6AV16JquiO40SBcBXEs8APIvKhiPwX+BZ4Oo0xm4AKQfvlA8eSKApcCMwSkfXAxcDEgKM6rbFOOtm7FyZMgBtvhHwb18ITT8CVV5pDOk8e2rUz38TQodb3hhvgvfcsFHbkyGMiXh3HySGE66T+OvDg7gwsBCYA+9IYFgdUFZEq2MO9HXBr0Dl3AqWS9kVkFvC4qsaLyD7g40A47VlYcsD54d6UczyTJsGePdD+lkTo2BHy5LEFEIHScKedBrfcYk7spJnE4ME2i3AcJ2cSbsGge7FIo/LAIuxtfy7HliA9BlVNEJHuwFQgN/CBqi4Rkd5AvKpOTGXsEhH5FFgKJAD3ewTTyfHxx3DWWdD45/9YGo0RI6BChWP6dOoEw4fDzz/D+PFwvSdTcZwcjaim7UoQkV+BesCPqlpbRM4DXlbVGyItYLjExsZqfHx8tMXIlPz9t+Xdu7/9dgaMKWce5y++OK6wtKoVj2vUyNc8OE5OQUQWqGrILGvhpsvYr6r7RQQRya+qy0WkegbK6ESQDz6Agwfh1vhHzdEwZMhxygHs0COPREFAx3EyJeEqiI2BdRATgOkisgP4X+TEcjKKnTstVLXFueuIXTLSnAxlykRbLMdxsgDhOqnbBDZ7ichMoBjwdcSkcjKM11+H7duh7652FsJ0yy3RFslxnCxCujOyquq3kRDEyXg2b4YBryfQLtdn1Km8HQZPCmlachzHCcWJ1qR2Mjuq9G69gEMHlRdjxlsJUV9M6DhOOnAFkR05cICVNzzF0LhadK0+k3Nmj7IC1I7jOOnAFUR2Y8cOuPJKnpsQS4F8iTw3qwXkzx9tqRzHyYK4gshuPP44cbMPMpabefzpfJxZxn0OjuOcGF42NDuxYQM6chQ9yi6m9AF47ITTIDqO47iCyF707894vYFvNlZn4EAoWjTaAjmOk5VxE1M2Qf/cSr9BBblFPyEmBrp0ibZEjuNkdVxBZAP27oXbLt/MEwmvcEOLf/juO0/P7TjOyeMKIouzfj00uvgwo5dcyCsX/JdPvz6NIkWiLZXjONkBVxBZmB9+gNhYWL/6EJO5lh4jzvOF0o7jZBjupM6i/PMPtGsHJYonMoVmVL20qGkLx3GcDMJnEFmUl1+GTZtg5PUTqLrtR3jmmWiL5DhONsMVRBZk1Sro1w/uvD2RS8Y/BhdfDE2aRFssx3GyGRFVECLSUkRWiMhqEekRor2riPwqIotE5AcRqRE4XllE9gWOLxKRdyMpZ1bj4YehQAF4td4481I/84xnaXUcJ8OJmA9CRHIDg4AWwEYgTkQmqurSoG4fq+q7gf6tgAFAy0DbGlWtHSn5siqTJsGUKdDv3mWU6dEB6tSBa6+NtliO42RDIjmDqA+sVtW1qnoQGA20Du6gqruCdgsDaRfIzsHs3w8PPQTnl9vJg8PrQPXqpi1yuaXQcZyMJ5JRTOWADUH7G4EGyTuJyP3Ao0A+4PKgpioishDYBTynqt+HGNsZ6AxQsWLFjJM8k9K/P6xdC9O5kbxNGsAXX0CxYtEWy3GcbErUXz1VdZCqngM8BTwXOLwZqKiqMZjy+FhETgsxdoiqxqpqbOlsXgznt/8pL/U6SFvG0bx1Yfj6a1cOjuNElEgqiE1AhaD98oFjKTEauB5AVQ+o6rbA9gJgDVAtQnJmCR6/6hdISKD/TfNg3DjzUjuO40SQSCqIOKCqiFQRkXxAO2BicAcRqRq0ey2wKnC8dMDJjYicDVQF1kZQ1kzNN2/8zNgVtegRO4NKY16DPL6+0XGcyBOxJ42qJohId2AqkBv4QFWXiEhvIF5VJwLdRaQ5cAjYAdwVGN4Y6C0ih4BEoKuqbo+UrJmZQ/8c4IEehaiS5zeenNrcw1kdxzllRPRVVFWnAFOSHesZtP1QCuPGA+MjKVtWYdBNs1h68Cq+eGEBBUpmf0e84ziZh6g7qZ2U2TJ7NS98fTEtyy7iXy/UjbY4juPkMFxBZFZU6XHjKvZRkLfGlnPLkuM4pxxXEJmUuc9PYcQfV/PoVUup1ih7h/A6jpM5cQWRCTm85S8e6FuOs/Jt5blPa0ZbHMdxciiuIDIbqnxw/UQWHK5Nvz77KXKa/4ocx4kO/vTJTKgypf2HPP5jWxpXXE+7JyqkPcZxHCdCuILIJBxOUHpeNpNrx9xJlZK7GDWrojumHceJKq4gMgF/bVWurraaPrMvp2O12cz9rRyVqvivxnGc6OJPoSgz70elzrk7+W5dBYY1HsUHyxpSsLD/WhzHiT7+JIoSixbBbbdBo0sSyb1rB3Nu6M89M2/32g6O42QaPOvbKUQVZsyA11+H6dOhSKHDPKRv8uwdGyg5YoArB8dxMhWuIE4R69dD27bw009Qpgz07QtdfnmQ4l+MhEGbXTk4jpPpcAVxCjh8GO68E1avhvffN9NS/gO7oOwIuPVWKFo02iI6juMchyuIU8Abb8D338PIkaYoABj+MezdC506RVU2x3GclHC7RoRZsgSefRauvx7uuCOoYdgwqFkT6tWLmmyO4zip4Qoighw8aEqhWDF4772gWj8LF8KCBXDvvV4AyHGcTIubmCLIiy+aLvjsMzjjjKCGoUOtpvTtt0dNNsdxnLTwGUSEiIuDl182n0ObNkENe/bARx/BjTdCiRJRk89xHCctIqogRKSliKwQkdUi0iNEe1cR+VVEFonIDyJSI6jt6cC4FSJyVSTlzGj27TPFULYsvPVWssaxY2HXLndOO46T6YmYiUlEcgODgBbARiBORCaq6tKgbh+r6ruB/q2AAUDLgKJoB1wAnAXMEJFqqno4UvJmJK+8AsuX22K44sWTNQ4dCtWrw2WXRUU2x3GccInkDKI+sFpV16rqQWA00Dq4g6ruCtotDGhguzUwWlUPqOo6YHXgfJmeLVtgwAC4+WZo3jxZ49KlMGeOO6cdx8kSRNJJXQ7YELS/EWiQvJOI3A88CuQDLg8a+2OyseVCjO0MdAaoWLFihgh9srz8MuzfD336hGgcNgzy5g1aDOE4jpN5ibqTWlUHqeo5wFPAc+kcO0RVY1U1tnTp6NdtXr8e3nkH7r4bqlVL1njgAIwaBa1bJwtpchzHyZxEUkFsAoJLopUPHEuJ0cD1Jzg2U9Crl6VU6tkzROPQobBtG3TufKrFchzHOSEiqSDigKoiUkVE8mFO54nBHUSkatDutcCqwPZEoJ2I5BeRKkBVYH4EZT1pliyBDz+EBx6A8uWTNf7+OzzzDLRoEcIx4TiOkzmJmA9CVRNEpDswFcgNfKCqS0SkNxCvqhOB7iLSHDgE7ADuCoxdIiKfAkuBBOD+zB7B9NxzUKQI9DgumBd4+GFbVj14sDunHcfJMkR0JbWqTgGmJDvWM2j7oVTGvgS8FDnpMo5582DCBOjdG04/PVnjlCm29qFPHzj33KjI5ziOcyKIqqbdKwsQGxur8fHxp/y6qnDFFbB4Maxda7OII+zdCxdcAAULWs6NIJQb/QAACqhJREFU/PlPuXyO4zipISILVDU2VJvnYjpJpk2DmTNtxfQxygFsSrF+PXz7rSsHx3GyHFEPc83KTJtmC+LOOQe6dEnW+Ouv0L8/dOwIjRtHRT7HcZyTwRXECTJ0KFxzDVSubDOIYyYIiYmmMYoXtwLUjuM4WRBXEOkkMRGeesqWM7RoAT/8ABUqJOvUty/MnQv9+oXwWjuO42QN3AeRDvbtswJA48dD167wn/9AnuTf4MCBVkKuXTtPqeE4TpbGZxDp4PbbrfhP//62pOE45TBkCDz0kBWAGDXK1zw4jpOlcQURJmvXmnJ45hl49NEQz/5Ro2xacc018MknlpTPcRwnC+MKIkyGDIHcuaFbtxCNY8ZYtNIVV5j9yUNaHcfJBriCCIMDB+CDD+Bf/4JyyZOOf/UV3HYbNGpky6kLFIiKjI7jOBmNK4gw+Pxz2LrVLEjHoAqPPWYV4iZPhsKFoyKf4zhOJPAopjB4912oUsXCWo9h+nRYtsz8D0WLRkU2x3GcSOEziDRYtswyZXTpYrUejuHNN6FMGVtO7TiOk81wBZEG771nAUkdOyZrWLHC/A/durlT2nGcbIkriFTYuxdGjoS2bUNUCR04EPLlC+GYcBzHyR64gkiFTz+Fv/8OoQN27IARIyx6yetLO46TTXEFkQrvvgvnnRciGev779v04qEU6x05juNkeSKqIESkpYisEJHVInJcMU4ReVRElorILyLyfyJSKajtsIgsCnwmJh8baRYtskpxXbokWzWdkGBJmJo2hVq1TrVYjuM4p4yIhbmKSG5gENAC2AjEichEVV0a1G0hEKuqe0WkG/AacEugbZ+q1o6UfGnx3nu25u24fHsTJsBvv5kPwnEcJxsTyRlEfWC1qq5V1YPAaKB1cAdVnamqewO7PwLlIyhP2IwebVak9u2hZMlkjW+9ZYsirrsuKrI5juOcKiKpIMoBG4L2NwaOpcQ9wFdB+wVEJF5EfhSR60MNEJHOgT7xW7duPXmJgUGD4NZboWFDeOONZI3x8VYA4sEHLTGT4zhONiZTOKlF5HYgFgguv1YpUEj7VuBNETkn+ThVHaKqsaoaW7p06RMXQBVV6NULune3nEtffw3FigX12bQJnnjCVkzfffeJX8txHCeLEEkFsQkIrrVWPnDsGESkOfAs0EpVDyQdV9VNgZ9rgVlATESk3LePw+ddQPc6c/j3v21B3PjxULDg0XZefBGqVYM5c+C11+C00yIiiuM4TmYikgoiDqgqIlVEJB/QDjgmGklEYoD3MOXwZ9DxEiKSP7BdCmgEBDu3M4yDf2zntj1DGLzoEp7gNd5f2pA8w4fCzp22EOL88+H55+Hqqy3vhi+McxwnhxCxKCZVTRCR7sBUIDfwgaouEZHeQLyqTsRMSkWAsWKxpL+paivgfOA9EUnElFjfZNFPGcZGLcf/HSjHaz3/4YlieeD9XVZwuls3OHzYQllHjLCwVsdxnByEqGq0ZcgQYmNjNT4+/oTGbt8eFK2kCnFxVgSoRg3o0MEd0o7jZFtEZEHA33scnu6bZKGsIlC/vn0cx3FyMJkiislxHMfJfLiCcBzHcULiCsJxHMcJiSsIx3EcJySuIBzHcZyQuIJwHMdxQuIKwnEcxwmJKwjHcRwnJNlmJbWIbAX+dxKnKAX8lUHiRJvsdC+Qve4nO90L+P1kZsK9l0qqGjIddrZRECeLiMSntNw8q5Gd7gWy1/1kp3sBv5/MTEbci5uYHMdxnJC4gnAcx3FC4griKEOiLUAGkp3uBbLX/WSnewG/n8zMSd+L+yAcx3GckPgMwnEcxwmJKwjHcRwnJDleQYhISxFZISKrRaRHtOVJLyLygYj8KSKLg46VFJHpIrIq8LNENGUMFxGpICIzRWSpiCwRkYcCx7Pq/RQQkfki8nPgfv4dOF5FROYF/ubGBGq2ZwlEJLeILBSRSYH9rHwv60XkVxFZJCLxgWNZ8m8NQESKi8g4EVn+/+3dW4hVVRzH8e+vpsRLaBcT0chMyQx0NDBNC1MKk4gejC4mEkIvPiQE1dANeusl80FKKMpIKiwt8aGLUwg+5LXJzMGugiPa9KCVQZL672GtieNwojPnTO7Znt8HNmevtfcc1p+zzvz3XuectSR1SprVaDxNnSAkXQisBu4EJgMPSJpcbKv67A1gQa+6J4H2iJgItOdyGZwCHouIycBMYHl+Pcoaz0lgXkRMBVqBBZJmAi8AKyNiAnAMWFZgG/vqUaCzolzmWABui4jWit8LlLWvAawCPoqIScBU0uvUWDwR0bQbMAv4uKLcBrQV3a464hgH7KsoHwBG5/3RwIGi21hnXB8Ct58P8QBDgD3ATaRft7bk+rP64EDegLH5n8w8YDOgssaS23sQuKJXXSn7GjAc+In8xaP+iqep7yCAMcChinJXriu7URFxJO8fBUYV2Zh6SBoHTAO2U+J48pBMB9ANfAr8AByPiFP5lDL1uZeAx4EzuXw55Y0FIIBPJO2W9EiuK2tfuwb4BXg9DwG+KmkoDcbT7AnivBfp0qFU32WWNAx4H1gREb9VHitbPBFxOiJaSVffM4BJBTepLpLuArojYnfRbelHcyJiOmmIebmkWysPlqyvtQDTgZcjYhrwB72Gk+qJp9kTxGHgqory2FxXdj9LGg2QH7sLbk/NJF1ESg7rImJDri5tPD0i4jjwOWkYZoSklnyoLH1uNnC3pIPAO6RhplWUMxYAIuJwfuwGNpISeFn7WhfQFRHbc/k9UsJoKJ5mTxA7gYn5mxgXA/cDmwpuU3/YBCzN+0tJY/kDniQBrwGdEfFixaGyxjNS0oi8P5j0eUonKVEsyqeVIp6IaIuIsRExjvQ++SwiFlPCWAAkDZV0Sc8+cAewj5L2tYg4ChySdF2umg/sp9F4iv5wpegNWAh8Sxobfqro9tTR/reBI8BfpKuIZaSx4XbgO2ALcFnR7awxljmkW+C9QEfeFpY4ninAlzmefcCzuX48sAP4HlgPDCq6rX2May6wucyx5HZ/lbdvet77Ze1rue2twK7c3z4ALm00Hk+1YWZmVTX7EJOZmf0LJwgzM6vKCcLMzKpygjAzs6qcIMzMrConCLMBQNLcnhlSzQYKJwgzM6vKCcKsDyQ9lNd46JC0Jk/Gd0LSyrzmQ7ukkfncVklfSNoraWPPXPySJkjakteJ2CPp2vz0wyrm81+Xf1luVhgnCLMaSboeuA+YHWkCvtPAYmAosCsibgC2As/lP3kTeCIipgBfV9SvA1ZHWifiZtIv4SHNXruCtDbJeNL8R2aFafnvU8wsmw/cCOzMF/eDSZOfnQHezee8BWyQNBwYERFbc/1aYH2e/2dMRGwEiIg/AfLz7YiIrlzuIK3zse3/D8usOicIs9oJWBsRbWdVSs/0Oq/e+WtOVuyfxu9PK5iHmMxq1w4sknQl/LN+8dWk91HPjKYPAtsi4lfgmKRbcv0SYGtE/A50SbonP8cgSUPOaRRmNfIVilmNImK/pKdJq5BdQJpBdzlpcZYZ+Vg36XMKSNMrv5ITwI/Aw7l+CbBG0vP5Oe49h2GY1cyzuZo1SNKJiBhWdDvM+puHmMzMrCrfQZiZWVW+gzAzs6qcIMzMrConCDMzq8oJwszMqnKCMDOzqv4GIS+079VPjl0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_LxatO5J-pp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f278908-d308-4376-f0e6-8870eb21500e"
      },
      "source": [
        "testloss = model.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "trainloss = model.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(trainloss[0]))\n",
        "print(\"Train Acc: \" + str(trainloss[1]))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 3s 26ms/step - loss: 1.1250 - accuracy: 0.5745\n",
            "Test Loss 1.1249611377716064\n",
            "Test Acc: 0.5745332837104797\n",
            "898/898 [==============================] - 23s 26ms/step - loss: 1.0447 - accuracy: 0.6025\n",
            "Train Loss 1.044724702835083\n",
            "Train Acc: 0.6024591326713562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swoRERVdKQ1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68e4da3c-15c7-4bbd-af54-e4ce2aeaea6a"
      },
      "source": [
        "testlosz = model.evaluate(x_val, y_val) \n",
        "print(\"Test Loss \" + str(testlosz[0]))\n",
        "print(\"Test Acc: \" + str(testlosz[1]))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 3s 25ms/step - loss: 1.1345 - accuracy: 0.5751\n",
            "Test Loss 1.1344587802886963\n",
            "Test Acc: 0.5750905275344849\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5iaZIU6pPzk",
        "outputId": "e316906e-d1cd-48a8-8ed6-186adba58c6f"
      },
      "source": [
        "from keras.models import load_model\n",
        "model_load = load_model('/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Fix_Model_resnet50AUGScracthSGD2.h5')\n",
        "\n",
        "model_load.summary()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_294 (Activation)     (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation_294[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_295 (Activation)     (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_295[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_296 (Activation)     (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation_294[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_296[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_96 (Add)                    (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_297 (Activation)     (None, 46, 46, 128)  0           add_96[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_298 (Activation)     (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_298[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_299 (Activation)     (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_299[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_97 (Add)                    (None, 46, 46, 128)  0           activation_297[0][0]             \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_300 (Activation)     (None, 46, 46, 128)  0           add_97[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_300[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_301 (Activation)     (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_301[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_302 (Activation)     (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_302[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_98 (Add)                    (None, 46, 46, 128)  0           activation_300[0][0]             \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_303 (Activation)     (None, 46, 46, 128)  0           add_98[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_303[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_304 (Activation)     (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_304[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_305 (Activation)     (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_303[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_305[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_99 (Add)                    (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_306 (Activation)     (None, 23, 23, 256)  0           add_99[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_306[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_307 (Activation)     (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_307[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_308 (Activation)     (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_308[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_100 (Add)                   (None, 23, 23, 256)  0           activation_306[0][0]             \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_309 (Activation)     (None, 23, 23, 256)  0           add_100[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_309[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_310 (Activation)     (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_310[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_311 (Activation)     (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_311[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_101 (Add)                   (None, 23, 23, 256)  0           activation_309[0][0]             \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_312 (Activation)     (None, 23, 23, 256)  0           add_101[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_312[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_313 (Activation)     (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_313[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_314 (Activation)     (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_314[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_102 (Add)                   (None, 23, 23, 256)  0           activation_312[0][0]             \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_315 (Activation)     (None, 23, 23, 256)  0           add_102[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_315[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_316 (Activation)     (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_316[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_317 (Activation)     (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_315[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_317[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_103 (Add)                   (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_318 (Activation)     (None, 12, 12, 512)  0           add_103[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_318[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_319 (Activation)     (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_319[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_320 (Activation)     (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_320[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_104 (Add)                   (None, 12, 12, 512)  0           activation_318[0][0]             \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_321 (Activation)     (None, 12, 12, 512)  0           add_104[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_321[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_322 (Activation)     (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_322[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_323 (Activation)     (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_323[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_105 (Add)                   (None, 12, 12, 512)  0           activation_321[0][0]             \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_324 (Activation)     (None, 12, 12, 512)  0           add_105[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_324[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_325 (Activation)     (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_325[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_326 (Activation)     (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_326[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_106 (Add)                   (None, 12, 12, 512)  0           activation_324[0][0]             \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_327 (Activation)     (None, 12, 12, 512)  0           add_106[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_327[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_328 (Activation)     (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_328[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_329 (Activation)     (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_329[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_107 (Add)                   (None, 12, 12, 512)  0           activation_327[0][0]             \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_330 (Activation)     (None, 12, 12, 512)  0           add_107[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_330[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_331 (Activation)     (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_331[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_332 (Activation)     (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_332[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_108 (Add)                   (None, 12, 12, 512)  0           activation_330[0][0]             \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_333 (Activation)     (None, 12, 12, 512)  0           add_108[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_333[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_334 (Activation)     (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_334[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_335 (Activation)     (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_333[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_335[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_109 (Add)                   (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_336 (Activation)     (None, 6, 6, 1024)   0           add_109[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_336[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_337 (Activation)     (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_337[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_338 (Activation)     (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_338[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_110 (Add)                   (None, 6, 6, 1024)   0           activation_336[0][0]             \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_339 (Activation)     (None, 6, 6, 1024)   0           add_110[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_339[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_340 (Activation)     (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_340[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_341 (Activation)     (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_341[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_111 (Add)                   (None, 6, 6, 1024)   0           activation_339[0][0]             \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_342 (Activation)     (None, 6, 6, 1024)   0           add_111[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_342[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_6 (Flatten)             (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypc8clklx2p8",
        "outputId": "e4539aa4-fac0-497a-b661-a9a2cb166b47"
      },
      "source": [
        "#loss,acc = model_load.evaluate(xtrain,ytrain)\n",
        "\"\"\"print(\"loss:\",loss)\n",
        "print(\"acc:\",acc)kjjkj\"\"\"\n",
        "\n",
        "\n",
        "testloss = model_load.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "\n",
        "testloss = model_load.evaluate(xtrain, ytrain) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 7s 25ms/step - loss: 1.1250 - accuracy: 0.5745\n",
            "Test Loss 1.1249611377716064\n",
            "Test Acc: 0.5745332837104797\n",
            "898/898 [==============================] - 23s 25ms/step - loss: 1.0447 - accuracy: 0.6025\n",
            "Test Loss 1.044724702835083\n",
            "Test Acc: 0.6024591326713562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7mSww_U2O_q",
        "outputId": "11465a02-dbab-4ce6-f728-aaddad4ac8b5"
      },
      "source": [
        "testlosz = model_load.evaluate(xtrain, ytrain) \n",
        "print(\"Test Loss \" + str(testlosz[0]))\n",
        "print(\"Test Acc: \" + str(testlosz[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1010/1010 [==============================] - 26s 26ms/step - loss: 0.9853 - accuracy: 0.6306\n",
            "Test Loss 0.9853226542472839\n",
            "Test Acc: 0.6306272745132446\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdU7uU3PYCnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06d70af4-10f5-47c0-e492-5823d7ed040a"
      },
      "source": [
        "print (x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (xtrain.shape)\n",
        "print (ytrain.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3589, 48, 48, 1)\n",
            "(3589,)\n",
            "(3589, 48, 48, 1)\n",
            "(3589,)\n",
            "(28709, 48, 48, 1)\n",
            "(28709,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J11OOgMKYHJV"
      },
      "source": [
        "dfsfsd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvXSq92Spf6f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqXhenHGpggc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}